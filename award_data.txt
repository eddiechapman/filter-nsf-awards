Society today critically depends on Internet services. The safety and performance of these Internet services in turn depends on the ability of individual networks to successfully; manage and optimize their network configurations in reaction to a changing operating environment (e.g., sudden increases in traffic or attacks or changes in policy compliance requirements). Today, network operators often resort to ad hoc and brittle solutions that affect the safety and performance of the networks. The goal of this project is combine theory and practice to develop foundational mechanisms enabling network administrators to implement diverse network operations tasks. This project will develop abstractions for expressing a broad spectrum of network optimization tasks and algorithmic foundations to reason about and achieve optimal (or near-­optimal) solutions that will be better than current state-of-the-art. ;The project will develop and release open­-source toolkits that will dramatically reduce the time to prototype and deploy novel network management applications, and democratize these benefits for a larger audience. The project will lead to educational advances that help create a well­-rounded workforce capable of handling future technology challenges by applying transformational research that couples theory and practice. The project will actively encourage participation from underrepresented groups as part of the proposed work and mentor them to be future technology leaders.<br><br>Software-­defined networking (SDN) is an emerging paradigm to simplify network management by moving policies embedded in the configurations of the network hardware to software running in centralized controllers. Realizing the potential benefits of SDN, however, currently requires significant theoretical and practical effort. Specifically, at the core of many SDN applications are complex optimization problems to tackle goals and requirements that arise in practice. These problems are ones for which good theoretical solutions are unknown.The goal of this project is to design and implement a novel framework that enables SDN application developers to express new application goals and constraints in a high-­level language, using a sound algorithmic approach to generate near­-optimal solutions, and then to generate compliant configurations that can be deployed to SDN control platforms directly. There are two requirements for this vision to be successful in practice: (i) the ability to express the requirements of a broad spectrum of applications and (ii)­­ generating provably optimal (or close ­to ­optimal) configurations, on a timescale that is responsive to application needs. The proposed research will investigate theoretical foundations and practical implementations to simultaneously achieve both goals. The project's contributions will include: (1) investigating the robustness of path-­based optimizations for a wide spectrum of SDN applications and developing algorithms for ensuring that such path­-based reformulations do not sacrifice efficiency; (2) designing richer abstractions for applications that require more dynamic network processing features and developing near­-optimal and practical algorithms for these applications; (3) designing efficient optimization-­preserving translations of solutions from such theoretical frameworks into practical network configurations; and (4) implementing these techniques in an end­-to-­end open-­source tool integrated with state­-of­-the-­art network management platforms.
A number of phenomena of societal importance, such as the spread of diseases and<br>contagion processes, can be modeled by stochastic processes on networks. The analysis <br>and control of such network phenomena involve, at their heart, fundamental graph-theoretic problems. <br>The graphs encountered are typically of large-scale (having tens of millions of nodes); <br>further, typical experimental analyses involve large designs with a number of parameters, <br>leading to hundreds of thousands of graph computations. Novel methods for solving these problems<br>are needed, since fast response times are critical to effective decision making.<br>The overarching goal of this project is to develop efficient distributed algorithms <br>and associated lower bounds for graph-theoretic problems that arise in computational <br>epidemiology and contagion dynamics. This will have a significant impact on these specific <br>applications, through more efficient algorithmic tools for enabling complex analyses. <br>The project will also make fundamental contributions to the design and analysis of <br>distributed algorithms for graph problems in large-scale networks, and will<br>result in an algorithmic toolkit with building blocks for performing large-scale <br>distributed graph computation. The project will lead to significant curriculum development <br>for undergraduate as well as graduate students, as well as public health analysts. <br>Finally, the project will help in involving minority and underrepresented students in research. <br><br>The technical focus of the project will be on distributed algorithms for fundamental topics <br>in graph algorithms such as graph connectivity, distances, subgraph analysis, and different<br>kinds of centrality measures. These topics underlie some of the recurring problems in the <br>modeling, simulation and analysis and control of different kinds of contagion processes. <br>For all these problems, the project will focus on developing provably efficient distributed <br>algorithms and showing lower bounds under a message-passing distributed computing model. <br>The PIs will also develop efficient implementations of these algorithms, and evaluate their <br>performance and solution quality in real-world graphs arising in epidemiology. The graphs <br>that arise in these applications have several novel characteristics, which will present new <br>challenges as well as opportunities for distributed computing.
The goal of this project is to investigate the question of provenance in federated distributed systems, such as networks and scientific workflows, where several self-interested entities generate and share data, and compute and make decisions on the shared data.  Computations and decisions give rise themselves to new shared data.  Provenance analysis allows us to understand the contributions of the various entities to the data.  This project seeks to put provenance on a sound mathematical foundation by unifying the theoretical notion of semiring provenance with practical approaches to network provenance.  The PIs would also like to design new algorithms and compression techniques for collecting and managing provenance data.  A second thrust of the project is to compute and associate reliability scores to each data item, in conjunction with their provenance.  In order to do this, the PIs will design techniques for assigning reliability scores to primitive data items, as well as a calculus based on sound axiomatic principles for assigning reliability scores to derived data items.  This project will achieve broad impact by allowing for networks to operate more reliably and by enhancing reproducibility in scientific workflows.
A conference titled "Drawing Causal Inference from Big Data" will be held March 26 and 27, 2015, in the National Academy of Sciences auditorium in Washington DC. The purpose of this conference is to present state-of-the-art approaches to the problem, and to bring together leading experts, both the featured speakers and other experts, who will generate progress through their interactions. In many respects the subject of this conference is in its infancy because the many methods that have been developed and used for causal inference in small data do not scale up, because Big Data is often collected in the field in uncontrolled fashion, and because of the sheer size of the data that, contrary to popular belief, make it more rather than less difficult to identify causal effects. The problems in dealing with Big Data are in good part rooted in the limitations of human cognition, so ongoing efforts are aimed at the development of computational algorithms. However it is likely that computational techniques are best viewed as augmenting rather than replacing human insight: Current algorithms can find complex patterns and associations but most are not aimed to discover causal explanations. The conference also addresses the appropriate way to define causality in large data collected from chaotic and noisy systems, and the way to find causes that lie outside the measured variables. For example a correlation observed in a health survey based on genetic mapping might be due to an unmeasured environmental factor such as poverty. <br><br>The subject of the conference is of vital and current interest to every field of study, business, and government agencies. Our society has developed methods of collecting and storing enormous amounts of data, and is increasingly doing so. The data can arrive from controlled experiments, but most often comes from relatively uncontrolled field observations, such as those from social networks, human medical and genetic measurements, and patterns of purchases. The amount of data has far outstripped our ability to discern what important patterns are in the data, and most important, what explains those patterns. In a typical large database there are huge number of variables that can be measured, and virtually uncountable numbers of correlations between different subgroups of those variables. There are enormous potential benefits to science, business, government, and society if the critical patterns in Big Data can not only be ascertained but explained. Explanation is the goal of this conference, represented by the phrase, "drawing causal inference." The most pressing questions we face are causal in nature. In health we might observe that a particular treatment is associated with a decrease of cancer deaths, but need to know if the treatment is the cause of the decrease. In education we might observe that students held back in early grades tend to drop out of high school, but need to know if the treatment causes that result.
Statistical models provide a powerful means of quantifying uncertainty, modeling prior beliefs, and describing complex dependencies in data.  The process of using a model to answer specific questions, such as inferring the state of several random variables given evidence observed about others, is called probabilistic inference.  Probabilistic graphical models, a type of statistical model, are often used in diverse applications such as medical diagnosis, understanding protein and gene regulatory networks, computer vision, and language understanding.  On account of the central role played by probabilistic graphical models in a wide range of automated reasoning applications, designing efficient algorithms for probabilistic inference is a fundamental problem in artificial intelligence and machine learning.<br> <br>Probabilistic inference in many of these applications corresponds to a complex combinatorial optimization problem that at first glance appears to be extremely difficult to solve.  However, practitioners have made significant strides in designing heuristic algorithms to perform real-world inference accurately and efficiently.  This project focuses on bridging the gap between theory and practice for probabilistic inference problems in large-scale machine learning systems.  The PIs will identify structural properties and methods of analysis that differentiate real-world instances from worst-case instances used to show NP-hardness, and will design efficient algorithms with provable guarantees that would apply to most real-world instances.  The project will also study why heuristics like linear programming and other convex relaxations are so successful on real-world instances.  The efficient algorithms for probabilistic inference developed as part of this project have the potential to be transformative in machine learning, statistics, and more applied areas like computer vision, social networks and computational biology.  To help disseminate the research and foster new collaborations, a series of workshops will be organized bringing together the theoretical computer science and machine learning communities.  Additionally, undergraduate curricula will be developed that use machine learning to introduce students to concepts in theoretical computer science.
Software-Defined Networking (SDN) is changing the way networks are designed and managed, by separating the "control plane" (which decides how to handle the traffic) from the "data plane" (which actually forwards each packet).  Many large companies---like Google, Microsoft, and Facebook---have already deployed SDN technology, and many equipment vendors support open interfaces for programming their switches.  While most work on SDN focuses on how to control the network, measuring the traffic in the network is equally important.  Traffic measurement is useful to identify congested links, denial-of-service attacks, performance problems, and configuration mistakes, and also drives decisions of how the network should forward traffic in the future.  However, the support for traffic measurement in today's commodity switches is quite primitive.  In this proposal, the PIs bring algorithmic research on so-called "compact data structures" to bear on the problem of programmable traffic measurement in SDNs.  Compact data structures can give approximate answers to measurement questions with limited overhead in terms of switch memory and processing resources.  <br><br>The project is interdisciplinary, bringing together researchers in computer networking and theoretical computer science to match practical problems with novel solutions.  The proposed research starts with designing new query abstractions for collecting traffic statistics on existing SDN switches, and then progresses to identifying new compact data structures so that future switches can support much richer traffic measurement at reasonable overhead.  The researchers have close ties with network administrators and switch vendors, allowing them to ground the project in a strong understanding of both operational requirements and hardware constraints, and also influence future SDN technology.<br><br>This project aims to identify a switch data-plane architecture for collecting diverse traffic statistics, as well as a small set of programmable sketches and samples for variety of analyses to trade-off accuracy and resources.  The architecture will include a measurement control API between the controller and the switch, and this needs a communication-efficient interface, along with a high-level language for specifying traffic queries, and with that, a run-time system on the controller that compiles these queries into commands to the switches with suitable CDSs.  These challenges will be addressed using OpenFlow API that is widely popular for SDNs and in new redesigns.  This is a conversation between the networking and algorithmic communities, mutually informing each other on what is possible, what is required, and ultimately what is effective and useful.
Mobile computing technologies are rapidly evolving and phone (and other mobile device) manufacturers are under constant pressure to offer new product models. Each manufacturer customizes operating system software for its devices and often changes this software to support its new models. Given the many manufacturers in the mobile device marketplace and the many different generations of products, there are many customized branches of mobile operating systems in use at any time. Unfortunately, high-impact, security-critical flaws have been introduced through the combination of the operating system customization process and the design of mobile applications. This project is the first to systematically study and mitigate such security hazards. The researchers are collaborating closely with device manufacturers to transfer the results of the project into practice. <br><br>More specifically, the project involves an in-depth study of the security risks and pitfalls that lead to fragmentation-related vulnerabilities. The researchers are developing novel technologies to detect such flaws in existing systems and avoid them when building new ones. The project includes the development of automatic analysis techniques that scan a large number of factory images to identify inconsistencies in the protection of a system capability on different operating system (OS) layers (e.g., Android framework layer, Linux layer, etc.), and across a customized version and its official counterpart. This consistency check helps elevate the security qualities of customized systems to that of Android official systems. Furthermore, to mitigate the security risk introduced by the services or apps designed for cross-version, cross-device compatibility, the research team is studying techniques for automatically analyzing a variety of services on new OS releases, enhancing the mechanism for capturing exploits on them, and eliminating new security hazards like hanging capabilities.
Social networking and sensor-rich devices such as smartphones are becoming increasingly pervasive in today's society. People can share information concerning their location, activity, fitness, and health with their friends and family while benefiting from applications that leverage such information. Yet, users already find managing their privacy to be challenging, and the complexity involved in doing so is bound to increase. Usable techniques are required to enable people to effectively manage the dissemination of their private information as sensed by their mobile devices and sensors in their environment. <br><br>This project explores `sensible' privacy controls and feedback mechanisms that allow people (or automated mechanisms acting on their behalf) to respond to unanticipated patterns and actual uses of their information in a way that is usable and intuitive. This approach has two advantages: 1) people need only care about the subset of data and usage scenarios that have the potential to violate their privacy, thus reducing the amount of data to which they must regulate access; and 2) people make better decisions concerning such access when these decisions are made in a context where they know how their data is being used. <br><br>Sensible privacy mechanisms can have a profound and positive societal impact by not only helping people control their privacy, but also potentially increasing their participation in sensor-enabled computing because of this added control. This project firmly integrates education into the research through research experiences for underrepresented groups and the development of course modules on privacy at the undergraduate and graduate levels. <br><br>
The miniaturization of technology has produced not only programmable microprocessor circuits, but also programmable lab-on-a-chip (PLoC) systems for microfluidics.  These systems control tiny fluid droplets, allowing precise mixing and testing, that can be developed into environmental monitors, malaria diagnostics, or blood tests for cancer cells.  As with microprocessors, programming a lab on a chip takes knowledge of what the chip can and cannot do, and a suitable language in which to express the commands.  This project 1) develops a theory of computational complexity for designing microfluidic devices that produce fluid mixtures with desired concentrations, 2) creates a domain-specific language  (including an Application Program Interface, or API and a compiler) for these devices, 3) fabricates and tests devices, and 4) explores the broader impacts of the ability to program complex biochemical reactions that include fluid concentration steps. The project results will make PLoC systems much easier to use, which the PIs will first demonstrate with students, including those from underrepresented groups, and then through tutorials presented at scientific meetings to promote the use of PLoC technologies among the broader scientific community. <br><br>This project investigates the complexity and approximability of algorithms to generate one or more discrete fluid droplets having a desired concentration, e.g., a sample diluted to 10%, 15%, etc., with objectives such as minimizing the number of dilution steps, minimizing waste, minimizing reactant usage, etc. These algorithms will be generalized to produce of a stream of droplets having desired time-dependent concentrations. Meanwhile, a collection of representative PLoCs will be designed and fabricated on-site, along with a domain-specific language and compiler, which will allow the PLoCs to be programmed using high-level software. The algorithms developed in the course of this project will be integrated into an API that can be called from the domain-specific language. This will enable users to specify biochemical reactions that include fluid concentration generation subroutines (which are performed automatically). The system will be validated by executing these biochemical reactions using the PLoCs that have been fabricated on-site. Upon successful completion of the project, PLoC design files along with the domain-specific language specification and compiler, documentation, and tutorial material, will be released publicly to encourage other scientists to use this platform and approach to increase productivity and reduce human error in their respective laboratories.
Every year the 19,000 students who graduate from medical schools in the U.S. are  matched with the hospitals where they will do their residency training. Both students and hospitals rank their choices, and an algorithm is used to find a matching that gives each student their best available choice. These problems also arise in other contexts: matching organ donors to recipients whose bodies will not reject the transplanted organ, matching advertisements to web surfers based on their interests, etc. Variations of matching problems, and related edge cover problems, are formalized in computer science on combinatorial objects called graphs, and involve beautiful mathematics, sophisticated algorithms, efficient implementations of these algorithms on modern desk-top computers and supercomputers, and empirical evaluation on a number of problems that arise in application areas such as computational science and engineering, data science, network science, etc.  In this project, the two PIs will develop new algorithms and software for matching and edge cover problems, and make implementations available for practitioners in various fields of science, engineering and industry. The PIs will also train two PhD students in this project, and develop teaching resources to make these developments accessible to undergraduate and graduate students in computer science. <br><br>The problem of computing a matching that maximizes some objective function has been actively investigated for decades, driven by many high-profile industrial and medical applications.  This project focuses on the design, theoretical analysis, and implementation of matching algorithms that meet the needs of modern applications, and considers generalized matching problems such as b-matching, b-edge cover, and metric matching.  Classical serial algorithms that compute exactly optimum matchings are not always suited to massive graph data sets, which can contain billions of edges.  Fortunately, in many applications it suffices to have nearly optimum matchings rather than exactly optimum ones.  One goal of this project is to design simple and efficient matching algorithms that are both highly parallel, and produce provably good approximate solutions.<br><br>This project will examine several open problems on the approximability of generalized weighted matching problems, particularly on which matching-type problems admit linear time algorithms with approximation factor arbitrarily close to one.  To that end, the PIs will study how relaxing standard linear programming formulations of generalized weighted matching problems allows for more efficient algorithms. These and other algorithms will be modified to make them efficient on modern processors that support parallel computing. <br><br>Two PhD students will be trained in this project. Generalized graph matching algorithms are now applied in numerical linear algebra software, for preconditioning, graph clustering, anonymizing data, and network alignment.  The PIs will evaluate the performance of new and existing algorithms on these applications.  The PIs will make freely available all code of matching algorithms developed under this project.<br><br>Basic matching algorithms from the mid-20th century are firmly established in the canon of computer science education, but few modern matching algorithms are taught at the undergraduate level.  The PIs will incorporate modules on modern matching and applications into their courses at Purdue University and the University of Michigan, and make these materials publicly available.
Every year the 19,000 students who graduate from medical schools in the U.S. are  matched with the hospitals where they will do their residency training. Both students and hospitals rank their choices, and an algorithm is used to find a matching that gives each student their best available choice. These problems also arise in other contexts: matching organ donors to recipients whose bodies will not reject the transplanted organ, matching advertisements to web surfers based on their interests, etc. Variations of matching problems, and related edge cover problems, are formalized in computer science on combinatorial objects called graphs, and involve beautiful mathematics, sophisticated algorithms, efficient implementations of these algorithms on modern desk-top computers and supercomputers, and empirical evaluation on a number of problems that arise in application areas such as computational science and engineering, data science, network science, etc.  In this project, the two PIs will develop new algorithms and software for matching and edge cover problems, and make implementations available for practitioners in various fields of science, engineering and industry. The PIs will also train two PhD students in this project, and develop teaching resources to make these developments accessible to undergraduate and graduate students in computer science. <br><br>The problem of computing a matching that maximizes some objective function has been actively investigated for decades, driven by many high-profile industrial and medical applications.  This project focuses on the design, theoretical analysis, and implementation of matching algorithms that meet the needs of modern applications, and considers generalized matching problems such as b-matching, b-edge cover, and metric matching.  Classical serial algorithms that compute exactly optimum matchings are not always suited to massive graph data sets, which can contain billions of edges.  Fortunately, in many applications it suffices to have nearly optimum matchings rather than exactly optimum ones.  One goal of this project is to design simple and efficient matching algorithms that are both highly parallel, and produce provably good approximate solutions.<br><br>This project will examine several open problems on the approximability of generalized weighted matching problems, particularly on which matching-type problems admit linear time algorithms with approximation factor arbitrarily close to one.  To that end, the PIs will study how relaxing standard linear programming formulations of generalized weighted matching problems allows for more efficient algorithms. These and other algorithms will be modified to make them efficient on modern processors that support parallel computing. <br><br>Two PhD students will be trained in this project. Generalized graph matching algorithms are now applied in numerical linear algebra software, for preconditioning, graph clustering, anonymizing data, and network alignment.  The PIs will evaluate the performance of new and existing algorithms on these applications.  The PIs will make freely available all code of matching algorithms developed under this project.<br><br>Basic matching algorithms from the mid-20th century are firmly established in the canon of computer science education, but few modern matching algorithms are taught at the undergraduate level.  The PIs will incorporate modules on modern matching and applications into their courses at Purdue University and the University of Michigan, and make these materials publicly available.
This project engages experts in systems and network algorithms from Carnegie Mellon University and Harvard University to improve hashing-based data structures for systems.  Hashing is an approach that turns a variable length string into a small, fixed-length value.  Hashing  provides a short, consistent fingerprint used to identify larger pieces of data, for uses including storing and locating data items quickly and effectively.  Hashing provides a key building block for sophisticated approaches to storing, measuring, and managing data. Hashing-based data structures have correspondingly become widely accepted, often key workhorses throughout systems and networking.<br><br>This project will create synergies between theory and systems in the area of hashing, with various approaches for lasting broader impact. Prototype code will be released for new algorithms and data structures created in the course of the project.  Curricular materials focused on project material will be developed and distributed.  The project will offer a wide range of research opportunities at various levels of sophistication for graduate and undergraduate students at both universities.<br><br>The team unites expertise with theoretical design and analysis with expertise in systems design and analysis, allowing ideas and insights to flow between the two sides.  The work starts from the lowest level of what choice of what hash functions to use, through the design and analysis of general data structures, to the development of applications that utilize hashing-based data structures to provide top performance.  Project goals include both improving existing structures such as Bloom filters and cuckoo hash tables in practical systems to developing new structures for related problems such as maintaining small structures for fast function evaluation on key sets and reconciliation of datasets.
Deep neural networks (DNNs) have emerged as a class of powerful techniques for learning solutions in a number of challenging problem domains, including computer vision, natural language processing and bioinformatics.  These solutions have been enabled mainly because we now have computational accelerators able to sift though the myriad of data required to train a neural network.   As the size of DNN models continues to grow, computational and memory resource requirements for training will also grow, limiting deployment of deep learning in many practical applications. <br><br>      Leveraging the theory of structured matrices, this project will develop a general framework for efficient DNN training and inference, providing a significant reduction in algorithmic complexity measures in terms of both computation and storage.  <br>The project, if successful, should fundamentally impact a broad class of deep learning applications.  It will explore accelerating this new structure for deep learning algorithms targeting emerging accelerator architectures, and will evaluate the benefits of these advances across a number of application domains, including big data analytics, cognitive systems, unmanned vehicles and aerial systems, and wearable devices.  The interdisciplinary nature of this project bridges the areas of matrix theory, machine learning, and computer architecture, and will affect education at both Northeastern and CCNY, including the involvement of underrepresented and undergraduate students in the rich array of research tasks.<br><br>     The project will: (1) for the first time, develop a general theoretical framework for structured matrix-based DNN models and perform detailed analysis and investigation of error bounds, convergence, fast training algorithms, etc.; (2) develop low-space-cost and high-speed inference and training schemes for the fully connected layers of DNNs; (3) impose a weight tensor with structure and enable low computational and space cost convolutional layers; (4) develop high-performance and energy-efficient implementations of deep learning systems on high-performance parallel platforms, low-power embedded platforms, as well as emerging computing paradigms and devices; (5) perform a comprehensive evaluation of the proposed approaches on different performance metrics in a variety of platforms.  The project will deliver tuned implementations targeting a range of computational platforms, including ASICs, FPGAs, GPUs and cloud servers. The hardware optimizations will focus on producing high-speed and low-cost implementations of deep learning systems.
As computer technology becomes increasingly pervasive in all aspects of our lives, it becomes critical for the researchers who develop algorithms to work closely with the domain experts who have a deep understanding of the underlying systems.  The purpose of the NSF Algorithms in the Field (AitF) program is to fund collaborations between theoretical computer scientists with other computing researchers.  Via this meeting, the program is providing an opportunity for its principal investigators to share and discuss their latest advances, demonstrate technical accomplishments, and inform NSF on promising future research directions.  The technical program agenda will highlight the contributions of the participating NSF divisions and address the research themes of the AitF program.  Student researchers will also attend and present their work.  This provides a valuable training opportunity and will contribute to the foundation for an enduring AitF research community.
The growing ubiquity of smartphones, combined with the rapid improvement of operating system support for direct wireless communication between nearby devices, creates a compelling opportunity for the emergence of easy to deploy and widely used smartphone peer-to-peer applications. There are several use cases for such applications. For example, in many user environments, cellular data minutes are bought in small blocks and carefully conserved by users, generating an interest in networking operations that can avoid infrastructure.  In addition, smartphone peer-to-peer networks can bring connectivity to settings such as disaster zones, festivals, or wilderness where traditional cellular and WiFi coverage is compromised, overwhelmed, or non-existent. This project aims to develop network algorithms and tools that simplify the design of useful distributed systems on top of local peer-to-peer connections. The project has the potential for significant societal impact by enabling compelling new applications for smartphone peer-to-peer networks. The project is also expected to have significant educational impact.<br> <br>The project focuses on designing and analyzing provably correct and efficient network computation algorithms that can run on top of existing smartphone peer-to-peer services, and simplify the design of peer-to-peer systems that can be deployed on existing smartphone hardware. The project consists of two major research directions. The first research direction is experimental in nature. It will study and evaluate peer-to-peer services available in commodity smartphone operating systems and define a small number of validated abstractions that capture their capabilities and behavior. The second research direction is theoretical in nature. It will describe and analyze solutions to well-motivated network computation primitives using these abstractions. The problems studied will include consensus, leader election, rumor spreading, gossip and function computation. The project will seek both provably correct and efficient algorithms as well as lower bounds that establish fundamental limits for useful computation in this setting.
Vast amounts of digitized images and videos are now commonly available, and the advent of search engines has further facilitated their access. This has created an exceptional opportunity for the application of machine learning techniques to model human visual perception. However, the data often does not conform to the core assumption of machine learning that training and test images are drawn from exactly the same distribution, or "domain." In practice, the training and test distributions are often somewhat dissimilar, and distributions may even drift with time. For example, a "dog" detector trained on Flickr may be tested on images from a wearable camera, where dogs are seen in different viewpoints and lighting conditions. The problem of compensating for these changes--the domain adaptation problem--must therefore be addressed both in theory and in practice for algorithms to be effective. This problem is not just a second-order effect and its solution does not constitute a small increase in performance.  Ignoring it can lead to dramatically poor results for algorithms "in the field."<br><br>This project will develop a core suite of theory and algorithms for PErceptual Adaptive Representation Learning (PEARL), which, when given a new task domain, and previous experience with related tasks and domains, will provide a learning architecture likely to achieve optimal generalization on the new task. We expect PEARL to have a significant impact on the research community by providing a much-needed theoretical and computational framework that takes steps toward unifying the subfields of domain adaptation theory and domain adaptation practice. Our theoretical and practical advancements will impact many application areas by allowing the use of pre-trained perceptual models (visual and otherwise) in new situations and across space and time. For example, in mobile technology and robotics, PEARL will help personal assistants and robots better adapt their perceptual interfaces to individual users and particular situated environments.  At the core of this project are three main research thrusts: 1) making theoretical advances for domain adaptation by developing generalized discrepancy distance minimization; 2) using the theoretical guarantees of generalized discrepancy distance to develop algorithms for key adaptation scenarios of deep perceptual representation learning, domain adaptation with active learning, and time-dependent adaptation; 3) advancing the theory and developing algorithms for the multiple-source adaptation scenario. In addition to our core aims, we plan to implement our algorithms within a scalable open-source framework, and evaluate our algorithms on large-scale visual data sets.
Vast amounts of digitized images and videos are now commonly available, and the advent of search engines has further facilitated their access. This has created an exceptional opportunity for the application of machine learning techniques to model human visual perception. However, the data often does not conform to the core assumption of machine learning that training and test images are drawn from exactly the same distribution, or "domain." In practice, the training and test distributions are often somewhat dissimilar, and distributions may even drift with time. For example, a "dog" detector trained on Flickr may be tested on images from a wearable camera, where dogs are seen in different viewpoints and lighting conditions. The problem of compensating for these changes--the domain adaptation problem--must therefore be addressed both in theory and in practice for algorithms to be effective. This problem is not just a second-order effect and its solution does not constitute a small increase in performance.  Ignoring it can lead to dramatically poor results for algorithms "in the field."<br><br>This project will develop a core suite of theory and algorithms for PErceptual Adaptive Representation Learning (PEARL), which, when given a new task domain, and previous experience with related tasks and domains, will provide a learning architecture likely to achieve optimal generalization on the new task. We expect PEARL to have a significant impact on the research community by providing a much-needed theoretical and computational framework that takes steps toward unifying the subfields of domain adaptation theory and domain adaptation practice. Our theoretical and practical advancements will impact many application areas by allowing the use of pre-trained perceptual models (visual and otherwise) in new situations and across space and time. For example, in mobile technology and robotics, PEARL will help personal assistants and robots better adapt their perceptual interfaces to individual users and particular situated environments.  At the core of this project are three main research thrusts: 1) making theoretical advances for domain adaptation by developing generalized discrepancy distance minimization; 2) using the theoretical guarantees of generalized discrepancy distance to develop algorithms for key adaptation scenarios of deep perceptual representation learning, domain adaptation with active learning, and time-dependent adaptation; 3) advancing the theory and developing algorithms for the multiple-source adaptation scenario. In addition to our core aims, we plan to implement our algorithms within a scalable open-source framework, and evaluate our algorithms on large-scale visual data sets.
Computer networks play an essential role in the day-to-day operations of businesses, organizations, and governments: they facilitate access to services and information as well as help protect against some types of cyberattacks.  Unfortunately, current networks require highly-skilled network operators to provide detailed specifications of how the network should behave.  This is a tedious and error prone process that limits how easily a network can evolve to meet emerging business needs and opens the door for subtle errors that can have a drastic impact on network availability, performance, and security.  The goal of this project is to automatically produce the detailed specifications required by networking hardware from a set of high-level security and performance objectives specified by individuals who may have limited networking background.  In other words, this project aims to allow administrators to focus on what the network should do rather than how it should be achieved.  The broader impact of this project is to pave the way for increased network stability and security, and also to aid in training the next generation of network professionals.<br><br>Automatically producing network configurations that satisfy a set of high-level policies and objectives (collectively referred to as "intent") requires both a language for network administrators to formally specify their intents and a mechanism for generating optimal and correct configurations for various types of networking hardware.  To satisfy these requirements, the PIs plan to explore how program synthesis techniques can be applied and extended to network configurations.  The project will lead to the design of synthesis techniques for generating specific types of intent implementations (e.g., traditional control plane configurations), as well as introduce domain-specific refinements to the chosen synthesis algorithms to ensure the time required for synthesis is practical and the resulting data and control planes are optimal (e.g., the configurations have minimal complexity).  The algorithms produced by this research will advance the state of the art of program synthesis and provide new insights into how to apply program synthesis to other domains.
Medical image segmentation, the process of dividing a medical image into meaningful objects such as organs, tumors, etc., is a critical tool that allows medical professionals to provide customized medical care to patients.  In the past this highly technical, individualized care has required experts to manually analyze the images, a process that is very expensive in both time and money.  Over the past decade, enormous technological advances have been made in biomedical imaging, leading to a large amount of new and improved medical data which has created a demand for algorithms which can process this data faster and more thoroughly.  Researchers have worked extensively to develop these medical image segmentation algorithms, but current algorithms suffer from the following drawbacks: 1) they do not have the capability of effectively representing diverse shapes of a wide variety of medical objects and/or 2) they require substantial interaction from an expert user.  This research will develop a novel medical image segmentation algorithm that can be applied to various types of medical images and will be able to be executed by any user with basic computer literacy.  Many important objects will be able to be handled with the same algorithm, such as livers, prostates, and vertebrae.  This research allows medical experts to spend less time analyzing a wide variety of medical images and more time directly working with patients. <br><br>The algorithm will work for any medical imaging object of interest whose shape can be decomposed into a small number of components with a very simple geometric structure.  For example, livers may be slightly different from person to person, but almost all livers can be represented as a union of two or three "star-shaped" components.  A component is defined to be star-shaped if there is a center point in the component such that the line segment connecting the center to every other point in the component is contained within the object.   If the center of a single star-shaped component is known, then the whole component can be very quickly identified by computer algorithms, but as the number of components increases, the simultaneous computation of all the components becomes much more difficult.  This research will develop algorithms which can automatically compute the centers of the star-shaped components for many medical imaging objects such as livers, prostates, and vertebrae, and further will develop algorithms that can simultaneously identify all the components for the objects.  The result will be a single algorithm that will be applied to many scenarios and can be executed by non-technical users.
Big Data analytics is changing traditional query processing in two ways.  The first is a shift from single server or small-scale parallel relational databases to massively distributed architectures, where hundreds or thousands of servers are used during the computation of a single query.  The second is an increased complexity in the queries being issued, from single- or star-joins, to complex graph-like structured queries.  This project develops new algorithms for query processing over large distributed systems, which are optimized for the cost of communication, then implements and evaluates these algorithms in an open-source big data management system and service.<br><br>The project studies a new approach to query evaluation that computes the entire query at once, replacing the traditional approach based on a query plan. The theoretical part of this project builds on a new model, called the Massively Parallel Communication model (MPC), where the communication is the only cost. The system development is performed over the Myria big data management system and service.<br><br>The Intellectual Merit of the project consists in advancing the state of the art in both the theory and systems approaches to query evaluation in modern, massive-scale shared-nothing clusters.  It develops new, fundamental algorithms for processing queries over massively distributed architectures, with a provably optimal communication cost. The project implements and deploys these algorithms in a system, validating and informing the theoretical model. In particular, the project makes the following contributions: it develops provably optimal, one-round algorithms for skewed data; it studies how and when multiple rounds can be used to further reduce the communication cost; it experiments with these novel algorithms on clusters with up to 1000 worker processes; and it develops a new theoretical model for the communication cost on large shared-nothing architectures with heterogeneous hardware.<br><br>The Broader Impact of the project is to contribute to a new architecture for massively parallel query processing, where the traditional multi-step, single-join query evaluation approaches are replaced with novel, single-step, multi-join algorithms. This change has the potential to lead to more efficient big data analytics engines, allowing data analysts to explore large datasets more efficiently. As an immediate application, the project will impact the domain scientists who already use the Myria big data management system and service. All algorithmic discoveries in this project will be implemented in the Myria system, and will significantly improve query performance, allowing domain scientists to conduct more complex analytics and explorations over their data.
Software-Defined Networking (SDN) is changing the way networks are designed and managed, by separating the "control plane" (which decides how to handle the traffic) from the "data plane" (which actually forwards each packet).  Many large companies---like Google, Microsoft, and Facebook---have already deployed SDN technology, and many equipment vendors support open interfaces for programming their switches.  While most work on SDN focuses on how to control the network, measuring the traffic in the network is equally important.  Traffic measurement is useful to identify congested links, denial-of-service attacks, performance problems, and configuration mistakes, and also drives decisions of how the network should forward traffic in the future.  However, the support for traffic measurement in today's commodity switches is quite primitive.  In this proposal, the PIs bring algorithmic research on so-called "compact data structures" to bear on the problem of programmable traffic measurement in SDNs.  Compact data structures can give approximate answers to measurement questions with limited overhead in terms of switch memory and processing resources.  <br><br>The project is interdisciplinary, bringing together researchers in computer networking and theoretical computer science to match practical problems with novel solutions.  The proposed research starts with designing new query abstractions for collecting traffic statistics on existing SDN switches, and then progresses to identifying new compact data structures so that future switches can support much richer traffic measurement at reasonable overhead.  The researchers have close ties with network administrators and switch vendors, allowing them to ground the project in a strong understanding of both operational requirements and hardware constraints, and also influence future SDN technology.<br><br>This project aims to identify a switch data-plane architecture for collecting diverse traffic statistics, as well as a small set of programmable sketches and samples for variety of analyses to trade-off accuracy and resources.  The architecture will include a measurement control API between the controller and the switch, and this needs a communication-efficient interface, along with a high-level language for specifying traffic queries, and with that, a run-time system on the controller that compiles these queries into commands to the switches with suitable CDSs.  These challenges will be addressed using OpenFlow API that is widely popular for SDNs and in new redesigns.  This is a conversation between the networking and algorithmic communities, mutually informing each other on what is possible, what is required, and ultimately what is effective and useful.
The interiors of ventricles of a human heart are spanned by a fine net of muscle fibers that are difficult to resolve, even in high resolution CT images.  An accurate account of these structures, however, could improve diagnosis of cardiac disease, evaluation of cardiac function, assessment of stroke risk, and simulation of cardiac blood flow. Topology is the branch of abstract mathematics that deals with connections; this project uses the theory of persistent homology to identify crucial topological handles that can be useful for accurate reconstruction and analysis of the complex cardiac dynamics from these CT images. The outcome of the project will not only advance our understanding of cardiac function, but also generate novel computational topology methods that are more efficient and effective for practical applications. This project not only bridges the gap between the theory of computational topology and the practical problem of cardiac image analysis, but also trains the next generation of researchers and educators to do so by a carefully integrated education plan. The PIs will engage undergraduate students, high school students, women and other underrepresented students in their proposed research.<br><br>The goal of this project is to develop a topological approach to unveil the intrinsic structures from complex and dynamic 3D/4D cardiac data, and furthermore, to provide principled tools to quantitatively analyze these structures. The PIs will create new computational topology methodologies and algorithms to extract rich information from the intrinsic structure of cardiac data. They will develop novel methodologies to extract localized topological features and to track them based on their spatial and temporal coherence. They also plan to design new algorithms to untangle ambiguous and uncertain situations for tracking structures through time sequence data. The resulting techniques and software will be validated on cardiac CT data to produce quantitative assessments of accuracy and to characterize the advantages and limitations of these approaches. Domain experts will validate the quality of the approaches via scientific hypotheses and data exploration. The methods to be developed are general and will impact other scientific fields where intrinsic complex and dynamic structures exist.
Efficiently estimating integrals of high-dimensional functions is a fundamental and largely unsolved computational problem, manifesting in scientific areas from biology and physics to economics. In particular, in Artificial Intelligence and Machine Learning, a wide array of methods are computationally limited precisely because they require the computation of high-dimensional integrals. While computing such integrals exactly is highly intractable, approximations suffice for many applications. Currently, approximation is attempted using two main classes of algorithms: Markov Chain Monte Carlo (MCMC) sampling methods and variational inference techniques. The former are asymptotically accurate, but their computational budget is inflexible and often prohibitive. The latter have manageable computational budget, but typically come with no accuracy guarantees. This project will investigate a new family of computationally efficient approximation methods which reduce the task of integration to the much better studied task of optimization, thus leveraging decades of research and engineering in combinatorial optimization methods and technology. A key goal of the project is to develop an open-source software library of efficient tools for high-dimensional integration.<br><br>The reduction of integration to optimization builds on the probabilistic reduction of decision problems to uniqueness promise problems developed in the mid-80s. Specifically, the idea is to use systems of random parity equations in order to specify random subsets of the function's domain, and relate integration to the task of optimization over these subsets. In general, the capacity for efficient optimization fundamentally stems from the capacity to summarily dispense large parts of the domain as uninteresting. The key question to be addressed by the project is whether it is possible to define random subsets over which optimization is both tractable and informative for integration. To that end, the project will employ random systems of linear equations corresponding to Low Density Parity Check (LDPC) matrices for error-correcting codes. The energy landscape, i.e., the number of violated equations, of such systems is far smoother than that of the generic (dense) random systems of linear equations that underlie the original mid-80s technique, thus being far more amenable to optimization. The project will also build upon the deep understanding gained in the last two decades for LDPC codes in the field of communications, with the goal of integrating a priori knowledge about the energy landscape in the optimization strategy. This will provide a fundamentally new use for error-correcting codes, creating a bridge between the areas of optimization and information theory.
The interiors of ventricles of a human heart are spanned by a fine net of muscle fibers that are difficult to resolve, even in high resolution CT images.  An accurate account of these structures, however, could improve diagnosis of cardiac disease, evaluation of cardiac function, assessment of stroke risk, and simulation of cardiac blood flow. Topology is the branch of abstract mathematics that deals with connections; this project uses the theory of persistent homology to identify crucial topological handles that can be useful for accurate reconstruction and analysis of the complex cardiac dynamics from these CT images. The outcome of the project will not only advance our understanding of cardiac function, but also generate novel computational topology methods that are more efficient and effective for practical applications. This project not only bridges the gap between the theory of computational topology and the practical problem of cardiac image analysis, but also trains the next generation of researchers and educators to do so by a carefully integrated education plan. The PIs will engage undergraduate students, high school students, women and other underrepresented students in their proposed research.<br><br>The goal of this project is to develop a topological approach to unveil the intrinsic structures from complex and dynamic 3D/4D cardiac data, and furthermore, to provide principled tools to quantitatively analyze these structures. The PIs will create new computational topology methodologies and algorithms to extract rich information from the intrinsic structure of cardiac data. They will develop novel methodologies to extract localized topological features and to track them based on their spatial and temporal coherence. They also plan to design new algorithms to untangle ambiguous and uncertain situations for tracking structures through time sequence data. The resulting techniques and software will be validated on cardiac CT data to produce quantitative assessments of accuracy and to characterize the advantages and limitations of these approaches. Domain experts will validate the quality of the approaches via scientific hypotheses and data exploration. The methods to be developed are general and will impact other scientific fields where intrinsic complex and dynamic structures exist.
More and more objects used in daily life have Internet connectivity, creating an "Internet of Things" (IoT). Computer security and privacy for an IoT ecosystem are fundamentally important because security breaches can cause real and significant harm to people, their homes, and their community. These security issues also are very challenging not only because of the properties of IoT devices themselves but also because the users are diverse, vary in their technical knowledge and access to technical support, and include vulnerable populations such as children and those using in-home care technologies. Moreover, additional risks emerge when users combine technologies in unexpected ways.<br> <br>Meeting the challenges of IoT security and privacy requires a large, interdisciplinary effort. An effective approach to IoT security and privacy is holistic, integrating human-computer interaction, network security, cryptography, and pervasive computing. Enforcing cryptographic requirements requires not only building systems that can function on low-capacity IoT devices, but also using threat models that incorporate human requirements. Translating security and privacy requirements and preferences requires understanding what people want, presenting the technologies in a manner people can understand, and knowing what is technologically realistic. This requires behavioral and organizational research, with discussions involving public and private sector stakeholders. The project is developing a foundation for IoT security and privacy that is intuitive, natural to the human experience, provides the necessary technical guarantees, and facilitates adoption by the larger IoT community of users and manufacturers.
The Fuzzy Log project seeks to democratize the design and development of complex distributed systems, accelerating innovation by allowing developers to focus on high-level application functionality instead of low-level protocol details. Examples of such complex systems include Software Defined Network controllers for the network, filesystem namespaces for storage, schedulers and allocators for big data run-times, and general-purpose coordination services.  These distributed systems require large numbers of highly trained engineers and scientists to construct and operate them. Simplifying the design, development, deployment and debugging of such systems can drastically reduce the cost to create and operate massively scalable cloud services that are reliable and responsive. More broadly, the Fuzzy Log project will also act as an educational gestalt that combines distributed systems and theory to improve the state of the art in cloud computing.<br><br>A Fuzzy Log is a partially ordered shared log that multiple clients can append to and read from concurrently. As in other shared log designs, applications can extract properties such as consistency, durability, and concurrency control from the Fuzzy Log. However, unlike a conventional shared log, a Fuzzy Log does not impose a total order over all entries. When clients append to the log, they specify dependencies to define a partial order; when they read from the log, the system returns entries in some sequence satisfying the partial order. Fuzzy Log applications are simple to design, implement, and debug, with full-fledged distributed systems realized in hundreds of lines of code. Fuzzy Log applications are also fast and scalable, extracting parallelism from workloads while imposing order only when strictly necessary.
To achieve scalable performance improvement in mobile devices such as smart phones, it is important to integrate a larger and faster memory. The major constraints on enlarging on-chip memory using traditional memory technologies are size and energy efficiency. Size is an issue because devices must inherently be small to be mobile. Energy efficiency is an issue because battery life is often the limiting factor in the usefulness of mobile devices, and the memory subsystem in mobile devices such as smart phones can consume about a third of the total energy. Because of these limitations, the amount of memory per processor in mobile devices such as smart phones has stayed relatively stable over the last few generations of technologies. The incorporation of the emerging technology of Domain Wall Memory in mobile devices is attractive as it can store more information in less volume than any competing technologies, while simultaneously using little energy, and being nearly as fast as traditional memory technologies.<br><br>However, Domain Wall Memory has physical properties that are different than traditional memory technologies, and that can potentially impact performance. In particular, Domain Wall Memory is divided into tracks, which like a tape, may only be accessed sequentially. Thus accessing two data items stored far apart within the same track will be a costly, time-consuming operation. Thus obtaining the best possible performance of Domain Wall Memory will require algorithms/solutions that will smartly manage the placement of data items into memory so that the sequential access properties of Domain Wall Memory do not significantly degrade performance. The goal of the project is to design, analyze, test and deploy algorithms/solutions for data allocation problems that will arise with the adoption of Domain Wall Memory in mobile devices. As these data management problems have unique features, the development of algorithms for these problems will likely require the development of new algorithmic design and analysis techniques. Developing a good practical implementation of these algorithms, or implementations inspired by these algorithms, will require the development of a significant understanding of both implementation issues and common instance properties. The project will cross-train students in the area of computer architecture and algorithms. Transfer of technology to the industry will be<br>pursued through collaborations and visits.<br><br>It is promising to incorporate Domain Wall Memory as a software-controlled scratchpad memory, which has been widely adopted in embedded systems for achieving high performance and energy efficiency. For data items allocated in the same Domain Wall Memory track, accesses start with shifting the target domains below the head, which is similar to accesses to sequential access memory such as tape and hard drives. The overhead to access a data item includes both the read/write overhead and the shift overhead. While the former is constant, the latter depends heavily on how the data items are allocated within the track. Thus optimizing aggregate access time in DWM-SPM largely involves minimizing shifts. The performance of DWM-SPM will be significantly affected by the policies used for: (a) Track management: How the data items are organized/ordered within a track, (b) Data layout: How the data items are assigned to tracks, and (c) Data selection: How the data items that will be stored in DWM-SPM are selected.<br><br>The project will design and formally analyze algorithms for track management, data layout, and data selection in idealized models of Domain Wall Memory. The advantage of formal algorithmics is that the formal objective can drive the discovery of non-intuitive algorithms. Concurrent with this theoretical investigation, a simulation environment will be created to test proposed solutions to managing Domain Wall Memory. This includes the assembly of hardware modeling tools, software simulators, and a collection of benchmark programs. The project will develop and implement some simple policies to serve as a baseline to compare against, and obtain test instances representative of those that would arise in practice, and will transfer the theoretical insights into actual implementations. These implementations would then be compared to the baseline and greedy heuristic solutions.
Computers organize data in "data structures," which are designed to allow certain operations on data such as looking up all items that match a particular set of criteria, or adding new items to an existing data set.  Computer scientists strive to build data structures that can perform these operations quickly and efficiently.  One way to make data structure operations faster is to use not just one but many processors, operating in parallel, to perform a given operation.  However, many of today's parallel data structures support only a limited set of operations and, notably, do not allow operations that modify these data structures instead of rebuilding an entire structure from scratch when only part of the data is updated.  In this project the PIs bring together expertise in data structures and parallel computing to design, build, and evaluate dynamic data structures that allow update operations.  This work targets the high-performance, highly-parallel graphics processing unit (GPU) and will significantly broaden the class of applications that the GPU can address.  The PIs will release their results as freely-available open-source software and will work with industrial partner NVIDIA to incorporate the research and educational outcomes of this project into NVIDIA's broad educational efforts.<br><br>In this project the PIs propose to build dynamic, high-performance data structures for manycore (GPU) computing.  Today's GPU data structures are rarely constructed on the GPU but instead are built on the CPU and copied to the GPU, and today's GPU data structures cannot be updated dynamically on the GPU but instead must be rebuilt from scratch.  This project targets dynamic dictionary data structures with point and range queries, lists, and approximate membership and range query structures.  The PIs will implement these data structures as high-performance, flexible, open-source software and use these data structures to develop a theoretical model, targeted at the GPU, for use by theorists and practitioners in manycore computing.  The project will also focus on numerous cross-cutting issues in data structure design, implementation, modeling, and evaluation that have the potential for significant practical impact on manycore computing.
When users store their data in the cloud, they take many privacy risks: Will the cloud storage provider allow others to see that data? If the user sets sharing rules for the data, will the cloud storage system follow those rules? Recent news stories of user data exfiltration from cloud storage systems show that users have reason for concern. Encrypting files before storing them in the cloud would provide strong protection, but this approach makes it very difficult for users to share data with others and to change their sharing policies. This project is exploring techniques to cryptographically protect user files in cloud-based storage systems, while supporting advanced, dynamic sharing policies.<br><br>While cryptographically protecting data under a static access control policy is well documented in the literature, existing constructions either do not efficiently support dynamic policies (e.g., changes to role/attribute assignments) or make heavy trust assumptions to support this dynamism. This project is (1) developing an open-source platform for prototyping, analyzing, and deploying dynamic access control enforcement solutions for untrusted environments; (2) creating cryptographic constructions that are capable of securely implementing popular role- and attribute-based access control models on untrusted storage platforms while supporting dynamic policy and data updates; (3) designing efficient, trusted hardware-assisted, cloud-scale implementations of popular access control models supporting dynamic policy and data updates in a variety of deployment scenarios; and (4) a carrying out a comprehensive evaluation that explores the trade-offs in trust between these cryptographically- and hardware-enforced approaches and examines the cryptographic, computational, and communication costs of the proposed constructions under a variety of real-world workloads.
Statistical models provide a powerful means of quantifying uncertainty, modeling prior beliefs, and describing complex dependencies in data.  The process of using a model to answer specific questions, such as inferring the state of several random variables given evidence observed about others, is called probabilistic inference.  Probabilistic graphical models, a type of statistical model, are often used in diverse applications such as medical diagnosis, understanding protein and gene regulatory networks, computer vision, and language understanding.  On account of the central role played by probabilistic graphical models in a wide range of automated reasoning applications, designing efficient algorithms for probabilistic inference is a fundamental problem in artificial intelligence and machine learning.<br> <br>Probabilistic inference in many of these applications corresponds to a complex combinatorial optimization problem that at first glance appears to be extremely difficult to solve.  However, practitioners have made significant strides in designing heuristic algorithms to perform real-world inference accurately and efficiently.  This project focuses on bridging the gap between theory and practice for probabilistic inference problems in large-scale machine learning systems.  The PIs will identify structural properties and methods of analysis that differentiate real-world instances from worst-case instances used to show NP-hardness, and will design efficient algorithms with provable guarantees that would apply to most real-world instances.  The project will also study why heuristics like linear programming and other convex relaxations are so successful on real-world instances.  The efficient algorithms for probabilistic inference developed as part of this project have the potential to be transformative in machine learning, statistics, and more applied areas like computer vision, social networks and computational biology.  To help disseminate the research and foster new collaborations, a series of workshops will be organized bringing together the theoretical computer science and machine learning communities.  Additionally, undergraduate curricula will be developed that use machine learning to introduce students to concepts in theoretical computer science.
Swarm robotics explores how groups of robots can work towards a singular goal, which is typically achieved by equipping each robot with sensory capabilities, basic computing power, and movement. The sensors detect and use information about the environment to decide on the next action. Swarm robotics has made many advances in recent years, but is still in its infancy. This project proposes to explore swarm robotics systems in a non-standard way as  physical systems. The PIs take a "task-oriented" approach to develop the distributed algorithmic rules that the robots will run (at the microscopic level) in order to converge to the desired collective behavior (at the macroscopic level).  This will provide understanding of the minimal requirements for individuals to accomplish the desired behavior, for both algorithmic and physical realizations, and will provide a more principled approach for studying swarm robotics. The robots envisioned are small in scale, ranging in size from millimeters to centimeters, so that when deployed in dense environments, they will behave as programmable active matter.<br><br>The PIs have strong records for interdisciplinary research, including initiating interdisciplinary areas (e.g., robo-physics, self-organizing particle systems, and the fusion of statistical physics and randomized algorithms). They have a strong commitment toward supporting minorities, women, and undergrad research (e.g., through NSF REUs, including through this project, NSF S-STEM programs at ASU; ADVANCE and S.U.R.E. programs at Georgia Tech).  Any breakthrough in this combination of swarm and active matter systems will require employing analyses and techniques from stochastic systems, condensed matter physics, swarm systems, robotics, and distributed algorithms to understand and achieve the desired group dynamics, and hence will bring together and educate researchers from different disciplines and specialties.  New research approaches and findings will be incorporated into multiple graduate courses and workshops will provide tutorials for bridging multiple disciplines, making material accessible to young researchers and helping to widely disseminate results. Findings (including open source code) will be published in the various disciplines, and will be be made available on our web pages and ArXiv.   <br> <br>The project explores the fundamentals of swarm robotics from a physics standpoint, by viewing the ensemble as active matter composed of programmable elements at the micro-level.  The project will follow a (macro-)task oriented approach, and design a distributed stochastic algorithmic framework to design and evaluate algorithms at the micro-level that will yield the targeted emergent macroscopic behavior.  The emergent behaviors it addresses include compression (maintaining coherence of a connected community while minimizing perimeter), bridging (connecting two or more locations in the most efficient manner), alignment (determining an agreed upon direction of orientation), jamming (obstruction of movement by increased collective flow), and locomotion (collectively moving while maintaining cohesiveness). Many of these have interesting converse problems which are also equally worthwhile, such as exploration (maintaining a connected population, but exploring maximal area) and non-alignment (representing a disordered ensemble). In some cases the collective behavior acts like a physical system changing between a liquid (disordered) and a solid (ordered) state, as determined by phase transitions in the systems. The project will explore stochastic and distributed algorithms for rigorously achieving these goals.
Computers organize data in "data structures," which are designed to allow certain operations on data such as looking up all items that match a particular set of criteria, or adding new items to an existing data set.  Computer scientists strive to build data structures that can perform these operations quickly and efficiently.  One way to make data structure operations faster is to use not just one but many processors, operating in parallel, to perform a given operation.  However, many of today's parallel data structures support only a limited set of operations and, notably, do not allow operations that modify these data structures instead of rebuilding an entire structure from scratch when only part of the data is updated.  In this project the PIs bring together expertise in data structures and parallel computing to design, build, and evaluate dynamic data structures that allow update operations.  This work targets the high-performance, highly-parallel graphics processing unit (GPU) and will significantly broaden the class of applications that the GPU can address.  The PIs will release their results as freely-available open-source software and will work with industrial partner NVIDIA to incorporate the research and educational outcomes of this project into NVIDIA's broad educational efforts.<br><br>In this project the PIs propose to build dynamic, high-performance data structures for manycore (GPU) computing.  Today's GPU data structures are rarely constructed on the GPU but instead are built on the CPU and copied to the GPU, and today's GPU data structures cannot be updated dynamically on the GPU but instead must be rebuilt from scratch.  This project targets dynamic dictionary data structures with point and range queries, lists, and approximate membership and range query structures.  The PIs will implement these data structures as high-performance, flexible, open-source software and use these data structures to develop a theoretical model, targeted at the GPU, for use by theorists and practitioners in manycore computing.  The project will also focus on numerous cross-cutting issues in data structure design, implementation, modeling, and evaluation that have the potential for significant practical impact on manycore computing.
With the wealth of data being generated in every sphere of human endeavor, data exploration--analyzing, understanding, and extracting value from data--has become absolutely vital. Data visualization is by far the most common data exploration mechanism, used by novice and expert data analysts alike. Yet data visualization on increasingly larger datasets remains difficult: even simple visualizations of a large dataset can be slow and non-interactive,  while visualizations of a sampled fraction of a dataset can mislead an analyst. <br><br>The project aims to develop FastViz, a scalable visualization engine, that will not only enable visualization on datasets that are orders of magnitude larger in the same time, but also ensure the resulting visualizations satisfy key properties essential for correct analysis by end-users. To ensure immediate utilization, FastViz will be applied to three real-world application domains: battery science, advertising analysis, and genomic data analysis, and implemented in Zenvisage, an open-source visual exploration platform developed by the PIs.  Students in the project gain invaluable experience in combining the algorithmic and systems considerations that enable data exploration. <br><br>FastViz's development is driven by simultaneous investigation of systems considerations, such as indexing and storage techniques that enable various forms of online sampling, and algorithmic considerations for <br>(a) visualization generation, where the goal is to produce incrementally improving visualizations in which the important features are displayed first, and <br>(b) visualization selection, where the goal is to select, from a collection of as yet not generated visualizations, those that satisfy desired criteria. <br>On the systems front, FastViz will leverage and contribute back to recent developments on online sampling systems that enable the use of more powerful sampling modalities.  <br>On the algorithms front, FastViz will draw ideas from testing, distribution learning, and sublinear algorithms literature that, to the best knowledge of the PIs, have not been adapted in practice.  The algorithms developed will obey optimality guarantees, and wherever possible, instance-optimality guarantees, ensuring that they will adapt to data characteristics in the most efficient way possible.  <br><br>The project will lead to a better understanding of the interplay between sampling algorithms development and systems design, facilitating the adoption of more realistic models and algorithms on the one hand, and the development of more powerful sampling engines that enable the models required within the algorithms.
The interiors of ventricles of a human heart are spanned by a fine net of muscle fibers that are difficult to resolve, even in high resolution CT images.  An accurate account of these structures, however, could improve diagnosis of cardiac disease, evaluation of cardiac function, assessment of stroke risk, and simulation of cardiac blood flow. Topology is the branch of abstract mathematics that deals with connections; this project uses the theory of persistent homology to identify crucial topological handles that can be useful for accurate reconstruction and analysis of the complex cardiac dynamics from these CT images. The outcome of the project will not only advance our understanding of cardiac function, but also generate novel computational topology methods that are more efficient and effective for practical applications. This project not only bridges the gap between the theory of computational topology and the practical problem of cardiac image analysis, but also trains the next generation of researchers and educators to do so by a carefully integrated education plan. The PIs will engage undergraduate students, high school students, women and other underrepresented students in their proposed research.<br><br>The goal of this project is to develop a topological approach to unveil the intrinsic structures from complex and dynamic 3D/4D cardiac data, and furthermore, to provide principled tools to quantitatively analyze these structures. The PIs will create new computational topology methodologies and algorithms to extract rich information from the intrinsic structure of cardiac data. They will develop novel methodologies to extract localized topological features and to track them based on their spatial and temporal coherence. They also plan to design new algorithms to untangle ambiguous and uncertain situations for tracking structures through time sequence data. The resulting techniques and software will be validated on cardiac CT data to produce quantitative assessments of accuracy and to characterize the advantages and limitations of these approaches. Domain experts will validate the quality of the approaches via scientific hypotheses and data exploration. The methods to be developed are general and will impact other scientific fields where intrinsic complex and dynamic structures exist.
Society today critically depends on Internet services. The safety and performance of these Internet services in turn depends on the ability of individual networks to successfully; manage and optimize their network configurations in reaction to a changing operating environment (e.g., sudden increases in traffic or attacks or changes in policy compliance requirements). Today, network operators often resort to ad hoc and brittle solutions that affect the safety and performance of the networks. The goal of this project is combine theory and practice to develop foundational mechanisms enabling network administrators to implement diverse network operations tasks. This project will develop abstractions for expressing a broad spectrum of network optimization tasks and algorithmic foundations to reason about and achieve optimal (or near-­optimal) solutions that will be better than current state-of-the-art. ;The project will develop and release open­-source toolkits that will dramatically reduce the time to prototype and deploy novel network management applications, and democratize these benefits for a larger audience. The project will lead to educational advances that help create a well­-rounded workforce capable of handling future technology challenges by applying transformational research that couples theory and practice. The project will actively encourage participation from underrepresented groups as part of the proposed work and mentor them to be future technology leaders.<br><br>Software-­defined networking (SDN) is an emerging paradigm to simplify network management by moving policies embedded in the configurations of the network hardware to software running in centralized controllers. Realizing the potential benefits of SDN, however, currently requires significant theoretical and practical effort. Specifically, at the core of many SDN applications are complex optimization problems to tackle goals and requirements that arise in practice. These problems are ones for which good theoretical solutions are unknown.The goal of this project is to design and implement a novel framework that enables SDN application developers to express new application goals and constraints in a high-­level language, using a sound algorithmic approach to generate near­-optimal solutions, and then to generate compliant configurations that can be deployed to SDN control platforms directly. There are two requirements for this vision to be successful in practice: (i) the ability to express the requirements of a broad spectrum of applications and (ii)­­ generating provably optimal (or close ­to ­optimal) configurations, on a timescale that is responsive to application needs. The proposed research will investigate theoretical foundations and practical implementations to simultaneously achieve both goals. The project's contributions will include: (1) investigating the robustness of path-­based optimizations for a wide spectrum of SDN applications and developing algorithms for ensuring that such path­-based reformulations do not sacrifice efficiency; (2) designing richer abstractions for applications that require more dynamic network processing features and developing near­-optimal and practical algorithms for these applications; (3) designing efficient optimization-­preserving translations of solutions from such theoretical frameworks into practical network configurations; and (4) implementing these techniques in an end­-to-­end open-­source tool integrated with state­-of-­the-­art network management platforms.
With the wealth of data being generated in every sphere of human endeavor, data exploration--analyzing, understanding, and extracting value from data--has become absolutely vital. Data visualization is by far the most common data exploration mechanism, used by novice and expert data analysts alike. Yet data visualization on increasingly larger datasets remains difficult: even simple visualizations of a large dataset can be slow and non-interactive,  while visualizations of a sampled fraction of a dataset can mislead an analyst. <br><br>The project aims to develop FastViz, a scalable visualization engine, that will not only enable visualization on datasets that are orders of magnitude larger in the same time, but also ensure the resulting visualizations satisfy key properties essential for correct analysis by end-users. To ensure immediate utilization, FastViz will be applied to three real-world application domains: battery science, advertising analysis, and genomic data analysis, and implemented in Zenvisage, an open-source visual exploration platform developed by the PIs.  Students in the project gain invaluable experience in combining the algorithmic and systems considerations that enable data exploration. <br><br>FastViz's development is driven by simultaneous investigation of systems considerations, such as indexing and storage techniques that enable various forms of online sampling, and algorithmic considerations for <br>(a) visualization generation, where the goal is to produce incrementally improving visualizations in which the important features are displayed first, and <br>(b) visualization selection, where the goal is to select, from a collection of as yet not generated visualizations, those that that satisfy desired criteria. <br>On the systems front, FastViz will leverage and contribute back to recent developments on online sampling systems that enable the use of more powerful sampling modalities.  <br>On the algorithms front, FastViz will draw ideas from testing, distribution learning, and sublinear algorithms literature that, to the best knowledge of the PIs, have not been adapted in practice.  The algorithms developed will obey optimality guarantees, and wherever possible, instance-optimality guarantees, ensuring that they will adapt to data characteristics in the most efficient way possible.  <br><br>The project will lead to a better understanding of the interplay between sampling algorithms development and systems design, facilitating the adoption of more realistic models and algorithms on the one hand, and the development of more powerful sampling engines that enable the models required within the algorithms.
This project will tackle the algorithmic challenges underlying the transformation of the power grid.  Society is at the cusp of a historic transformation of our energy systems, driven by sustainability. Daunting challenges arise in the stable, reliable, secure, and efficient operation of the future grid that will be much more distributed, dynamic, and open. This project will push the boundaries of control, optimization, and learning to develop practical solutions to some of these difficulties.  It will advance state of the art in both the science of general cyber-physical systems and its application to smart grids.  It will support education and diversity through a tight integration of the research with educational courses and the training of female and minority students. <br><br>The theory and algorithms to be developed in this project will contribute directly towards the historic transformation of energy systems to a more sustainable future. Specifically, the project will focus on three core algorithmic challenges facing cyber-physical networks such as a smart grid: control, optimization, and learning. First, this project will develop an optimization-based approach to the design of feedback controllers for cyber-physical systems so that the closed-loop system is asymptotically stable, and every equilibrium point of the closed-loop system is an optimal solution of a given optimization problem.  Second, this project will develop a new hierarchy of convex relaxations for exponential programs based on relative entropy optimization. This will immediately yield a fundamentally new approach for solving Optimal Power Flow (OPF) problems, which underlie numerous power system applications and are non-convex and NP-hard in general.  Third, this project will develop methods to learn a policy that is near-optimal efficiently, despite not having access to the objective function at run time. This will allow power systems to "learn to optimize" in real time, addressing one of the biggest challenges in power systems -- that data about the system is too expensive or impossible to obtain in real time.
Deep neural networks (DNNs) have emerged as a class of powerful techniques for learning solutions in a number of challenging problem domains, including computer vision, natural language processing and bioinformatics.  These solutions have been enabled mainly because we now have computational accelerators able to sift through the myriad of data required to train a neural network.   As the size of DNN models continues to grow, computational and memory resource requirements for training will also grow, limiting deployment of deep learning in many practical applications. <br><br>      Leveraging the theory of structured matrices, this project will develop a general framework for efficient DNN training and inference, providing a significant reduction in algorithmic complexity measures in terms of both computation and storage.  <br>The project, if successful, should fundamentally impact a broad class of deep learning applications.  It will explore accelerating this new structure for deep learning algorithms targeting emerging accelerator architectures, and will evaluate the benefits of these advances across a number of application domains, including big data analytics, cognitive systems, unmanned vehicles and aerial systems, and wearable devices.  The interdisciplinary nature of this project bridges the areas of matrix theory, machine learning, and computer architecture, and will affect education at both Northeastern and CCNY, including the involvement of underrepresented and undergraduate students in the rich array of research tasks.<br><br>     The project will: (1) for the first time, develop a general theoretical framework for structured matrix-based DNN models and perform detailed analysis and investigation of error bounds, convergence, fast training algorithms, etc.; (2) develop low-space-cost and high-speed inference and training schemes for the fully connected layers of DNNs; (3) impose a weight tensor with structure and enable low computational and space cost convolutional layers; (4) develop high-performance and energy-efficient implementations of deep learning systems on high-performance parallel platforms, low-power embedded platforms, as well as emerging computing paradigms and devices; (5) perform a comprehensive evaluation of the proposed approaches on different performance metrics in a variety of platforms.  The project will deliver tuned implementations targeting a range of computational platforms, including ASICs, FPGAs, GPUs and cloud servers. The hardware optimizations will focus on producing high-speed and low-cost implementations of deep learning systems.
Fast and robust solvers for systems of linear equations are the work horse of many communities in the sciences, engineering, business, and industry. Few pieces of software are so important of all these areas. Recent theoretical progress on efficient solvers for special cases of linear systems, including Symmetric Diagonally Dominant matrices, have sparked a renaissance in faster algorithms for wide classes of optimization problems that have not seen improvements in many years.<br><br>The main goal of this project is to take the next step to find and implement fast robust solvers that work in seconds on systems that are a factor of 100 to 1000 times larger than is now possible on a modern large workstation. For the applications mentioned above the solver may be called 100s or 1000s times for a single run. As a result, such a solver needs to meet several important requirements: 1) it must be robust enough to not need human intervention between these runs; 2) it must be fast enough to finish all work in a reasonable amount of time. 3) it must be able to handle the very different systems of equations that arise in applications.<br><br>This project aims to bridge the theoretical and practical aspects of designing efficient and robust solvers for linear systems in graph Laplacians. The PIs plan to develop code packages that have good practical performances as well as provable guarantees in the worst case. Doing so requires them to address a range of issues arising from numerical analysis, combinatorics, high performance computing, and data structures.<br><br>They plan to address shortcomings of existing packages for solving linear systems in graph Laplacians, specifically their robustness in the presence of widely varying edge weights. Resolving this issue is crucial for bridging the theory and practice of incorporating these solvers in optimization algorithms such as iterative least squares, mirror descent, and interior point methods. Specifically, they will study a variety of theoretical algorithmic tools from the perspective of high performance computing, focusing on topics at the core of data structures, high performance computing, numerical analysis, scientific computing, and graph theory. Progresses on them have the potential of opening up novel lines of investigations on well-studied topics for the team and the students that they will train.
Many challenging real world problems, e.g., voting and blind auction, require computation over sensitive data supplied by multiple mutually-distrustful entities. Elegant cryptographic theories have been developed to solve these problems without relying on a mutually-trusted third party. Practitioners also built prototypes capable of securely computing set intersection, AES encryption, Hamming distance, etc. However, many other applications, such as data mining and running universal machines, are far more complex than what can be supported by the state-of-the-art techniques. This work studies new methods and platforms to enable large-scale, complex cryptographic protocols in more efficient ways. Software produced will be released as open-source projects to benefit future research in related areas. <br><br>One part of this project explores new extensible approaches to accommodate multiple Secure Multiparty Computation (SMC) protocols and enable studying interesting combinations of them, including a new compiler to provide a higher-level abstraction for generating SMC protocols. The other part involves research into several new optimizations to improve the performance and scalability of SMC, through reuse of validated components to amortize validation costs. The educational activities of this project include mentoring both undergraduate and graduate students in applied cryptography research and developing a graduate course in applied cryptography.<br><br>For further information see the project web site at: http://smc-in-action.soic.indiana.edu
Support for research on distributed data sets is challenged by stakeholder requirements limiting sharing. Researchers need early stage access to determine whether data sets are likely to contain the data they need. The Broker Leads project is developing privacy-enhancing technologies adapted to this discovery phase of data-driven research. Its approach is inspired by health information exchanges that are based on a broker system where data are held by healthcare providers and collected in distributed queries managed by the broker. Such systems have potential to support public health and biomedical research. The project targets "similar patient queries" where the query is a patient medical record and the response is information about similar patients. Such queries have value for many applications, including developing cohorts for finding institutions for further discussions about joint research.<br><br>Broker Leads uses the concept of a "lead" in which data holders provide representative collections of non-identifiable real or synthetic data meeting strong privacy guarantees, e.g., differential privacy. Even though such data may be unsuitable for clinical decision making and scientific discovery due to the transformations done for privacy protection, they guide a user of a broker lead system to the data sets very likely to be useful to addressing a given similar patient query. These data sets can then be used with other privacy-protecting strategies, such as secure multiparty computation or restrictive data use agreements ensuring adequate data protection. In addition to providing practical and well-analyzed strategies for early stages of research on healthcare data, this project will provide new insights into practical issues with privacy technology in end-to-end applications.
A common objective in many computer networks is to balance traffic across multiple paths in order to improve throughput, reduce congestion, and achieve higher utilization. Although there is an extensive theoretical literature on how best to route traffic through a capacitated network, most networks today rely on schemes that are easy to implement but do not always perform well in practice. This is due, in part, to the gap between the community of theory researchers who study advanced routing schemes and the community of systems researchers who design, build, and operate networks.<br><br>This project will advance the theory and practice of routing by developing oblivious and semi-oblivious routing algorithms that can be implemented on top of current hardware. The intellectual merit of this research lies in designing new programming languages based on probabilistic semantics that can be used to express and reason about these algorithms, and engineering implementations for these languages based on software-defined networking platforms. This project will have broad impact on society by producing tools that could help to make networks more reliable and efficient while simplifying network management.
Swarm robotics explores how groups of robots can work towards a singular goal, which is typically achieved by equipping each robot with sensory capabilities, basic computing power, and movement. The sensors detect and use information about the environment to decide on the next action. Swarm robotics has made many advances in recent years, but is still in its infancy. This project proposes to explore swarm robotics systems in a non-standard way as  physical systems. The PIs take a "task-oriented" approach to develop the distributed algorithmic rules that the robots will run (at the microscopic level) in order to converge to the desired collective behavior (at the macroscopic level).  This will provide understanding of the minimal requirements for individuals to accomplish the desired behavior, for both algorithmic and physical realizations, and will provide a more principled approach for studying swarm robotics. The robots envisioned are small in scale, ranging in size from millimeters to centimeters, so that when deployed in dense environments, they will behave as programmable active matter.<br><br>The PIs have strong records for interdisciplinary research, including initiating interdisciplinary areas (e.g., robo-physics, self-organizing particle systems, and the fusion of statistical physics and randomized algorithms). They have a strong commitment toward supporting minorities, women, and undergrad research (e.g., through NSF REUs, including through this project, NSF S-STEM programs at ASU; ADVANCE and S.U.R.E. programs at Georgia Tech).  Any breakthrough in this combination of swarm and active matter systems will require employing analyses and techniques from stochastic systems, condensed matter physics, swarm systems, robotics, and distributed algorithms to understand and achieve the desired group dynamics, and hence will bring together and educate researchers from different disciplines and specialties.  New research approaches and findings will be incorporated into multiple graduate courses and workshops will provide tutorials for bridging multiple disciplines, making material accessible to young researchers and helping to widely disseminate results. Findings (including open source code) will be published in the various disciplines, and will be be made available on our web pages and ArXiv.   <br> <br>The project explores the fundamentals of swarm robotics from a physics standpoint, by viewing the ensemble as active matter composed of programmable elements at the micro-level.  The project will follow a (macro-)task oriented approach, and design a distributed stochastic algorithmic framework to design and evaluate algorithms at the micro-level that will yield the targeted emergent macroscopic behavior.  The emergent behaviors it addresses include compression (maintaining coherence of a connected community while minimizing perimeter), bridging (connecting two or more locations in the most efficient manner), alignment (determining an agreed upon direction of orientation), jamming (obstruction of movement by increased collective flow), and locomotion (collectively moving while maintaining cohesiveness). Many of these have interesting converse problems which are also equally worthwhile, such as exploration (maintaining a connected population, but exploring maximal area) and non-alignment (representing a disordered ensemble). In some cases the collective behavior acts like a physical system changing between a liquid (disordered) and a solid (ordered) state, as determined by phase transitions in the systems. The project will explore stochastic and distributed algorithms for rigorously achieving these goals.
This award funds Student Travel Fellowships for US students attending a workshop on the intersection of Security and Privacy with Computer Vision at the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). It helps cover the travel expenses and conference registration fees for these students, making it possible for them to attend the workshop and the conference, and to discuss their work or recent advances in the field with other attendees of the workshop or conference.<br><br>The workshop brings together privacy, security and computer vision experts to discuss how to better understand the potential threats of computer vision to people's security and privacy, as well as the potential opportunities and applications for enhancing them. The workshop also helps spark interest among young researchers in the important emerging intersection between privacy and security and computer vision.
Medical image segmentation, the process of dividing a medical image into meaningful objects such as organs, tumors, etc., is a critical tool that allows medical professionals to provide customized medical care to patients.  In the past this highly technical, individualized care has required experts to manually analyze the images, a process that is very expensive in both time and money.  Over the past decade, enormous technological advances have been made in biomedical imaging, leading to a large amount of new and improved medical data which has created a demand for algorithms which can process this data faster and more thoroughly.  Researchers have worked extensively to develop these medical image segmentation algorithms, but current algorithms suffer from the following drawbacks: 1) they do not have the capability of effectively representing diverse shapes of a wide variety of medical objects and/or 2) they require substantial interaction from an expert user.  This research will develop a novel medical image segmentation algorithm that can be applied to various types of medical images and will be able to be executed by any user with basic computer literacy.  Many important objects will be able to be handled with the same algorithm, such as livers, prostates, and vertebrae.  This research allows medical experts to spend less time analyzing a wide variety of medical images and more time directly working with patients. <br><br>The algorithm will work for any medical imaging object of interest whose shape can be decomposed into a small number of components with a very simple geometric structure.  For example, livers may be slightly different from person to person, but almost all livers can be represented as a union of two or three "star-shaped" components.  A component is defined to be star-shaped if there is a center point in the component such that the line segment connecting the center to every other point in the component is contained within the object.   If the center of a single star-shaped component is known, then the whole component can be very quickly identified by computer algorithms, but as the number of components increases, the simultaneous computation of all the components becomes much more difficult.  This research will develop algorithms which can automatically compute the centers of the star-shaped components for many medical imaging objects such as livers, prostates, and vertebrae, and further will develop algorithms that can simultaneously identify all the components for the objects.  The result will be a single algorithm that will be applied to many scenarios and can be executed by non-technical users.
Swarm robotics explores how groups of robots can work towards a singular goal. Such a goal is typically achieved by equipping each robot with sensory capabilities, basic computing power, and actuation. The sensors detect something about the environment, this information is used to make a decision about the next action, and some resulting actuation is performed. Swarm robotics has made many advances in recent years, but it is still in its infancy.  The PIs will take a "task-oriented" approach and start from a desired macroscopic emergent collective behavior to develop the distributed and stochastic algorithmic underpinnings that the robots will run (at the microscopic level) in order to converge to the desired macroscopic behavior; as part of the process, they will also provide the understanding for yet unexplored  collective and emergent systems. The robots envisioned are small in scale, ranging in size from millimeters to centimeters, so that when deployed in crowded (i.e., dense) environments, they will behave as active matter, more specifically as macroscopic programmable active matter.  The emergent behaviors of interest for simulations include clustering (forming a tight-knit community that is mostly well-connected), compression (maintaining coherence of a connected community while minimizing perimeter), flocking (determining an agreed upon direction of orientation), and locomotion (collectively moving while maintaining cohesiveness). Many of these have interesting converse problems which are also equally worthwhile, such as exploration (maintaining a connected population, but exploring maximal area) and desegregation (preventing separation in a binary mixture of particles).<br><br>The PIs have strong records for interdisciplinary research, including initiating interdisciplinary areas, e.g., robo-physics (Goldman), self-organizing particle systems (Richa), and the fusion of statistical physics and randomized algorithms (Randall). The PIs also have a strong commitment toward supporting minorities, women, and undergraduate research (e.g., through NSF S-STEM programs at ASU; ADVANCE and S.U.R.E. programs at Georgia Tech).  This project will bring together techniques from multiple disciplines, and new research approaches and findings will be incorporated into graduate courses. Findings (including open source code) will be published in the various disciplines, and will be made available on the web and ArXiv.<br><br>The specific goals of this project are to work toward developing a theoretical framework for task-oriented active matter, informed by models of simple physical systems, that can realize and test the algorithms. The swarm robotics systems that biophysicists build to understand nature can be modified to perform the tasks these new algorithms require. The physical models will allow refinements to the theories under additional constraints, such as gravity and limited energy. It also will allow the PIs to test their algorithms for robustness, as physical systems admit some error.  The fundamentals of swarm robotics will be studied from a physics standpoint, by viewing the ensemble as active matter composed of programmable elements at the micro-level. Thus, a (macro-)task oriented approach will be followed in order to design a distributed, stochastic algorithmic framework to construct and evaluate algorithms at the micro-level that yield the targeted emergent macro-behavior.
In the current data-centered era, there are many highly diverse data sources that provide information about movement on transportation networks. Examples include GPS trajectories, social media data, and traffic flow measurements. Much of this movement data is challenging to utilize due to the inherent uncertainty caused by infrequent sampling and sparse coverage. The goal of this project is to develop a unified framework that uses as many available data sources as possible to extract meaningful traffic and movement information automatically from the data. Probabilistic network movement models will be developed that capture movement probabilities and traffic volume on a network over time. The results will impact a range of applications that rely on capturing population movements, such as urban planning, geomarketing, traffic management, and emergency management. Educational activities will be integrated throughout the project. Students will be closely involved in research and practical implementations, and will be trained in spatio-temporal data management, algorithms development, and (trajectory) data analysis. The combination of such skills is increasingly important in spatial data science. Topics involved in this project will enrich the course material and curriculum development at both institutions. <br><br> The objective of this project is to create a unified framework for aggregating and analyzing diverse and uncertain movement data on road networks, with the aim to provide tools for querying and predicting traffic volume and movement. Probabilistic movement models on the network will be developed that can handle heterogeneous data sources, including GPS trajectories, geo-tagged social media data, bike-share data, public transport data, and traffic volume data. The diversity and spatio-temporal uncertainty of this data will be addressed with a Bayesian traffic pattern learning approach that first trains the movement models with the more certain data, which in turn will be used to fill gaps in the more uncertain data. The project will advance the state-of-the-art in theoretical communities (computational geometry, data mining) as well as in applied communities (spatial databases, location science). The results of the research will available on the project website (movementanalytics.org), and will be disseminated in prestigious venues through presentations and demonstrations at conferences, and through publications in journals.
The Discrete Fourier Transform (DFT) is a powerful tool used in many big data domains, including multimedia processing, medical imaging, genomics research, astronomy, seismology for oil and gas reserve discovery, and malicious traffic detection in cybersecurity domains.  Building upon a recent breakthrough by the researchers behind this project, this award will develop the algorithmic and system foundations for practical high-spped DFT over sparse data sets. Addressing this goal involves highly interdisciplinary research encompassing ideas and techniques from mathematics, theoretical computer science, software design, and specific application areas such as wireless networks.<br><br>The project will be multi-pronged, focusing on three main themes: (a) Algorithms: The PIs will develop a family of algorithms that are faster, simpler and more accurate than the current state of the art in sparse DFT. The new algorithms will be capable of incorporating priors on the structure of the data and apply to multi-dimensional data sets. (b) Software implementations: The PIs will develop software implementations of sparse FFT algorithms and explore algorithm parallelization for further reduction in power and processing time. (c) Applications: The PIs will apply these algorithms and empirically demonstrate them in the context of cost-effective networked system for delivering smart services for intelligent transportation systems using existing e-toll transponders.
Over the past decades, the world's dominant computational infrastructure has gradually transitioned from individual personal computers to massive networked systems of unprecedented scale and complexity. Not only has this led to tremendous technological and engineering challenges, but it has also called into question fundamental assumptions in classical algorithmic theory. A defining distinction is the limited information that algorithms in such decentralized and heterogeneous systems have access to. For example, a content delivery network serves a heterogeneous set of end devices, and has to optimize performance often without knowledge of the device it is optimizing for. Similarly, a data center scheduler must be optimized for future demands that it is oblivious to. In this project, the PIs seek to address novel algorithmic questions in non-clairvoyant models of computation that arise in real world networked systems. The successful completion of this project will lead to new advances in building reliable and resilient information networks. The project will enable collaborations and exchange of ideas between theoreticians and practitioners, and will provide extensive training in real world algorithms to several graduate students, with attention paid to gender diversity and participation of under-represented groups.<br> <br>The goal of the project is to design novel algorithms with provable guarantees for networked systems in limited information settings. In particular, the PIs plan to address key algorithmic problems in the three dominant computational infrastructure models in the Internet: (a) data centers: allocating parallelizable jobs requiring multiple resources on processing nodes and clusters; (b) wide-area network of clusters: long-term planning of resource deployment and synergistic operations in the client-server model; and (c) P2P browser clouds: content delivery in web and gaming applications and swarm computing on a fabric of a large number of loosely coupled unreliable browsers. These problem domains are characterized by uncertainty and limited information for several reasons, including uncertainty about future predictions, autonomy of individual components in the networked system, and distributed implementation of the network architecture. The algorithms designed as part of this project will be evaluated on and optimized for real world testbeds.
Efficiently estimating integrals of high-dimensional functions is a fundamental and largely unsolved computational problem, manifesting in scientific areas from biology and physics to economics. In particular, in Artificial Intelligence and Machine Learning, a wide array of methods are computationally limited precisely because they require the computation of high-dimensional integrals. While computing such integrals exactly is highly intractable, approximations suffice for many applications. Currently, approximation is attempted using two main classes of algorithms: Markov Chain Monte Carlo (MCMC) sampling methods and variational inference techniques. The former are asymptotically accurate, but their computational budget is inflexible and often prohibitive. The latter have manageable computational budget, but typically come with no accuracy guarantees. This project will investigate a new family of computationally efficient approximation methods which reduce the task of integration to the much better studied task of optimization, thus leveraging decades of research and engineering in combinatorial optimization methods and technology. A key goal of the project is to develop an open-source software library of efficient tools for high-dimensional integration.<br><br>The reduction of integration to optimization builds on the probabilistic reduction of decision problems to uniqueness promise problems developed in the mid-80s. Specifically, the idea is to use systems of random parity equations in order to specify random subsets of the function's domain, and relate integration to the task of optimization over these subsets. In general, the capacity for efficient optimization fundamentally stems from the capacity to summarily dispense large parts of the domain as uninteresting. The key question to be addressed by the project is whether it is possible to define random subsets over which optimization is both tractable and informative for integration. To that end, the project will employ random systems of linear equations corresponding to Low Density Parity Check (LDPC) matrices for error-correcting codes. The energy landscape, i.e., the number of violated equations, of such systems is far smoother than that of the generic (dense) random systems of linear equations that underlie the original mid-80s technique, thus being far more amenable to optimization. The project will also build upon the deep understanding gained in the last two decades for LDPC codes in the field of communications, with the goal of integrating a priori knowledge about the energy landscape in the optimization strategy. This will provide a fundamentally new use for error-correcting codes, creating a bridge between the areas of optimization and information theory.
This award establishes a new CISE REU site focused on mobile computing security at Indiana University Purdue University Indianapolis. A team of faculty will lead undergraduate students in hands-on projects based on the latest research on mobile device security, mobile cloud security, and mobile social network security. Working together in small groups, the students will learn how to plan, implement, and evaluate research projects. Participating students will have access to an internal cloud computing platform as well as smartphones and tablet computers. Through this program, participants will gain first-hand experience in research and graduate student life, which will help them make informed decisions in pursuing postgraduate studies as well as in choosing professional careers. This project is co-funded by the CISE Secure and Trustworthy Cyberspace (SaTC) Cluster.<br><br>Intellectual Merit. The intellectual merit of this proposal includes a faculty with expertise in mobile and cloud computing security, an important and timely area of computing that is of national interest. Students will acquire first-hand experiences with state-of-the-art technologies, which are often inaccessible to them due to high acquisition and maintenance costs. Through this REU grant, students will work with faculty mentors in completing cutting-edge research projects that have the potential to change our everyday computing experiences. By the end of program, students will acquire valuable skills, gain a broader and deeper understanding of research, and develop greater confidence in their abilities.<br><br>Broader Impact. The broader impact of this proposal is to help students tap into cutting-edge research, to boost their interests in science and engineering, and to inspire them to pursue postgraduate education in these fields. The team is committed to recruiting underrepresented minority and female students, as well as students from institutes with inadequate resources to conduct research in mobile computing security. Thus the project has the potential to produce new computer science graduate students and faculty members and to advance discovery and understanding while promoting learning.
Mobile cloud technologies have begun to rely heavily on services known as Mobile Back-end as a Service (MBaaS), including push messaging, data synchronization, and mobile identity management. Many of today's popular apps have already integrated push messaging services such as Google Cloud Messaging (GCM), Amazon Device Messaging (ADM), and third parties like Baidu, to enable the apps to receive notifications such as private messages, financial secrets or family members' locations. Prior research has demonstrated significant security weaknesses inside such services, endangering the information assets of billions of mobile users. By exploiting flaws in services like GCM and ADM, and their integration within popular apps such as Facebook, Google+, Skype, PayPal etc., an attacker could steal a mobile user's sensitive messages, install or uninstall apps on her device, remotely lock out the user or even wipe out her data. This project is studying security risks in such services in order to significantly improve the security assurance of the new MBaaS computing paradigm. The team is collaborating with industry to facilitate the transfer of research outcomes to practical protections. <br><br><br>To identify the security properties needed in individual components of mobile cloud technologies, the researchers are modeling different MBaaS services. The models enable the development of novel static and dynamic security analysis techniques, tailored to the unique features of different service types. These techniques will allow mobile cloud service providers to automatically verify security properties on both cloud and device fronts, find problems within their systems, and improve the security quality of their services. The researchers are also developing new techniques to enable app vendors, users and app stores to automatically detect threats to mobile clouds and protect their communication against the attempts to exploit those services' weaknesses. The research covers push messaging for Android, Apple, and mobile browsers, as well as other MBaaS services (e.g., identity management, data synchronization, and the platforms integrating them.)
Information, beliefs, diseases, technologies, and behaviors propagate through social interactions as a contagion. Understanding of how these contagions spread is crucial in encouraging beneficial and healthy behaviors and discouraging the ones that are destructive and damaging. Rigorous, mathematical understanding of complex social contagions is not just an abstraction, but will guide applications from healthcare to word-of-mouth advertising. The technical content of this project is inherently interdisciplinary, and its lessons will apply to related fields such as probability, economics, sociology, and statistical physics. The research efforts are integrated with the educational and outreach activities of the PIs, who have strong records of broadly disseminating cutting-edge research to high school, undergraduate, and graduate students through teaching, outreach programs, and personal mentoring. <br><br>This project will transform our understanding of social contagions by: 1) Developing a suite of technical tools to enable improved understanding of specific complex processes; 2) Determining how various parameters of cascade and social structure together impact the chances of a cascade's success or failure; and 3) Obtaining empirical evidence to both corroborate the theoretical findings, and uncover the space of realistic setting for certain parameters. <br><br>Many existing models of contagion assume that increasing the number of infected (or affected) neighbors marginally decreases the chance of infection. Many contagions, such as adoption of expensive new technology, fail to have this property, but instead have more complex rules for infection.  This leads to different spreading behaviors even on the same networks. Motivated by sociology research findings, this project will greatly enhance our understanding of social contagions in three aspects. First this project will provide rigorous study of the spreading behavior of a simplified theoretical model called k-complex contagions and its interactions with structures in the underlying graph such as tie strength, unusually influential nodes, and community structures. Second, this project presents a general model for studying cascades that is both theoretically tractable and practically motivated. The general model generalizes most previous theoretical models of complex and simple contagions and includes homophily and environmental factors on cascades. Finally, this project will use post-hoc analysis as well as real world social experiments to verify the veracity of the model and fit the parameters in different settings.
Cameras are now pervasive on consumer devices, including smartphones, laptops, tablets, and new wearable devices like Google Glass and the Narrative Clip lifelogging camera. The ubiquity of these cameras will soon create a new era of visual sensing applications, for example, devices that collect photos and videos of our daily lives, augmented reality applications that help us understand and navigate the world around us, and community-oriented applications, e.g., where cameras close to a crisis tasked with obtaining a real-time "million-eye view" of the scene to guide first responders in an emergency. These technologies raise significant implications for individuals and society, including both potential benefits for individuals and communities, but also significant hazards including privacy invasion for individuals, and, if unchecked, for society, as surveillance causes a chilling effect in the public square. This research couples a sociological understanding of privacy with an investigation of technical mechanisms to address these needs. Issues such as context (e.g., capturing images for public use may be okay at a public event, but not in the home) and content (are individuals recognizable?) will be explored both on technical and sociological fronts: What can we determine about images, what does this mean in terms of privacy risk, and how can systems protect against risk to privacy?<br><br>Specific research challenges to be addressed include formulating technical means through image and context analysis to improve the privacy of people captured in images; exploring the unique privacy needs of camera owners and how image and contextual analysis can improve privacy; and developing image transformations to afford privacy as well as enable novel applications using the cloud and crowdsourcing. Companion sociological studies will examine how context affects privacy perceptions, the impact on perception of new technologies, and image-sharing behavior. These studies will guide each other, ensuring that mechanisms for image transformation/privatization, non-visual transformations (e.g., altering or obscuring image metadata) and other techniques can improve both privacy protection against automated analysis and how they affect individual perceptions of the invasiveness of the technology. Through a deeper understanding of the privacy implications of such technologies from both a social and technical perspective, the proposed research has the potential for profound and positive societal impact by laying a foundation for privacy-sensitive visual sensing techniques for a society where cameras are ubiquitous.
Fast and robust solvers for systems of linear equations are the work horse of many communities in the sciences, engineering, business, and industry. Few pieces of software are so important of all these areas. Recent theoretical progress on efficient solvers for special cases of linear systems, including Symmetric Diagonally Dominant matrices, have sparked a renaissance in faster algorithms for wide classes of optimization problems that have not seen improvements in many years.<br><br>The main goal of this project is to take the next step to find and implement fast robust solvers that work in seconds on systems that are a factor of 100 to 1000 times larger than is now possible on a modern large workstation. For the applications mentioned above the solver may be called 100s or 1000s times for a single run. As a result, such a solver needs to meet several important requirements: 1) it must be robust enough to not need human intervention between these runs; 2) it must be fast enough to finish all work in a reasonable amount of time. 3) it must be able to handle the very different systems of equations that arise in applications.<br><br>This project aims to bridge the theoretical and practical aspects of designing efficient and robust solvers for linear systems in graph Laplacians. The PIs plan to develop code packages that have good practical performances as well as provable guarantees in the worst case. Doing so requires them to address a range of issues arising from numerical analysis, combinatorics, high performance computing, and data structures.<br><br>They plan to address shortcomings of existing packages for solving linear systems in graph Laplacians, specifically their robustness in the presence of widely varying edge weights. Resolving this issue is crucial for bridging the theory and practice of incorporating these solvers in optimization algorithms such as iterative least squares, mirror descent, and interior point methods. Specifically, they will study a variety of theoretical algorithmic tools from the perspective of high performance computing, focusing on topics at the core of data structures, high performance computing, numerical analysis, scientific computing, and graph theory. Progresses on them have the potential of opening up novel lines of investigations on well-studied topics for the team and the students that they will train.
The aim of this project is to develop mathematical models, analysis, and algorithms that will advance both the design and understanding of large-scale machine learning systems.  In recent years, machine learning has come into widespread use across a range of applications, and we have also seen significant advances in the theoretical understanding of learning processes. Yet despite these successes, there remains a gulf between theory and application.  For example, applications often demonstrate success on problems that theory tells us are intractable in the worst case.  Furthermore, as modern machine learning applications scale up from learning of single tasks to learning many tasks simultaneously, new theory is needed to analyze these larger scale multi-task learning settings.  This project aims to bridge this gap by developing and applying theory targeted toward realistic-case analysis of learning problems, which capture the structures that enable applications to succeed even when theoretical analyses show the impossibility of doing so in the worst case.  This work will be guided by problems at the core of NELL and InMind, two current learning systems that address large-scale multi-task machine learning problems, for reading the web and providing highly personalized electronic assistants to hundreds of interconnected mobile phone users.<br><br>More specifically, this project has three main components:<br><br>(1) To develop computationally efficient algorithms for clustering, constrained optimization, and related optimization tasks crucial to large-scale machine learning, with provable guarantees under natural, realistic non-worst-case analysis models.<br><br>(2) To develop foundations and practical algorithms for multi-task and life-long learning that exploit explicit and implicit structure to minimize key resources including computation time and human labeling effort, as well as address key constraints such as privacy.<br><br>(3) To apply the algorithms developed to solve key challenges in two current large-scale learning systems, NELL and InMind.<br><br>The proposed work will aid the development of large-scale machine learning applications, as well as create important connections between multiple areas of significant importance in modern machine learning and theoretical computer science. In addition to advising students on topics connected to this project, research progress (on multi-task learning, life-long learning, and clustering) will be integrated in the curricula of several courses at CMU and course materials will be made available on the world wide web. Course projects based on this research will be available to students in the introductory machine learning course at CMU, which enrolls over 600 students each year. In addition, students seeking topics for undergraduate thesis or independent study may also pursue research affiliated with this project.
YouTube competes with Hollywood as an entertainment channel, and also supplements Hollywood by acting as a distribution mechanism. Twitter has a similar relationship to news media, and Coursera to Universities. But there are no online alternatives for making democratic decisions at large scale as a society. As opposed to building consensus and compromise, public discussion boards often devolve into flame wars when dealing with contentious socio-political issues. This project aims to develop algorithms and platforms for collaborative decision making at scale. These platforms will be deployed in real decision-making processes, resulting in substantial broad impact.<br><br>Much of the work will be informed by participatory budgeting, where a group of users collectively produce a budget. Since budgetary constraints can be modeled as convex constraints, the insights from participatory budgeting will then be applied to more general convex decision spaces.<br><br>On the algorithmic side, the PIs propose to develop algorithms and mechanisms for consensus that go beyond simple voting. In complex decision spaces, the normal voting methodology of ranking a set of candidates breaks down, and we need new mechanisms. For example, for participatory budgeting, the users might be asked to solve a knapsack problem, providing a complete budget. This leads to exciting directions in incentive compatibility, opinion dynamics, fairness, and convex optimization.  Indeed, the PIs believe that this is the natural next step in the evolution of social choice theory, and would represent a substantial intellectual advance in both algorithms and mechanism design.<br><br>On the experimental and evaluation side, this work will take the deliberative polling methodology developed by Co-PI Fishkin, and design tools for extending it to participatory budgeting. This project will also evaluate how deliberative polling can scale to large online communities. This is a natural next step in the evolution of deliberative democracy.<br><br>On the deployment side, this project will advance our understanding of how to design interfaces for discussion, collaboration, and voting that lead to genuine deliberation and consensus on complex problems, as opposed to devolving into vitriol like many discussion boards and comment threads.
Graphics processing units (GPUs) were originally developed as specialized hardware exclusively for graphics rendering. In recent years they have become massively parallel systems with hundreds of processing cores supporting thousands of threads. Given their computational potential, they are now used to support general-purpose computation via high-level programming languages.  As a result, they have become a standard platform for high-performance computing (HPC) simulations in natural sciences.<br><br>However, there is still very little understanding of what types of algorithms translate into efficient GPU programs, and many implementations rely on a limited number of design patterns and many rounds of trial-and-error. There is a need for simple but accurate algorithmic models to get a wider algorithmic community involved in GPU computing. The project will develop such a model, intended to have the transformative effect of enabling algorithms researchers to focus their efforts on creating algorithms for GPUs in a way that is currently not possible, increasing the algorithmic knowledgebase in GPU computing. Over time, more efficient algorithms will lead to better utilization of computing resources and reuse of code implemented as libraries. Such a model for GPUs will also enable teaching GPU computing to a wider group of students, similarly to how sequential and PRAM algorithms are currently taught.<br><br>This project will study the algorithmic aspects of GPU computing and will develop a simple but accurate theoretical model for GPUs, that will define clear guidelines and complexity metrics for algorithm evaluation. The PIs will develop and implement algorithms that will improve the state of the art code base of general purpose computation on GPUs in the areas of combinatorial algorithms, computational geometry, visualization, search algorithms, and data structures.
As computer technology becomes increasingly pervasive in all aspects of our lives, it becomes critical for the researchers who develop algorithms to work closely with the domain experts who have a deep understanding of the underlying systems.  The purpose of the NSF Algorithms in the Field (AitF) program is to fund collaborations between theoretical computer scientists with other computing researchers.  Via this meeting, the program is providing an opportunity for its principal investigators to share and discuss their latest advances, demonstrate technical accomplishments, and inform NSF on promising future research directions.  The technical program agenda will highlight the contributions of the participating NSF divisions and address the research themes of the AitF program.  Student researchers will also attend and present their work.  This provides a valuable training opportunity and will contribute to the foundation for an enduring AitF research community.
The rapid rise in the use of mobile phones, social media, and digital sensors has created opportunities to observe and understand the rapidly changing structure of populations around the world. In particular, the data captured on these population-scale digital networks can inform policy-relevant questions about the evolving nature of societies around the world. For example, policymakers would like to know how idiosyncratic violence impacts the resilience of local communities, how the presence of foreign troops changes local patterns of interaction, and how draughts and natural disasters affect feelings of national solidarity. Unfortunately, appropriate models and algorithms do not exist to make sense of evolving, societal-scale data. This project will develop scalable algorithms to help make sense of real-world networked sensor data, with the potential for significant impact in the increasingly connected global society.<br><br> The technical focus of this project is on adapting recent algorithmic advances in the theoretical computer science and machine learning literatures to real-world, societal-scale network data. This approach will leverage recent advances in spectral methods, which provide provably efficient algorithms for estimating hidden structure in data and improve upon the state of the art in three important ways. The first objective is to adapt and scale current spectral models to real-world datasets with millions of interconnected actors, which have weighted and directed edges with heavy-tailed degree distributions. The second goal is to translate existing methods to dynamic regime, to address the non-stationary nature of real-world data. The third goal is to characterize the computational and statistical limits of what can be achieved with these models. The algorithms and tools developed through this research will be made available to the broader academic community via open source code repositories such as GitHub and BitBucket.
Graphics processing units (GPUs) were originally developed as specialized hardware exclusively for graphics rendering. In recent years they have become massively parallel systems with hundreds of processing cores supporting thousands of threads. Given their computational potential, they are now used to support general-purpose computation via high-level programming languages. As a result, they have become a standard platform for high-performance computing (HPC) simulations in natural sciences.<br><br>However, there is still very little understanding of what types of algorithms translate into efficient GPU programs, and many implementations rely on a limited number of design patterns and many rounds of trial-and-error. There is a need for simple but accurate algorithmic models to get a wider algorithmic community involved in GPU computing. The project will develop such a model, intended to have the transformative effect of enabling algorithms researchers to focus their efforts on creating algorithms for GPUs in a way that is currently not possible, increasing the algorithmic knowledgebase in GPU computing. Over time, more efficient algorithms will lead to better utilization of computing resources and reuse of code implemented as libraries. Such a model for GPUs will also enable teaching GPU computing to a wider group of students, similarly to how sequential and PRAM algorithms are currently taught.<br><br>This project will study the algorithmic aspects of GPU computing and will develop a simple but accurate theoretical model for GPUs, that will define clear guidelines and complexity metrics for algorithm evaluation. The PIs will develop and implement algorithms that will improve the state of the art code base of general purpose computation on GPUs in the areas of combinatorial algorithms, computational geometry, visualization, search algorithms, and data structures.
Many new Internet applications have extremely strict reliability and timeliness constraints.  For example, when trying to remotely manipulate an object (such as in remote robotic surgery), in order to provide seamless feedback the connection needs to be essentially uninterrupted and have delay of at most 130 ms. One way of achieving this is to build an overlay network: a small number of computers, strategically positioned in datacenters around the world, which communicate with each other over the Internet in a way designed to improve reliability while maintaining timeliness.<br><br>This project seeks to provide timeliness and reliability by sending messages over a select subset of the network, rather than along the best path, and to select subsets that are cost-effective. Successfully designing such techniques will enable applications that require timely, reliable service, well beyond what the current state-of-the-art can provide over the Internet. In addition to the practical benefits, this research will also significantly improve our understanding of the theory of overlay networks and network design: existing algorithms and techniques do not give the strong guarantees that are required, so we will need to develop both new algorithms and new mathematical tools to analyze these algorithms.  Hence this research will also have significant impact on the state of the art in the mathematics and theory of networking.<br><br>This project will develop new theory and a practical architecture for resilient routing. There has since been extensive work on designing approximation algorithms for related reliability-under-random-faults problems, as well as studying them for specific graph classes.  However, there has been almost no work on the network design versions of these problems, which form the theoretical aspects of this proposal.  Thus the results of this work will be a significant step forward in fault-tolerant network design. Moreover, the proposed research will advance the understanding of how to model practical networking problems and how to translate theoretical solutions into concrete systems, by evaluating solutions developed under different levels of abstraction in a fully realistic setting.
The National Science Foundation funds over seven billion dollars of research annually, nearly all of which relies heavily on information technology. The digital data produced and computing systems used by that research are subject to the same risks as other data and computing systems on the Internet. Appropriate cybersecurity is necessary both to make today's scientific discoveries possible and to ensure that the science is trustworthy. However, NSF science is often necessarily performed in open, collaborative environments that span organizational and national boundaries. These constraints limit the use of traditional cybersecurity paradigms and technologies. Moreover, maintaining the usability of computer systems while providing cybersecurity is critical for many scientists who are not information technology experts. Different science domains also have varying requirements for data confidentiality and integrity. As the NSF Cybersecurity Center of Excellence, the Center for Trustworthy Scientific Cyberinfrastructure (CTSC) brings together experts in cybersecurity, knowledgeable and experienced in the scientific endeavor, who will provide the NSF community with leadership and support necessary to tackle the unique cybersecurity challenges in maximizing the production of trustworthy NSF science.<br><br>CTSC will directly support individual NSF cyberinfrastructure projects and Large Facilities through collaborative engagements that address specific project needs. CTSC engagement activities include (but are not limited to) security reviews, security architecture design, identity and access management, and software assurance. CTSC will provide cybersecurity situational awareness to the NSF cyberinfrastructure community through timely advisories and notices. In collaboration with the Department of Energy's Energy Science Network, CTSC will develop and publish an information security threat model scoped to the particular assets and interests of the open science community. CTSC will continue to organize the annual NSF Cybersecurity Summit for Large Facilities and Cyberinfrastructure, providing the community with the opportunity to share best practices, attend practical training sessions, and collaborate on solving common challenges. CTSC will perform outreach and dissemination of best practices via the CTSC website (http://trustedci.org), blog posts, email lists, and online chats, as well as providing cybersecurity training in person and via online courses.
Discrete programming (DP) deals with optimization problems involving variables that range over a discrete (e.g., integer-valued) solution space. DP is an important tool in a variety of practical applications including digital communications, operations research, power grid optimization, and computer vision. While discrete programs are typically solved offline by sophisticated software using powerful computers, DP has recently emerged as an important tool in applications requiring real-time processing in embedded systems with stringent area, cost, and power constraints. Since existing DP solvers entail prohibitive complexity and power consumption when implemented on existing embedded hardware, novel algorithms and hardware architectures are necessary to unlock the potential of DP in real-time applications. This project fuses optimization theory, numerical methods, and circuit design to develop fast algorithms and suitable hardware architectures for real-time DP in embedded systems. Besides a thorough theoretical analysis of the proposed methods, the project includes extensive software and hardware benchmarking to reveal the efficacy of real-time DP in practice. To bridge the ever-growing gap between recent advances in numerical optimization and hardware design, the project also includes the development of undergraduate and graduate courses that build upon the vertically-integrated research approach of this project, in addition to offering summer research internships (REUs) to introduce young scientists to the field of discrete programming.<br><br>The project develops a set of computationally efficient and hardware-aware algorithms and corresponding dedicated very-large scale integration (VLSI) architectures that enable DP for real-time embedded systems.  The proposed DP algorithms rely on a variety of algorithmic transformations, ranging from semidefinite and infinity-norm-based relaxations to exact variable-splitting methods and non-convex approximations. These disparate approaches offer a wide range of tradeoffs between solution quality and hardware implementation complexity. The project studies these fundamental tradeoffs, as well as the effects of finite-precision arithmetic in VLSI, from both a theoretical and practical perspective. To carry out this investigation, three dedicated VLSI architectures will be developed that exploit the inherent parallelism of the proposed algorithms. These architectures target (i) data detection in multi-antenna (MIMO) wireless systems that is the key bottleneck in next-generation communication systems, (ii) signal recovery problems in hyperspectral imaging, and (iii) phase retrieval problems from x-ray crystallography. By investigating the domain-specific performance and complexity of various numerical solvers in a variety of conditions and hardware configurations, the project will reveal the efficacy and limits of DP for a broad range of real-time applications beyond the ones studied in this project.
Most modern computing systems contain multiprocessor hardware which is shared by many applications.  In these systems, good scheduling algorithms that decide how to allocate resources among applications are crucial to ensure good quality of service and efficient use of system resources.  This project will design foundational algorithms and prototype implementations of scheduling algorithms that provide guarantees of performance and resource utilization for these shared machines.  This work will shape the efficiency of critical computing infrastructure by improving performance of parallel systems from personal computers to data centers to supercomputers.   All results, including published articles and software artifacts, will be released to the public via world-wide web.  The PIs will integrate research with education by incorporating this research into the PIs' graduate courses and training PhD, MS, and BS students in applied and theoretical parallel computing research.<br><br>The project will involve designing practically efficient schedulers guided by theoretical foundations.  The PIs will design a theory of multi-programmed scheduling for parallel programs by considering a variety of scheduling objectives important to system designers.  In particular, the research will focus on optimizing latency objectives that are used in servers, clouds, and interactive systems.  The PIs will also explore efficient mechanisms that can be used to implement these algorithms in practice and perform empirical validations of their designs.  By combining theoretical analysis with feedback from empirical evaluations, the proposed work will gain insights that will advance the state of the art of both theory and practice of parallel job scheduling.
Swarm robotics explores how groups of robots can work towards a singular goal. Such a goal is typically achieved by equipping each robot with sensory capabilities, basic computing power, and actuation. The sensors detect something about the environment, this information is used to make a decision about the next action, and some resulting actuation is performed. Swarm robotics has made many advances in recent years, but it is still in its infancy.  The PIs will take a "task-oriented" approach and start from a desired macroscopic emergent collective behavior to develop the distributed and stochastic algorithmic underpinnings that the robots will run (at the microscopic level) in order to converge to the desired macroscopic behavior; as part of the process, they will also provide the understanding for yet unexplored  collective and emergent systems. The robots envisioned are small in scale, ranging in size from millimeters to centimeters, so that when deployed in crowded (i.e., dense) environments, they will behave as active matter, more specifically as macroscopic programmable active matter.  The emergent behaviors of interest for simulations include clustering (forming a tight-knit community that is mostly well-connected), compression (maintaining coherence of a connected community while minimizing perimeter), flocking (determining an agreed upon direction of orientation), and locomotion (collectively moving while maintaining cohesiveness). Many of these have interesting converse problems which are also equally worthwhile, such as exploration (maintaining a connected population, but exploring maximal area) and desegregation (preventing separation in a binary mixture of particles).<br><br>The PIs have strong records for interdisciplinary research, including initiating interdisciplinary areas, e.g., robo-physics (Goldman), self-organizing particle systems (Richa), and the fusion of statistical physics and randomized algorithms (Randall). The PIs also have a strong commitment toward supporting minorities, women, and undergraduate research (e.g., through NSF S-STEM programs at ASU; ADVANCE and S.U.R.E. programs at Georgia Tech).  This project will bring together techniques from multiple disciplines, and new research approaches and findings will be incorporated into graduate courses. Findings (including open source code) will be published in the various disciplines, and will be made available on the web and ArXiv.<br><br>The specific goals of this project are to work toward developing a theoretical framework for task-oriented active matter, informed by models of simple physical systems, that can realize and test the algorithms. The swarm robotics systems that biophysicists build to understand nature can be modified to perform the tasks these new algorithms require. The physical models will allow refinements to the theories under additional constraints, such as gravity and limited energy. It also will allow the PIs to test their algorithms for robustness, as physical systems admit some error.  The fundamentals of swarm robotics will be studied from a physics standpoint, by viewing the ensemble as active matter composed of programmable elements at the micro-level. Thus, a (macro-)task oriented approach will be followed in order to design a distributed, stochastic algorithmic framework to construct and evaluate algorithms at the micro-level that yield the targeted emergent macro-behavior.
Vast amounts of digitized images and videos are now commonly available, and the advent of search engines has further facilitated their access. This has created an exceptional opportunity for the application of machine learning techniques to model human visual perception. However, the data often does not conform to the core assumption of machine learning that training and test images are drawn from exactly the same distribution, or "domain." In practice, the training and test distributions are often somewhat dissimilar, and distributions may even drift with time. For example, a "dog" detector trained on Flickr may be tested on images from a wearable camera, where dogs are seen in different viewpoints and lighting conditions. The problem of compensating for these changes--the domain adaptation problem--must therefore be addressed both in theory and in practice for algorithms to be effective. This problem is not just a second-order effect and its solution does not constitute a small increase in performance.  Ignoring it can lead to dramatically poor results for algorithms "in the field."<br><br>This project will develop a core suite of theory and algorithms for PErceptual Adaptive Representation Learning (PEARL), which, when given a new task domain, and previous experience with related tasks and domains, will provide a learning architecture likely to achieve optimal generalization on the new task. We expect PEARL to have a significant impact on the research community by providing a much-needed theoretical and computational framework that takes steps toward unifying the subfields of domain adaptation theory and domain adaptation practice. Our theoretical and practical advancements will impact many application areas by allowing the use of pre-trained perceptual models (visual and otherwise) in new situations and across space and time. For example, in mobile technology and robotics, PEARL will help personal assistants and robots better adapt their perceptual interfaces to individual users and particular situated environments.  At the core of this project are three main research thrusts: 1) making theoretical advances for domain adaptation by developing generalized discrepancy distance minimization; 2) using the theoretical guarantees of generalized discrepancy distance to develop algorithms for key adaptation scenarios of deep perceptual representation learning, domain adaptation with active learning, and time-dependent adaptation; 3) advancing the theory and developing algorithms for the multiple-source adaptation scenario. In addition to our core aims, we plan to implement our algorithms within a scalable open-source framework, and evaluate our algorithms on large-scale visual data sets.
Over the past decades, the world's dominant computational infrastructure has gradually transitioned from individual personal computers to massive networked systems of unprecedented scale and complexity. Not only has this led to tremendous technological and engineering challenges, but it has also called into question fundamental assumptions in classical algorithmic theory. A defining distinction is the limited information that algorithms in such decentralized and heterogeneous systems have access to. For example, a content delivery network serves a heterogeneous set of end devices, and has to optimize performance often without knowledge of the device it is optimizing for. Similarly, a data center scheduler must be optimized for future demands that it is oblivious to. In this project, the PIs seek to address novel algorithmic questions in non-clairvoyant models of computation that arise in real world networked systems. The successful completion of this project will lead to new advances in building reliable and resilient information networks. The project will enable collaborations and exchange of ideas between theoreticians and practitioners, and will provide extensive training in real world algorithms to several graduate students, with attention paid to gender diversity and participation of under-represented groups.<br> <br>The goal of the project is to design novel algorithms with provable guarantees for networked systems in limited information settings. In particular, the PIs plan to address key algorithmic problems in the three dominant computational infrastructure models in the Internet: (a) data centers: allocating parallelizable jobs requiring multiple resources on processing nodes and clusters; (b) wide-area network of clusters: long-term planning of resource deployment and synergistic operations in the client-server model; and (c) P2P browser clouds: content delivery in web and gaming applications and swarm computing on a fabric of a large number of loosely coupled unreliable browsers. These problem domains are characterized by uncertainty and limited information for several reasons, including uncertainty about future predictions, autonomy of individual components in the networked system, and distributed implementation of the network architecture. The algorithms designed as part of this project will be evaluated on and optimized for real world testbeds.
The rapid development of information technology not only leads to great convenience in our daily lives, but also raises significant concerns in the field of security and privacy. Particularly, the authentication process, which serves as the first line of information security by verifying the identity of a person or device, has become increasingly critical. An unauthorized access could result in detrimental impact on both corporation and individual in both secrecy loss and privacy leakage. Unlike many existing studies on user/device authentication, which either employ specialized or expensive hardware that needs experts for installation and calibration or require users' active involvement, the emerging low-cost and unobtrusive authentication solution without the users' participation is particularly attractive to effectively complement conventional security approaches. Due to the rich wireless connectivity and unique signal characteristics in pervasive wireless environments, this project takes a different view point by exploiting unique physical properties in wireless networks to facilitate implicit authentication for both human and mobile devices. The proposed research could advance our knowledge in exploiting the physical layer information in wireless networks to capture unique physiological and behavioral characteristics from human during their daily activities. It could also enhance our understanding in developing deep learning techniques to authenticate people based on their activities in the physical environments. Additionally, the educational efforts include curriculum development, K-12 and undergraduate involvement, and underrepresented student engagement in research.<br><br>This project focuses on building a holistic framework that leverages fine-grained radio signals available from the commercial wireless networks to perform implicit user/device authentication. The proposed framework aims to advance the foundation of integrating fine-grained physical properties in wireless networks to enhance wireless security. The research reveals that the fine-grained signal properties in wireless networks are capable to capture unique physiological and behavioral characteristics from human in both stationary and mobile daily activities. The proposed framework develops smart segmentation on the wireless signals and extract unique features that enable the capability of distinguishing individual. It further develops deep learning techniques to authenticate people based on their daily activities in the physical environments. The authentication process does not require active user involvement nor require the user to wear any device. This project also develops efficient techniques to detect the presence of user spoofing and localize attackers to facilitate the employment of a broad array of defending strategies.
This project explores the design and analysis of peer grading technology.  A peer grading system is an online tool that collects student submissions, assigns review tasks to the students and graders, and aggregates reviews to produce assessments of both the submissions and the peer reviews.  The PIs have developed a prototype system and have collected preliminary evidence that suggests that peer review has important potential benefits:<br><br>1.  Learning by reviewing: Students learn from critical assessment of other students' work.  In the PIs' prototype at Northwestern, 60% of the students reported that peer review helped them learn course material and 55% of the students reported that peer review helped them to prepare better homework solutions themselves.<br><br>2.  Reduced grading staff: Peer grading reduces the grading load on course staff and allows for effective teaching with larger classes.  This is especially important currently, as interest in computer science classes increases at a faster pace than teaching resources.  In the PIs' prototype at Northwestern, the course staff graded 1/5 of the student submissions.<br><br>3.  Promptness of feedback: Reduced teacher grading enables prompt feedback to students.  In the PIs' prototype at Northwestern, peer reviews were available within three days and final assessment of both the submission and peer reviews were available within five days.  Prior to introducing peer review, assessments took one to two weeks.<br><br>A peer grading system is comprised of three main components:<br><br>1.  The review matching algorithm determines which peers should review which submissions and which submissions should be reviewed by the teacher.<br><br>2.  The submission grading algorithm aggregates the reviews of the peers and the submissions and assigns grades to the submissions.<br><br>3.  The review grading algorithm compares the peer reviews with the teacher reviews and assigns grades to the peer reviews.  Without this algorithm, peers may not put effort into providing quality reviews, and the reviews will be neither accurate for grading nor beneficial for the peer.<br><br>The details of these algorithms are crucial for the proper working of the peer review system.  A main research effort of this project is to identify the algorithms to use for each of these components.  The review matching algorithm affects the accuracy of the subsequent grading algorithms and the grading load of the teacher.  The submission grading algorithm determines which peer reviews are accurate and which are inaccurate and uses this understanding to assign grades to the submissions that are representative of the submission quality.  The review grading algorithm incentivizes the peers to put in sufficient effort to determine whether a submission is good or bad and it is calibrated so that good reviews and bad reviews get the appropriate review grades.  <br><br>The PIs have implemented prototypes of these algorithms as part of a peer grading system that has been prototyped in Northwestern computer science classes.  However, the space of possible algorithms is large and the PIs' work on the prototype has yet to determine the algorithms that combine to give the best education outcomes.  A main focus of this project will be improving the understanding of which algorithms lead to the best education outcomes.<br><br>Theoretical work in algorithms and machine learning provides a starting point for the project's study of good algorithms for peer grading systems.  A key endeavor of the project is translating and applying these theoretical algorithms to the peer grading domain.  As one example, proper scoring rules are a natural approach for grading the peer reviews.  However, test runs of the PIs' prototype implementation suggest that these rules might not be so good in practice.  Both new models and algorithms are needed in theory, and these new algorithms need to work in practice.
Wireless communications technology plays a critical role in society, supporting personal communication, business, defense and security, family connectivity, and entertainment. As new applications emerge, the demand for connectivity is increasing at a rapid pace. This development has put a strain on the available resources for communications: the spectrum is a finite natural resource; the most useful portions for mobile applications lie roughly from 700 MHz to 6 GHz. Large portions of it have been allocated to primary users, many of whom play socially critical roles. To accommodate the growing demand for wireless connectivity, there is a need for devices that can sense and utilize available spectrum in an opportunistic manner, while not interfering with primary users. The challenge is to do this in a time- and energy-efficient manner, on mobile devices. A general approach, which promises order-of-magnitude improvements in energy efficiency for rapidly detecting large interfering signals, uses a combination of new hardware to take a small number of measurements of the spectrum as a whole, and nontrivial algorithms to interpret those measurements. This project develops from machine learning to learn algorithms that are adapted to the specific characteristics of the hardware sensor, improving handling of non-linearities, yielding lower power sensors with improved sensitivity. The researchers are mentoring graduate and undergraduate students, whose work crosses disciplinary boundaries, and disseminating the results through new course development and a new textbook. <br><br>The project studies methodologies for learning and adapting algorithms for sparse recovery for RF spectrum sensing, leveraging a known connection to artificial neural networks, in which the structure of the algorithm dictates the topology and weights of the network. These weights can then be adapted and optimized to fit the characteristics of a physical sensor. A major promise of this approach is the ability to adapt to modeling errors, while simultaneously producing recovery methods that are more sensitive, more robust, and implementable in a simple and efficient manner. The project is developing a principled and transparent methodology, including theoretical characterizations of when and why it is possible to learn reconstruction and support recovery procedures that are effective in both typical and worst-case senses. The project studies these problems both for linear inverse problems and for nonlinear problems, both for sensing the spectrum at a single time, and for integrating information over time. The project experimentally evaluates the impact of these methodologies on the efficiency and sensitivity of hardware sensors, realized as integrated circuits.
Private information retrieval (PIR) is a cryptographic primitive that solves the seemingly impossible problem of letting users fetch records from untrusted and remote database servers without letting those servers learn which records the users are fetching. The research literature on PIR is vast; for over two decades, the cryptography, privacy, and theory research communities have studied PIR intensively and from a variety of perspectives; compelling applications for PIR abound in the resulting research literature. Alas, despite a series of significant advances, existing PIR techniques remain notoriously inefficient and none of the numerous PIR-based applications proposed in the research literature have been deployed at scale to protect the privacy of users "in the wild". This project entails an integrated research agenda that couples a strong theoretical component with an ambitious practical component centered around developing, analyzing, and implementing novel "batch" IT-PIR techniques, which can potentially alleviate the "prohibitive cost" problem for so-called information-theoretic private information retrieval (IT-PIR), the most performant and well-studied category of PIR protocols. Beyond improving performance, the new batch techniques also improve the "expressiveness" of PIR, exposing intuitive APIs through which applications can safely, easily, and efficiently interact with IT-PIR protocols.<br><br>PIR has long provided compelling solutions in theory to a wide array of important problems, but it has seen little adoption in practice due in part to the inefficiency and limited expressiveness of existing techniques. Indeed, traditional PIR constructions let users fetch just one data record at a time by encoding the record's index (i.e., its physical locations relative to the other records in the database) in a cryptographically protected query. This project builds on preliminary results by the PI, which extend that basic functionality to not only let users fetch several records (i.e., a "batch" of records) for a lower cost than that of fetching each record separately, but also to let users fetch such batches of records using "contextual" queries that specify which data they seek, as opposed to "positional" queries that specify where those data happen to reside in the database. The main research goals are to (i) develop theoretical frameworks to better understand the mathematics underlying batch IT-PIR, to (ii) use insights gained from these frameworks to improve upon and generalize the known constructions, and to (iii) use the improved constructions to implement practical, privacy-respecting alternatives to a selection of existing privacy-agnostic products and services. The new batch IT-PIR constructions will be incorporated into the open-source Percy++ library, an effort which will deeply involve both graduate and undergraduate students.
This CISE Research Experiences for Undergraduates (REU) Site award funds the renewal of an outstanding REU site at Indiana University - Purdue University Indianapolis. The site will recruit undergraduates from across the nation to participate in research topics related to mobile cloud security, which focuses on issues related to the use of mobile devices such as smart phones and the secure use of mobile clouds to access, manage, store, and secure digital assets. Mobile cloud security is an area of current interest that is well-suited to undergraduate research productivity. The students will use controlled and competitive test environments to experiment with cyber attack and defense techniques needed to secure the mobile devices that are pervasive in our society. This site should help develop a group of computing professionals who can develop the systems of the future that impact society and enhance our quality of life. The REU experience provides students with the foundations and inspiration to pursue computing careers and research in areas that are rapidly evolving and impacting all of our citizens. This site is co-funded by the Secure and Trustworthy Cyberspace program.<br><br>The is project is led by an outstanding team offering state-of-the art facilities and professional mentors to guide undergraduates in explorations of problems related to mobile cloud security. Students will learn how to use current tools and techniques to solve those problems that have direct impact on people. The team will use proven strategies to recruit undergraduate students from groups traditionally under-represented in computer science including African American, Hispanic and female students. The students will participate in research and professional development activities all designed to achieve the goals of retaining and graduating undergraduate students in computer science and engineering, recruiting students from groups traditionally under-represented in computing fields, and increasing recruitment of students into graduate programs.
Understanding the history of life on earth ? how species evolved from their common ancestor ? is a major goal of biological research. These evolutionary trees are very hard to construct with high accuracy, because nearly all of the most accurate approaches require the solution to computationally hard optimization problems. Furthermore, research has shown that the evolutionary tree for a single gene can be different from the evolutionary tree for the species, and current methods do not provide adequate accuracy on genome-scale data. As a result, large evolutionary trees, covering big portions of ?The Tree of Life?, are very difficult to compute with high accuracy. This project will develop methods that can enable highly accurate species tree estimation. The key approach is the development of novel divide-and-conquer strategies, whereby a dataset is divided into overlapping subsets, species trees are constructed on the subsets, and then the subset species trees are merged together into a tree on the full dataset. These approaches will be combined with powerful statistical estimation methods, to potentially transform the capability of evolutionary biologists to analyze their data. This project will also provide open source software for the new methods that are developed, and provide training in the use of the software to biologists at national meetings. The project will also contribute to interdisciplinary training for two doctoral students, one at Illinois and one at Berkeley, and course materials for computational biology will be made available online.<br> <br>Understanding evolution, and how it has operated on species and on genes, is a major part of biological data analysis. Statistical estimation approaches often provide the best accuracy, but cannot scale to dataset sizes that are required for modern biology. In addition, species tree estimation is challenged by the heterogeneity of evolutionary trees across the genome, and no current methods are able to provide highly accurate species trees for genome-scale data. These challenges make it essential that new methods be developed in order to make highly accurate large-scale evolutionary tree estimation possible under these complex evolutionary scenarios.  This project will develop novel algorithmic strategies to address three key problems: supertree estimation, species tree estimation in the presence of gene tree heterogeneity, and scaling statistical methods to large datasets. In addition to developing graph-theoretic algorithms, the project team will establish mathematical guarantees for these methods using chordal graph theory and probabilistic analysis, under stochastic models of gene and sequence evolution.
Discrete programming (DP) deals with optimization problems involving variables that range over a discrete (e.g., integer-valued) solution space. DP is an important tool in a variety of practical applications including digital communications, operations research, power grid optimization, and computer vision. While discrete programs are typically solved offline by sophisticated software using powerful computers, DP has recently emerged as an important tool in applications requiring real-time processing in embedded systems with stringent area, cost, and power constraints. Since existing DP solvers entail prohibitive complexity and power consumption when implemented on existing embedded hardware, novel algorithms and hardware architectures are necessary to unlock the potential of DP in real-time applications. This project fuses optimization theory, numerical methods, and circuit design to develop fast algorithms and suitable hardware architectures for real-time DP in embedded systems. Besides a thorough theoretical analysis of the proposed methods, the project includes extensive software and hardware benchmarking to reveal the efficacy of real-time DP in practice. To bridge the ever-growing gap between recent advances in numerical optimization and hardware design, the project also includes the development of undergraduate and graduate courses that build upon the vertically-integrated research approach of this project, in addition to offering summer research internships (REUs) to introduce young scientists to the field of discrete programming.<br><br>The project develops a set of computationally efficient and hardware-aware algorithms and corresponding dedicated very-large scale integration (VLSI) architectures that enable DP for real-time embedded systems.  The proposed DP algorithms rely on a variety of algorithmic transformations, ranging from semidefinite and infinity-norm-based relaxations to exact variable-splitting methods and non-convex approximations. These disparate approaches offer a wide range of tradeoffs between solution quality and hardware implementation complexity. The project studies these fundamental tradeoffs, as well as the effects of finite-precision arithmetic in VLSI, from both a theoretical and practical perspective. To carry out this investigation, three dedicated VLSI architectures will be developed that exploit the inherent parallelism of the proposed algorithms. These architectures target (i) data detection in multi-antenna (MIMO) wireless systems that is the key bottleneck in next-generation communication systems, (ii) signal recovery problems in hyperspectral imaging, and (iii) phase retrieval problems from x-ray crystallography. By investigating the domain-specific performance and complexity of various numerical solvers in a variety of conditions and hardware configurations, the project will reveal the efficacy and limits of DP for a broad range of real-time applications beyond the ones studied in this project.
The electricity distribution grid --the low-voltage line networks that distribute power to end consumers--is about to undergo a major transformation. More and more consumers are becoming "prosumers", namely consumers and producers of power at the same time, by installing solar panels (PVs) on their home roofs and by purchasing electric vehicles, which may be used for energy storage. Traditionally, power in distribution grids has flown one way: from the substation to the end consumer. In the new world of prosumers, distribution grids need to accommodate flow in both directions. This is challenging the existing wire and transformer abilities to serve load at acceptable quality levels. Moreover, the increasing number of prosumers is resulting in dramatically higher uncertainty in demand forecasting, which, with further prosumer increase, may prove unsustainable and ultimately threaten the utility companies' operation and business viability. This research advances the fields of computation and economics as well as the power systems domain, by contributing with novel algorithmic and mechanism design problem formulations and techniques, and with solutions that can enable improved distribution grid planning and operation. In terms of broader impact, this research has the potential to improve aspects of the grid such as planning for increased integration of renewable energy resources, mitigation of risks associated with variability of renewables, better management of congestion in the face of strategic prosumers and ultimately provide for more reliable, cost effective and efficient operation of the grid. <br><br>The goal of this project is to help the distribution grid and its participants transition from its current functionality of serving mostly traditional consumers, to the future grid that needs to sustainably integrate prosumers, renewables and distributed energy resources, via: (1) Developing simplified mathematical models to solve combinatorial and incentive problems that will enable the future power grid to sustain massive growth in renewables and distributed energy resources; (2) Designing new algorithmic and mechanism design approaches that reduce congestion, and improve the investment and operational efficiency of the grid while further enhancing its reliability; (3) Working with Distribution Utilities for real-world models and operational advice, while facilitating the transfer of research findings to practice.  The scope of the project includes (i) distribution network reconfiguration, (ii) distribution system upgrades and (iii) market mechanisms for supply-demand balancing.  The research relies on methods from approximation algorithms and mechanism design, such as submodular optimization, stochastic combinatorial optimization, and price of anarchy analysis.
This research will leverage ideas from algebraic and differential geometry to address core problems in modern high-dimensional and massive data science. The project will develop statistical methods and numerical tools, grounded in solid mathematical, statistical, and computational foundations, to extract low dimensional geometry from massive data with applications in clustering, data summarization, prediction, dimension reduction, and visualization. The solutions developed as part of this project can result in fundamental advances in practical applications across fields as diverse as biology, medicine, social sciences, communication networks, and engineering. In addition to internal validation via statistical and mathematical theory and simulation studies, the methods developed in the project will involve external validation via interdisciplinary applications. These applications include: (1) inference of population structure from genomic data; (2) document analysis via topic models; and (3) inference of subsets of putative gene networks relevant to drug resistance in melanoma.<br><br>The research is motivated by the central premise that, even though the amount of data may be massive, a compact model can represent these data. Specifically, high-dimensional and/or massive data can be reasonably approximated by a mixture of subspaces, for which sparse representations exist. A mixture of subspaces of potentially different dimensions is a flexible, rich representation of data with nice mathematical properties that can scale to large data. There are several fundamental challenges in modeling mixtures of subspaces that will be addressed in this research: 1) the subspaces will be of different dimensions, 2) both the subspace parameters and the mixing parameters need to be inferred, 3) efficient algorithms for inference are required for both high-dimensional and massive data. The central foundational impediment in all of these challenges is that the model is a stratified space (a union of manifolds), and therefore has singularities. The key insight in this research is that there exist embeddings and representations of the model space that mitigate these singularities. These ideas are implemented as concrete Bayesian, frequentist, and numerical algorithms and models to address the real world examples listed above.
Big data analytics is, fundamentally, the problem of bringing the massive amounts of data produced today down to human scale. In particular scientists, engineers, physicians, and many others in knowledge-intensive professions face data that is beyond human scale. This data is in the repositories that collect the data and the reports or results in their fields. This project will address the problem of bringing all this knowledge under control by using even more data, namely the individual and social patterns of how these repositories are accessed and used, and user-specific judgments (valuations) of the data. The proposed research will develop novel algorithms and an open-source infrastructure for improving discovery within and access to data repositories. These algorithms will aggregate and analyze the social analytic data, gathered from professional communities of data users, and will motivate them to participate by providing recommendations.<br><br>The transformative goal is to develop methods for organizing, and operationalizing the access and preference patterns of users of large repositories, and for integrating those valuations to accelerate discovery within the collections. Diverse human minds interacting with data collections, as they carry out their own research or operational activities, provide a powerful source of information about the value of the data itself. Those data items may be textual documents, numerical datasets, or other kinds of media content. The novel methods for representing, aggregating, organizing and valuating interactions between the users and the items can reveal structures within data collections, which were previously invisible to any individual. This discovery of interrelations within data, driven by the capture of human intelligence, will accelerate the processes of scientific discovery. Users who are permitted to valuate data, and who are motivated by receiving valuable recommendations in return, reveal more about their own interests. This makes it possible to discover relations among the data items and among the users themselves. The educational goals are to: (a) contribute to the education of specific graduate students supported by the project, and undergraduates via the REU mechanism; (b) generate new educational materials related to algorithmic innovations, and to research findings; and (c) improve access to and discovery within specific collections of materials. Research findings will be included in courses at all three collaborating universities.<br><br>Additional information about the project (including publication, software, data sets) will be made available through the project web site: http://arxiv_xs.rutgers.edu/.
The outcomes from this project is to assist human operators in their disaster management coordination and planning, such as directing a medical physician's team to their nearest cluster of affected people in a region to administer medications as necessary, or finding a safe route for evacuation of affected people. Sensor data integrated with microblogs such as Tweets help identifying some local events and people's sentiments, which are significantly useful in handling/understanding disaster situations. It will also benefit other applications such as real-time tracking of road/driving conditions in vehicular networks.<br><br>This research is conducted jointly with Osaka University in Japan, to benefit both the universities in enhancing not only their knowledge but also to learn global perspective in solving important problems. The research team is designing schemes for dynamic and collaborative data compression and multi-streams compression of multi-dimensional sensor data with error correction and recovery for addressing the energy efficiency and bandwidth limitation issues. Compression schemes exploit temporal locality and delta compression to provide better bandwidth utilization. Different methods for measuring error are designed and compared for the compressibility and actual error for variations in methods of utilizing the error tolerance. In addition, the team is developing algorithms for highly scalable indexing schemes for efficient data retrieval involving mainly range queries, top-k query, ranked-based searches and snapshot queries for multi-dimensional sensor data from different data sources to address the issue of timely dissemination. Hilbert Curve based linearization technique integrated with an overlay network is designed to (1) map multidimensional attributes onto a single dimension while preserving its data locality, and (2) to create a balanced network by associating only one node with each leaf of the virtual tree and then partition the multidimensional search space into subspaces and assign each node to a unique subspace. This allows an overlay network to start from a predefined prefix to handle data skewness. This research is also designing a scheme for using microblog messages as social sensors for efficient integration with other sensor data. We are using machine-learning techniques to match each message with its associate location based on the characteristics of the message. The results will be validated and evaluated using the sensor cloud test-bed available at Missouri S&T.
The recent emergence of a variety of high-throughput DNA sequencing instrumentation, and the concomitant rapid decline in the cost per base, is causing severe data deluge in all areas of life sciences. The heterogeneity of sequencing instrumentation and the vast diversity of applications enabled by them are creating numerous analytics problems for the bioinformatics community to address. In addition, the conventional serial algorithms that have been the mainstay of bioinformatics research are severely challenged by the ever increasing data sets. The goal of the proposed project is to develop core techniques and software libraries to enable scalable, efficient, high performance computing solutions for high-throughput DNA sequencing, also known as next-generation sequencing (NGS). To empower the larger community, the project seeks to 1) identify a set of core functionalities that frequently occur in many types of high-throughput sequencing applications, 2) develop efficient parallel algorithms and high performance implementations for them, 3) pursue mapping to HPC architectures including clusters, multicores, and GPUs, 4) develop software libraries encapsulating these functionalities with the goal of enabling the bioinformatics community to exploit HPC architectures, and 5) design a domain specific language to enable bioinformatics researchers unfamiliar with parallel processing to benefit from this work through automatic generation of parallel codes. The research will be conducted in the context of challenging problems in human genetics and metagenomics, in collaboration with domain specialists.<br><br>This project is focused on a key capacity building activity to facilitate pervasive use of parallelism by NGS bioinformatics researchers and practitioners. The goal is to empower the broader community to benefit from clever parallel algorithms, highly tuned implementations, and specialized HPC hardware, without requiring expertise in any of these. The software libraries will be released as open source for use, further development, enhancements, and incorporation by the community. The project will provide opportunities for training postdoctoral and graduate students in bigdata analytics and computer science driven interdisciplinary research. Diverse existing mechanisms at the partner institutions will be leveraged to advance goals of minority and women recruitment, undergraduate participation in research, and K-12 outreach.
This project aims to assess how online data impacts the hiring process. In an ideal situation, one might imagine that employers hire the most skilled applicant, but sociological research indicates that this may not be the case. A job applicant's similarity to the interviewer in class background and class-based leisure activities often matters as much or more to employers than a job applicant's skills or work experience. The ability of a recruiter or employer to learn such information from seemingly unrelated data has led researchers to express concerns about privacy, job relevance, and the potential for discrimination. This is the first stage in a larger project that aims to illuminate how online information impacts the ability of job seekers to find employment in post-recession United States. The project creates a framework for identifying systematic patterns of discrimination in regionally specific job markets, and also provide a fuller picture of precisely when in the hiring process are certain forms of discrimination likely to take place (upon submission of resume, at interview stage, and so on). In addition, the collected data will enable job seekers to discover how online information affects their employability, and aid the development of strategies to align online data and professional profiles. <br><br>The researchers will develop a novel mixed-methods framework to better understand the hiring process and study hiring discrimination by combining ethnographic studies of employers and companies that aggregate applicant profiles; surveys of applicants' background, skillset, and job-seeking history; online profile aggregation; and traditional data mining techniques. This project will contribute to the understanding of how employment works in the United States, and the types of online information that may limit employability. The problem will be addressed across populations that have varying demographic profiles and skill sets, and whose primary industries vary greatly. The proposed analysis will capture regionally specific hiring practices and reveal insights into the kinds of demographic indicators that work for or against job seekers in different regions.
This project seeks better ways to protect individual privacy in big data without compromising the accuracy of population-level information for research and public use. The differential privacy community has explored private release of datasets, but this has largely been within the computer science theory community and has not rigorously evaluated the practical utility of the methods. This project develops techniques and tools to create synthetic "surrogate datasets" with the same structure and statistical properties as the original dataset, but satisfying differential privacy. The work includes development of techniques to generate synthetic data amenable to statistical analysis, evaluation of the techniques in real-life big data, and to develop and release as open source tools for dataset creation. This project brings a statistician's viewpoint to the utility question, and evaluates against both simulated data, the census record based ADULT dataset frequently used in anonymization studies, and two real datasets, one with hospital inpatient data and the other a social science study on poverty. The work is being featured in several community outreach programs to stimulate interests in STEM careers among K-12 students.<br><br>The project builds on multiple synthesis (generating multiple datasets from posterior distribution-derived sufficient statistics). The project is first establishing theoretical and methodological foundations, including but not limited to mathematical derivation of the global sensitivity of the sufficient statistics in commonly used statistical models, establishment of a theory that guarantees individual privacy protection in released data, and establishment of large-sample inferential theories on the synthetic data. Probability theory, stochastic process, asymptotic theory, Bayesian modelling and computing, and missing data analysis techniques are heavily employed. To ensure scalability to Big Data, sufficient statistics whose scalar components do not increase as the number of data items increases are being investigated. The developed method is evaluated by simulation studies and applications to real life data sets (including social/financial data and health care data) benchmarked against current methodologies for releasing individual-level data. Finally, open-source software is being developed for release on the Comprehensive R Archive Network that produces a synthetic dataset matching the schema of the original data, as well as certain statistics to explain disclosure risk and support analysis of data utility.
The planned research aims to radically transform the current state of the art of dimension reduction, through the development of new approaches to interpretation, resolution, and feature extraction for high-dimensional dynamical data. These extensions fit into a larger program of data analysis which seeks to find the intrinsic geometry tailored to each type of data set. The development of diffusion maps first established a new way to recover geometry from generic data sets. Recently, we showed how to recover the intrinsic geometry for observations of a dynamical system, meaning data sets that have the additional structure of a time ordering. In each case the focus on discovery of the intrinsic geometry for the particular structure of the data resulted in significant practical benefits in the form of new algorithms for dimensionality reduction and noise reduction. With this progress as a foundation, the proposal greatly expands the impact of this effort in two important directions: (1) Overcoming critical weaknesses in the current dynamical diffusion map approach, by (a) extensions to allow drift and anisotropy in the Laplace-Beltrami operator represented by the diffusion map, and (b) merging diffusion maps with discrete exterior calculus through the Hodge star operator to handle higher-dimensional dynamics; and (2) development of an automatically-constructed, data-adapted harmonic (or wavelet) basis in order to capture essential features of spatiotemporal data. Our data-adapted construction starts with an a priori spatial structure and then combines this with the data itself to form the data-adapted spatial geometry. We then propose a novel method of using the diffusion geometry, improved with the results of (1), to find symmetries in the adapted geometry that represent intrinsic features of the data. <br><br>The project involves a series of investigations in the development of computational dynamical systems theory and methods, with the goal of significantly changing the way massive spatiotemporal data sets are analyzed. The algorithms resulting from the study represent a distinctly new form of time-scale and space-scale separation that can break high-dimensional dynamical data into parts adapted to the dynamics. This new approach will handle a wide range of spatiotemporal inputs, such as high-frame-rate videos of physical experiments, spatially and temporally irregular geophysical databases such as oceanographic, weather or climate time series, econometric and logistical databases, and multivariate measurements on complex dynamic networks such as biological connectomes. The data comes from problems spanning diverse areas of sciences and engineering, with special focus on physical and biological systems. These modern high-resolution data sets are particularly vulnerable to the curse of dimensionality, making current parametric statistical techniques impractical due to exponential increases in model complexity and data requirements. Our approach implicitly eliminates redundancies and selects features of interest in an automatic data-adapted way, reducing the data requirements for statistically significant analyses to feasible levels. Educational impacts include integration of the research topics into undergraduate and graduate teaching, and the enhancement of research infrastructure through joint research with collaborators in physics, bioengineering, biology, and medicine.
Scientific Bigdata sets are becoming too large and complex to fit in RAM, forcing scientific applications to perform a lot of slow disk and network I/O. This growth also makes scientific data more vulnerable to corruptions due to crashes and human errors. This project will use recent results from algorithms, database, and storage research to improve the performance and reliability of standard scientific data formats. This will make scientific research cheaper, faster, more reliable, and more reproducible.<br><br>The Hierarchical Data Format (HDF5) standard is a container format for scientific data. It allows scientists to define and store complex data structures inside HDF5 files. Unfortunately, the current standard forces users to store all data objects and their meta-data properties inside one large physical file; this mix hinders meta-data-specific optimizations. The current storage also uses data-structures that scale poorly for large data. Lastly, the current model lacks snapshot support, important for recovery from errors.<br><br>A new HDF5 release allows users to create more versatile storage plugins to control storage policies on each object and attribute. This project is developing support for snapshots in HDF5, designing new data structures and algorithms to scale HDF5 data access on modern storage devices to Bigdata. The project is designing several new HDF5 drivers: mapping objects to a Linux file system; storing objects in a database; and accessing data objects on remote Web servers. These improvements are evaluated using large-scale visualization applications with Bigdata, stemming from real-world scientific computations.
This research explores ways to simultaneously improve both the scalability and privacy of blockchain technologies. A blockchain is a massively distributed, append-only log of transactions that is cryptographically protected from tampering. Thanks to their capacity towards facilitating fast and inexpensive transactions across the globe and their powerful scripting-language support for complex financial instruments, blockchains have already proven to be a highly disruptive force in the finance and e-commerce sectors. Nevertheless, at least two major hurdles still stand in the way of mainstream blockchain acceptance: 1) 'traditional' blockchain architectures are not sufficiently scalable to handle the ever-growing base of blockchain users and the resulting proliferation of transactions, and 2) despite myriad efforts to improve blockchain privacy, users of public blockchains remain susceptible to devastating attacks on the privacy of their accounts and transactions, which often lead to security breaches causing financial losses for the victims. The approaches explored in this project provide privacy for blockchain users where previous efforts have failed by rethinking the one-size-fits-all approach of using Tor to solve all problems requiring anonymity and/or unlinkability. Indeed, running complex protocols over Tor is fraught with risks and can open users to subtle-yet-devastating deanonymization attacks; the tailor-made solutions developed in this project leverage domain-specific knowledge to mitigate these risks.<br><br>The project addresses privacy concerns as they relate both to traditional blockchain transactions and to newer 'payment channel network' transactions. Payment channel networks promise greatly improved scalability by allowing secure (off-chain) payment requiring no interaction with the blockchain ledger. In the context of traditional blockchain transactions, this research develops innovative ways to 1) privately publish transactions to a blockchain by integrating tailor-made anonymous communication protocols directly into the blockchain communication infrastructure, and 2) privately retrieve transactions from a blockchain using carefully optimized private information retrieval (PIR) protocols that support expressive blockchain queries. In the context of payment channel networks, the project 1) explores the (im)possibility of performing off-chain transactions privately, and 2) develops a new theoretical framework and toolkit of algorithms for ensuring availability and quality of service for payment channel transactions in extreme adversarial conditions. Additionally, as part of this project, the multi-institution and transnational team of PIs are deploying a distributed instantiation of the new private blockchain transaction retrieval solutions, which will be open to use by the public. Along with training graduate students, the project puts a major emphasis on undergraduate involvement in this emerging area of blockchain research.
The goal of this project is to develop new methods for unsupervised learning from multivariate data based on counting and comparing frequencies of data patterns. A recursive testing approach will be used to infer the multivariate distribution. The investigator will use hardware-algorithm co-design to achieve qualitative improvement over existing methods in computational time as well as in the maximum data dimension and sample size that can be handled. The economic feasibility of making this methodology widely available will also be investigated. <br><br>This research is motivated by the challenge of "Big Data" analysis where the high dimensionality and extremely large sample size had made it infeasible to apply traditional statistical methods. The new methods developed in this project will be applied to several "big data" applications such as the analysis of videos, next generation sequencing data and microblogs. By developing the statistical methods for such analyses as well as customized computing resources to make these methods scalable to extremely large data sets, this research will enable more effective use of the rich information embedded in these data. Finally, the multidisciplinary approach integrating statistical, computational and hardware expertise is well suited for the training of next generation data scientists.
The recent financial crisis has accentuated the need for effective monitoring, oversight and regulation of financial markets and institutions. Complex market structures involving intricate interconnected relationships among financial institutions can help propagate and amplify shocks and hence also foster systemic risk. This project develops an integrative framework, based on accounting principles, that leverages a wide array of diverse quantitative financial datastreams, complemented by metadata and market announcements for the purpose of identifying and predicting market participants that could endanger the overall financial system.<br><br>The proposed research builds upon modern statistics and computer science works, as well as recent financial and economic ideas aimed at assessing threats to financial stability and uncovering the complexity of financial systems in different market conditions. It will result in both new methods for complex Big Data and empirical results that can advance the state-of-the-art in financial research, as well as tools that support and enhance financial policymaking and decision-making. Key tasks of the project include: (1) Develop a rigorous accounting framework to integrate multiple financial and econometric data streams from many platforms and technologies. (2) Develop and customize a range of new network models and analysis tools for use with multiple financial data streams. An important idea will be to extend network and econometric tools in order to compare the structural evolution of different types of networks in response to external events and policy changes.
Microscopy is a pillar of modern science, which enables us to understand, inspect and improve on nature. While the technology of modern microscopes has progressed by leaps and bounds in the past decades, the methods used by microscopists to analyze data remain primitive. Common to new and emerging modalities of microscopy is the generation of massive, multi-dimensional data sets. This project develops fundamental analysis tools to extract basic motifs from these datasets; in particular, from data produced by scanning tunneling microscopes. These analysis tools will transform microscopy imaging by improving the quality and statistical significance of atomic-scale observations of materials. Key analysis goals that will be addressed include guarantees that algorithms produce models which accurately reflect the physics of the material of interest, and that algorithms perform reliably on practical data which may contain noise and errors. Key experimental goals include the generation of large scale data sets from multiple microscopy modalities which will be used to test and extend the analysis tools.<br><br>The project leverages recent advances in high-dimensional nonconvex optimization to address fundamental challenges in convolutional data modeling, the problem of modeling data as superpositions of translated motifs. Because the goal is to produce accurate information about novel materials whose properties are not yet understood, the investigators seek algorithms which exhibit (i) guaranteed performance,(ii) robustness to gross errors and (iii) scalability to massive, high-dimensional datasets. Building on recent progress in dictionary learning, the investigators study the properties of efficient methods for recovering models with one or more motifs. They seek highly scalable algorithms for these problems, using Riemannian optimization and active set methods. They study variants which are robust to commonly occurring gross errors, including pixel and scanline corruption, and contrast variations. The algorithms are applied to study materials for which previous analysis methodologies fail, including materials with multiple types of defects, quasiparticle interference, and high temperature superconductors. For each of these materials, high resolution scanning tunneling microscopy and spectroscopic imaging will be performed to produce large-scale, multidimensional data sets. Data sets on well-studied materials will be used to test and verify analysis algorithms, and the application of these algorithms to data sets on novel materials will be used to transform our understanding of the electronic structure of complex materials. Data sets on other microscopy modalities will also be obtained to generalize analysis tools to multiple scales in space, time and energy.
The world is being changed by Big Data, and data science is receiving a remarkably rapid uptake across the nation and the globe as it institutionalized in university curricula, state governance, and industry strategy. Across the sciences, state and industry, new forms of data collection and analysis hold the prospect of our being able to address the major social and scientific issues of our times: from responding to natural disasters to monitoring the environment to developing fundamental technological insights which will revolutionize industry. None of this will happen by fiat ? the development of the appropriate data analytics must be accompanied by new organizational alignments between research, policy and industry. The Big Data Hubs and Spokes (BDHubs) program is a key site for analyzing the nature of these alignments with a view to gaining a basic understanding of the stakes as the terrain shifts. All long-term research and innovation infrastructure must adapt to such ongoing changes. This research will contribute to understanding institutional flexibility: strategies, techniques and organizational innovations to adapt to changes in regulatory, policy and funding environments. We can expect but not precisely predict, continuing transformations in the sociotechnical, scientific and institutional ecologies of today?s research and scientific infrastructure. This project will investigate the ongoing activities at the BDHubs and its partner institutions, their emerging plans for the future, and tie these to the long-history of developing research infrastructures (50+ years) to understand the changes we can expect BDHubs to encounter over time (scientific, technological and institutional), and what strategies they employ in the face of transformations to the landscape of science, information technology and institutional environment. <br><br>Many challenges facing contemporary science such as environmental research or chronic disease management require long-term studies and supporting infrastructures. This project will contribute directly to NSF and other efforts to build more open, effective, and sustainable knowledge communities across the sciences, industry and government. Improving understanding of the long-term trajectory of research infrastructure will lead to smarter and more sustainable investment and design choices on the part of project leaders, participants, tool builders, and funders. Many other science agencies are in the midst of funding such cross-cutting projects. This research will inform science policy and regulatory environments to help develop sustainable and productive research infrastructures. In order to do so, this study will develop a general organizational understanding of the development of large-scale and long-term endeavors in the data sciences and map the institutional landscape of modern data science with particular focus on the activities of infrastructure building, policy development and community formation. In addition, this study will help to develop an understanding of the ?rise of the data sciences? in the US both as an institutional movement and as a form of technical research, with special focus on establishing a framework for evaluating and understanding large-scale, cross-disciplinary collaboration on big data tools, techniques and methods.
The objective of this project is to develop optimization and control techniques and integrate them with real-time simulation models to achieve load balancing in complex networks. The application case is the regional freight system. Freight moves on rail and road networks which are also shared by passengers. These networks today work independently, even though they are highly interdependent, and the result is inefficiencies in the form of congestion, pollution, and excess fuel consumption. These inefficiencies are observed for example by the peaks of demand across time and space. Inefficiencies exist in part due to lack of information and appropriate tools, and in part due to lack of policies and institutional structures that would promote more integrated operations. The problem is made even more complex due to the large quantities of real time data that will be available to inform the decision-making.<br><br>This research develops the theoretical foundations of a new approach referred to as COSMO to balance loads across complex dynamical networks with temporal and spacial characteristics. In contrast to current practices where simple mathematical models are used to predict the states of the network the method employs computational simulation models that are far more accurate in estimating the states of the network by taking into account dynamics and complex interactions. The project develops the optimization and load balancing control segments of the cyber physical system and integrate them with real time network simulation models using freight transportation as the driving application area. The research also examines how identified barriers and policy issues/incentives can be incorporated as mathematical constraints and/or control variables in the optimized dynamic freight load balancing system. Data supporting the analysis may include freight characterization, traffic, weather, and other large data volumes. The project will utilize real time data from the port of Los Angeles /Long Beach area to validate the approach. The port of Los Angeles/Long Beach is the port of entry for much of the freight that enters the West Coast, and provides rich sets of data that will stimulate the model especially in regional transportation involving interaction between road/rail/port networks. This fundamental technology in this important transportation domain with direct applications to other large scale freight centers, can be applied to other application domains including networking and smart grid. Besides the broader impact derived from more efficient allocation of transportation resources, the project also provide educational outreach and produce course modules.
-Part 1:<br><br>Cloud computing can transform computer science research and education through on-demand, elastic, and self-serve access to computation and storage resources at scale, coupled with contemporary hardware (e.g., graphical and tensor processing units), advanced software stacks (e.g., machine-learning libraries), and shared data sets. Researchers and educators can avoid the substantial time, energy, and expense of building and maintaining local infrastructure, students can be better prepared for the cloud-centered world they will enter upon graduation, and research projects across institutional boundaries can more easily share and maintain data and the results of their analysis. <br><br>Although academic adoption of the cloud is increasing, significant challenges remain. Researchers worry about the relative costs compared to local infrastructure, especially when some local costs are hidden (e.g., "free" rack space, cooling, and power, as well as lower overhead charges on grants for equipment purchases). Graduate students worry about causing run-away costs if their experiments in the cloud run amok, and the risk of escalating costs near major paper submission deadlines. Some projects may not be able to use the public cloud, due to privacy issues (or the perception of increased privacy risk) concerning the underlying data. Plus, for both researchers and educators, making the transition to the cloud requires overcoming a "learning curve" to select a particular cloud offering---and learn how to use it effectively. <br><br>This workshop will identify opportunities and challenges for Computer and Information Science and Engineering (CISE) researchers and educators to use the cloud, and recommend steps the major stakeholders can take to lower the barriers to cloud adoption. By convening a diverse community of stakeholders who can contribute to the strategic development of a cloud-computing roadmap, this workshop will lower the barriers for cloud adoption for academic research and education in CISE. The perspectives and insights shared from industry, government, and academia, coupled with discussions focused on actionable challenges and measurable outcomes, will serve to advance CISE research and education. The workshop will identify high-priority topics and high-impact opportunities for future research, training, and collaboration in conjunction with cloud computing.<br><br>-Part 2<br><br>The workshop will engage about 35-45 participants from academic, industry, and government, including principal investigators, educators, cloud-computing researchers, campus CIOs, public cloud providers, and government funding agencies. The workshop will focus on several key issues including, (1) CISE research and the cloud: What types of CISE research are (or are not) best enabled by cloud platforms? (2) CISE education and the cloud: What types of CISE education are best enabled by cloud platforms? What novel concepts can be taught? (3) Key challenges with cloud usage: What are the barriers to cloud adoption and how should the stakeholders address these issues? (4) Relationship among various types of resources: What roles should on-campus resources, national resources, and cloud-provided resources each play in supporting research and teaching? (5) Cloud costs: How can researchers and educators best manage the costs of cloud usage, including the risks of runaway costs or costs that continue after a grant funding a project has ended? (6) Education for prospective cloud users: What are good ways to educate and train researchers, students, and campus IT staff on using the cloud effectively? (7) Ongoing user support: What ongoing support is needed for academic users, whether locally or at the national level? <br><br>The workshop will host a series of presentations and working sessions with live note-takers, resulting in a post-meeting white paper describing key themes, insights, and recommendations from the discussions. Lowering the barriers to academic use of the cloud has the potential to significantly improve how CISE researchers and educators conduct their work. Using the cloud can reduce IT costs, foster cross-institution and interdisciplinary research collaborators, and better train students for a cloud-centric world. Innovations in cloud computing services can help cloud providers recognize new opportunities ahead of future commercial demands, while better supporting academic research and education.
Scientific discovery is a collective process based on collaboration, assessment and consensus. But the enormous expansion of scientific research makes it difficult to tell which intellectual efforts forge collective advances. Better models for identifying and tracking scientific movements from the vast collections of articles, books, grants, and patents that compromise scientific and academic work is crucial to improving our nation's ability to make advances in science and industry, helping policy makers, funding agencies, and venture capitalists as well as scientists and scholars themselves. Our project studies innovation by collecting and analyzing texts in vast collections of scientific and other scholarly articles, books, grants and patents. By looking at the subtle patterns of language and how they change over time, we can describe and predict where and when collective trends of knowledge innovation emerge and decline; which scientific ideas and movements result in translational knowledge key to industry and health care; and what the key drivers are for such collective intellectual movements. This work is helping identify where the potential is greatest for innovation, which fields are most primed and receptive to the arrival of new discoveries, and the times and places where resources have the greatest influence.<br><br>The project is based on a large dataset of texts the researchers have compiled on US research activity from 1990-2016, including scientific articles, grants, and patents, and by disambiguating and linking mentions of individual people across these datasets. This project uses topic modeling and other natural language processing algorithms to identify distinct intellectual movements in these corpora by drawing on the sub-languages that characterize them, also applying methods to validate and evaluate these movements. This allows the researchers to model the trajectories of movements over time with tools like latent growth mixture modeling and k-spectral clustering, identifying the mechanisms associated with each movement, how they rise and fall over time, and how they translate into industrial or health applications. For example, the project studies how the trajectory of intellectual movements is a function of their environment and competing research efforts, and show the ways in which it depends on the timing and magnitude of key resources (e.g., money, recognition, new recruits and trainees, social networks of support, or the coherence of the knowledge itself). In such a fashion, this work is an important first step in unraveling the recipe for innovation as a collective, episodic process.
The past decade has seen dramatic growth in systems that collect data from human activities. Online social networks record not just friendships, but interactions, messages, photos, and interests. Mobile devices track location via GPS information. Online stores monitor millions of customers as they explore and transact. Sensors, wearable and otherwise, produce detailed behavioral data. Collectively, this provides ever-larger collections of human social-activity information -- we refer to this as Big Social Data. While Big Social Data is growing rapidly, the available processing resources -- CPU, memory, communication -- are growing at a slower pace. To realize the promise of big social data, we need algorithms that use only sublinear resources, that is, resources growing much less than the growth of the data in suitable parameters. Designing these algorithms will be the core activity of this research project. This work will be in consultation with practitioners handling Big Social Data, leading to many opportunities for technology transfer. The research program both enables and benefits from an education and outreach program that will help develop the new breed of algorithmically-trained data scientists for Big Social Data.<br><br>Emerging systems -- MapReduce, Hadoop, Spark, Storm, etc. -- use large scale distributed computation: clusters of machines not only gathering and storing data in parallel, but also working together to perform computations. Often, these systems and applications work via incremental processing, storing and returning only approximate solutions, trading off quality and certainty for efficiency. In addition, these systems take a data-centric view, wherein the data is stored as <Key, Value> pairs. This project will address fundamental problems with Big Social Data -- search, ranking, and optimization, etc. in these modern computing and data models. For these problems, this project will design algorithms that are sublinear in the relevant parameter -- number of keys, size of values, computing time per key or over all keys, and other variations that map to underlying storage, number of machines, bandwidth and other computational constraints.<br><br>For further information, see the project web site at http://www.stanford.edu/~ashishg/socialdata.html .
This big data project develops tools to support researchers and developers in the task of prototyping multimedia content analysis algorithms in a large scale. Typically, scientists and engineers prefer to use high-level programming languages such as Python or MATLAB to conduct experiments, as they allow for a quick implementation of a novel idea. Experiments on big data, however, are often computationally-intensive and therefore must eventually be recoded into a low-level language by expert programmers in order to achieve sufficient performance, creating a gap between productivity and performance. In addition, multiple strategies may exist for mapping a problem onto parallel hardware depending on the input data size and the hardware parameters, further exacerbating the problem. Using the application area of multimedia content analysis as an example (an area with one of the largest and the fastest growing amounts of data due to the steady upload of consumer produced videos), this project performs research on a pattern-oriented, application-specific specialization framework that uses a tiered approach to parallel programming. The ultimate aim is to provide the scalability of diverse parallel processing at the productivity level of high-level languages.<br><br>Social media videos are increasingly being used for scientific research, as they allow us to observe and model many phenomena studied, for example, in social sciences, economics, meteorology and medicine. More scalable content analysis impacts any field that uses social media videos. Moreover, social media videos are an everyday part of many people's lives. Making multimedia content analysis more scalable allows for better algorithms to be developed by more students and researchers, and therefore impacts many people's lives. The framework is made available on the project website (http://smash.icsi.berkeley.edu).
This workshop engages a multidisciplinary community in a discussion about taking the initial steps in building an evolving Open Knowledge Network to encode all entities and the relationships among them, that would evolve continuously with new data and information. The OKN would thus be a fundamental building block in evolving the world-wide web to a new level of semantic understanding and application. The vision of such a knowledge graph is feasible given the availability of big data that are growing with time; advanced machine learning techniques that can aid in the creation of such a massive graph, and in its use; and, importantly, demonstration of the power of such knowledge graphs via extant commercial services such as Apple Siri; GoogleTalk; Amazon Alexa, and Microsoft Cortana. An Open Knowledge Network would enable a new generation of knowledge-rich intelligent applications and systems. <br><br>The workshop examines the applicability of this idea across multiple disciplines and applications domains. Experts from a wide range of disciplines, including biomedicine, medicine, geosciences, finance, and manufacturing, will discuss domain-specific issues as well as identify common approaches and common issues that cut across domains. The workshop will develop concrete steps to be taken to help realize the vision of OKN.<br><br>Natural interfaces to large knowledge structures have the potential to impact science, education and business to an extent comparable to the WWW. While the first wave of such technology is now available in consumer services such as Siri, GoogleTalk, Cortana and Alexa, these services are limited in their scope of knowledge; not open to direct access or to contributors beyond their corporate firewalls; and, able to answer only relatively limited questions in specific business domains. An open initiative of the type being proposed would allow for experimentation at scale across many user communities and would support research and innovation in academia, enable industry to experiment, and enable governments at various levels (local, state, federal) to create new services using Open Data. The vision for the proposed OKN is that it would aspire to be a listing of every known concept from the worlds of science, business, medicine and human affairs. It would include not just raw data, but semantic information in machine readable form. The architecture would allow contributors to encode the knowledge related to their topics of interest and, thus, connect that to the larger network, without having to go through so-called "gatekeepers". By providing an open service, OKN would enable the notion of "permission-less innovation." Indeed, an open resource like OKN may be in a better position to provide more trustworthy information/knowledge than proprietary, closed systems. The vision for creating such a common knowledge network resonates with the NSF Big Ideas of Harnessing the Data Revolution and Convergence.
In the context of social networks, "big data" generally involves information on very large social systems whose elements of interest display complex dependence. State-of-the-art statistical models for such systems require the use of computationally expensive stochastic simulation techniques to capture this dependence; these techniques do not generally scale well to the large-population case. One potential solution to this problem is to focus detailed modeling efforts on smaller subpopulations (e.g., groups, communities, etc.) extracted from the larger system. While scalability of the subsystem models is less challenging in this case, one must have appropriate methods for sampling from large networks in such a manner as to permit principled inference, and modeling techniques that recognize the coupling between local subpopulations and the broader network in which they are embedded.<br><br>The PI will bridge the gap between expensive, highly detailed models and the limits of computability imposed by Big Data by combining expertise from machine learning and social network modeling within a unifying exponential family framework. The research will develop novel methods for the scalable measurement and analysis of large social networks, validating these techniques by deploying them in the context of dynamic data collection from online social networks. Specifically, the researchers will combine probabilistic graphical models and exponential family random graph models (ERGMs) to: (i) identify models with low computational requirements by exploiting limited-range dependence; (ii) develop machine learning techniques for identifying weakly coupled regimes in large networks to facilitate sampling and subgraph modeling; and (iii) develop integrated sampling and modeling strategies for inference from subgraphs of large networks that capture coupling to the structures in which they are embedded. This proposal investigates these questions in both the cross-sectional and dynamic contexts, for networks with and without vertex attributes. The sampling techniques created via this project will be deployed as an extension of a broader infrastructure for data collection in online social networks developed and maintained by one of the PIs, allowing for evaluation in a practical setting.<br><br>The methods developed via this research will allow for analysis of data relating to many problems of public interest, including epidemiological, security, and emergency management applications; data collection and analysis activities within the project will include applications in the natural hazard context, with the potential to inform policies that can save lives and property during disasters. The project will be integrated with graduate and undergraduate education, as well as postdoctoral mentoring. Tools developed via this project will be released as part of a widely used open-source toolkit for statistical network analysis (statnet), allowing widespread dissemination to researchers and practitioners in a range of fields.
This proposal supports 15-20 students for their travel to attend the 2017 Annual International Cryptology Conference (CRYPTO), sponsored by IACR (International Association of Cryptologic Research), in cooperation with the Computer Science Department of the University of California, Santa Barbara. CRYPTO is a highly selective conference in cryptography, attracting students, researchers and industry specialists from all over the world. The scope of research papers accepted to CRYPTO range from the theoretical foundations of cryptology to application and implementation of cryptographic schemes. As such, it fits closely with the goals of NSF's Secure and Trustworthy Cyberspace (SaTC) program, which include applied cryptography and implementation of cryptographic schemes.
The fundamental objective of ubiquitous sensing and control in engineered and natural systems is to understand, analyze, and optimize operational conditions of these systems. Although the classical feedback control theories lay a solid foundation to enable meeting operating goals and constraints based on the assessed system states, the traditional control paradigm has limited applicability to the modern dynamic big data and complex systems. The fundamental challenge is the efficiency of processing, fusing, and computing of data from multiple heterogeneous and distributed sources to arrive at a timely and optimal decision. This project will develop innovative approaches to enable seamlessly and efficiently integrating unprecedented dynamic interactions of multiple entities multimodal and multi-fidelity data collection activities, and the computing of systems operational conditions at different levels and scales. The technological developments will enable the evaluation of a very large decision space for multiple entities in the system in an efficient and robust manner, and scale up to the big data environment brought forth by ubiquitous sensing. The research outcome has a potential to significantly advance the state of the art in dynamic data system, simulation, and optimization research, potentially opening a new avenue to improve the execution of a large variety of application systems. The research, while generic and applicable to other dynamic data engineered systems, is specifically motivated by the big data problem in semiconductor industry, a crucial sector of the US and world economy. Research findings will be disseminated through technical publications and presentations as well as classroom teaching where a new multi-disciplinary course will be developed at GMU and offered to a wide-range of students. <br><br>The objective of this exploratory research is to develop a new scalable computational paradigm for real-time optimal resource allocation in dynamic data systems. The transformative aspect of this research is the recognition that the successful execution of a dynamic data system relies on real-time global situational awareness and the capability to translate awareness into (near) optimal resource allocation decisions in a timely manner. The fundamental technical breakthrough is a new multi-scale and multi-fidelity simulation and optimization framework that integrates data collection and decision making at multiple scales and multiple fidelity levels in an adaptive, efficient, and robust manner. Multi-scale simulation and optimization allows identifying promising local scale resource allocation decision using localized data. Local scale resource allocation decisions are then evaluated by global scale multi-fidelity simulation and optimization in search of the optimal system-wide decision. Such an integrated multi-scale and multi-fidelity paradigm exploits the responsiveness at local scale and the global situational awareness at the global scale, and thus has the potential to attain both efficiency and robustness in the real-time decision making process. Through efficient and scalable fusion of multi-modal and multi-fidelity data, distributed entities in the system monitor the operating conditions of the dynamic data system and autonomously control the instrumentation and data collection process in response to perturbations in system operating conditions. With value of information, the decision model enables joint evaluation of data collection, computing, and resource allocation decisions to dynamically schedule and prioritize tasks that would contribute most to the successful execution of dynamic data systems.
At a time when thousands of scientists are creating millions of datasets describing an increasingly diverse mix of neuroscience phenomena, the chances of an individual unaided scientist finding all of the data relevant to a particular line of investigation are shrinking every day. At the same time, this rapid increase in the amount and diversity of stored data implies a corresponding increase in the potential of these datasets to empower important new collaborative research and discovery. Meeting these challenges requires tools specifically created to assist scientists in their search for relevant datasets and collaborators. Massive number of relatively small datasets gathered and generated by individual scientists and groups, form a distinct class of Big Data called the "long tail of science" data and harnessing their hidden power is crucial for advancing science. This project will engage in a set of planning activities for the application of a novel data discovery system for Neuroscience, based upon a platform called, DataBridge, which has been developed by the investigators and their collaborators under a grant from the NSF Big Data program. DataBridge applies "signature" and "similarity" algorithms to semantically bridge large numbers of diverse datasets into a "sociometric" network. Prior work has focused on data from the Social Sciences. This work will study the extension of those techniques to the Neuroscience domain. If the techniques can be demonstrated to work with neuroscience data, the project would have broad impact not only in the neuroscience research community but, potentially, in other science communities as well.<br><br>Neuroscience is at an inflection point where more and more data are being aggregated and shared through common repositories. The main challenge facing the neuroscience community in the Big Data era is the difficulty of discovering relevant datasets across these repositories. The complication of effective discovery and identification of relevant data forms the last mile problem for long tail of science data. Solving this problem can increase the value of the data through reuse and repurposing and can immensely benefit the NSF Brain Initiative by providing increased access to data in its various thematic areas. This project will initiate studies on the application of a novel data discovery system for Neuroscience based upon a platform called DataBridge, which the project team has developed under a grant from the NSF Big Data program. DataBridge applies "signature" and "similarity" algorithms to semantically bridge large numbers of diverse datasets into a "sociometric" network. The DataBridge for Neuroscience platform will attempt to harness complex analytics algorithms developed by neuroscience researchers in order to extract key signatures and find data associations from large volumes, and diverse collections, of so-called "long-tail" neuroscience data. By providing a venue for defining complicated search criteria through pattern analysis, feature extraction and other relevance criteria, DataBridge provides a highly customizable search engine for scientific data. This project will conduct a preliminary, feasibility study on the applicability of DataBridge on Neuroscience data with two goals: 1. Implement a pilot DataBridge system for Neuroscience and demonstrate a proof of concept for semantically bridging a small collection of neuroscience datasets, and 2. Conduct a workshop to develop a coalition of users from the neuroscience community in order to build a sustainable DataBridge-based infrastructure for neuroscience. This community-based activity will leverage the community infrastructure created by the NSF Big Data Hubs and Spokes program.
The sparsity of large networks makes it difficult to efficiently extract features for machine learning algorithms. Recent work on network embeddings (DeepWalk) has revealed how neural language modeling can be applied to a very general class of graph analysis problems in data mining and information retrieval. This project will improve training algorithms and data representation for large-scale networks, creating better, more powerful graph embeddings for weighted and attributed networks. It will also enable meaningful comparison of the relative performance of network connectivity features vs. more text-oriented features. It is possible that there might be more usable information in links than in the readable content itself.<br><br>This project will develop these methods in several new directions, including extensions to new graph classes and speed/scale enhancements. The original DeepWalk induced latent representations only from unweighted, undirected, and connected graphs. But there is considerable interest in applying it to more general graphs arising in data analysis. Doing the right thing on such natural networks as bipartite and disconnected graphs presents surprisingly subtle issues of theoretical and practical significance. This project will also explore several ideas to increase training performance of network embeddings, including more efficient gradient updates and improved graph sampling methods and particularly the power of self-avoiding random walks to oversample otherwise rare nodes. This project seeks to extend the effective range of DeepWalk by several orders of magnitude, from the 10 million vertex graphs we routinely handle today to web-scale networks on billions of nodes. The broader impacts of this work are far reaching across data mining and information retrieval, including user profiling/demographic inference, online advertising, and fraud detection. The software and data resources developed under this research project will be released as open source. They will be directly applicable to the biomedical and social sciences, and serve as both an educational and scholarly resource. For further information, see the project website at http://www.cs.stonybrook.edu/~skiena/deepwalking.
Big Data often results from multiple sources, giving collections that contain multiple, often partial, "views" of the same object, space, or phenomenon from various observers. Extracting information robustly from such data sets calls for a joint analysis of a large collection of data sets. The project is developing a novel geometric framework for modeling, structure detection, and information extraction from a collection of large related data sets, with an emphasis on the relationships between data. While this approach clearly applies to data with a clear geometric character (e.g., objects in images), the work is also applied to datasets as diverse as computer networks (identifying common structure in subnets) and Massive Open Online Course homework data (automatically carrying grader annotations to similar problems in other students' homeworks).<br><br>The novel framework is based on the construction of maps between the objects under considerations (point clouds, graphs, images, etc...), and on the analysis of the networks of maps that result as a way of extracting information, generating latent models for the data, and transporting or inferring functional / semantic information. These tasks define a new field of map processing between data sets and require tool sets with new ideas from functional analysis, non-convex optimization, and homological algebra in mathematics, and geometric algorithms, machine learning, optimization, and approximation algorithms in computer science. Sophisticated algorithmic techniques for attacking the large-scale non-linear optimization problems that emerge within the framework will also be investigated.
We live in an era when vast amounts of data are being generated at a low cost in several domains of science and engineering. However, advances in analytics tools have not caught up with data generation. In particular, existing tools take too much time. A main reason is that core memories of computers cannot hold all the data to be analyzed -- most of the data have to be stored in secondary storages (SSs) such as solid state drives and (rotating) disks. Data access times from SSs are several orders of magnitude more than from core memories. Tremendous speedups can be obtained by minimizing the number of data accesses from SSs. Also, although there has been much recent research in the development of multicore and GPU algorithms for biological problems, for many of the problems only sequential in-core algorithms are known.<br><br>This project is to develop novel out-of-core algorithms for biological big data (BBD) analytics. The proposed novel parallel algorithms employ various architectures including heterogeneous clusters of multicores and GPUs, to solve BBD problems. The developed novel scalable algorithms can handle petabytes of data and beyond for data mining applicable over varied datasets. This interdisciplinary project provides a new computation suite for mining voluminous biological and other data. This project provides educational opportunities to graduate and undergraduate students to get first-hand research experience in computational aspects of biological data analysis.
The past two decades have witnessed the development of accurate and efficient computational methods for a wide range of physical processes and the transition of these models into regularly used tools for product design and development within all sectors of the US economy. One important exception to this trend is in the field of material science where progress in creating new classes of materials and advancing the use of existing systems is hampered by the lack of validated computational models. Of particular interest in this proposal are structural polycrystalline metals, of central importance in the automotive, aircraft, and energy industries, where the processes of fatigue and fracture pose significant modeling and computational challenges. To resolve these issues, dynamic high-energy X-ray diffraction (HEXD) experiments have recently come on line that are capable of probing the internal evolution of samples of these materials in real time as they are subject to processing or service conditions. The resulting data sets are both large (up to 10Tb for a single experiment) and complex thereby complicating their analysis and integration within the material design process. Even with extensive human interaction, state-of-the-art computational tools can extract only a tiny fraction of the full information contained in these data sets. Realizing the potential offered by these data and models requires fundamentally new Big Data-type of computational methods. The work in this project is aimed at developing such a tool set. <br> <br>Of specific concern in this project are the use and extension of sophisticated, probabilistic, video processing methods as the basis for addressing a pressing problem in the analysis of dynamic HEXD data. The physics of X-ray diffraction from polycrystalline samples gives rise to data sets comprised of temporally evolving collections of localized structures, referred to as "spots," in a three-dimensional data space. Use of these data in conjunction with computational plasticity codes requires that these spots be associated with individual grains in the polycrystal and that these sets of evolving structures be tracked over time. To date, the only tools for addressing this indexing problem are static in nature and function best for cases where the material sample is in a pristine state. Similarities between this dynamic indexing problem and the problem of identifying and tracking objects moving in a video scene motivate the adaptation and further development of a multi-hypothesis tracking approach developed by the PI team to the analysis of HEXD data. The method is based on the construction of a conditional random field over a large set of hypotheses capturing ways in which spots can be associated with one. Estimation of the optimal tracks and association is carried out using efficient graph cut methods making the overall approach well suited to near real time implementation. The existing work in this field will be extended through the construction of dynamic models for the evolution of features associated with the spots (e.g., centroid location, low order moments) based on existing plasticity codes and incorporation of these models into the random field to achieve a multiple model, multi-hypothesis tracking approach for dynamic HEXD data.
Genomes contain the complete set of instructions for building an organism. Structural variants are rearrangements in the genome such as insertions and deletions, whose discovery advances the understanding of the evolution and the adaptability of species. Recent advances in high-throughput sequencing technologies have led to the collection of vast quantities of genomic data. Because of this, fast and robust algorithms are needed to identify structural variants, which are rare and are prone to noise. This research will contribute fundamentally to optimization methods for large-scale problems in computational genomics. The algorithms will be disseminated publicly for use within and outside the biology, mathematics, and computer science community. Graduate students will be trained in scientific research and programming through this interdisciplinary research, and the participation of students from under-represented backgrounds will be highly encouraged. <br><br>The research objective of this award is to develop computational tools for large-scale data-driven problems arising in computational genomics. These problems are especially difficult to solve since they are high-dimensional and the data are noisy and inexact. This study will take advantage of known relationships in sequenced genomes to improve the accuracy of identifying genomic variants in population studies when there is both low coverage in the data and multiple related individuals are sequenced. Specifically, the proposed research will (i) explore statistical models for describing the presence of structural variants in genomes, (ii) develop and implement novel sparse optimization methods for genomic structural variant detection, and (iii) validate on existing genomic data sets and predict on new data.
This RAISE project is jointly funded by the Big Data Spokes and BIGDATA Program in the Division of Information and Intelligent Systems in the Directorate for Computing and Information Science and Engineering; the Condensed Matter and Materials Theory Program in the Division of Materials Research and the Office of Multidisciplinary Activities in the Directorate for Mathematical and Physical Sciences; and the Office of Integrative Activities. <br><br>Large amounts of data get generated in every field of science and engineering. Effective tools are needed to analyze these data and extract useful information. During the past two decades, much progress has been made in the domain of biological data analytics. Clearly, if we can translate this progress to other domains, we can avoid repetition of efforts and also speedup discoveries in the other domains. This project will promote translation of approaches and tools first developed for biological genomics to materials genomics. To maximize scientific impact and use in industry and academia, the software tools to be built will be disseminated to a wide audience. The participation of women and other underrepresented groups will be promoted by leveraging collaborations with the Northeast Big Data Hub and strong, existing institutional programs to encourage diversity at the University of Connecticut. The project will allow many students to gain significant classroom and research experience using the software tools, and they, in turn, will form the core of the highly trained workforce that is essential for the advanced industries critical to our nation's economy. <br><br>Some of the existing tools developed for biological data may not be directly applicable for materials data. In such cases, novel algorithmic techniques will be developed to suitably modify them. This project will engineer tools for the analysis and discovery of materials to accelerate research in Materials Science. The project will support workshops to bring together scientists from bioinformatics and materials science. The interactions among scientists from these areas are expected to result in crosscutting advances in big data analytics and hence create transformative knowledge. The Northeast Hub as well as the Materials Science Spoke will participate in the project's dissemination effort.
The NSF Big Data Innovation Hubs (Big Data Hubs) will organize and co-sponsor a Trans-Atlantic Workshop on Public Private Partnerships for Big Data Research & Innovation and Workforce Development in Versailles, France, on November 20, 2017, in conjunction with the European Big Data Value Forum 2017 (http://www.european-big-data-value-forum.eu), and in cooperation with the EU Big Data Value Association, PICASSO Project, and INRIA, and also work towards organizing additional workshops to ensure a continuing dialogue among US and EU researchers and educators.<br><br>The goals of the first workshop are to bring together academic and industry actors from the United States and the European Union (EU) to: (1) discuss effective models and practices for supporting academia-industry collaborative research programs in Big Data/data science research and innovation, with particular focus on public-private partnerships (PPP) in the application domains of smart cities, transportation, health, environment, and food-energy-water; (2) identify opportunities for direct bilateral research and innovation collaborations (at the project level and between individual researchers) and data sharing between the US and the EU, especially between the NSF Big Data Hub & Spoke projects and the European BDV PPP Lighthouse projects along the verticals listed above; and (3) discuss effective models and practices for bridging data science workforce needs with the developing academic discipline of data science.<br><br>Videoconferencing meetings are planned between US and EU researchers to discuss priorities in Big Data research and applications areas, and to plan for potential subsequent<br>workshops. The lessons learned from the first workshop will directly influence and determine the direction and structure of future workshops, after which plans will be drawn up for those future meetings.<br><br>The intellectual merit of this activity is that it will serve as a platform for bringing the US Big Data Hubs, European Big Data Value Association, and PICASSO project teams and associated communities together for sharing their collective knowledge about successes and pain points in coordinating data science research and innovation activities. This dialogue will afford a deeper understanding of complementary approaches, technologies and policies for (1) building effective public-private partnerships focused on Big Data<br>research and innovation and (2) establishing data science curricula that satisfies the needs of stakeholders across domains and on both sides of the Atlantic.<br><br>This activity is expected to have significant broader impact?it represents a critical step in forging a productive transcontinental relationship around Big Data research and innovation, facilitating US-EU collaborations and access to international data sets. In addition, it will highlight overlap and synergies between the US Federal Big Data Strategic R&D Plan and EU Big Data Strategic Research Agenda, and will prioritize future and emerging research challenges, which could inform potential jointly funded strategic trans-Atlantic collaborations in Big Data/data science research and innovation. The workshop also will allow participating organizations to explore opportunities for sharing open-source data collections and industry-relevant curricula of Big Data education programs that can be used for workforce development.
Molecular dynamics simulations studying the classical time evolution of a molecular system at atomic resolution are widely recognized in the fields of chemistry, material sciences, molecular biology and drug design; these simulations are one of the most common simulations on supercomputers. Next-generation supercomputers will have dramatically higher performance than do current systems, generating more data that needs to be analyzed (i.e., in terms of number and length of molecular dynamics trajectories). The coordination of data generation and analysis cannot rely on manual, centralized approaches as it does now. This interdisciplinary project integrates research from various areas across programs such as computer science, structural molecular biosciences, and high performance computing to transform the centralized nature of the molecular dynamics analysis into a distributed approach that is predominantly performed in situ. Specifically, this effort combines machine learning and data analytics approaches, workflow management methods, and high performance computing techniques to analyze molecular dynamics data as it is generated, save to disk only what is really needed for future analysis, and annotate molecular dynamics trajectories to drive the next steps in increasingly complex simulations' workflows. <br><br>The investigators tackle the data challenge of data analysis of molecular dynamics simulations on the next-generation supercomputers by (1) creating new in situ methods to trace molecular events such as conformational changes, phase transitions, or binding events in molecular dynamics simulations at runtime by locally reducing knowledge on high-dimensional molecular organization into a set of relevant structural molecular properties; (2) designing new data representations and extend unsupervised machine learning techniques to accurately and efficiently build an explicit global organization of structural and temporal molecular properties; (3) integrating simulation and analytics into complex workflows for runtime detection of changes in structural and temporal molecular properties; and (4) developing new curriculum material, online courses, and online training material targeting data analytics. The project's harnessed knowledge of molecular structures' transformations at runtime can be used to steer simulations to more promising areas of the simulation space, identify the data that should be written to congested parallel file systems, and index generated data for retrieval and post-simulation analysis. Supported by this knowledge, molecular dynamics workflows such as replica exchange simulations, Markov state models, and the string method with swarms of trajectories can be executed ?from the outside? (i.e., without reengineering the molecular dynamics code).
This project will develop novel theoretical methods and algorithms for clustering massive datasets with applications to astronomy, neuroscience and natural language processing. Clustering is the process of creating groups of data based on similarities between individual data points. The developed theoretical methods will be used in applications where clustering algorithms are critical and the input data is extremely large. First, new clustering algorithms will be designed to scale and will allow for better cosmological simulations. The simulations involve billions of particles in each snapshot, and existing clustering algorithms based upon a simple friends-of-friends approach do not scale to these cardinalities. Second, this project will advance the computational capabilities in statistical neuroscience by employing clustering algorithms to discover both regular patterns and anomalies in normal and abnormal brain graphs. Finally, this research will explore the important topic of finding anomalies in massive text streams, such as Twitter. In this setting, one is concerned with detecting anomalous bursts in traffic content that share a similar pattern. These bursts might signal an important political event or a natural disaster. This project will support undergraduate and graduate research aimed at developing skills needed for algorithmic work on massive data sets.<br><br>There exist numerous heuristics and approximation algorithms for many variants of the clustering problem. However, these methods are often slow or infeasible for applications with massive datasets. This research will improve space and time upper bounds for clustering algorithms in the streaming model. This project will address the k-mean and k-median problems in the dynamic streaming model, extend the results on separable data when the input comes from Euclidian space, improve the bounds in the sliding window model, combine the coresets technique with novel sampling approaches and the method of smooth histograms. The PIs' previous work has already been applied to natural language processing and this project will expand this direction further and explore the important topic of "First Story Detection." Furthermore, this research will explore the similarities and differences between various sampling and sketching techniques, and how they could be used in large multidimensional astronomical databases, like SDSS (Sloan Digital Sky Survey) SkyServer. These novel approaches will provide major speedups for the execution of large statistical aggregate queries. The new streaming algorithms will be used to find substructure in very large cosmological N-body simulations. <br><br>For further information see the project web site at: http://www.cs.jhu.edu/~vova
Computer simulations of turbulent fluid flows are playing an increasingly vital role in engineering applications (e.g. reducing drag forces on vehicles and predicting wind turbine aerodynamic efficiency) and in geophysical sciences (e.g. describing the fate of pollutant dispersion or Lagrangian transport and mixing in the ocean). Simulations consist of discretizing and integrating the partial differential equations governing fluid flow and transport forward in time, providing solutions for physical variables (fields such as velocity and pressure) as function of time and space in the entire domain of interest. Since such simulations generate enormous amounts of data, the prevailing approach has been for researchers to analyze the data "on the fly" during the simulation runs while only a small subset of time-steps are stored for subsequent analysis. As a result, often large simulations of the same process must be repeated after new questions arise that were not initially obvious. Many (or even most) breakthrough concepts cannot be anticipated in advance, as they will be motivated in part by output data and must then be tested against it. As a result, there is a need for methods to store entire space-time data from such simulations. This project develops innovative tools for the efficient creation of open numerical databases that contain massive outputs from computational fluid dynamics simulations used in turbulence research and geophysical transport modeling and makes these available to the entire community. Several of the datasets to be included into the Open Numerical Laboratory will be contributed by external researchers. In addition to enhancing engineering and geophysical fluid mechanics and turbulence research, democratized access to large-scale turbulent flow simulation data will also play a crucial role in education and training for the next generation of researchers. Active learning through new educational modules that allow students to query simulation datasets in unprecedented detail will provide new educational paradigms. More broadly, the lessons learned from this project will be generalizable to many other fields where numerical simulations generate very large datasets that are difficult to access using prevailing approaches. In this way, the project will enhance the scientific and broader impacts of the US high-performance scientific computing infrastructure. <br><br>This project will develop innovative tools for the efficient creation of open numerical databases that contain massive outputs from computational fluid dynamics simulations used in turbulence research and geophysical transport modeling. An ingest pipeline to be developed will enable users to transfer data from file systems containing the output of their massive direct numerical simulations, build a database, and serve it to the community for open exploratory data analysis and innovative turbulence and oceanic mixing research. To date, the investigators involved in this project have built an Open Numerical Laboratory focusing on direct numerical simulations (DNS) of canonical turbulent flows, in which the entire space-time data are available to the wider research community. However, the existing datasets are few in number and databases have been created one by one, using methodologies difficult to replicate on a massive scale. Moreover, emerging Exascale simulations will potentially result in data sets of unprecedented scale (tens to hundreds of PetaBytes). Advanced computer science algorithms will be required to tackle these challenges. This project will (a) develop automated, and scalable data management algorithms to ingest, index and serve very large data sets generated by a wide range of groups, (b) explore novel algorithms using spatio-temporal subsampling combined with online interpolation with re-simulation, yielding large compression factors depending on the subsampling stride, and (c) use machine learning algorithms to identify localized regions of interest in the simulations and save these 4D domains in a database for detailed follow-up analytics. The new databases will include data from (1) the largest channel flow DNS, (2) rotating and stratified turbulence of geophysical interest, (3) a DNS of developing wall boundary layer and (4) detailed ocean circulation models with complex boundary conditions. As part of the innovative domain science applications, data sets will be used to improve turbulence models using data-assimilation concepts, study Lagrangian vortex dynamics, and explore geophysical transport in a regional general circulation model of the North Atlantic Ocean.
This project develops theory and algorithms for automatically discovering multiple low-dimensional structures in high-dimensional data, and evaluates these algorithms in image clustering applications. The developed techniques enhance our ability to handle big data problems from multiple sources and modalities, and advance the knowledge on how to interpret massive amounts of complex high-dimensional data. The techniques developed in this project can significantly broaden the applicability of existing results in sparse representation theory to subspace clustering problems, which have found widespread applications in image processing (e.g., image denoising, compression, representation, and segmentation), computer vision (e.g., motion segmentation and face clustering) and dynamical systems (e.g., hybrid system identification).<br> <br>This research develops provably correct and scalable algorithms for learning a union of low-dimensional subspaces from big and corrupted data. The algorithms are based on the so-called self-expressiveness property of the data, which states that an uncorrupted data point can be well approximated by an affine combination of other uncorrupted data points. This research shows that by imposing a structured sparse and low-rank prior on the coefficients, one can discover multiple structures in the data. In the case of uncorrupted data, the research team studies conditions on the data under which a perfect clustering is possible. In the case of data corrupted by outliers, the research team studies conditions under which perfect clustering and outlier rejection are possible. In the case of data with missing entries, the research team studies conditions under which perfect clustering and data completion are possible. The project also develops efficient and scalable algorithms that benefit from distributed and high-performance computing for solving the various subspace clustering problems. These algorithms enable solving large-scale problems in computer vision, including image clustering.
Unsupervised learning of useful features, or representations, is one of the most basic challenges of machine learning. Unsupervised representation learning techniques capitalize on unlabeled data which is often cheap and abundant and sometimes virtually unlimited. The goal of these ubiquitous techniques is to learn a representation that reveals intrinsic low-dimensional structure in data, disentangles underlying factors of variation by incorporating universal AI priors such as smoothness and sparsity, and is useful across multiple tasks and domains. <br><br>This project aims to develop new theory and methods for representation learning that can easily scale to large datasets. In particular, this project is concerned with methods for large-scale unsupervised feature learning, including Principal Component Analysis (PCA) and Partial Least Squares (PLS). To capitalize on massive amounts of unlabeled data, this project will develop appropriate computational approaches and study them in the "data-laden" regime. Therefore, instead of viewing representation learning as dimensionality reduction techniques and focusing on an empirical objective on finite data, these methods are studied with the goal of optimizing a population objective based on sample. This view suggests using Stochastic Approximation approaches, such as Stochastic Gradient Descent (SGD) and Stochastic Mirror Descent, that are incremental in nature and process each new sample with a computationally cheap update. Furthermore, this view enables a rigorous analysis of benefits of stochastic approximation algorithms over traditional finite-data methods. The project aims to develop stochastic approximation approaches to PCA and PLS and related problems and extensions, including deep, and sparse variants, and analyze these problems in the data-laden regime.
The objective of this workshop is to convene leaders of data science initiatives across a number of research universities, in order to begin the formation of an academic community for data science. While there were only a few data science institutes/centers/initiatives at major research universities a few years ago, there are currently more than twenty such activities across public and private universities. This meeting will be the first ever convening of such a group, to allow for sharing of experiences and best practices in initiating teaching and research programs in data science. Meeting participants will discuss challenges and opportunities facing their respective institutions. One objective of the workshop group is to assume collective responsibility for preparing the next-generation data scientists in order to prepare them to be able to contribute towards the best interests of science and society.<br><br>In addition to the data science leadership across different institutions, invitees to the summit will also include representatives of associated data science activities currently underway, including PIs of the NSF TRIPODS Phase I projects; participants in the NSF-funded NAS study on Envisioning the Data Science Discipline: The Undergraduate Perspective; and, organizers of NSF-sponsored workshops on Translational Data Science, Data Science Corps, and Keeping Data Science Broad: Negotiating the Digital and Data Divide.<br><br>An express purpose of the summit is the formation of an academic community around data science research and teaching. Across the globe, numerous academic institutions are forming data science initiatives, leading to the recognition of Data Science as a discipline and/or as a key sub-disciplinary area. Much as the Computing Research Association (CRA) helped the computer science research community develop an identity, the organizers of this meeting believe that it will be helpful to initiate a community in data science leadership in the US, evolving into an organization like CRA for data science. This summit is the start of such a community-building effort. The intention is to initiate an organization dedicated to the enhancement of data science as a discipline, which can also convene activities to ensure a robust and growing data science community.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
Big data presents both opportunities and challenges to all fields of study and practice. Visualization has been proven effective as a knowledge discovery and storytelling tool for big data. This project aims to develop new visualization technologies for big network data that will both illustrate empirical findings and generate new discoveries. Although many network visualization techniques and tools have been introduced, visualizing large, dynamic networks to extract key entities, structures, and trends from the network data remains a challenging task. Most of the existing network visualization solutions were not designed for handling dynamic networks and are too slow for interactive exploration of large networks. This project will closely examine the integral parts of a holistic solution for the problem of big network visualization. The research study will be largely driven by the data analysis needs of sociological studies such as finding hidden associations between multiple networks; however, the project team will also investigate the solution's applicability in areas such as emergency management, life science and cyber security. The resulting technologies are expected to drastically enhance one's ability to explore and understand large, complex dynamic networks for knowledge discovery, critical decision making, and storytelling. This research effort is timely because of the explosive growth of data and common use of graphs as both the internal data structure and a visual representation in data-driven applications. Those who must deal with large, complex dynamic network data for their work will benefit from the advanced visualization technologies resulted from this research project. Students participating in this project will acquire strong interdisciplinary research skills for real-world problem solving. <br><br>This research underscores the importance of providing a comprehensive solution to the understanding of big data containing complex relations, structure, and trends. Primary research topics are: (1) Visual depiction and exploration of big network data; (2) Modeling and visualizing dynamic network data; (3) Visual monitoring and analysis of live, streaming network data; and (4) Provenance and storytelling with dynamic network data. This project will explore and integrate new network modeling, reduction, and visualization techniques for analyzing large, multivariate dynamic graphs. The resulting research innovations will both enhance existing methods and investigate new approaches to dynamic network visual analytics and drastically improve their usability for real-world applications. The targeted applications, emergency service and sociology, present the project team with some of the most challenging problems to address in making sense of heterogeneous dynamic big networks data. The collaborating domain experts are fully committed to participating in the evaluation work, which promises to produce usable technologies that will enable respondents to look at the data in new ways and uncover intricate relations among different entities/events for critical decision making and mitigation planning. The project results will be disseminated to the visualization community and beyond through annual conferences, workshops, and tutorials, and also through the project website which will include project status updates and resulting images, videos, and prototype software.
Successfully tackling many urgent challenges in socio-economically critical domains (such as sustainability, public health, and biology) requires obtaining a deeper understanding of complex relationships and interactions among a diverse spectrum of entities in different contexts. In complex systems, (a) it is critical to discover how one object influences others within specific contexts, rather than seeking an overall measure of impact, and (b) the context-aware understanding of impact has the potential to transform the way people explore, search, and make decisions in complex systems. This project establishes the foundations of big data driven Context-Sensitive Impact Discovery (CSID) in complex systems and fills an important hole in big data driven decision making in many critical application domains, including epidemic preparedness, biological pathway analysis, climate, and resilient water/energy infrastructures. Thus, it enables applications and services with significant economic and health impact. The educational impacts of this project include the mentoring of graduate and undergraduate students, and the enhancement of graduate and undergraduate Computer Science curricula at both Arizona State University (ASU) and New Mexico State University (NMSU) through the incorporation of research challenges and outcomes into existing classes. <br><br>The technical goal of this project is to establish the theoretical, algorithmic, and computational foundations of big data driven context-sensitive impact discovery in complex systems. This project develops probabilistic and tensor-based models to capture context-sensitive impact from complex systems, often modeled as graphs, and designs efficient learning algorithms that can capture both the contexts and the impact scores among entities within these different contexts. The modeling of the context sensitive impact considers dynamic nature of relevant contexts and the diverse applications. This requires addressing several major challenges, including latent contexts of impact, heterogeneous networks of entities, dynamicity of impact in varying contexts, and high computational and I/O costs of context-sensitive impact discovery. Therefore, this project designs novel scalable probabilistic and tensor-based algorithms to capture and represent context-sensitive impact. These algorithms and the novel data platforms they are deployed in are efficient and scalable in terms of off-line and on-line running times and their space requirements. To achieve necessary scalabilities, the developed platforms employ novel multi-resolution data partitioning and resource allocation strategies and the research enables massive parallelism and efficient data access through new non-volatile memory based data management techniques.
A large fraction of the ever-growing internet content is found in social media such as (micro)blogs. Users access it to both form and share their opinions about events and people, election preferences, product and brand recommendations. This situation provides opportunities to create added layers of data mining and analysis regarding users' views on developing events, products, services, or government actions; at the same time, it raises challenges for Entity Linking (EL) in social media. EL is the task of linking an extracted mention to a specific definition of the entity. The definition of an entity is usually a pointer to a Web page that defines the entity. Information extraction from social media generally faces many challenging issues due to: message volume, message speed (Twitter alone generates over 500 million messages per day), variety, free-form language, lack of context, large reference variation and language diversity. Hashtags are an essential part of the ethos of social networks. They are used to denote brands, events, people, social rallies, etc. The hashtag disambiguation problem is to detect synonymous hashtags and recognize the polysemic ones. For example, the hashtag '#BHaram' refers to the entity 'Boko Haram', defined at Wikipedia page en.wikipedia.org/wiki/Boko_Haram or at National Counterterrorism Center Web web page www.nctc.gov/site/groups/boko_haram.html. The purpose of this project is to perform EL in social media. This work will benefit multiple segments of society that rely on applications using data from microblog systems, such as targeted monitoring of Twitter and Facebook to collect and understand users' opinions about a recent product or a world event; data aggregation (e.g., reviews about products and services); and data mining for early crisis detection and response as well as national security. This project is one more step towards addressing the government's latest initiative of fighting crime using big data.<br><br>The goals of this project are to research algorithms to detect in near real-time those pieces of text in messages that reference entities, Web pages that describe entities, and to link entity references to Web pages and across microblog systems so that together a broad, more complete characterization of each entity can be automatically generated. The proposed approaches are based on innovative techniques that include: incremental, iterative message analysis; smart indexing techniques with live updates to support fast incremental entity reference detection; computationally light soft-clustering of messages to improve entity reference detection; and fast incremental K-partite graph clustering. The resulting artifacts (e.g., software tools) will be made available to benefit researchers in academe and industry. Distribution of free, open-source software for implementing the techniques developed will enhance existing research infrastructure. The project will support and train at least three PhD students, as well as involve undergraduate students in research at Temple University and Binghampton University. The project web site (http://cis.temple.edu/~edragut/projects/nimel.htm) includes more information on the project, software, datasets, educational materials, and publications.
While statistical machine learning has seen major advances over the past two decades, rigorous approaches for high-dimensional spatio-temporal scientific data analysis have not received as much attention. On the other hand, several core scientific areas, including climate science, ecology, environmental sciences, and neuroscience, are generating increasing amounts of high-resolution spatio-temporal data. It is vital to develop rigorous machine learning approaches for such complex high-dimensional spatio-temporal data in order for key scientific breakthroughs in these areas in the next few decades. The project contributes to these endeavors by focusing on two key technical and scientific areas: spatio-temporal big data analysis and climate science. The project systematically develops the statistical machine learning foundations for the analysis of large scale complex high-dimensional spatio-temporal data, and applies such advances to problems arising in climate science, where the total amount of data is set to cross an Exabyte (1 Exabyte = 1000 Petabytes) soon. <br><br>The technical work in the project has three broad and interacting components: structured probabilistic graphical models for spatio-temporal data analysis, generalized graphical models for multivariate heavy tailed distributions, and physics-guided models with a richer class of structural constraints and capturing multi-scale phenomena. The project applies these technical advances to climate science, by generating climate projections at high-resolutions. Currently, the lack of requisite spatial resolution of current climate models makes automatic assessments of impacts, adaptation and vulnerability (IAV) difficult for a variety of sectors, including urban planning, freshwater resources, food security, energy, transportation systems, human health, and coastal systems.
The explosion in data gathering has greatly exacerbated existing privacy issues in computing systems and created new ones due to the increase in the scale and the scope of available data as well as the advances in the capabilities of computational data analysis. Software professionals typically have no formal training or education on sociotechnical aspects of privacy. As a result, addressing privacy issues raised by a system is frequently an afterthought and/or a matter of compliance-check during the late phases of the system development lifecycle. To tackle this challenge, this research aims to bridge the gap between policy makers and regulators and system designers by making privacy laws and regulations understandable and actionable by software professionals. Specifically, this research designs and develops a deck of privacy ideation cards based on US privacy laws and regulations. The privacy ideation cards produced by this research can potentially transform how privacy-relevant aspects are handled in real-world software solutions built by industry and inform how students are taught these issues in undergraduate software curricula.<br><br>A critical contribution of this research is a deck of ideation cards to facilitate the design, development, and deployment of systems that take into account relevant US privacy laws and regulations at every step of the system building process. The cards are designed based on input from legal scholars and experts in the domain of US privacy laws. The design is geared toward promoting an understanding of privacy regulation by software professionals as well as students. This research involves applying the cards to the design of real-world solutions in industry as well as at a university (in a software project course). These applications enhance the knowledge of how privacy-related ideation techniques can be effectively employed in professional software development as well as software education. The findings facilitate the design and development of systems that comply with privacy laws and regulations and are sensitive to the privacy needs of their users, thus promoting and extending the Privacy by Design approach.
Emergency communications networks are crucial for reaching out and helping affected people during long-persisting disasters such as the Tohoku earthquake in Japan or Hurricane Katrina in the US. Because of the ubiquitous availability of smartphones, it is important to integrate them into the emergency communications network consisting of both surviving cellular network and deployed emergency communications infrastructure. All these components vary in their ability to provide necessary communications as the disaster unfolds. It is therefore essential to continuously monitor and ``tune'' the network to provide the best possible coverage and communications capability. <br><br>This project explores how to interconnect clusters of smartphones via WiFi tethering technology and integrate them with the deployed emergency network. Since the densities of people and hence of smartphones can vary substantially over the affected area, the project will explore mechanisms to conserve battery and other smartphone resources by exploiting overlap/redundancy in the sensed data. Another key issue addressed by the project is the evolution of the emergency network as the disaster situation itself evolves. The project analyzes data obtained from twitter during the disaster in order to get insights into how the network should evolve. Furthermore, the project examines how to deploy the mobile access points initially and later move them to tune the network to the needs of the evolving disaster. The analysis of twitter data involves several bigdata challenges including classification, prioritization, and ordering of tweets so the interpretation and decision making -- which is still expected to be done by humans -- is considerably simplified.<br> <br>The rapidly increasing penetration of smart phones that carry a wide array of sensors makes them ideal for disaster communications. In addition, twitter has established itself as the premier human communication mechanism during disasters owing to its modest technological requirements and ease of use. This project takes these phenomena and stitches them together to create an agile disaster communications network that can provide significant additional value in quickly reaching affected people and collecting crucial data for rushing the required assistance to them. As a part of US-Japan joint program, with research teams from Temple University in the United States and Aizu University in Japan, the project will develop technologies that will be of direct relevance to both countries.
A fundamental problem in analyzing big data is to extract and represent the relations among the huge number of variables in a dataset. For example, in a genomic dataset, one may want to find out the dependence among a large number of genetic variations and various disease states. The Bayesian network is a commonly used class of mathematical models to represent such complex relations among a collection of variables, with wide applications in many scientific fields, ranging from the biomedical sciences to the social sciences. The goal of this project is to develop statistical and machine learning methods to construct Bayesian networks from big data, where the datasets may contain thousands to millions of variables. This is a challenging problem, particularly for large networks, as seen from the fact that state-of-the-art methods can barely handle thousands of variables. In this project, a novel divide-and-conquer approach will be developed and implemented as open-source packages for public use. The PIs will also study the theoretical properties of key components of this approach. Through seminar organization and educational activities in both graduate and undergraduate training, the cutting-edge research in this project will be communicated immediately to a much broader audience.<br><br>The proposed approach consists of three main components: Partition, Estimation and Fusion (PEF). In the partition stage, spectral clustering will be embedded into an iterative subsampling approach to efficiently group variables into clusters. In the estimation stage, a few new methods will be developed to estimate the structure of a Bayesian network for each cluster of nodes, which serves as a subgraph of the big network. These methods include convex relaxations for permutations, fast algorithms for large-scale regularized estimation of the parameters of a Bayesian network, and novel formulations for discrete data. The final fusion stage will merge subgraphs into one big Bayesian network via a new method based on multiple-response sparse regression. Rigorous analysis of the PEF learning strategy for Bayesian networks under high-dimensional scaling will be conducted to provide theoretical guarantees for the methods and the algorithms.
This project investigates semi-supervised training of deep neural network models using large-scale labeled and unlabeled data in a distributed fashion. Deep neural networks have recently been widely deployed in artificial intelligence and related scientific fields, largely attributing to well-labeled big datasets and improved computing capabilities. However, the unlabeled data, which is often bigger, is inherently ruled out by the prevailing supervised training of the deep models. It is indeed highly challenging to model the unlabeled parts of many recent and emerging datasets, which are often unstructured and distributed over different nodes of a network (e.g., the videos captured by a camera network). This project aims to explore how to effectively use the unlabeled and distributed data to complement the discriminative cues of the labeled data, to jointly learn accurate and robust deep models. The research seamlessly unifies machine learning, computer vision, and parallel computing, and fosters unique interdisciplinary research and education programs for the graduate and undergraduate students.<br><br>Despite the progress on semi-supervised learning and deep learning, the confluence of these two is mostly studied on a small scale in single-machine environment. However, many new datasets easily grow beyond the computation or even storage capacity of a single machine. Hence, it becomes a pressing need to investigate the semi-supervised learning of deep models on parallel computing platforms. To better account for this scenario, this project develops improved network architectures to facilitate the parallel training, and the training procedure developed adaptively switches between synchronized and asynchronized modes for optimal efficiency. The main idea is to incorporate a parametric distribution to the neural network and use covariate matching to coordinate the network behaviors across different machines. The researchers also explore a novel application, extreme-scale spatial-temporal action annotation of video sequences, to benchmark the algorithms and frameworks in this project.
This workshop will bring together, for the first time, all of the PIs of the NSF BIGDATA program, at a venue in the Washington DC/Northern Virginia area. The goals of the NSF BIGDATA program are to "develop new methods for deriving knowledge from data; construct new infrastructure to manage, curate and serve data to communities; and forge new approaches for associated education and training." Given the range of possible activities, there is a need and opportunity to introduce the funded project PI's to the breadth of work funded under the Big Data Research Initiative and to new potential research partners. The workshop is by invitation, and open to researchers who are currently funded through the NSF BIGDATA program. The goal of this two-day workshop is to bring together PIs/co-PIs with government and industry invitees to discuss current research, as well as identify and elaborate on new, emerging challenges, and future directions.<br><br>This workshop will bring together experts in different disciplines comprising the Big Data community, funded by NSF. The meeting will identify gaps, needs, resources, and barriers related to Big Data research, and also develop a forward-looking research agenda that will identify future directions in this area. The workshop will provide current PIs with opportunities to showcase and discuss their current work; establish new collaborations; develop knowledge of available research and infrastructure resources; and gain insight into new areas of research. The broader impact of this meeting will be the ability to more broadly share research results in the foundational as well as application aspects of big data in society.
To date, that has been limited involvement by researchers and developers in the National Big Data R&D Strategic Plan. However, their input is vital to the success of the plan. This one-day workshop in Washington, D.C. will being together academics and industry leaders across disciplines to inform the development of an effective National Big Data R&D Strategic Plan. The development of a government-wide strategic plan impacts all of the agencies involved. The workshop will engage a range of experts to hear about the plan status and share concerns and ideas. Incorporating this feedback will improve the plan and develop an overall blueprint for Big Data R&D across much of the government. The growth in scale, diversity, and complexity of data has increased the demand for understanding large amounts of heterogeneous data. This present new challenges to the way data and information are used and managed. Need exists to understand ways to design systems for big data analytics, consider privacy issues that arise when using this massive data a determine ways to teach big data analytics across the sciences. The workshops aims to balance plenary presentations and smaller focus discussion groups for in=depth discussions. Coordinator reporters for each focus group will participate in writing the reports and outcomes of the workshop.
A workshop will be held in Washington, DC on December 7-8, 2017 to plan for the creation of a Data Science Corps. The Data Science Corps will help build the capacity of organizations at the local, state, national and international levels to utilize data to advance science and to help solve social problems. The Data Science Corps would offer practical experiences and teaching opportunities to U.S. data scientists and data science students, who would serve as volunteers working on data science projects in a variety of venues including, academia, industry, government, and various urban and rural communities. <br><br>The workshop will bring together a wide variety of stakeholders to discuss the vision and implementation of such a Data Science Corps. It will provide the opportunity to define the organizational and implementation details of the Data Science Corps, and will elaborate upon how the initiative can best serve the volunteers as well as the program beneficiaries. The workshop will include presentations by speakers representing a variety of stakeholders, and will include discussions sessions to help develop ideas for establishment of the program.<br><br>Via the Data Science Corps, volunteers--including data science professionals as well as data science students--will be able to offer assistance to real world data science problems, and will provide data science training to users across a wide variety of sectors. By providing assistance to projects in academia, industry, government in communities at the local, state and national levels, Data Science Corps volunteers would gain practical experience on real world data science problems, as well as gain experience as data science teachers and trainers.<br><br>The Data Science Corps program can help enhance existing internship programs at academic institutions by providing a data science theme and focus. The Data Science Corps would complement existing NSF programs, including the Big Data Regional Innovation Hubs, Spokes, and Smart and Connected Communities.<br><br>Such a program will help with improved data collection and data analysis across all applications areas, whether in urban or rural communities, and at the local, state, national and international levels. As a result, these communities will have greater capacity to implement data-driven solutions.
This project addresses the challenge of achieving extreme low latency in datacenter networks for Online Big Data (OLBD) applications which are critical workloads in datacenter computing. Remote Direct Memory Access (RDMA), which is a promising alternative to traditional TCP, significantly reduces datacenter network latencies by about an order-of-magnitude. However, RDMA adoption poses two major challenges as RDMA suffers from performance fragility under congestion, and RDMA incurs either wasted memory or significant programmer burden for typical OLBD traffic. This project develops two novel networking technologies -- Blitz and RIMA -- which enable scalable datacenter networks that achieve the low latency benefits of RDMA while avoiding its drawbacks (performance fragility, programmer burden, and wasted memory).<br><br>Blitz addresses performance fragility by decoupling edge-congestion and in-network congestion. Blitz handles edge-congestion using receiver-directed congestion control (RDCC) unlike prior approaches where senders have to infer sending rates indirectly from round-trip-times and/or dropped packets. RDCC enables accurate and fast (within-one-round-trip-time) convergence, which leads to lower latency and higher throughput. Blitz handles transient in-network congestion by deflecting packets along longer yet less-congested paths.<br>Remote Indirect Memory Access (RIMA) addresses the second challenge by enabling reactive, on-demand memory allocation as opposed to RDMAs proactive memory allocation for the worst case, which minimizes the memory footprint without programmer effort. Together, Blitz and RIMA enable extreme low datacenter network latency for OLBD applications. The project will extensively involve Ph.D, Masters, and undergraduate students in cross-layer research activities. Results from the projects will be broadly disseminated via publication in scientific conferences.
This proposal supports 20 students for their travel to attend the 2016 Annual International Cryptology Conference (CRYPTO), sponsored by IACR (International Association of Cryptologic Research), in cooperation with the Computer Science Department of the University of California, Santa Barbara. CRYPTO is a highly selective conference in cryptography, attracting students, researchers and industry specialists from all over the world. The scope of research papers accepted to CRYPTO range from the theoretical foundations of cryptology to application and implementation of cryptographic schemes. As such, it fits closely with the goals of NSF's Secure and Trustworthy Cyberspace (SaTC) program, which include applied cryptography and implementation of cryptographic schemes.
The Cyberlearning and Future Learning Technologies Program funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning Exploration (EXP) Projects explore the viability of new kinds of learning technologies by designing and building new kinds of learning technologies and studying their possibilities for fostering learning and challenges to using them effectively. The Promoting Learning through Annotation of Embodiment (PLAE) project will research how new motion-tracking technologies and augmented reality can be adapted to support young children's science learning in the classroom. Embodied resources - gesture, physical motion, and one's location in space - are increasingly recognized as important modalities for students to engage and better understand science and mathematics concepts. However, these embodied resources need to be connected to other intellectual resources more readily recognized by school-notation systems, mathematical equations, graphs, and scientific vocabulary. The project will investigate how the ability to label, identify, and view key elements of activity within augmented reality learning environments support student reflection on scientific content in the physical sciences. Project research will help develop the foundations for the application of technology systems employing embodied resources combined with annotation to support children's learning of basic science concepts. Because of the popularity of motion-tracking interfaces for commercial computer gaming (e.g. the Xbox Kinect and Wii), the capabilities of less expensive motion-tracking systems are rapidly advancing to the point where practical classroom applications can be developed in the near future.<br><br>The project will research how annotations of embodied play simulations in an augmented reality environment can direct student attention towards key scientific concepts while providing them with opportunities to reflect upon and revise their understanding of those concepts. After development and pilot testing of the system, students will be assigned to one of two conditions that involve either: (1) all student-generated annotations or (2) all teacher- and researcher-created annotations. By contrasting these two models, the project will be able to explore in detail the role of annotation in supporting students' reflection within embodied modeling activities, and to further demonstrate the value that is added by allowing students to design and negotiate their own annotations. There will be two main sources of data for each of the experiments: (1) a pre-post content measure to assess overall growth in student understanding of the particulate nature of matter, and (2) project coding and analysis of videos of student activity to analyze the types of learning processes promoted by the technology and curriculum, with a focus on how the annotation features support reflection about the underlying rules of the system. The results of this research will inform the design of future educational technologies which rely upon embodied motion.
Many research and commercial endeavors are experiencing dramatic transformations through the use of Big Data, wherein large data repositories are collected and analyzed to reveal trends, correlation, and information that may not be apparent in smaller samples. Current approaches assume centralizing the repository, which may be a poor fit in environments where the data generation rate exceeds the network capabilities. In this project, the PIs investigate system architectures for both real-time and historical analysis of geographically distributed data, combined with research in adaptively reducing data volumes to optimize bandwidth capabilities. This combination allows better use of the computation and storage associated with smarter end devices, including, but not limited to, distributed sensors, smart meters, and even full servers, without requiring network upgrades. Given the historical trends of the growth of computation and storage versus the capacity limits of wide-area networks, this research enables more data collection and analysis to be performed at a lower overall system cost. Further, the ability to dynamically adapt data precision and fidelity to available network bandwidth allows systems to gracefully and automatically improve performance in the presence of higher-capacity networks. The research enables the collection and analysis of data that is currently left unanalyzed because of network constraints. Such data can include finer-granularity usage data, which could indicate actionable steps to reducing household energy consumption, or it could include a greater olume of debugging and monitoring data, which could better predict system failures or provide greater insight than with current methods.
Establishing causal relationships -- for example, that cigarette smoking causes lung cancer -- is one of the most challenging aspects of scientific research. Computers excel at calculation, but are unable to separate cause-and-effect from mere correlation. Humans, on the other hand, can make logical conclusions based on their experiences but, in the modern era of Big Data, there are far too many potential relationships for humans to manually examine. This research aims to build a crowdsourcing web platform to use the knowledge of interested non-experts (Hunch) and the algorithmic power of computers (Crunch) to discover and test causal relationships in large-scale data. Algorithms identify potential relationships and users are asked to validate them. Further, users are able to propose their own hypotheses that can subsequently be validated, creating an accelerating feedback loop of scientific discovery. The goal of systematically discovering causal relationships has the potential for broad societal impact, and virtually anyone with web access can participate directly in this scientific research.<br><br>To support this goal, the researchers are developing novel statistical methods that determine the data types of crowd-suggested observables on the fly. For example, are 'wages' and 'gender' real-valued or binary variables? Finally, the crowd is a relatively limited resource. To use it efficiently, machine learning algorithms would identify which substructures in the correlational network are most likely to be causal, and then focus the crowd's efforts towards them. These efficient, adaptive methods allow causal relationships to be combined into larger chains that explain growing numbers of causes and effects.
Molecular dynamics simulations studying the classical time evolution of a molecular system at atomic resolution are widely recognized in the fields of chemistry, material sciences, molecular biology and drug design; these simulations are one of the most common simulations on supercomputers. Next-generation supercomputers will have dramatically higher performance than do current systems, generating more data that needs to be analyzed (i.e., in terms of number and length of molecular dynamics trajectories). The coordination of data generation and analysis cannot rely on manual, centralized approaches as it does now. This interdisciplinary project integrates research from various areas across programs such as computer science, structural molecular biosciences, and high performance computing to transform the centralized nature of the molecular dynamics analysis into a distributed approach that is predominantly performed in situ. Specifically, this effort combines machine learning and data analytics approaches, workflow management methods, and high performance computing techniques to analyze molecular dynamics data as it is generated, save to disk only what is really needed for future analysis, and annotate molecular dynamics trajectories to drive the next steps in increasingly complex simulations' workflows. <br><br>The investigators tackle the data challenge of data analysis of molecular dynamics simulations on the next-generation supercomputers by (1) creating new in situ methods to trace molecular events such as conformational changes, phase transitions, or binding events in molecular dynamics simulations at runtime by locally reducing knowledge on high-dimensional molecular organization into a set of relevant structural molecular properties; (2) designing new data representations and extend unsupervised machine learning techniques to accurately and efficiently build an explicit global organization of structural and temporal molecular properties; (3) integrating simulation and analytics into complex workflows for runtime detection of changes in structural and temporal molecular properties; and (4) developing new curriculum material, online courses, and online training material targeting data analytics. The project's harnessed knowledge of molecular structures' transformations at runtime can be used to steer simulations to more promising areas of the simulation space, identify the data that should be written to congested parallel file systems, and index generated data for retrieval and post-simulation analysis. Supported by this knowledge, molecular dynamics workflows such as replica exchange simulations, Markov state models, and the string method with swarms of trajectories can be executed ?from the outside? (i.e., without reengineering the molecular dynamics code).
General Audience Summary <br><br>This award will support US participation in the Global Science Forum (GSF) of the Organization for Economic Co-operation and Development (OECD). GSF provides a venue for mutual consultation among senior science policy officials of OECD member countries. It produces findings on high-priority science-policy issues that require international co-operation, and identifies opportunities for collaboration on major scientific undertakings. This award will support the participation of two PIs in planning meetings with GSF experts for an international conference tentatively entitled "The Ethics of Using New Forms of Data for Social Research." The conference is to be held in Chicago, and it will bring US scientists together with OECD experts to develop an international framework for the ethical use of big data in research. The analysis and application of large datasets, also known as big data research, is an important area of research supported by NSF's Directorate for Social, Behavioral, and Economic Sciences (SBE). The conference will be organized as plenary, breakout and poster sessions. It will bring together scientists, policy makers, industry, funding agencies, and public interest groups who have an interest in addressing the ethical use of big data in the SBE sciences. Big data is growing in importance for many areas critical to society, including health, finance and science. The outputs of this conference will help researchers identify the key issues in research ethics and explore an international framework related to the ethics of the use of big data in research.<br><br>Technical Summary <br><br>The conference being planned will advance the SBE subfields of Research Ethics and Privacy Protection in Big Data by developing a forward-looking framework on how to overcome the tradeoff between big data and research ethics to effectively pursue the potential of big data without sacrificing privacy rights or violating research ethics. These goals are particularly challenging because satisfying them will require inherently interdisciplinary approaches, and they will require anticipatory approaches (scenario development), which are just starting to be developed. The proposed activities will serve to improve insights and to provide a framework for approaching the reuse of new forms of data. They will inform policy making and scientific practice with regards to data reuse, as well as provide a foundation for conducting ethical analysis of relevant data use scenarios. The proposed effort will result in a framework for internationally acceptable guidelines for the use of big data in SBE research, and it will thereby have profound implications not only for data-related research but also for data-related governance and policies.
Our lives are becoming increasingly connected with Big Data. Massive amounts of digital trace data are being generated from the activities and events of complex socio-technical systems consisting of human actors and man-made artifacts (which refer to as social objects). Such complexity comes from the massively interconnected and computed nature of the contemporary digital world. These data sets are different from traditional data as they are typically massive, unstructured, granular, heterogeneous, dynamic, and performative. Using Big Data, the researchers are able to understand and predict behaviors of complex socio-technical systems. To support such efforts, the researchers will build a new methodological framework based on an evolutionary ontology that treats variation as real and as the fuel of evolution. Specifically, the researchers analyze data set from Twitter (one of the largest social media sites) and Github (the largest open source community) to test and validate their framework. As the role of Big Data continues to increase in our society, the researchers plan to develop online curricula to help students learn how to access, manage, analyze, and visualize big data sets via a variety of approaches.<br><br>The researchers are developing a method to predict the emergence of system-level behaviors by analyzing large volumes of digital trace data using evolutionary social ontology to build a multi-level model of complex socio-technical systems. They use analytical techniques developed in evolutionary biology and systems biology: (1) to characterize a stream of digital trace data from a complex socio-technical system with finite genetic elements; (2) to predict the behavior of socio-technical systems based on the pattern of "behavioral gene" interactions; and (3) to explore the impact of mutational input, gene flow, and recombination in "behavioral genes" on the evolution of socio-technical systems. The researchers test their model in GitHub, one of the largest open source communities that includes over 5 million open source software development projects and Twitter, one of the largest social media site, that has over 500 million messages per day. The model generated from this research can be used for other types of massive digital trace data including sensor data from Internet of the Things and mobile data from smartphones.
In this Cyberlearning: Transforming Education DIP (Development and Implementation) Project, the PIs focus on better promoting science learning in early elementary school (grades K-3). They focus in the discipline of life sciences, with specific focus on complex biological systems. The approach to learning about complex systems is through participatory simulation augmented by wearable computers. Children act out the roles of agents in complex biological systems (e.g., bees gathering honey, predators and preys) together, and with the help of electronic puppets that they can wear on one hand, they watch changes in the characteristics of animals they are simulating (e.g., energy, hunger, thirst, need for sleep) as they interact in the environment the way those animals would. Research focuses on how learning happens in the context of 1st person participation in a simulated system and how to best facilitate that learning, how learning about one complex system readies children to learn about other complex systems, how the understanding of complex systems builds over time with exposure to a variety of such systems, and best ways of using technology to affect such learning.<br><br>There is little understanding currently of how to teach science productively in elementary school. As is appropriate for this age group, these PIs take a playful approach to immersing youngsters (in grades K through 3) in the lives of animals and organisms and the ecosystems they live in. Children participate in simulations of natural ecosystems, taking on the roles of animals or organisms in those systems. To promote the kinds of reflection on experience that will lead to learning, children are equipped with electronic puppets that help them experience how those animals? lives are affected by their interactions with animal and plant life in their environment.
Unsupervised learning of useful features, or representations, is one of the most basic challenges of machine learning. Unsupervised representation learning techniques capitalize on unlabeled data which is often cheap and abundant and sometimes virtually unlimited. The goal of these ubiquitous techniques is to learn a representation that reveals intrinsic low-dimensional structure in data, disentangles underlying factors of variation by incorporating universal AI priors such as smoothness and sparsity, and is useful across multiple tasks and domains. <br><br>This project aims to develop new theory and methods for representation learning that can easily scale to large datasets. In particular, this project is concerned with methods for large-scale unsupervised feature learning, including Principal Component Analysis (PCA) and Partial Least Squares (PLS). To capitalize on massive amounts of unlabeled data, this project will develop appropriate computational approaches and study them in the ?data laden? regime. Therefore, instead of viewing representation learning as dimensionality reduction techniques and focusing on an empirical objective on finite data, these methods are studied with the goal of optimizing a population objective based on sample. This view suggests using Stochastic Approximation approaches, such as Stochastic Gradient Descent (SGD) and Stochastic Mirror Descent, that are incremental in nature and process each new sample with a computationally cheap update. Furthermore, this view enables a rigorous analysis of benefits of stochastic approximation algorithms over traditional finite-data methods. The project aims to develop stochastic approximation approaches to PCA and PLS and related problems and extensions, including deep, and sparse variants, and analyze these problems in the data-laden regime.
Understanding how the brain works is arguably one of the most significant scientific challenges of our time and the focus of the BRAIN initiative. It is widely believed that neural circuit function is emergent, the result of complex interactions between constituents with individual neurons forming synaptic connections with thousands of other neurons. Mapping of these complex circuits has been virtually impossible because of the reliance on electrophysiological recordings which sample these networks extremely sparsely. These tools for extracellular spike recordings are only able to simultaneously record from several tens to a few hundred neurons. Raw signals from these recording electrodes are first filtered to remove out-of-band signals. Putative spike events are then detected and extracted. Finally, these snippets of time-series event are sorted, typically on the basis of waveform shapes, into clusters. Even at the very modest bandwidths for these systems, computing systems struggle to save the data and process the resulting data sets. Scalability of these measurement techniques by many orders of magnitude in recording density and channels will be essential to future progress in understanding neuron circuits.<br><br>This project is exploiting emerging electrophysiological recording systems in which the electrode (and channel) count is increased by almost three orders of magnitude over conventional systems with data bandwidths exceeding 1GB/sec. To handle these data bandwidths and resulting data volumes and deliver scalability, this project will develop dedicated hardware and associated algorithms for spike detection and sorting that allow these tasks to be performed in real-time in close proximity to the recording system. Compression by more than three orders of magnitude is possible by these means by taking advantage of the special spatiotemporal local structure in these data sets; by exploiting strong prior information about the spiking signal and reducing the dimensionality of the problem accordingly; and by adapting and extending modern scalable nonparametric Bayesian inference methods. In addition to providing important new tools for neuroscience, the tools developed here for scalable real-time event detection and annotation have broad applicability to other spatiotemporal data sets (or more generally, any data set comprising multiple streams of data, in which the streams could involve different data modalities) in which objects of interest are spatially and temporally localized with fixed spatial footprints. Examples abound in cell and molecular biology, particle and solid-state physics, financial monitoring, monitoring of power networks, and sensor networks.
Recent technological and scientific advances have allowed the acquisition of vast amounts of various types of data. Such an abundance of information should lead to new scientific understanding and breakthroughs. However, the large-scale nature of this data introduces serious complications that choke classical data analysis techniques, leading to a stagnation of scientific progress in many areas. This issue requires novel mathematical techniques in order to effectively extract and analyze the information. This project will use Lyme disease data (through a collaboration with LymeDisease.org) as a motivating example in the design and testing of the methods, as it serves as a prime example of complex large-scale data with very significant impact to a fast growing community. The results of this project will thus have swift societal impact; for example, analysis on the LymeData will not only further the understanding of the disease itself, but will also lead to more accurate and precise diagnoses, and more personalized and effective treatments for patients. In addition, this proposal will support the education of postdoctoral, graduate and undergraduate students, and facilitate outreach efforts aimed especially at increasing the participation of under-represented populations. To accomplish this task, in addition to the activities funded by this proposal, the PIs will utilize existing programs such as the Women In Technology Sharing Online (WitsOn) program, Women in Data Science and Mathematics Research Collaboration Workshop (WiSDM), and MAPS 4 College of Los Angeles, all in which the PIs are already actively involved, to recruit under-represented populations and to promote the mathematical and technical sciences.<br><br>The fundamental research in this project will center around three main objectives, each addressing a particularly important challenge that arises in large-scale data applications. The first goal is to design innovative data completion techniques that are practical for big data; this will involve the design and theoretical development of data completion methods using non-random (and non-uniform) observation patterns, adaptive sampling schemes, and utilizing additional structures hidden in the observations. Rather than using classical (computationally expensive) convex programming techniques, the project will focus on extremely efficient simple solvers that can be run in real-time during an inference task. Secondly, the team proposes two novel deep learning approaches for inferential tasks that (i) are extremely computationally efficient and can thus be applied to massive datasets, and (ii) achieve the accuracy benefits of modern deep learning approaches, which improve upon state of the art methods. Third, the project will develop critical data fusion techniques that allow data from a wide variety of sources to be analyzed in an aggregated manner. Lastly, the team proposes to combine these three data analysis tasks in a novel multi-stage feedback design where outputs from data completion, deep learning inferences and fusion will be cycled back as inputs to these mechanisms for an iterative and robust inference framework. Progress on these goals will yield new mathematical frameworks in data science, and provide techniques that will be directly applied to large-scale data to allow efficient and powerful data analysis.
Big Data often results from multiple sources, giving collections that contain multiple, often partial, "views" of the same object, space, or phenomenon from various observers. Extracting information robustly from such data sets calls for a joint analysis of a large collection of data sets. The project is developing a novel geometric framework for modeling, structure detection, and information extraction from a collection of large related data sets, with an emphasis on the relationships between data. While this approach clearly applies to data with a clear geometric character (e.g., objects in images), the work is also applied to datasets as diverse as computer networks (identifying common structure in subnets) and Massive Open Online Course homework data (automatically carrying grader annotations to similar problems in other students' homeworks).<br><br>The novel framework is based on the construction of maps between the objects under considerations (point clouds, graphs, images, etc...), and on the analysis of the networks of maps that result as a way of extracting information, generating latent models for the data, and transporting or inferring functional / semantic information. These tasks define a new field of map processing between data sets and require tool sets with new ideas from functional analysis, non-convex optimization, and homological algebra in mathematics, and geometric algorithms, machine learning, optimization, and approximation algorithms in computer science. Sophisticated algorithmic techniques for attacking the large-scale non-linear optimization problems that emerge within the framework will also be investigated.
The biological, physical and socials sciences are being overwhelmed by the large amounts of data: i) from new generations of instruments and sensors, with rapidly decreasing costs and rapidly increasing resolutions; ii) the creation of large scale instrumented environments; and iii) the use of high performance simulation that produces large datasets. Data Science is an emerging field that is developing to meet this challenge, which integrates domain knowledge from the relevant disciplines with statistics/mathematics and computer science/informatics. Translational data science is a new term that is being used for an emerging field that applies new data science principles, techniques and technologies to challenging scientific problems that hold the promise of having an important impact on human or societal welfare. The term is also used when data science principles, techniques and technologies are applied to problems in different domains in general, including,but not restricted to,science and engineering research. The team will hold the first Workshop on Translational Data Science (TDS 17) in Chicago on June 26-27, 2017 as a first, important step to foster the creation of the discipline of translational data science. This workshop will bring together about 50 scientists from academia, industry, foundations, and federal funding agencies to discuss important issues, challenges and opportunities, including the scope of translational data science. A key outcome from the workshop will be a white paper about translational data science. Another key outcome will be planning for future workshops around translational data science and the beginning of the creation of Translational Data Science Community.
The iSTEP project addresses a basic research question by exploring the role of the body and physical activity in learning through the design of a new genre of developmentally appropriate learning technologies for young children. There is increasing recognition that the body plays a role in cognition: human beings, especially young children, understand complex concepts in part by relating them to how we move our own bodies. In extending these ideas, the iSTEP project also aims to develop teaching techniques and technological tools that can be used in real classrooms in the near future. Instead of supporting the learning of individual students as many current technological advances attempt to do, the iSTEP project creates opportunities for entire classrooms of students to engage together to model scientific phenomena using their bodies. For instance, a classroom of students can use their own bodies to model how a state of matter such as liquid is made up of many moving particles and technologically enhance this activity to improve learning. The iSTEP project builds upon the already successful STEP mixed reality platform (IIS-1323767) by adding new forms of interaction - the use of gestures and physical props to control the STEP computer simulation. Adding these new forms of interaction allows us to examine their role in supporting learning.<br><br>The existing open source STEP platform uses commercially available vision-based sensors to track the motion of up to 12 children in an 8m x 8m space. The children simply walk into the space, are assigned an avatar (i.e., they become a water particle), and that avatar follows them as they move around the room. The children's avatars are then immersed in a virtual simulation that is programed to mimic the scientific concept they are learning. In this case, the state of matter of water (e.g., solid, liquid, or gas) is determined by how fast the children move and the relative distance between them. This allows the students to discover the laws that govern state changes through their collaborative activity. Students can also use the PLAE interface (IIS-1522945) to annotate the simulation and create representations of their peers' activity, helping them all to reflect on the underlying principles inherent in the system. In iSTEP, students will now also be able to control the simulation by gesturing, posing with their whole body, and by manipulating physical objects in addition to the previous model of interacting with their entire body. In addition, by using smart watches, the project will explore alternative forms of feedback to the students as they can feel vibrations, hear sounds, and even see simple images that are targeted to help them explore the simulation. In the first round of experiments this project will contrast the gesture (and pose) interface with a new interface that uses physical props to see how each contributes to student learning. In the final year, these will be integrated to develop deeper insights into how they can best be used to support the design of learning environments that build on mixed reality systems.
The project investigates the use of big-data analysis techniques for classifying crisis-related data in social media with respect to situational awareness categories, such as caution, advice, fatality, injury, and support, with the goal of helping emergency response teams identify useful information. A major challenge is the scale of the data, where millions of short messages are continuously posted during a disaster, and need to be analyzed. The use of current technologies based on automated machine learning is limited due to the lack of labeled data for an emergent target disaster, and the fact that every event is unique in terms of geography, culture, infrastructure, technology, and the people involved. To tackle the above challenges, domain adaptation techniques that make use of existing labeled data from prior disasters and unlabeled data from a current disaster are designed. The resulting models are continuously updated and improved based on feedback from crowdsourcing volunteers. The research will provide real, usable solutions to emergency response organizations and will enable these organizations to improve the speed, quality and efficiency of their response. <br><br>The research provides novel solutions based on domain adaptation and deep neural networks to tackle the unique challenges in applying machine learning for crisis-related data analysis, specifically the volume and velocity challenges of big crisis data. Domain adaptation approaches enable the transfer of information from prior source disasters to an emergenet target disaster. Deep learning approaches make it possible to employ large amounts of labeled source data and unlabeled target data, and to incrementally update the models as more labeled target data becomes available. Large-scale analysis across combinations of source and target crises will help identify patterns of transferable situational awareness knowledge. The resulting technical and social solutions will be blended together for use in data management and emergency response.
An important step in understanding large volumes of data is the construction of a model: a succinct but abstract representation of the phenomenon that produced the data. In order to understand a phenomenon, a data analyst needs to be able to propose a model, evaluate how the proposed model explains the data, and refine the model as new data becomes available. Statistical models, which specify relationships among random variables, have traditionally been used to understand large volumes of noisy data. Logical models have been used widely in databases and knowledge bases for organizing and reasoning with large and complex data sets. This project is aimed at developing a programming language and system for the creation, evaluation and refinement of combined statistical and logical models for the express purpose of understanding very large and complex data sets. Apart from its direct effect on model development for Big Data problems, the semantic foundations and scalable computing infrastructure resulting from this project is expected to directly impact the areas of system development and verification, planning, and optimization, with broad application in Science and Engineering. The tools developed in this project will facilitate the training of a new generation of scientists capable of transforming data into knowledge for use across disciplines. The project's education and outreach component is designed to train select undergraduate students on Big Data modeling and analysis via annual workshops and research mentorship; and graduate students via curriculum modifications including a specialization in Data Science.<br><br>The project will develop Px, a language with well-defined declarative semantics, to support high-level model construction and analysis. Px will be capable of expressing generative and discriminative probabilistic and relational models, and the Px system will support complex queries over such models. The project will encompass three significant and complementary research directions, aimed at developing: (1) semantic foundations, including language constructs needed for succinct specification of complex models with rich logical and statistical structure; (2) scalable inference techniques combining exact and approximate methods, and query optimizations over combined logic/statistical models; and (3) programming extensions as well as static and dynamic analyses to support the creation and refinement of complex models. The Px language and system will be evaluated using two important and diverse application problems: (1) analysis and verification of infinite-state probabilistic systems, including parameterized systems, and (2) construction of phylogenetic trees from phenomic data, used in the Tree of Life project, for mapping the evolutionary history of organisms. The project is expected to make significant contributions towards creating a unifying framework combining probabilistic inference, logical inference, and constraint processing, with an emphasis on semantic clarity, efficiency, and scalability. The project will also demonstrate the practical utility of the proposed integrated framework by developing complex models from big data that take advantage of this technology in fundamental ways.
The project investigates the use of big-data analysis techniques for classifying crisis-related data in social media with respect to situational awareness categories, such as caution, advice, fatality, injury, and support, with the goal of helping emergency response teams identify useful information. A major challenge is the scale of the data, where millions of short messages are continuously posted during a disaster, and need to be analyzed. The use of current technologies based on automated machine learning is limited due to the lack of labeled data for an emergent target disaster, and the fact that every event is unique in terms of geography, culture, infrastructure, technology, and the people involved. To tackle the above challenges, domain adaptation techniques that make use of existing labeled data from prior disasters and unlabeled data from a current disaster are designed. The resulting models are continuously updated and improved based on feedback from crowdsourcing volunteers. The research will provide real, usable solutions to emergency response organizations and will enable these organizations to improve the speed, quality and efficiency of their response. <br><br>The research provides novel solutions based on domain adaptation and deep neural networks to tackle the unique challenges in applying machine learning for crisis-related data analysis, specifically the volume and velocity challenges of big crisis data. Domain adaptation approaches enable the transfer of information from prior source disasters to an emergenet target disaster. Deep learning approaches make it possible to employ large amounts of labeled source data and unlabeled target data, and to incrementally update the models as more labeled target data becomes available. Large-scale analysis across combinations of source and target crises will help identify patterns of transferable situational awareness knowledge. The resulting technical and social solutions will be blended together for use in data management and emergency response.
The persistently lopsided gender makeup of computer and information science programs in US universities and colleges suggests that the gender gap in computing education is still obstinately wide. Despite several national initiatives to diversify participation in STEM fields, the underlying culture of computing education remains relatively stagnant, with curriculum, tools and materials that continue to emphasize areas historically aligned more closely with male interests than women's. This project takes a very different starting point to understanding the pipeline challenge of women's underrepresentation in STEM careers through focusing on how young girls learn. Through understanding the socially situated nature of learning tools and materials, educators and technologists can design more equitable learning environments for all youth and extend current learning theory to better understand the role of tools and artifacts in the learning process.<br><br>Central to the understanding of learning is the relationship between various tools and technologies and the structuring of disciplinary subject matter. However, very little empirical research exists to inform contemporary understanding of how tools and materials shape learning and participation across this emerging technological landscape. Through a series of systematic and crosscutting research investigations, this project provides a basis for theorizing how contemporary electronic tools and materials (e.g., toolkits like paper computing, squishy circuits, e-textiles) shape learning and participation. Each investigation occurs in the complexities of real-world settings such as schools and afterschool clubs; includes the development of new sets of assessments; illuminates design principles for creating new tools and educational ecosystems to better support learning and equitable participation; and explores the design of new toolkits and parts based on these emergent principles. Design-based research guides the methods of each study, in consultation with practitioners to help ensure each proposed activity system effectively complements curricular and practical realities.
Clinical decision support has the potential to reduce healthcare costs and improve patient outcomes, while shedding light into policy questions surrounding healthcare costs and practices in the US. This project aims to develop intelligent clinical decision support techniques for recommending optimal action plans - including both diagnostic tests and medical interventions - for treating chronic disease, performing multi-step and adaptive treatments, and modifying long-term health habits. In an effort to integrate evidence-driven decision-making with established clinical practices, the research will develop disease-agnostic artificial intelligence techniques that combine data from large electronic health records (EHRs) with recommendations from human experts. A prototype decision support system will be tested on three clinical settings - cardiology, clinical depression, and emergency room readmission - using existing EHR datasets and consultation with domain experts from clinical partners. Outcomes-driven and cost-driven optimized decisions will be compared to current clinical practice. This exploratory research will provide the groundwork for follow-up projects in decision support information presentation, integration with clinical workflow and IT systems, and making the transition from retrospective studies to clinical trials. Other broader impacts include workshops for healthcare applications of AI, and women and minority students will be recruited and mentored in graduate and undergraduate computer science research.<br><br>The technical approach of this research builds on state-of-the-art machine learning and artificial intelligence methods to automatically learn, simulate, and reason about patient-specific treatment plans. Such methods must be simultaneously probabilistic and temporal. Probabilistic techniques are needed to handle significant uncertainties in clinical diagnoses and outcomes, much like a human clinician would. Temporal techniques are needed to consider sequences of future decisions over the course of treatment, rather than decisions at single time points. More specifically, this project will consider the use of statistical relational learning (SRL) techniques to mine for probabilistic, temporal patterns in large electronic health records, and these patterns will be used in partially-observable Markov decision processes (POMDPs) that exhaustively search for optimal treatment sequences. Recent results indicate that SRL achieves superior performance to other machine learning methods in predicting cardiac arrest from demographic and lifestyle observations, and POMDP treatment plans outperform existing fee-for-service practices by reducing costs by 50% and improving outcomes by 40% on a clinical depression dataset. By combining SRL and POMDPs, specifically, using SRL to learn a disease progression model used by the POMDP, this project aims to achieve further improvements in recommendation quality and computational scalability for complex treatments. Furthermore, because EHRs may suffer from limited or missing data, clinical decision support tools should follow established practices and expert knowledge when necessary. To do so, new workflows for integrating expert knowledge into SRL and POMDPs will be explored. Evaluation will be performed on a variety of disease scenarios in conjunction with clinical partners at Marshfield Clinic, Centerstone, Wake Forest School of Medicine, and South Bend Memorial Hospital.
Diabetes is a global and national epidemic. One in ten healthcare dollars in the U.S. is spent on costs directly attributable to diabetes. Persons with Type-1 diabetes, especially children and the elderly, can experience sudden drops in blood sugar, that is, they can become hypoglycemic. This can be very dangerous if it remains unrecognized. The metabolic processes that lead to hypoglycemia generate odorants in human breath and perspiration. The specific odorants are not known by the medical community, but trained diabetes alert dogs can recognize the onset of hypoglycemia from odorants in a patient's breath. This award supports the basic research to identify the odorants of hypoglycemia in human breath and the development of a noninvasive hand-held smart sensor able to detect the odorants and communicate health information to patients, caregivers, and family members. Development of the smart device will improve health-monitoring options for persons with Type-1 diabetes, ultimately leading to decreased healthcare costs and improved lifestyles for the patients and their caregivers. This research will provide interdisciplinary research experiences to graduate and undergraduate students. In addition, this project will support participation of underrepresented groups and educational outreach programs for K-12 students and teachers across Indiana and the U.S.<br><br>The metabolic processes that lead to hypoglycemia cause the production of specific volatile organic compounds in human breath. This fact is not currently used by the medical community to monitor diabetes or track the onset of hypoglycemia. However, trained diabetes alert dogs are able to identify these compounds and recognize the onset of hypoglycemia. Following this, the objective of this proposal is to develop a novel smart device able to detect the volatile organic compound profile in human breath that correlates with hypoglycemia. This will be accomplished in three steps. First, the identification of the hypoglycemic-signature breath profile, which will be validated by testing with diabetes alert dogs. Second, the development of a nanosensor array capable of detecting the identified compounds. Third, the incorporation of the nanosensor array into a portable smart device. The monitoring of volatile organic compounds in breath challenges the existing way of thinking that glucose is the only useful metabolic marker of hypoglycemia. This work will also aid researchers in understanding metabolic pathways associated with hypoglycemia. Moreover, the intuitive and secure mobile application interface that will be developed will effectively communicate relevant healthcare information.
To prescribe safe medications, physicians use computerized physician order entry (CPOE) that routinely relies on drug-drug interaction (DDI) alerts. Despite the current attempts to reduce frequency and complexity of alerts, the effectiveness of such alerts remains extremely low, with up to 96% of warnings being ignored by physicians on a daily basis. The primary cause for this is alert fatigue, a state in which physicians, bombarded by numerous warnings, become desensitized. The goal of this project is to transform drug safety alerts from oft-ignored warnings to trusted tools that advise physicians in daily decision making. To accomplish this, the investigators are aiming beyond incremental improvement establishing novel principles for alert design that are based on what physicians consider important when taking advice from peers in their daily clinical work. The project is addressing this problem with a three prong approach: (1) determining principles that accompany trusted physician-to-physician advice regarding appropriate medication prescribing; formative studies will be conducted in a variety of clinical settings to identify key factors in sharing trusted advice among doctors and residents; (2) generating novel designs for drug safety guidance that elicit physician trust and maximize compliance and (3) evaluating the impact of novel designs on physician compliance to DDI warnings.<br><br>Intellectual Merit:<br>By investigating the question of why physicians trust each other, the project is leveraging a fundamental behavioral dynamics reconsidering the role of clinical alerts, and thus generating new principles to design effective computerized guidance that elicits similar notions of trust. A very important contribution of this research is a more complete understanding of what makes physician-to-physician advice trustworthy in the ecosystem of daily clinical activities provides a solid, long-term intellectual basis for the creation of substantially better alerts for a broad variety of CPOE systems. Key innovative aspect of this work is the departure from the mere optimization of alerts to focus rather on complex yet crucial dynamics by which trusted advice is shared among physicians. There are potentially transformative aspects of the proposed work, which if successful, could unleash a new generation of drug-drug interaction warnings that will substantially advance the level of adherence in daily medication prescribing.<br><br>Broader Impacts:<br>The outcomes from this project will potentially affect the over 600,000 physicians in the United States who spend the majority of their time in direct patient care, and who are exposed to dozens of DDI alerts on a daily basis. By reframing current alerting strategies, the project results are expected to substantially increase safe drug prescription in day-to-day clinical setting. The investigators are disseminating the project results through large-scale real-world CPOE deployments and live experimental evaluations available to hundreds of physicians. The team is also reaching out to CPOE vendors, to promote the incorporation of the ideas generated in the project in the current and next generation of products. Ultimately, this basic research in physician communication and human-computer interaction is providing the research basis to catalyze a change in industry practice, also facilitated by the PI's leadership of the EMR Innovations Summit, an annual meeting of national EMR vendors hosted by the Regenstrief Institute.
With the advent of Internet, numerous applications in the context of network traffic, search, and databases are faced with very large, inherently high-dimensional, or naturally streaming datasets. To effectively tackle these extremely large-scale practical problems (e.g., building statistical models from massive data, real-time network traffic monitoring and anomaly detection), methods based on statistics and probability have become increasingly popular. This proposal aims at developing theoretical, well-grounded statistical methods for massive data based on random projections, including data stream algorithms, quantized projection algorithms, and sparse projection algorithms.<br><br>Massive data are often generated as high-rate streams. Network traffic is a typical example. Effective measurements (and updates) of network traffic in real-time using small storage space are crucial for detecting anomaly events, for example the DDoS (Distributed Denial of Service) attacks. For many applications such as databases and machine learning, appropriate quantization of random projections will substantially improve the accuracies (in terms of variance per bit) and provide efficient indexing and dimension reductions to facilitate efficient search and learning. The proposed research will tackle a series of mathematically challenging problems in the development of random projections. A wide range of statistical learning and numerical linear algebra algorithms will be re-engineered to take advantage of the state-the-art projection methods.<br><br>These days, many industries such as search are in urgent demand for statistical algorithms which can effectively handle massive data. It is expected that algorithms to be developed in this proposal will be integrated with parallel platforms, to solve truly large-scale real-world problems. Research results will be disseminated to practitioners through publications, conference presentations, industry visits and collaborations, tutorials, and open-source distributions. Many of the proposed research problems involve statistical analysis and may continue to help attract statisticians/mathematicians to work on area of big data. The proposed research activities will engage both undergraduate and graduate students in statistics and engineering, through innovative curriculum and research training.
Dynamic Data Driven Avionics Systems (DDDAS) have the potential to endow aircraft with the ability to dynamically use sensor data to detect failure conditions and accurately simulate flight plans in order to support pilot decisions in emergency scenarios. PI Varela will investigate how to dynamically detect data errors and equipment failures by matching measured data to pre-computed error signatures and damage performance profiles. Once a failure type is detected, redundant data will be used to correct for instrument errors when possible and to increase the fidelity of an onboard self flight simulator. This research will enable virtual failure enhanced flight simulations to predict the outcome of different flight plans before they are executed. DDDAS will thus support better-informed decision making for pilots in emergency conditions and it will also be applicable to autonomous unmanned air and space vehicles. Furthermore, new mathematical techniques and associated software for data streaming analytics will likely be applicable to other domains, including health monitoring and spacesuit technologies. The PI intends to make all developed programming technology, run-time middleware, and flight data available to the community in open-source form.<br><br>This research project will investigate methodologies and develop new techniques in several fundamental research directions as they pertain to the proposed DDDAS model: (1) This project will enhance dataflow concurrent programming to make it fault-cognizant and fault-tolerant. In particular, this work will extend the unbound and bound states of dataflow variables with a new dataflow variable state: correlated uncertainly bound. This enhancement will allow software developers to explicitly model distributed redundant data streams to be able to recognize and tolerate failures with quantified uncertainty. The project will also study the impact of this enhancement on the heterogeneity and asynchrony tolerance already afforded by the dataflow concurrent programming model. (2) This project will investigate extensions to logic programming to support stochastic reasoning. In particular, the PI will create language extensions to standard Horn clause-based knowledge bases to incorporate probabilities. Additional extensions will specifically support spatial and temporal data streams. Furthermore, the PI will create incremental reasoning algorithms to be able to recompute queries efficiently as applications dynamically receive new data. (3) Finally, this project will investigate cloud-based techniques for scalable data analytics. The PI will explore the use of hybrid (private and public) clouds for online (real-time) data analytics as well as for offline data storage and processing. Elasticity and scalability of data streaming, storage, and processing techniques on hybrid clouds will enable multi-criteria optimization. Policies will include optimizing for analytics performance, aircraft-to-cloud communication, and/or cost. &#8232;The DDDAS model will be applied to flight decision support systems in emergency conditions. Specific activities will include: i) creating multi-fidelity models and incremental algorithms that will allow DDDAS to inject data from aircraft sensors dynamically, ii) formalizing the notion of aircraft damage/failure profiles, and iii) evaluating the new mathematical and computational techniques with actual flight accident data.
Recent advances in large-scale electronic health record database techniques provide exciting new opportunities to the study of drug safety. Drug-drug interactions (DDIs), a major cause of adverse drug events (ADEs), are a serious global health concern, and a severe detriment to public health. The scale of DDIs involving three or more drugs (also called high-order DDIs) has posed a prohibitory challenge for its molecular pharmacology and clinical research, which motivates alternative strategies such as mining health record data. This project aims to develop large-scale computational strategies and effective software tools for mining high-order DDI effects from health record databases, in order to yield novel discoveries in drug safety, and ultimately to benefit national health and well being.<br><br> <br>To achieve the above goal, this project is designed to complete four specific tasks. Task 1 aims to develop a novel statistical framework to discover high-order DDI signals associated with ADEs from health record databases. Task 2 aims to study a novel drug safety problem for mining directional DDI signals. Task 3 aims to develop an innovative approach for mining directional DDI patterns at the drug-group level. Task 4 is devoted to software development, evaluation and validation. The project applies these methods to analyze three independent databases, packages method implementations into a user-friendly software toolkit, and releases the toolkit to the public. This project not only facilitates the development of novel computational techniques in drug safety research, but also addresses emerging scientific questions in modeling, mining, and visual exploration of complex data such as the health record data. The project's educational activities include course development, student mentoring and advising, and involvement of minority and underrepresented students in research activities.
The electric power grid is the indispensable infrastructure for power delivery and distribution. It is a system of high complexity and heterogeneity comprised of a variety of interconnected systems, subsystems, generators, and loads. In addition, it is a dynamic system with evolving characteristics that suffers from several infrastructure limitations, which if not handled properly, may lead to instabilities with severe consequences including costly brownouts and blackouts. However, advancements in information and data-driven technologies offer the necessary ground for developing tools that efficiently monitor grid infrastructure and manage electricity flows in ways that achieve and maintain high performance and reliability in grid operations. Towards that end, coupling power systems with information systems converts traditional electric energy delivery infrastructures into interconnected hybrid energy-data systems called smart energy systems, where power flow is controlled via information signals. Dynamic data available in smart energy systems includes, but is not limited to, hourly user energy consumption measurements from smart meters, electricity pricing signals, system voltage readings from GPS-synchronized measuring units scattered throughout the network that can take hundreds of readings per second, and data from weather stations. Thus, due to grid complexity, a tremendous amount of information is not only generated but also transferred throughout the grid, and grid participants, such as customers, utility companies, and grid operators, are exposed to multiple heterogeneous data streams coming from various sources. In this data intensive environment, participants are being engaged to make fast real-time decisions regarding morphing of their load demand and consumption behavior patterns. Nodal load forecasting is identified as a key point for developing future smart energy systems and electricity markets. The principal theme of this research is the fast and optimal nodal load morphing in smart energy systems that takes into account big volumes of dynamically varying data.<br><br>In particular, this research addresses the problem of management and processing of big data within the framework of Dynamic Data Driven Systems (DDDS) as applied to nodal load morphing. The focus of this study will be the development of a set of new intelligent and self-adaptive algorithms for online big data processing and fast real-time decision-making in smart energy infrastructures. The main feature of the current research is the integration of machine learning DDDS with dynamic optimization methods to solve the computational problem of forecasting optimal or near-optimal shapes of a load in a timely manner accounting for multiple streams of continuously incoming data and their inherent uncertainty. Emphasis will be given in handling and processing incentive signals and more particularly electricity pricing signals as a major factor in load morphing. Furthermore, extensive testing and verification of the developed algorithms will be performed on real-time simulated scenarios obtained with the GridLAB-D software simulator. In short, the proposed research for nodal load morphing will enable a new and transformative approach towards efficient, inexpensive, and fast processing of big data as applied to smart energy systems.
This research will address a dynamic big data problem that is of urgent national interest: the need for efficient methods to diagnose faults and attacks in critical interconnected infrastructures, such as electricity power networks. Additionally, this project will investigate new methodologies to extract knowledge from the complex streams of data that come from various sensors in infrastructure systems and the models of their behavior. Results and findings in this project will be validated via industry-accredited power system simulators, and will be useful to the power industry in enhancing the safety, stability, and security of essential power infrastructure. This project will promote multi-disciplinary research involving expertise in big data analysis, machine learning, security, power systems, and control systems. This research will provide a powerful bridge between theory and real-world applications while serving as a training platform for a diverse new generation of engineers at the University of California, Riverside, one of America's most ethnically diverse research-intensive institutions.<br> <br>This project will foster the use of multi-resolution data-driven methods for the detection and classification of anomalies in critical dynamical infrastructures, with focus on power networks. This project has three novel, innovative, and potentially transformative technical elements: (1) A comprehensive statistical model, as an alternative to existing physics-based models, using Dynamic Bayesian Networks and Conditional Random Fields to model complex infrastructures subject to failures and attacks; (2) A hierarchical detection and classification method based upon machine learning concepts to tame and leverage the vast amount and diversity of dynamic multi-resolution data collected by spatially distributed sensors; (3) A systematic method to train and inform data-driven methodologies from model-based and analytical knowledge that come from power systems and control theory to build scalable and performing detection and classification mechanisms in power infrastructure security.
Predicting and quantifying the behavior of complex systems in engineering and science is a topic of critical importance for many areas such as design, optimization, and safety. Even more critical is the forecast of extreme responses of these systems. Rare responses that can lead to catastrophic events manifest themselves in a wide range of systems such as geophysical phenomena, power and communication networks, and epileptic incidents in brain activity, just to mention a few. In all of these cases, accurate predictions are hampered by the fact that the exact dynamics of the system in nature is often poorly understood. This poor understanding is due to the large number of essentially coupled mechanisms that operate at different temporal and spatial scales. Although it is not always essential to predict the system with high accuracy over all these different levels, it is important to understand and model the effect of the unresolved mechanisms to the degrees of freedom we want to predict. This requires a reliable knowledge of the descriptive laws for these mechanisms as well as their coupling to the degrees-of-freedom of interest and this is clearly not always (well) done. This incomplete modeling of the dynamics leads to inevitable model error that is essential to be taken into account for reliable predictions. An obvious way that this can be done is by the utilization of available and dynamically incoming data. The goal of this work is the development of methods and algorithms to extend the capability for data-driven morphing (that is, data-driven adaptation) of parsimonious models. These will be able to adequately capture the instantaneously most significant dynamics of the system and utilize them to inexpensively perform informative prediction and uncertainty quantification. Such a development will be of critical importance for many fields where the modeling and predictive capacity is limited by the inadequate understanding of the underlying physical mechanisms.<br><br>The aim of this proposal is to link machine learning with model reduction in a data-stream-driven environment, in order to formulate fundamentally novel methods for the probabilistic forecast of complex stochastic systems. Of particular interest is the quantification and prediction of extreme responses, by relying exclusively on the utilization of available data and with the minimum use of equations (or high fidelity solvers), if these are available. The effort is driven by the presence of serious obstacles associated with the prediction of such features in complex dynamical systems: non-negligible model error in the descriptive laws (if these are available), prohibitive cost for real time computations, sparse data or data with non-negligible error, and transient dynamics. These difficulties are manifest at a time when there is a great need for understanding and prediction of extreme responses in contexts such as climate dynamics, nonlinear waves, and networks of high dimensionality. The aim is to address several of theses challenges by constructing new stochastic prediction methods that will extend the existing state-of-the-art for data-driven modeling and prediction through the implementation (and appropriate extension) of machine learning / data mining techniques and the combination with stochastic order reduction and uncertainty quantification methods that dynamically adapt the reduced order subspace according to the dynamics. These efforts will be guided by a proof-of-concept application involving prediction of extreme, localized events in nonlinear waves. Adaptive reduced order models driven by data will be a key element for the inference of critical dynamical properties, which are otherwise "buried" in the complex responses. By linking machine learning techniques to adaptive reduced order models our research will catalyze new domains of numerical/mathematical analysis and it will extend the reach of more conventional mathematics-assisted modeling beyond some of its current limits.
Recent advances in sensor and robotics technology have led to large networks of coordinated mobile platforms that can perform automatic sensing, mapping, learning, and control tasks. While the remote tasks can be controlled by the ground center via long-range communication links, the links are expensive and suffer long delays. This project develops computational methods that will significant improve the ability for the remote agents to coordinate locally with one another for tasks such as recognize and navigate around obstacles, reconstruct signals, and learn new control policies from a large amount of multi-modal sensor data, all done with little or no communication to a center. The proposed approach is radically different from the current state of the art. It also includes educational components such as courses, seminars, and initiatives for under-represented minority and women.<br><br>The proposed work is a set of novel algorithms for a variety of computing problems in multi-agent networks, for problems involving extremely large-scale distributed datasets and high complexity objectives, and with greater accuracy at rates that are provably faster than existing methods. Very promising preliminary results have been obtained. The proposed project includes (a) a new approach to integrate multi-agent coordination with problems arising in optimization, game theory, control, and learning, into systems of equations, inclusions, or variational inequalities; (b) novel operator splitting methods that lead to decentralized numerical solutions of these systems, which scale to new levels of size, complexity, and diversity; (c) stochastic approximation techniques to deal with the imminent "distributed data deluge", along with accelerations techniques based on variance reduction, importance sampling, and asynchronous parallelization; and (d) a set of open-source software products for optimization, control, and learning problems with dynamic and large-scale data, along with a comprehensive evaluation plan. The contributions of the project is a unified framework in parts (a) and (b) above, which enable the decentralized numerical solutions at new levels of speed, complexity, diversity, and resilience. In order to achieve the goals, substantial resources will be devoted to both mathematical research and engineering challenges.
This project aims to carry out fundamental work on the transformative/disruptive idea of data analytics and data-feature extraction by newly defined and calculated principal-component vectors that best represent the main features of a given data set, even in the presence of faulty/missing/outlier data. Based on this idea, an algorithmic framework will be developed to support several targeted applications, such as data processing in social networks, image processing and video libraries, wireless-sensor-network data fusion, economics, genomics and proteomics, and bioinformatics. The potential impact of the project work is immense and may extend well beyond these applications to cover any field of science and engineering where conventional data feature extraction has been used in the past.<br><br>Technically speaking, the investigation aims at rewriting the enormously rewarding over the past century chapter on L2-norm (eigen-vector and singular-vector decomposition) data analysis. Optimal L1-norm data analytics are being developed that are inherently resistant to data contamination and as good as L2-norm analytics on "clean" data. L1-norm data principal component analysis has seen a limited amount of previous research and is non-existent so far in education/textbooks. Several profound differences between L1-norm based principle component analysis (PCA) and standard L2-norm PCA have, to date, blocked progress in the theoretical understanding (and thus in the design of efficient algorithmic solutions) of L1-based PCA. The project seeks the development of a novel approach toward dimensionality reduction under the L1 norm to deal with processing of outlier-prone/contaminated ?big data? (large amount of high-dimensional data) by interpreting the fundamental L1-norm principal-components optimization problem as an equivalent binary-field maximization problem, and in such opening a spectrum of potentially new analytical and algorithmic techniques. The project goals include: (i) Fundamental algorithmic research on the exact calculation of maximum-L1-norm-projection data features; (ii) fundamental understanding and execution of L1-norm-measured data dimensionality reduction; and (iii) sample-space reduction.
The obesity epidemic among children has become a widespread problem in the United States. This trend is disturbing because overweight children tend to become overweight or obese adults with potentially life threatening chronic conditions. By focusing on children?s physical activity, we can shift the problem from treatment to prevention. There are numerous academic and commercial applications that aim to help individuals monitor and make proactive decisions about their physical activity; however they do not integrate well into an individual's daily life because they may require manual activity input, asynchronous visualization, and non-instinctive awareness of the application for actionable feedback. Thus, while existing devices have had some success in monitoring, inferring, and presenting activity, they do not always convey the value of physical activity in an intuitive visual abstraction. The feedback design is important in designing wearable technology for children because children are less likely to connect quantifiable measurements - in this case with their health.<br><br>In response to these issues, we design innovative wearable computing components that empower children to craft their own intuitive abstractions of wellness data for physical activity promotion. This project builds on existing socio-technical research in health informatics by extending the nascent research subarea, wellness informatics, that studies how technology can be utilized to empower lay populations to stay well and adopt preventative health behaviors. The research objectives of this project are to: (1) Design plug-and-play wellness monitoring Health Sense systems; (2) Design a graphical programming environment to control the actions of the Health Sense systems; and (3) Understand how children use Health Sense systems. The research methodology is inspired by participatory design activities including participant observations, design workshops, and iterative evaluation of prototypes. Overall, the proposed system provides innovations in computing by creating new, wearable computing prototypes and paradigms of interaction. <br><br>The broader impacts of Health Sense include undergraduate and graduate research assistant interdisciplinary research training. The research team is introducing low socioeconomic status K-12 students to computing, electronics, and health through Health Sense workshops. Research methodology and results is being integrated into the PIs' established 1st year general engineering projects courses. In addition, the PIs and their students are helping increase the pipeline of future scholars by developing teaching and outreach materials that are being distributed through the project website. The PIs and their students are disseminating their research by publishing results in health informatics and traditional computing venues. Finally, the system also helps fulfill Healthy People 2020 Educational and Community-Based Programs goals.
The goal of the Doctoral Consortium in Pervasive Health Care is to support the doctoral students through constructive remarks and feedback on their research from prominent researchers and through interaction with other students. Student participants will be from a broad range of disciplines and approaches that inform pervasive computing, including biomedical informatics, computer science, information science, engineering, clinical sciences, law, and related fields. The student participants should be well into their dissertation research and will be expected to give short presentations of their work during the Consortium. <br><br>The Consortium will be held in conjunction with the 8th International Conference on Pervasive Computing Technologies for Healthcare in Oldenburg, Germany. PervasiveHealth is a premier international forum with specific focus on technologies and human factors related to the use of ubiquitous computing in healthcare and wellbeing. The participants will be mentored by faculty members and provide a longer term supportive mentoring network to help new researchers navigate the challenges of interdisciplinary research. The DC will take place on the weekend prior to the PervasiveHealth conference. This will allow students to also participate in the overall conference as well.
Predicting and quantifying the behavior of complex systems in engineering and science is a topic of critical importance for many areas such as design, optimization, and safety. Even more critical is the forecast of extreme responses of these systems. Rare responses that can lead to catastrophic events manifest themselves in a wide range of systems such as geophysical phenomena, power and communication networks, and epileptic incidents in brain activity, just to mention a few. In all of these cases, accurate predictions are hampered by the fact that the exact dynamics of the system in nature is often poorly understood. This poor understanding is due to the large number of essentially coupled mechanisms that operate at different temporal and spatial scales. Although it is not always essential to predict the system with high accuracy over all these different levels, it is important to understand and model the effect of the unresolved mechanisms to the degrees of freedom we want to predict. This requires a reliable knowledge of the descriptive laws for these mechanisms as well as their coupling to the degrees-of-freedom of interest and this is clearly not always (well) done. This incomplete modeling of the dynamics leads to inevitable model error that is essential to be taken into account for reliable predictions. An obvious way that this can be done is by the utilization of available and dynamically incoming data. The goal of this work is the development of methods and algorithms to extend the capability for data-driven morphing (that is, data-driven adaptation) of parsimonious models. These will be able to adequately capture the instantaneously most significant dynamics of the system and utilize them to inexpensively perform informative prediction and uncertainty quantification. Such a development will be of critical importance for many fields where the modeling and predictive capacity is limited by the inadequate understanding of the underlying physical mechanisms.<br><br>The aim of this proposal is to link machine learning with model reduction in a data-stream-driven environment, in order to formulate fundamentally novel methods for the probabilistic forecast of complex stochastic systems. Of particular interest is the quantification and prediction of extreme responses, by relying exclusively on the utilization of available data and with the minimum use of equations (or high fidelity solvers), if these are available. The effort is driven by the presence of serious obstacles associated with the prediction of such features in complex dynamical systems: non-negligible model error in the descriptive laws (if these are available), prohibitive cost for real time computations, sparse data or data with non-negligible error, and transient dynamics. These difficulties are manifest at a time when there is a great need for understanding and prediction of extreme responses in contexts such as climate dynamics, nonlinear waves, and networks of high dimensionality. The aim is to address several of theses challenges by constructing new stochastic prediction methods that will extend the existing state-of-the-art for data-driven modeling and prediction through the implementation (and appropriate extension) of machine learning / data mining techniques and the combination with stochastic order reduction and uncertainty quantification methods that dynamically adapt the reduced order subspace according to the dynamics. These efforts will be guided by a proof-of-concept application involving prediction of extreme, localized events in nonlinear waves. Adaptive reduced order models driven by data will be a key element for the inference of critical dynamical properties, which are otherwise "buried" in the complex responses. By linking machine learning techniques to adaptive reduced order models our research will catalyze new domains of numerical/mathematical analysis and it will extend the reach of more conventional mathematics-assisted modeling beyond some of its current limits.
Emergency responders (police, fire, ambulance services) have more and more access to more and more data stream: sensor readings, security cameras, personal reports (via cellphone, texts, tweets), GPS data etc. The availability of these data streams presents enormous opportunities - but also poses fundamental challenges:<br>* Data streams arrive from a wide variety of sources and contain many diverse features; this makes it difficult to extract information from the streams, and especially, to integrate information from different streams. <br>* Knowledge learned from past events must be transferred to knowledge about present (and future) events. Because no two events are ever identical, the knowledge learned from past events must be transferred to knowledge about present events that are not identical but only "similar" - and in ways that may not be known in advance and so must be discovered. <br>* Learning and detection - and the actions that follow learning and detection ? must take place in a timely fashion: it is of little use to learn how to respond to an emergency only long after the emergency has passed. <br>To accomplish this, the proposed work relies on new methods to discover what is relevant both in each individual data stream and across data streams, and to learn and exploit the similarities between the past and the present. This work is transformative and success in this project has the potential to lead to enormously enhanced, even life-saving, responses to emergencies of many sorts. <br><br>Existing approaches treat individual data streams by exploiting particular physical characteristics of the signal, and treat multiple data streams in an ad-hoc fashion. These approaches miss the fact that it is not the physical characteristics of the signal that are important but rather the (semantic) information in the signal, and that there are connections between the information in different data streams. This project transforms the problem of learning from multiple (multi-modal) data streams by focusing on the relevance of information in each data stream, across data streams, and through time. The relevant information will generally be different for different events and different purposes and will not be known in advance, so relevance must be learned. To do this, this project organizes the information available at each moment in time in terms of contexts which encode exogenous metadata (e.g., when, where and by whom data was gathered) and endogenous metadata (e.g., features and statistics extracted from the data). In general, there are an enormous number and variety of contexts, but the most relevant information is embedded in only a few contexts. Because these most relevant contexts will not generally be known in advance and will be different in different scenarios, this project will develop a new class of methods and algorithms to discover the relevant contexts from multiple dynamic, multi-modal and high-dimensional data streams, and to use what is discovered to learn, detect and respond in a timely fashion. Because no two events are exactly the same, this project will develop of a new class of methods and algorithms for the discovery of relevant semantic similarities and their application, making it possible to transfer knowledge learned from past events to knowledge about present events. This work requires the development of highly innovative methodology and techniques that go far beyond existing work (high risk) and are potentially transformative for a wide variety of applications ranging from event detection to actionable intelligence.
Sensors or sensing systems are increasingly critical in a variety of applications including national security, surveillance monitoring and health care. Those systems should function with minimal hardware recourses, minimal communications and minimal computation overhead, and these efficiencies can dramatically improve the performance, reliability and usability, which can broaden the overall application scope of sensor systems. This EAGER project is to pursue preliminary results of dynamic configurability of architectural and circuit models in sensing systems, and the proposed research will have significant impacts on a range of sensing applications under the resource-constrained environment. For example, in large-scale sensor networks or implantable sensors, energy is tightly constrained. The ultimate goal of the research is to exploit the configurability and dynamics of sensing systems to improve the overall system efficiency. This project serves as an expedition to investigate the dynamically architectural sensing techniques and may open a new research direction of theory and practice in the signal acquisition. Upon the success of this project, a better performance-energy tradeoff in the sensing system will be obtained, which can further strengthen its advantage compared to other sampling techniques, and extend its application regime. To broaden the impacts of this project, PIs will disseminate the research results through multiple channels, including conference presentation, journal publication and open research material online. PIs also plan to integrate the research outcomes into the curriculum development and develop a new research seminar on related topics. The project will provide research opportunities for undergraduate students and researchers from underrepresented groups.<br><br>Specifically, this EAGER project investigates the dynamic configurability of parameterized Compressed Sensing architecture. With the physical and architectural models, the Compressed Sensing architecture is flexible and provides a larger design/configuration space, and can adapt towards different signal structures and use conditions. The research work is expected to explore a deeper bound of the performance-energy by exploiting the architectural configurability with physical models. To this aim, a set of research tasks will be performed in this project, and the technical thrusts can be summarized from three aspects. First, the project will explore the configurability at both architectural- and circuit- levels in Compressed Sensing, incorporating signal structure variations. Multiple factors in the Compressed Sensing will be investigated. Second, by integrating physical models into the Compressed Sensing architecture, a larger design space will be discovered and defined. The benefit of the performance-energy trade-off will be demonstrated in the new space. Third, a set of novel algorithms will be developed for efficient configuration search in the design space. Several deterministic and heuristic strategies will be investigated in the project.
Pervasive Healthcare Doctoral Consortium 2016<br><br>The aim of the Sixth Pervasive Healthcare Doctoral Consortium is to provide doctoral students a supportive scientific forum for students to engage in inter- and multi-disciplinary scholarship focusing on organizational, technical, social, and biomedical issues surrounding health-related technologies. The consortium provide a forum for expert and peer critique of students' doctoral work with the goal of improving their dissertation. Student participants will also have the opportunity to receive networking support and career advice from internationally-recognized experts. Overall, the doctoral consortium brings together people who might not otherwise engage with one another and engage in inter-disciplinary research in fields involving healthcare and pervasive computing. The consortium also exposes participant to different scientific disciplinary approaches and develops the next generation of scholars in pervasive computing in the domain of healthcare. <br><br>The aim of the Sixth Pervasive Healthcare Doctoral Consortium is to support doctoral students through constructive remarks and feedback on their interdisciplinary research from prominent researchers and through interaction with other students. Student participants from a broad range of disciplines including pervasive computing, biomedical informatics, computer science, information science, engineering, clinical sciences, law, and medical informatics will give short presentations of their work and receive constructive feedback from five internationally respected experts in pervasive healthcare. The expert panelists will also provide student participants with career guidance and mentoring through presentations and small group advising throughout the day. In addition, the doctoral consortium will be held during pre-conference activities, thus student participants will have the opportunity to see the conference and network with conference attendees.
Sensors or sensing systems are increasingly critical in a variety of applications including national security, surveillance monitoring and health care. Those systems should function with minimal hardware recourses, minimal communications and minimal computation overhead, and these efficiencies can dramatically improve the performance, reliability and usability, which can broaden the overall application scope of sensor systems. This EAGER project is to pursue preliminary results of dynamic configurability of architectural and circuit models in sensing systems, and the proposed research will have significant impacts on a range of sensing applications under the resource-constrained environment. For example, in large-scale sensor networks or implantable sensors, energy is tightly constrained. The ultimate goal of the research is to exploit the configurability and dynamics of sensing systems to improve the overall system efficiency. This project serves as an expedition to investigate the dynamically architectural sensing techniques and may open a new research direction of theory and practice in the signal acquisition. Upon the success of this project, a better performance-energy tradeoff in the sensing system will be obtained, which can further strengthen its advantage compared to other sampling techniques, and extend its application regime. To broaden the impacts of this project, PIs will disseminate the research results through multiple channels, including conference presentation, journal publication and open research material online. PIs also plan to integrate the research outcomes into the curriculum development and develop a new research seminar on related topics. The project will provide research opportunities for undergraduate students and researchers from underrepresented groups.<br><br>Specifically, this EAGER project investigates the dynamic configurability of parameterized Compressed Sensing architecture. With the physical and architectural models, the Compressed Sensing architecture is flexible and provides a larger design/configuration space, and can adapt towards different signal structures and use conditions. The research work is expected to explore a deeper bound of the performance-energy by exploiting the architectural configurability with physical models. To this aim, a set of research tasks will be performed in this project, and the technical thrusts can be summarized from three aspects. First, the project will explore the configurability at both architectural- and circuit- levels in Compressed Sensing, incorporating signal structure variations. Multiple factors in the Compressed Sensing will be investigated. Second, by integrating physical models into the Compressed Sensing architecture, a larger design space will be discovered and defined. The benefit of the performance-energy trade-off will be demonstrated in the new space. Third, a set of novel algorithms will be developed for efficient configuration search in the design space. Several deterministic and heuristic strategies will be investigated in the project.
REU Site: Proactive Health Informatics<br>The Proactive Health (ProHealth) Informatics Research Experience for Undergraduates site at Indiana University Bloomington will provide 10 undergraduate students with the opportunity to conduct research for 10 weeks with world-renown faculty members in the fields of human computer interaction, pervasive computing, machine learning, privacy, and technical policy. At least 5 of the undergraduate students will be from underrepresented groups, including first generation college students, and students who do not have access to research opportunities. The undergraduate students will have the opportunity to: (1) learn how to design and build new mobile or wearable health systems; (2) use the data collected from these systems to create personalized recommendations; (3) investigate possible privacy issues from collecting this data and propose solutions to protect one's privacy; or (4) understand the law implications for collecting, using, and storing this data. These projects can potentially improve the health of the broader United States population. Undergraduate researchers will learn how to: conduct ethical research; document their progress; represent themselves professionally online; prepare for graduate school; network in professional settings; appropriately disseminate one's findings through writing and presentation; and prepare oneself for future career opportunities.<br> <br>The objective of the Proactive Health (ProHealth) Informatics REU Site is to train undergraduates from diverse backgrounds to become the next generation of researchers who design, develop, and evaluate intelligent, pervasive systems that empower lay people to proactively manage their health. Innovations include the design of new mobile or wearable health systems that integrate seamlessly into a person's life while providing appropriately shared, and valuable feedback. To this end, the interdisciplinary ProHealth team will (1) train undergraduates to conduct cross-cutting computing research; (2) introduce students to graduate education and research career opportunities through preparatory workshops and one-on-one mentoring; (3) increase faculty and graduate student awareness of undergraduate research mentoring through Affinity Research Group model workshops; (4) provide opportunities for students to disseminate research results and faculty to disseminate best practices for mentoring; and (5) inspire middle and high school students to consider computing through REU panels and shadowing opportunities during computing-related summer camps.
Wildland fires are a costly natural hazard. Newer modeling systems have combined numerical weather prediction models with the traditional tools used to model fire behavior, making them more capable of realistically modeling how fires unfold, however, applying them to accurately anticipate a fire?s growth is a difficult forecasting challenge. The principal challenges are that errors accumulate as the accuracy of weather forecasts decreases with time and that some processes cannot be anticipated by the model such as the lofting of burning embers ahead of the fire (potentially starting new fires) and firefighting. The team?s recent work has combined the<br>Coupled Atmosphere-Wildland Fire Environment (CAWFETM) weather?fire behavior modeling system with satellite-based fire detection data from the Visible and Infrared Imaging Radiometer Suite (VIIRS) instrument to ignite fires already in progress, allowing an accurate forecast of fire growth for the next 12-24 hours; sequences of these simulations can maintain a reasonable forecast of fire growth from the time the satellite detects it until it is extinguished. The remaining challenges limiting the forecast skill are common to traditional approaches to modeling complex, nonlinear natural systems and include accumulating error and optimally exploiting all available data sources. The team will investigate how more tightly integrating new and underused sensor and data sources with the modeling could potentially transform both wildfire detection and prediction. Advances will be integrated into the team?s work transitioning the system into operations, benefiting society with earlier wildfire detection, faster response, and better fire forecasts.<br><br>The goal is to develop innovative Dynamic Data System techniques that improve wildfire detection and growth forecasting. The work will address three objectives, 1) develop and apply algorithms (steered by other data) to distill new and existing (but underutilized) sources of data on wildfire detection and mapping, 2) develop and apply algorithms to integrate asynchronous<br>data on wildfire detection and monitoring with coupled weather?wildland fire models, and 3) measure the improvement in wildfire detection time and forecasted fire growth. The methods include creating an adaptive control system for initiating forecasts based on the arrival of new data; allowing sensors to inform algorithms where to look in other underutilized datasets; creating<br>approaches for intelligent, iterative processing of large datasets; and using model forecasts to drive these intelligent searches. The techniques could have broad application across other nonlinear systems that are currently done in a traditional manner with rigorous scheduling of routine, repeated modeling relying on fixed detection algorithms and regular, periodic input data<br>arrival.
Major changes in urban transportation systems are now underway due to innovations occurring along several different dimensions. Smart cars, autonomous and semi-autonomous vehicles, electric vehicles, compact energy-efficient micro-vehicles, and increased deployment of vehicle-to-vehicle and vehicle-to-infrastructure communications are revolutionizing the vehicle fleet. New types of transportation services are emerging such as short-term vehicle rentals and commercial crowd-sourced taxi services that are increasing shared use and lessening reliance on private vehicle ownership. New sources of data and vast amounts of information concerning the transportation network itself are becoming available including crowd-sourced data provided by citizens through mobile devices and data collected from surveillance systems including unmanned aerial vehicles (UAVs). At the same time advances in computing and communications are enabling new, mobile high performance computing platforms that can be embedded within the transportation system. It is not well understood how these platforms can be best exploited in emerging transportation system applications to help address long-standing issues concerning safety, congestion, resource consumption, and pollution that significantly degrade the quality of life in the U.S. and throughout the world. New computational methods are needed to maximally exploit these new technologies to create the reliable, resilient, and efficient transportation systems demanded by modern cities.<br><br>This project will explore synergies and challenges arising from the integration of three largely separate areas dynamic data analytics, embedded distributed simulations, and power-aware computing on emerging high performance mobile computing platforms for transportation system applications. The context for this research is power-tunable platforms termed micro-clusters that are small closely coupled multi-node computer systems assembled from mobile computing components. On a larger scale, distributed networked micro-clusters will form the computation core for many dynamic data driven application system (DDDAS) deployments in the future. This project seeks to develop deep understandings of key principles concerning the design and operation of micro-clusters executing integrated dynamic data analysis algorithms and embedded distributed simulations for emerging transportation system applications. A micro-cluster hardware testbed will be created as a key element of this project for experimental research in power aware dynamic data-driven distributed simulation and used for benchmarking. The results of this study will be used to develop a research agenda and follow-on research to develop approaches and techniques to minimize energy consumption while maintaining effectiveness of scalable DDDAS deployments. Beyond transportation system applications, platforms such as micro-clusters will become commonplace and widely used in the operation of real-world systems for a variety of applications besides transportation in areas such as manufacturing, logistics, and telecommunications. Project results will be incorporated into undergraduate and graduate courses in transportation, modeling and simulation and parallel computing. The project will engage underrepresented and K-12 groups in computing and engineering through participation in summer internship programs and summer camps.
Emergence of the Big Data phenomenon has given rise to data collections that are massive, highly heterogeneous and multi-modal, dynamically evolving, as well as incomplete, noisy and imprecise. These characteristics are becoming increasingly prevalent in data from a diverse range of domains, such as robotics, cognitive neuroscience, sensor generated data (e.g., in geoscience and remote sensing), and the dynamically evolving data on the web. The heterogeneity, complexity, dynamic evolution, and the often real-time processing requirements, call for methods that are both statistically rigorous as well as computationally scalable. Moreover, performing fast feature-extraction and/or predictions at *test time* is another key requirement, especially in problems involving dynamic data arriving at high speeds. This project will innovate on scalable statistical methods for learning from such massive dynamic multi-modal data, with a focus on designing novel probabilistic models for multi-layer latent feature extraction for such data. These multi-layer latent feature representations of the data will help capture the underlying dynamics and allow reconciling the data heterogeneity arising due to diverse data types and widely differing spatial and temporal resolutions across the different modalities, while also being useful for a wide range of fundamental data analysis tasks, such as classification, clustering, and predicting missing data. At the same time, the focus will also be on developing methods that are efficient at test time, so that fast feature extraction and predictions can be made in real time, to make these methods readily applicable to dynamic streaming data.<br><br>This EArly Grant for Exploratory Research (EAGER) project endeavors to move beyond existing ad hoc approaches currently used for these problems, and develop a probabilistically grounded, statistically rigorous, and computationally scalable framework, based on Bayesian and nonparametric Bayesian modeling. Taking a Bayesian generative modeling approach will naturally enable modeling the dynamic behavior of the data and seamlessly integrate diverse types of data, while handling issues such as missingness, noise and the imprecise nature of the data. In addition, the nonparametric Bayesian treatment will provide the much-needed modeling flexibility and address many of the limitations of the existing Deep Learning models, e.g., by doing away with the need of extensive hand-tuning, incorporating rich prior knowledge about the model parameters, and allowing a natural sharing of statistical strength across the multiple data modalities. To handle the associated computational challenges, the framework will provide novel inference machinery in form of online Bayesian inference methods that will naturally handle dynamic, real-time data, and parallel and distributed Bayesian inference methods to handle massive multi-modal data that are too large for the capacity (storage and/or computational) of a single computing node. Furthermore, due to its inherent ability of quantifying model uncertainty, the proposed Bayesian framework will naturally facilitate a dynamic integration between model computation (inference) and data acquisition, and help design informed data acquisition (i.e., "active" sensing) methods in the context of dynamic multi-modal data. An overarching goal of this project is to also help synergize two important research directions in machine learning - nonparametric Bayesian methods and Deep Learning methods. By designing scalable nonparametric Bayesian solutions to the type of problems Deep Learning methods have been applied for, the project will convince the skeptics of Deep Learning methods to adopt these methods more openly. At the same time, the compelling range of problems and applications Deep Learning are being used for, will broaden the appeal of nonparametric Bayesian methods from a practical sense. We expect this synergy between these two areas will significantly advance the state-of-the-art in both areas.
Plankton play an essential role in the global ecosystem, forming the base of marine food webs, linking the atmosphere to the deep ocean, and regulating a myriad of ecologically and climatologically important processes. Despite their importance, however, the technology to assess abundances and distributions of plankton has been limited. Changes in abundances of individual species are particularly poorly resolved; this includes the harmful algal blooms that have profound economic, societal, and ecosystem effects in many coastal systems. Traditional tools such as nets and bottles can destroy fragile organisms during sampling. Underwater microscopes, on the other hand, allow observation of the organisms undisturbed, and in their natural setting. New underwater microscopes are generating many thousands of high-resolution images of individual plankton each day. Before these images can be used for scientific analyses, the imaged organisms must be identified and classified. However, the vast number of images generated by such microscopes has led to a serious bottleneck: identification and classification of the images takes an impossibly long time for individuals to accomplish. Fortunately, advances in computer vision science have shown great promise in accurately performing such classification tasks. The main goal of this award is to explore and develop computer vision approaches for plankton image classification. A team of instrumentation specialists, an ocean ecologist, and a computer scientist, including two graduate students and one post doctoral student, will formulate, implement, and test methods to advance the goal of efficient and accurate automated plankton image classification. The advances made in this award will enable both improved classification algorithms in computer science, and vast new data streams for plankton ecology.<br><br>Plankton form the base of marine food webs, link the atmosphere to the deep ocean, and regulate global biogeochemical cycles. Plankton are often studied either through bulk measures, or by manual enumeration of individual taxa. Novel underwater microscope systems such as the Scripps Plankton Camera System (SPCS) are generating tens of thousands of images of individual plankton daily. However, without accurate annotation of the images, the potential science is limited. This project will explore the use of many-layer, deep Convolutional Neural Nets (CNN) as automated computer recognition methods; these techniques hold promise for classifying the nearly one trillion underwater microscope images that have been collected by a variety of research groups around the globe. The primary source of images will be a pair of microscopes that have been operating for 2 years from the Scripps Inst. of Oceanography's pier, yielding 200 million regions of interest. The project will build a large data base of training sets using a novel approach: a bench-top imaging system that is capable of rapidly producing thousands of annotated images showing organisms in all orientations and configurations identical to that in the field. Based on these automatically collected training sets, and hand annotation of in situ images from experts, a deep (many layer) CNN will embed taxonomic and attribute constraints, and will be used to classify the organisms imaged. With success, this massive, growing, taxonomically classified dataset will enable unprecedented, transformative, taxon-specific explorations of the dynamics of the planktonic ecosystem on time scales from hours to decades.
Science is increasingly based on computation for science simulations, data management and analysis, instrument control and collaboration. For scientific results generated through computation to be considered robust and become widely accepted, the computational techniques should be automated, reproducible and trustworthy. By exploring the practices of gravitational-wave astronomy researchers working on the Laser Interferometer Gravitational-Wave Observatory (LIGO) project, this project seeks to create a set of case studies documenting broadly applicable methods for reproducible computational science. Specifically, the project will explore and articulate what reproducibility, automation, and trust mean with respect to computation-based research in gravitational-wave astronomy, identify, implement and validate a set of experimental practices, that will include computational techniques, and finally, evaluate how these experimental practices can be extended to other science domains. <br><br>Robust computational science builds on rigorous methods and is composed of three key elements: (1) reproducibility, which enables the verification and leveraging of scientists' findings; (2) automation, which speeds up the exploration of alternative solutions and the processing of large amounts of data while reducing the introduction of errors; and (3) trust, providing security and reliability for software and data, while supplying the necessary attributes for confidence in the scientist's own results and results from others. This project explores robust science in the LIGO project through the following activities within the context of gravitational-wave astronomy: (1) articulating the roles of reproducibility, automation, and trust in gravitational-wave astronomy; (2) identifying, implementing and validating a set of experimental practices, including computational techniques; and (3) advancing towards the project's vision of general computational methods for robust science by evaluating how the experimental practices can be extended to other science domains. The project will develop and use a survey to collect information about LIGO workflows that are composed of a series of experimental, computational, and data manipulation steps. The analysis of the survey will result in a document that describes what reproducibility means in the LIGO context and help identify potential improvements in LIGO's practices. The project will generalize these findings by documenting a mapping of LIGOÕs original and enhanced approach to other science workflows including those of the molecular dynamics and bioinformatics communities. The final project document will target a broad audience that includes researchers and students at various levels of education, with the goal of introducing them to the concept of robust computational research, and the underlying concepts of reproducibility, automation and trust, teaching them to access code, data, and workflow information to regenerate findings, learn about the scientific methods, and to engage in STEM research.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
REU Site: Data Intensive Scientific Computing<br>Douglas Thain and Kevin Lannon, University of Notre Dame<br><br>This REU Site project will bring ten undergraduate students to the University of Notre Dame each summer for three years to perform research projects in scientific computing. These students will work in collaborative groups including experts in both high performance computing techniques and scientific fields that rely upon computing. Using advanced computational systems, the students will work in scientific areas such a gene sequencing, network visualization, particle physics, and astronomy. Students will gain experience in working in groups, using computational tools, and presenting scientific results, which will help to prepare them for entering a career in computational science.<br><br><br>Computing has become an essential component of scientific discovery across the scientific disciplines. Novel algorithms combined with large scale infrastructure have the potential to multiply the power of simulation and data analysis tasks by many orders of magnitude. However, our current educational models are not aligned toward advancing scientific computing: computer science students have too little exposure to scientific applications, while physical science students have too little exposure to computing techniques. To address this, we propose an REU site in Data Intensive Scientific Computing (DISC) that will bring together undergraduates in computer science, physical sciences, and other interdisciplinary majors. Our objective is to train all participants in collaborative techniques so that they gain experience in both computing techniques and a physical science domain, as appropriate to their background. To achieve this, we have assembled a team of faculty from three distinct areas (computer science, physics, and biological sciences) that have already formed an active set of collaborations. Resources for the students and faculty involved will be provided by the Notre Dame Center for Research Computing (CRC) which provides large scale computing, storage, and communication facilities. Every participant will have access to a large shared cluster, a high performance parallel storage system and a data analysis cluster.
Managing and processing large volumes of data and gaining meaningful insights is a significant challenge facing the Big Data community. Thus, it is critical that data-intensive computing middleware (such as Hadoop, HBase and Spark) to process such data are diligently designed, with high performance and scalability, in order to meet the growing demands of such Big Data applications. While Hadoop, Spark and HBase are gaining popularity for processing Big Data applications, these middleware and the associated Big Data applications are not able to take advantage of the advanced features on modern High Performance Computing (HPC) systems widely deployed all over the world, including many of of the multi-Petaflop systems in the XSEDE environment. Modern HPC systems and the associated middleware (such as MPI and Parallel File systems) have been exploiting the advances in HPC technologies (multi/many-core architectures, RDMA-enabled networking, NVRAMs and SSDs) during the last decade. However, Big Data middleware (such as Hadoop, HBase and Spark) have not embraced such technologies. These disparities are taking HPC and Big Data processing into "divergent trajectories." <br><br>The proposed research, undertaken by a team of computer and application scientists from OSU and SDSC, aim to bring HPC and Big Data processing into a "convergent trajectory." The investigators will specifically address the following challenges: 1) designing novel communication and I/O runtime for Big Data processing while exploiting the features of modern multi-/many-core, networking and storage technologies; 2) redesigning Big Data middleware (such as Hadoop, HBase and Spark) to deliver performance and scalability on modern and next-generation HPC systems; and 3) demonstrating the benefits of the proposed approach for a set of driving Big Data applications on HPC system. The proposed work targets four major workloads and applications in the Big Data community (namely data analytics, query, interactive, and iterative) using the popular Big Data middleware (Hadoop, HBase and Spark). The proposed framework will be validated on a variety of Big Data benchmarks and applications. The proposed middleware and runtimes will be made publicly available to the community. The research enables curricular advancements via research in pedagogy for key courses in the new data analytics program at Ohio State and SDSC -- among the first of its kind nationwide.
A fundamental problem in the analysis of large datasets consists of finding one or more data items that are as similar as possible to an input query. This situation occurs, for example, when a user wants to identify a product captured in a photo. The corresponding computational problem, called Nearest Neighbor (NN) Search, has attracted a large body of research, with several algorithms having significant impact. Yet the state of the art in NN suffers from important theoretical and practical limitations. In particular, it does not provide a natural way to exploit data *structure* that is present in many applications. For example, although the identity of a depicted object does not change when one varies the lighting or the position of the object, the current NN algorithms will treat the resulting images as completely different from each other and thus will mis-identify the object. To overcome this difficulty, in this project the PIs will develop new efficient algorithms that incorporate problem structure into NN search. The PIs expect that such methods will produce substantially better results for many massive data analysis tasks.<br><br>To ensure that the work is grounded in an important application, the PIs will focus on computer vision, an area where Internet-scale datasets are having a substantial impact. NN search is vital for computer vision, and in fact many senior computer vision researchers view improved NN techniques as their top algorithmic priority. Image and video have significant structure, often spatial in nature, which algorithmic techniques such as graph cuts have been able to exploit with considerable success. The proposed work will formulate new variants of NN search that make use of additional structure, and will design efficient algorithms to solve these problems over large datasets. In particular, the PIs will investigate three structured NN problem formulations. Simultaneous nearest-neighbor queries involves multiple queries where the answers should be compatible with each other. Nearest-neighbor under transformations considers distances that are invariant to a variety of image transformations. Nearest-neighbors for subspaces involves searching a set of linear or affine subspaces for the one that comes closest to a query point. Broader impacts of the project include graduate training in both algorithms and image processing.<br><br>For further information see the project web site at: http://cs.brown.edu/~pff/SNN/
This project seeks to understand how inaccurate messages are propagated over large-scale information networks that are consumed by the general public, how the public responds to such inaccuracy, and what content- or metadata-related characteristics/features make certain messages more error-resistant or error-prone than others. The results of the project have the potential to help build a platform that accurately identifies errors being propagated on an information network and effectively manages/controls such error propagation.<br><br>The technical objective of this project involves the design of efficient information extraction techniques that properly extract features from microblog-like messages that are short and often noisy. Specifically, it aims to develop a variety of content models, e.g., graph-based modeling, sentiment-based coding, and shingle- and user-frequency based metrics to make the information extraction techniques more resilient to the noise and high volume commonly present on real-world microblog platforms. The project also includes a case study over a large-scale real-world microblog platform to test the effectiveness of the proposed approaches and their superiority over the existing techniques.
In the Internet Age, information entities and objects are interconnected, thereby forming gigantic information networks. Recently, network embedding methods, that create low-dimensional feature representations that preserve the structure of data points in their original space, have been shown to be greatly beneficial for many data mining and machine learning problems over networks. Despite significant research progress, we are still lacking powerful network embedding techniques with theoretical guarantees to effectively deal with massive, heterogeneous, complex and dynamic networks. The PIs aim to develop a new generation of network embedding methods for analyzing massive networks. The research project has the potential to significantly transform graph mining and network analysis. The PIs also plan to develop open course materials and open source software tools that integrate information network analysis and machine learning. <br><br>This project consists of four synergistic research thrusts. First, it develops model-based network embedding to leverage the first-order and second-order proximity of networks. Second, it devises a family of inductive network embedding methods that are able to leverage both linkage information and side information. Third, it develops both local clustering and deep learning based network embedding methods to attack the complex structure of networks such as locality and non-linearity. Fourth, it develops online and stochastic optimization algorithms for different network embedding methods to tackle the fast growth and evolution of modern massive networks. The new methods developed in this project enjoy faster rates of convergence in optimization, lower computational complexities, and statistical learning guarantees. The targeted applications include but are not limited to semantic search and information retrieval in social/information network analysis, expert finding in bibliographical database, and recommendation systems.
Open source software is an engine for innovation and a critical infrastructure for the nation and yet it is implemented by communities formed from a loose collection of individuals. With each software project relying on thousands of other software projects, this complex and dynamic supply chain introduces new risks and unpredictability, since, unlike in traditional software projects, no contractual relationships with the community exist and individuals could simply lose interest or move on to other activities.<br>The big data-based approach to software supply chains will stimulate academic and practical work. The tools and practices to quantify and mitigate risks in the rapidly changing global environment with no centralized control or authority will lead to dramatic reductions in risk manifested in, for example, the spread of vulnerabilities thus making the nation both safer and more innovative. The theoretical frameworks and approaches developed will likely influence research and practice in other supply chain contexts.<br><br>The objective of this research is to advance the state of knowledge of software supply chains by collecting and integrating massive public operational data representing development activity and source code from all open source projects and using it to develop novel theories, methods, and tools. The construction and analysis of the entire open source supply chain provides static and dynamic properties of the network, risk propagation, and system-level risks. Novel statistical and game-theoretic models are used to assess and mitigate these risks, while methods to contextualize, augment, and correct operational data provide ways to cope with data?s size, complexity, and observational nature.
Concerns about privacy continue to pervade large-scale deployments of technologies including big data, cloud services and the Internet of Things. The main purpose of the proposed work is to build a community of academic researchers and industry practitioners to address research priorities identified in the newly released National Privacy Research Strategy. By engaging industry stakeholders with researchers and advancing new thinking, research, best practices and practical tools, this work will prompt industry action and advocate privacy-aware approaches to collecting and processing personal information in a manner that respects individual privacy, equality and fairness. This project aims to enhance opportunities for innovation, provide meaningful protections for personal information across industry sectors and institutions, inform the public debate on privacy, and contribute to the development of systems and products used to help society realize the benefits of networked information technology without sacrificing privacy and individual rights.<br><br>The project will undertake major activities such as an inaugural launch conference and a series of academic workshops and networking opportunities. Issues for discussion will include mechanisms to encourage and support multi-disciplinary research along a continuum of privacy challenges, including how to increase transparency of data collection and use; to ensure data flows are consistent with privacy rules; and to reduce privacy risks of analytical algorithms. Its emphasis on engagement of industry practitioners with academic researchers furthers the development of a community of privacy researchers working across disciplines and sectors and dedicated to the promotion of new knowledge, techniques and practices to better protect individual privacy.
A number of phenomena of societal importance, such as the spread of diseases and<br>contagion processes, can be modeled by stochastic processes on networks. The analysis <br>and control of such network phenomena involve, at their heart, fundamental graph-theoretic problems. <br>The graphs encountered are typically of large-scale (having tens of millions of nodes); <br>further, typical experimental analyses involve large designs with a number of parameters, <br>leading to hundreds of thousands of graph computations. Novel methods for solving these problems<br>are needed, since fast response times are critical to effective decision making.<br>The overarching goal of this project is to develop efficient distributed algorithms <br>and associated lower bounds for graph-theoretic problems that arise in computational <br>epidemiology and contagion dynamics. This will have a significant impact on these specific <br>applications, through more efficient algorithmic tools for enabling complex analyses. <br>The project will also make fundamental contributions to the design and analysis of <br>distributed algorithms for graph problems in large-scale networks, and will<br>result in an algorithmic toolkit with building blocks for performing large-scale <br>distributed graph computation. The project will lead to significant curriculum development <br>for undergraduate as well as graduate students, as well as public health analysts. <br>Finally, the project will help in involving minority and underrepresented students in research. <br><br>The technical focus of the project will be on distributed algorithms for fundamental topics <br>in graph algorithms such as graph connectivity, distances, subgraph analysis, and different<br>kinds of centrality measures. These topics underlie some of the recurring problems in the <br>modeling, simulation and analysis and control of different kinds of contagion processes. <br>For all these problems, the project will focus on developing provably efficient distributed <br>algorithms and showing lower bounds under a message-passing distributed computing model. <br>The PIs will also develop efficient implementations of these algorithms, and evaluate their <br>performance and solution quality in real-world graphs arising in epidemiology. The graphs <br>that arise in these applications have several novel characteristics, which will present new <br>challenges as well as opportunities for distributed computing.
In today's digital world, huge amounts of data, i.e., big data, can be found in almost every aspect of scientific research and human activity. These data need to be managed effectively for reliable prediction and inference to improve decision making. Statistical learning is an emergent scientific discipline wherein mathematical modeling, computational algorithms, and statistical analysis are jointly employed to address these challenging data management problems. Invariably, quantitative criteria need to be introduced for the overall learning process in order to gauge the quality of the solutions obtained. This research focuses on two important criteria: data fitness and sparsity representation of the underlying learning model. Potential applications of the results can be found in computational statistics, compressed sensing, imaging, machine learning, bio-informatics, portfolio selection, and decision making under uncertainty, among many areas involving big data.<br><br>Till now, convex optimization has been the dominant methodology for statistical learning in which the two criteria employed are expressed by convex functions either to be optimized and/or set as constraints of the variables being sought. Recently, non-convex functions of the difference-of-convex (DC) type and the difference-of-convex algorithm (DCA) have been shown to yield superior results in many contexts and serve as the motivation for this project. The goal is to develop a solid foundation and a unified framework to address many fundamental issues in big data problems in which non-convexity and non-differentiability are present in the optimization problems to be solved. These two non-standard features in computational statistical learning are challenging and their rigorous treatment requires the fusion of expertise from different domains of mathematical sciences. Technical issues to be investigated will cover the optimality, sparsity, and statistical properties of computable solutions to the non-convex, non-smooth optimization problems arising from statistical learning and its many applications. Novel algorithms will be developed and tested first on synthetic data sets for preliminary experimentation and then on publicly available data sets for realism; comparisons will be made among different formulations of the learning problems.
This is a comprehensive research proposal on the statistical modeling and analysis for educational assessment. This research addresses issues concerning fundamental statistical problems that arise in the analysis of Big Data in education. The research focus is on modeling and inference for large-scale data with complex dependence and structures (such as high-dimensional response and process data). These data arise from the introduction of new methods of testing student knowledge that rely on scenarios presented to the students and on simulation-based environments where student responses to a simulated environment are tested. This research is collaborative between Columbia University and the Educational Testing Service.<br><br>The topics studied include latent graphical modeling for high-dimensional item response data, modeling and segmentation of process data via dictionary models, estimation of item-attribute relationship, dimension reduction, theoretical analysis and computational methods for the proposed models. The analysis combines techniques and concepts from mathematics and probability and applies them to nonlinear statistical models and data analysis. The proposed model combines latent variable and graphical approaches for high-dimensional data; for modeling process data, recent advances in modeling and segmenting techniques for natural language processing will be investigated. In the theoretical development, several algebraic concepts to formulate model identifiability and perform combinatorial analysis on high-dimensional discrete spaces will be studied. In addition, optimization algorithms will be developed using recent advances in numerical methods.
Driven by the need to learn from vast amounts of text data, efforts throughout natural language processing, information extraction, databases, and AI are coming together to build large-scale knowledge bases. These systems continuously crawl the web to extract relational data from text, and have already populated their databases with millions of entities and billions of tuples. Large-scale probabilistic knowledge bases are revolutionizing the way we access data. They are now routinely used by scientists to build knowledge bases of publications, by law enforcement to extract information from the dark web, and by regular search engine users who find their results augmented with structured information. Such knowledge bases are inherently probabilistic: to go from raw text to structured data, a sequence of statistical machine learning techniques associate probabilities with database tuples. This project revisits the semantics underlying such systems, and provide a more adequate foundational framework. In particular, the closed-world assumption of probabilistic databases, that facts not in the database have probability zero, clearly conflicts with their everyday use, and obstructs the progress in this area.<br><br>More specifically, this project develops a new semantic foundation based on the open-world assumption, that facts not in the database are possible, but have unknown probability. It designs the basic algorithms for query answering in this setting, both exact and approximate. Moreover, in a deep theoretical component, this project studies fundamental questions of data and domain complexity that are unique to open-world reasoning about big uncertain data. Finally it develops proof-of-concept applications in machine learning and data mining, and additional knowledge-representation layers that strengthen open-world reasoning. The developed semantics provide meaningful answers when some tuple probabilities are not precisely known. The developed algorithms allow for efficient query answering, even when reasoning about the open world, in time linear in the database size for tractable queries. This project provides a scientific leap at the fundamental, semantic level. It also provides a context for training undergraduate and graduate students in subjects spanning databases, artificial intelligence, theory, and machine learning, and will target the integration of probabilistic knowledge bases into computer science curricula.
A number of phenomena of societal importance, such as the spread of diseases and<br>contagion processes, can be modeled by stochastic processes on networks. The analysis <br>and control of such network phenomena involve, at their heart, fundamental graph-theoretic problems. <br>The graphs encountered are typically of large-scale (having tens of millions of nodes); <br>further, typical experimental analyses involve large designs with a number of parameters, <br>leading to hundreds of thousands of graph computations. Novel methods for solving these problems<br>are needed, since fast response times are critical to effective decision making.<br>The overarching goal of this project is to develop efficient distributed algorithms <br>and associated lower bounds for graph-theoretic problems that arise in computational <br>epidemiology and contagion dynamics. This will have a significant impact on these specific <br>applications, through more efficient algorithmic tools for enabling complex analyses. <br>The project will also make fundamental contributions to the design and analysis of <br>distributed algorithms for graph problems in large-scale networks, and will<br>result in an algorithmic toolkit with building blocks for performing large-scale <br>distributed graph computation. The project will lead to significant curriculum development <br>for undergraduate as well as graduate students, as well as public health analysts. <br>Finally, the project will help in involving minority and underrepresented students in research. <br><br>The technical focus of the project will be on distributed algorithms for fundamental topics <br>in graph algorithms such as graph connectivity, distances, subgraph analysis, and different<br>kinds of centrality measures. These topics underlie some of the recurring problems in the <br>modeling, simulation and analysis and control of different kinds of contagion processes. <br>For all these problems, the project will focus on developing provably efficient distributed <br>algorithms and showing lower bounds under a message-passing distributed computing model. <br>The PIs will also develop efficient implementations of these algorithms, and evaluate their <br>performance and solution quality in real-world graphs arising in epidemiology. The graphs <br>that arise in these applications have several novel characteristics, which will present new <br>challenges as well as opportunities for distributed computing.
Transforming villages, towns, and cities into smart, connected, and sustainable communities is one of the most critical technological challenges of the coming decade. Realizing this vision is contingent upon enabling existing community infrastructure such as transportation, communications, and energy systems, to seamlessly integrate sustainable components such as renewable sources, smart sensors, and electric vehicles. Such an integration will ensure that tomorrow's communities are truly sustainable and connected by exhibiting desirable qualities that include: a) zero energy, in that they are self-sufficient in their energy production, b) zero outage, in that communication links across the community are ultra-reliable and experience significantly low interruption, and c) zero congestion, in that the traffic congestion is minimized across the community. With this overarching vision, the goal of this project is to develop a new planning framework for smart, connected and sustainable communities that allows meeting such zero-energy, zero-outage, and zero-congestions goals by optimally deciding on how, when, and where to deploy or upgrade a community's infrastructure. These decisions will be driven by massive volumes of community data, stemming from multiple sources that can include mobility, energy, traffic, communication demands, and other socio-technological information, to make informed decisions on how to gradually and organically transform a community into a fully sustainable and truly connected environment. The scale and heterogeneity of this problem necessitates the need for innovation in the tools used to process, analyze, and visualize heterogeneous data, as well as the data-aware metrics used to monitor the performance of this community infrastructure. One key element of this research is creation of a virtual testbed that can accurately reconstruct, simulate, and evaluate the theoretical framework by leveraging real-world big data sets from Virginia Tech and a zero-energy community in Florida as well as other sources, such as the DOE. The testbed is intended to be open access and will be able to support both research at host institution as well as other users requiring non-proprietary multi-domain open-data sets. The holistic nature of this research is thus expected to catalyze the global deployment of sustainable and connected communities. The proposed research will be complemented by a smart community big data challenge event that will enable broad community participation. The educational plan includes new big data-centric courses, as well as a large-scale involvement of graduate and undergraduate students in big data and smart communities research. Broad dissemination is ensured via open-source software and periodic workshops and tutorials. K-12 outreach events will be organized to attract under-represented student groups to big data research.<br><br>This transformative research will lay the theoretical and practical foundations of smart, connected, and sustainable communities by developing the first big data-driven holistic approach to joint planning, optimization, and deployment of community infrastructure for systems of critical importance, such as communication, energy, and transportation networks. By bringing together interdisciplinary domain experts from data science, electrical engineering, and civil and architectural engineering, this research will yield several innovations: 1) Novel big data techniques for faithfully creating spatio-temporal models for smart communities that integrate data from heterogeneous sources and shed light on the composition and operation of a given smart community, 2) Novel, data-driven performance metrics that advance powerful mathematical tools from stochastic geometry to explicitly quantify the health of smart communities via tractable notions of zero energy, zero outage, and zero congestion, 3) Advanced analytical tools that bring forward novel ideas from optimization theory to devise the most effective strategies for deploying, upgrading, and operating various community infrastructure nodes, given the scale, dynamics, and structure of both the data and the community, and 4) A virtual smart community testbed that can accurately reconstruct, simulate, and evaluate the theoretical framework by leveraging open non-proprietary real-world big data sets.
The field of visual recognition, which focuses on creating computer algorithms for automatically understanding photographs and videos, has made tremendous gains in the past few years. Algorithms can now recognize and localize thousands of objects with reasonable accuracy as well as identify other visual content, such as scenes and activities. For instance, there are now smart phone apps that can automatically sift through a user's photos and find all party pictures, or all pictures of cars, or all sunset photos. However, the type of "visual understanding" done by these methods is still rather superficial, exhibiting mostly rote memorization rather than true reasoning. For example, current algorithms have a hard time telling if an image is typical (e.g., car on a road) or unusual (e.g., car in the sky), or answering simple questions about a photograph, e.g., "what are the people looking at?", "what just happened?", "what might happen next?" A central problem is that current methods lack the data about the world outside of the photograph. To achieve true human-like visual understanding, computers will have to reason about the broader spatial, temporal, perceptual, and social context suggested by a given visual input. This project is using big visual data to gather large-scale deep semantic knowledge about how events, physical and social interactions, and how people perceive the world and each other. The research focuses on developing methods to capture and represent this knowledge in a way that makes it broadly applicable to a range of visual understanding tasks. This will enable novel computer algorithms that have a deeper, more human-like, understanding of the visual world and can effectively function in complex, real-world situations and environments. For example, if a robot can predict what a person might do next in a given situation, then the robot can better aid the person in their task. Broader impacts will include new publicly-available software tools and data that can be used for various visual reasoning tasks. Additionally, the project will have a multi-pronged educational component, including incorporating aspects of the research in the graduate teaching curriculum, undergraduate and K-12 outreach, as well as special mentoring and focused events for advancement of women in computer science.<br><br>The main technical focus of this project is to advance computational recognition efforts toward producing a general human-like visual understanding of images and video that can function on previously unseen data, unseen tasks and settings. The aim of this project is to develop a new large-scale knowledge base called the visual Memex that extracts and stores vast set of visual relationships between data items in a multi-graph representation, with nodes corresponding to data items and edges indicating different types of relationships. This large knowledge base will be used in a lambda-calculus-powered reasoning engine to make inferences about visual data on a global scale. Additionally, the project will test computational recognition algorithms on several visual understanding tasks designed to evaluate progress on a variety of aspects of visual understanding, including: linguistic (evaluating our understanding about imagery through language tasks such as visual question-answering), to purely visual (evaluating our understanding of spatial context through visual fill-in-the-blanks), to temporal (evaluating our temporal understanding by predicting future states), to physical (evaluating our understanding of human-object and human-scene interactions by predicting affordances). Datasets, knowledge base, and evaluation tools will be hosted on the project web site (http://www.tamaraberg.com/grants/bigdata.html).
Current bioacoustic monitoring of natural environments requires processing by humans to extract information content from recordings. Thus human processing creates a fundamental bottleneck in which data collection far outpaces capabilities to extract relevant and desired information. Bioacoustic research on automatic species classification in natural environments can be broadly divided into two groups: distinguishing a predefined set of known species from audio clips and extracting species as events that occur in a continuous audio stream. Both classification techniques have their specific problems--many of the data used distinguishing predefined species are recorded under "studio" conditions and not extensible to natural conditions, while processing of continuous audio streams generate many false positives. <br><br>To overcome these challenges we will take a multi-tiered approach: Analyzing a data set consisting of full-night recordings from 10 recording units over 100 nights. Building a web-enabled software to engage citizen scientists to identify the flight calls, providing us with a large and extensive model training dataset. Developing novel convolutional deep-learning networks, which are well suited for analysis of complex auditory scenes. Visualizing patterns detected and classified flight calls in space and time to produce novel information about the bird migration. Comparing model-generated acoustic data with radar, video, and direct visual citizen science datasets to produce the most comprehensive accounts of nocturnal bird migration possible. The combination of domain knowledge in bird vocalizations, engaging citizen scientists to allow development of large well annotated training datasets, and taking a novel deep-learning approach, will finally resolve the machine classification of acoustic signals in natural environments.
Transforming villages, towns, and cities into smart, connected, and sustainable communities is one of the most critical technological challenges of the coming decade. Realizing this vision is contingent upon enabling existing community infrastructure such as transportation, communications, and energy systems, to seamlessly integrate sustainable components such as renewable sources, smart sensors, and electric vehicles. Such an integration will ensure that tomorrow's communities are truly sustainable and connected by exhibiting desirable qualities that include: a) zero energy, in that they are self-sufficient in their energy production, b) zero outage, in that communication links across the community are ultra-reliable and experience significantly low interruption, and c) zero congestion, in that the traffic congestion is minimized across the community. With this overarching vision, the goal of this project is to develop a new planning framework for smart, connected and sustainable communities that allows meeting such zero-energy, zero-outage, and zero-congestions goals by optimally deciding on how, when, and where to deploy or upgrade a community's infrastructure. These decisions will be driven by massive volumes of community data, stemming from multiple sources that can include mobility, energy, traffic, communication demands, and other socio-technological information, to make informed decisions on how to gradually and organically transform a community into a fully sustainable and truly connected environment. The scale and heterogeneity of this problem necessitates the need for innovation in the tools used to process, analyze, and visualize heterogeneous data, as well as the data-aware metrics used to monitor the performance of this community infrastructure. One key element of this research is creation of a virtual testbed that can accurately reconstruct, simulate, and evaluate the theoretical framework by leveraging real-world big data sets from Virginia Tech and a zero-energy community in Florida as well as other sources, such as the DOE. The testbed is intended to be open access and will be able to support both research at host institution as well as other users requiring non-proprietary multi-domain open-data sets. The holistic nature of this research is thus expected to catalyze the global deployment of sustainable and connected communities. The proposed research will be complemented by a smart community big data challenge event that will enable broad community participation. The educational plan includes new big data-centric courses, as well as a large-scale involvement of graduate and undergraduate students in big data and smart communities research. Broad dissemination is ensured via open-source software and periodic workshops and tutorials. K-12 outreach events will be organized to attract under-represented student groups to big data research.<br><br>This transformative research will lay the theoretical and practical foundations of smart, connected, and sustainable communities by developing the first big data-driven holistic approach to joint planning, optimization, and deployment of community infrastructure for systems of critical importance, such as communication, energy, and transportation networks. By bringing together interdisciplinary domain experts from data science, electrical engineering, and civil and architectural engineering, this research will yield several innovations: 1) Novel big data techniques for faithfully creating spatio-temporal models for smart communities that integrate data from heterogeneous sources and shed light on the composition and operation of a given smart community, 2) Novel, data-driven performance metrics that advance powerful mathematical tools from stochastic geometry to explicitly quantify the health of smart communities via tractable notions of zero energy, zero outage, and zero congestion, 3) Advanced analytical tools that bring forward novel ideas from optimization theory to devise the most effective strategies for deploying, upgrading, and operating various community infrastructure nodes, given the scale, dynamics, and structure of both the data and the community, and 4) A virtual smart community testbed that can accurately reconstruct, simulate, and evaluate the theoretical framework by leveraging open non-proprietary real-world big data sets.
This research concerns the development of innovative mathematical theory and algorithms to facilitate knowledge discovery in the massive data sets generated by scientists, engineers and today's data driven society. New approaches will be developed that permit the encoding of large quantities of data in a way that enables the detection of similarities and differences buried in the volumes of information. The framework is especially useful for characterizing degrees of similarity, and discovering features or patterns that may be shared between data sets. The project focuses on the use of tools from geometry and optimization to provide effective data representations that expand the toolkit of analysts and enhances their capacity for understanding large and complex data sets. The methodology will be validated on real world data sets like extreme weather simulations or biological data sets such as those capturing the human immune response to infection by pathogens. The techniques being developed may be viewed as part of the emerging field of geometric data learning.<br> <br>The mathematical approach exploits the geometric framework of the Grassmannian, the manifold that parameterizes the set of subspaces of a given dimension of a vector space. The appeal of this approach is that subspaces, as abstract points on the Grassmann manifold, are an effective tool to capture the natural variability in data observations stemming from, for example, variations in illumination, or noise. If a subspace of data intersects another subspace of data in some prescribed number of dimensions, then these abstract points should be considered to be more related than subspaces that intersect in fewer dimensions, or not at all. This type of geometric picture, when formulated in a mathematical framework, leads to the use of flag manifolds and Schubert varieties for representing and comparing data. The proposed research program addresses new problems in data driven optimization subject to geometric constraints, for example, when the feasible set is a Schubert variety. This framework allows us to extract geometric models that characterize patterns, and leads naturally to comparisons between large sets of observations based on similarity measures which are functions of angles between subspaces.
The goals of this project include developing new Big Data analytical methods, providing an insightful understanding of their properties, and demonstrating major improvements over existing methods. While the driving application is cancer research, the lessons learned will be broadly applicable to a wide array of Big Data contexts. The major challenges addressed here include Data Integration, Data Heterogeneity and Parallelization. Data Integration is a recently understood need for combining widely differing types of measurements made on a common set of subjects. For example, in cancer research, common measurements in modern Big Data sets include gene expression, copy number, mutations, methylation and protein expression. The development of deep new statistical methods is proposed which focus on central scientific issues such as how the various measurements interact with each other, and simultaneously on which aspects operate in an independent manner. Data Heterogeneity addresses a different issue which is also critical in cancer research. In this case, current efforts to boost sample sizes (essential to deeper scientific insights) involve multiple laboratories combining their data. A whole new conceptual model for understanding the bias-oriented challenges presented by this scenario, plus the foundations for the development of new analytical methods that are robust against such effects, will be developed here. Parallelization is the computational concept of doing large scale numerical analysis through the simultaneous use of multiple computer processors. The proposed research will provide new foundational understanding of several important issues in this area.<br><br>Data Integration will center on the Joint and Individual Variation Explained methodology. Early versions have already provided scientific insights not available from previous data analytic approaches. The basic idea will be first extended in the direction of more insightful groupings of data blocks, essential for understanding the full breadth of relationships between the available measurement types. The second extension will be in the direction of divergent groups of subjects, very important to the study of subtypes in cancer research and to the rest of precision medicine. In addition to new methodology, new methods of validation are proposed, and an asymptotic study of the properties will be conducted. The key new concept behind Data Heterogeneity is to replace the usual Gaussian conceptual model with a Gaussian mixture model, which makes intuitive sense but creates challenges, for example when using likelihood approaches as the mixture distributions are not an exponential family. An even bigger challenge is that mere scale issues usually entail that full estimation of the distributional parameters is completely intractable. Yet many standard statistical methods can be negatively impacted by such structure in data, so the invention of a new class of statistical methods that are robust against this effect, without requiring full parameter estimation, are proposed. Validation and development of mathematical statistical insights will again be an important part of the research. Parallelization is an essential component of all modern computing environments. The proposed research takes a Fiducial Inference viewpoint, which gives new insights into how the needed numerical calculations can be farmed out to a variety of processors, and then the results combined into a useful analysis for complicated statistical tasks including hypothesis testing and construction of confidence intervals.
With recent advances in technology, it is now possible to measure and record significant numbers of features on a single individual. The volume, velocity, and variety, the "3Vs", of Big Data pose significant challenges for modeling and analysis of these massive datasets. For example, to understand cancer at the genetic level, researchers need to detect rare and weak signals from thousands, or even millions, of candidate genetic markers obtained from a limited number of subjects. Existing methods typically assume that the number of subjects is very large, an assumption often violated in practice. The main goal of this project is to develop efficient methods for extremely large-dimensional, small sample size data. The methodological advances will be extremely valuable in addressing Big Data challenges in different areas such as medical research, bioinformatics, financial analysis, and astronomic image analysis. Efficient software packages and algorithms to implement the proposed methods will be developed and made publicly available.<br><br>The key innovative idea motivating this research is viewing a high-dimensional problem from a novel packing perspective, which allows the number of variables, p, to be arbitrarily large and the number of observations, n, to be finite. The proposed research will systematically investigate three fundamental problems under this "finite n, arbitrarily large p" paradigm: (1) asymptotic theory of spurious correlations, (2) fast detection of low-rank correlation structures, and (3) detection boundary and optimal testing procedures for detecting rare and weak signals. This research will transform the current asymptotic framework, transitioning from the regimes of "large n, small p" and "large n, larger p" to the regime of "finite n, arbitrarily large p".
The research objective of this proposal is to address the computational challenges in an innovative BIGDATA application on imaging-omics based precision medicine. Recent advances in high-throughput imaging (such as histopathology image) and multi-omics (such as DNA sequence, RNA expression, methylation, etc.) technologies created new opportunities for exploring relationships between histology, molecular events, and clinical outcomes using quantitative methods. However, the unprecedented scale and complexity of these imaging-omic data have presented critical computational bottlenecks requiring new concepts and enabling tools. This project builds a new computational framework to integrate novel big data mining algorithms with cloud and high-performance computing strategies for revealing complex relationships between histopathology images, multi-omics, and phenotypic outcomes. This project is innovative and crucial not only to facilitating the development of new big data mining techniques, but also to addressing emerging scientific questions in imaging-omics and many other biomedical applications. The developed methods and tools are expected to impact other cancer genomics research and enable investigators working on cancer medicine to effectively test their scientific hypothesis. This project facilitates the development of novel educational tools to enhance several current courses. University of Texas at Arlington is a minority-serving institution and has large population of Hispanic and Black Americans. This project engages the minority students and under-served populations in research activities to give them a better exposure to cutting-edge science research.<br><br>To solve the key and challenge problems in big imaging-omics data mining, this project explores the following research tasks. First, the large-scale non-convex sparse learning models are developed for identifying outcome-relevant phenotypic traits from big histopathology images. Second, the biological domain knowledge is utilized to guide the sparse learning models to uncover the molecular bases of complex traits. Third, the data integration models are designed to integrate imaging-omics data from multiple sources and discover the heterogeneous biomarkers. Fourth, the Baysian learning model is explored to predict longitudinal cancer outcomes. Fifth, the cloud computing and high-performance computing strategies are developed to support the big imaging-omics data mining, such as optimizations for various data mining workloads on heterogeneous hardware (e.g. GPU and NUMA multicore processors) to fully unlock the potential of data center hardware. It is innovative to integrate big data mining algorithms with cloud and high-performance computing to imaging-omics that hold great promise for a systems biology of the precision medicine.
Understanding the structure and dynamics of social networks is crucial for detecting any anomalous behavior and for managing its impacts. Most existing approaches view a network as a series of snapshots, where a snapshot represents the state of a network in a given time period. Therefore, different network operations need to be individually performed over each snapshot. In reality, online social networks are continuously evolving and therefore, network operations should be automatically performed as networks evolve and need to be done efficiently and reliably. Viewing the problem from this perspective allows us to create a solution that supports advanced, real-world use cases such as tracking the neighborhood of a given node or tracking how network connections evolve in time to determine effective marketing campaigns. These examples indicate the need for efficient computing techniques for important network statistics as the large networks evolve over time. To address this problem, the researchers in this project complement existing distributed evolving social graph analysis techniques with bootstrap and other statistical re-sampling based approaches. The ultimate goal is to develop novel data-driven tools so that when needed, not only certain estimates of statistical network models could be computed efficiently but their estimation errors are reliably quantified. <br><br>This project primarily targets development of new efficient and robust methods for anomaly and outlier detection on large sparse networks. The resulting methodology provides the following functions: 1) a computationally efficient finite sample inference for an extensive range of network topology statistics; 2) a flexible data-driven characterization of network structure and dynamics, and 3) comprehensively quantifying uncertainty in modeling and estimation of large networks, without imposing restrictive conditions on network model specification. The expected advances are both in research methods - new approaches to data-driven nonparametric inference for large sparse networks and in substantial enhancement of knowledge of network dynamics and formation in the era of digital communication. The project can significantly benefit students by providing a broad exposure to interdisciplinary applications of large network and fostering awareness of interdisciplinary relationships -- hence enhancing their capacity for critical thinking and opening up new career paths.
The project investigates the use of big-data analysis techniques for classifying crisis-related data in social media with respect to situational awareness categories, such as caution, advice, fatality, injury, and support, with the goal of helping emergency response teams identify useful information. A major challenge is the scale of the data, where millions of short messages are continuously posted during a disaster, and need to be analyzed. The use of current technologies based on automated machine learning is limited due to the lack of labeled data for an emergent target disaster, and the fact that every event is unique in terms of geography, culture, infrastructure, technology, and the people involved. To tackle the above challenges, domain adaptation techniques that make use of existing labeled data from prior disasters and unlabeled data from a current disaster are designed. The resulting models are continuously updated and improved based on feedback from crowdsourcing volunteers. The research will provide real, usable solutions to emergency response organizations and will enable these organizations to improve the speed, quality and efficiency of their response. <br><br>The research provides novel solutions based on domain adaptation and deep neural networks to tackle the unique challenges in applying machine learning for crisis-related data analysis, specifically the volume and velocity challenges of big crisis data. Domain adaptation approaches enable the transfer of information from prior source disasters to an emergenet target disaster. Deep learning approaches make it possible to employ large amounts of labeled source data and unlabeled target data, and to incrementally update the models as more labeled target data becomes available. Large-scale analysis across combinations of source and target crises will help identify patterns of transferable situational awareness knowledge. The resulting technical and social solutions will be blended together for use in data management and emergency response.
Honey bees exhibit highly complex behavior and are vital for our agriculture. Due to the rich social organization of bees, the overall performance and health of a bee colony depends both on a successful division of labor among the bees and on adequate reaction to the environment, which involves complex behavioral patterns and biological mechanisms. Much remains to be discovered on these matters as research is currently limited by our ability to effectively collect and analyze individual's behavior at large scale, out of the laboratory. The technology developed in this project will enable biologists to study the individual behavior of thousands of bees over extended periods of time. It builds on innovative algorithms and software to analyze big data collected from colonies in the field. Study of behavioral patterns at such scale will provide unique information to advance knowledge on biological processes such as circadian rhythms that influence bee behavior in addition to playing an important role in animals and humans. The models developed will help better understand factors involved in colony collapse disorder, thus guiding future research on threats to such an important pollinator. This work will be performed through the tight collaboration of a multi-disciplinary team of researchers to combine the latest advances in computer science and data science with expertise in biology. It will provide the opportunity to train students from underrepresented minority on research at the intersection of these fields and to reach more than 600 undergraduate students, high school students, and the general public about how the Big Data approach can contribute to current scientific and ecological challenges.<br><br>The project will develop a platform for the high-throughput analysis of individual insect behaviors and gain new insights into the role of individual variations of behavior on bee colony performance. Joint video and sensor data acquisition will monitor marked individuals at multiple colonies over large continuous periods, generating the first datasets of bee activities of this kind on such a scale. Algorithms and software will be developed to take advantage of a High Performance Computing facility to perform the analysis of these massive datasets. Semi-supervised machine learning will leverage the large amount of data available to facilitate the creation of new detectors for parameters such as pollen carrying bees or fanning behavior, currently annotated manually. Predictive models and functional data analysis methods will be developed to find patterns in individual behavior based on multiple parameters and over large temporal scales. These advances are expected to help uncover mechanisms of individual variations previously unobservable. They will enable the first large scale biological study on the circadian rhythms of the bee based on the variations in behavior of individuals in multiple activities instead of reasoning on single activities or averages. Progress, datasets and software will be shared with the community on the project website (sites.google.com/a/upr.edu/bigdbee).
Our lives are becoming increasingly connected with Big Data. Massive amounts of digital trace data are being generated from the activities and events of complex socio-technical systems consisting of human actors and man-made artifacts (which refer to as social objects). Such complexity comes from the massively interconnected and computed nature of the contemporary digital world. These data sets are different from traditional data as they are typically massive, unstructured, granular, heterogeneous, dynamic, and performative. Using Big Data, the researchers are able to understand and predict behaviors of complex socio-technical systems. To support such efforts, the researchers will build a new methodological framework based on an evolutionary ontology that treats variation as real and as the fuel of evolution. Specifically, the researchers analyze data set from Twitter (one of the largest social media sites) and Github (the largest open source community) to test and validate their framework. As the role of Big Data continues to increase in our society, the researchers plan to develop online curricula to help students learn how to access, manage, analyze, and visualize big data sets via a variety of approaches.<br><br>The researchers are developing a method to predict the emergence of system-level behaviors by analyzing large volumes of digital trace data using evolutionary social ontology to build a multi-level model of complex socio-technical systems. They use analytical techniques developed in evolutionary biology and systems biology: (1) to characterize a stream of digital trace data from a complex socio-technical system with finite genetic elements; (2) to predict the behavior of socio-technical systems based on the pattern of "behavioral gene" interactions; and (3) to explore the impact of mutational input, gene flow, and recombination in "behavioral genes" on the evolution of socio-technical systems. The researchers test their model in GitHub, one of the largest open source communities that includes over 5 million open source software development projects and Twitter, one of the largest social media site, that has over 500 million messages per day. The model generated from this research can be used for other types of massive digital trace data including sensor data from Internet of the Things and mobile data from smartphones.
The objective of this work is to provide big data owners with tools to safely share their social networks data with the research community. The specific type of big data is large online social graphs that evolve over time due to two different dynamic processes: one is the natural evolution of the graph with edge and node removal and insertion; the other is a dynamic process that changes the state of the vertices of the network. Real, longitudinal social graphs datasets are fundamental to understanding a variety of phenomena, such as epidemics, adoption of behavior, crowd management and political uprisings. However, publishing real data is significantly hampered by serious privacy risks: even when humans' identities are removed, studies have proven repeatedly that de-anonymization is doable with high success rate. This project aims to investigate and compare structural anonymization techniques that rely on generating graphs with given characteristics of the original, real graph. The results of this study alleviate the privacy and security risks related to graph sharing and contribute to a faster understanding of natural and social phenomena on real graphs by facilitating real graph sharing for better, faster, more impactful research. The project also contributes to the understanding of dynamic processes on social graphs; involves graduate and undergraduate students in interdisciplinary research; shares resulting code on github; enhances curriculum via collaborative teaching targeted at Sociology and Computer Science students; and disseminates resulting knowledge to audiences ranging from middleschool to graduate students via presentation, publications, and summer schools.<br><br>The project aims to approach graph anonymization via two techniques for graph generation: dK-series techniques, introduced in the context of internet network generation, and Exponential Random Graph Model-based approaches (ERGM), which are the state of the art in modeling social networks in Sociology. For each approach, the project first investigates its effectiveness on anonymizing static social networks sampled from representative datasets (some available, others collected as part of this effort). Second, it adapts the dK series and ERGM techniques to dynamic social networks based on empirical characterizations of the evolution of social relations. Third, the empirically-described dynamic processes are added on top of the static and dynamic networks from the previous steps. And finally, the research focuses on scaling up the computational techniques to be able to anonymize social (thus, sparse) graphs in the order of millions of nodes.
Broad and diverse adoption of data science educational programming by institutions of higher education in the United States is essential to the future of scientific and economic progress. By developing data science programs and integrating data science into curricula, U.S. institutions can ensure that graduates are better prepared for the research and industry needs of the twenty-first century. While there are significant programs in data science under development at research-oriented institutions of higher education, progress in program development at primarily undergraduate, teaching-focused, and minority-serving institutions is lagging and underrepresented in the national conversation. Consequently, there is an emerging "Data Divide" between the different types of institutions of higher education, which would be detrimental both to science and to the future workforce needs of the nation. This workshop will identify the unique challenges faced by primarily undergraduate, teaching-focused, and minority-serving institutions in developing data science educational programs. Topics to be addressed include instructor training, infrastructure needs, existing and potential resources, and expertise gaps that have a disproportionate impact on program development at such institutions. The workshop will also stimulate discussions about the necessary resources and the available opportunities for supporting efforts in the development of data science programs at these types of institutions.<br><br>Data Science education is an essential component in the continued competitiveness of the United States on the international stage. The outcomes of this workshop will help the community move one step closer to ensuring that data science education is broadly accessible to a very broad cross-section of the student population across the nation. The workshop is an important step towards ensuring that diverse student populations across the U.S. are able to receive education in data science education regardless of their location, gender, ethnicity, financial need, or other demographics that may currently limit opportunities for advancement.
With recent advances in technology, it is now possible to measure and record significant numbers of features on a single individual. The volume, velocity, and variety, the "3Vs", of Big Data pose significant challenges for modeling and analysis of these massive datasets. For example, to understand cancer at the genetic level, researchers need to detect rare and weak signals from thousands, or even millions, of candidate genetic markers obtained from a limited number of subjects. Existing methods typically assume that the number of subjects is very large, an assumption often violated in practice. The main goal of this project is to develop efficient methods for extremely large-dimensional, small sample size data. The methodological advances will be extremely valuable in addressing Big Data challenges in different areas such as medical research, bioinformatics, financial analysis, and astronomic image analysis. Efficient software packages and algorithms to implement the proposed methods will be developed and made publicly available.<br><br>The key innovative idea motivating this research is viewing a high-dimensional problem from a novel packing perspective, which allows the number of variables, p, to be arbitrarily large and the number of observations, n, to be finite. The proposed research will systematically investigate three fundamental problems under this "finite n, arbitrarily large p" paradigm: (1) asymptotic theory of spurious correlations, (2) fast detection of low-rank correlation structures, and (3) detection boundary and optimal testing procedures for detecting rare and weak signals. This research will transform the current asymptotic framework, transitioning from the regimes of "large n, small p" and "large n, larger p" to the regime of "finite n, arbitrarily large p".
Massive longitudinal healthcare data, such as administrative claims and electronic health records, provide an opportunity to greatly enhance the accuracy and clinical impact of patient-level predictions across a wide range of outcomes. This research targets the national priority domain of healthcare IT and showcases the advances that Big Data afford in helping patients make informed healthcare decisions leading to improved outcomes. Other involved stakeholders include healthcare providers, insurers and governmental agencies, and the databases this proposed grant employs encompass diverse and vulnerable patient populations, including the young, the poor and the elderly. Within this context, this grant is seeking to predict patient-level health events based upon personal characteristics and conditions. Accurate and well-calibrated predictions could significantly improve the wellbeing of patients and populations. This grant proposes to derive predictive models from massive observational data and then, for example, predict that a particular patient has an 18% chance of experiencing a stroke in the next 12 months. With this prediction in hand, caregivers and patients can optimize medical interventions and implement behavioral changes to hopefully prevent the predicted event. Further, this grant integrates two graduate student researchers, whose mentored experiences begin to rectify the shortage of data scientists trained at the intersection of statistics and medicine, and provides general statistical software tools for building large-scale predictive models from massive data across scientific domains.<br><br><br>From a technical perspective, the proposed grant aims to first evaluate performance and applicability of an existing predictive model across five administrative claims and electronic health record databases covering over 80 million lives, using CHADS2 stroke risk as a motivating example. Then the grant will develop an innovative data-driven process for building patient-level predictive models from longitudinal observational data, and initially apply the process to predicting stroke in patients with atrial fibrillation for comparison of performance against CHADS2, Finally, the grant aims to explore characteristics of the process<br>and resulting models, such as: evaluation of out-of-sample predictive performance in different databases; consideration of how models change over time; and assessment of which clinical variables most substantially contribute to patient-level predictions. Together, this research will focus on identifying heuristics to extract clinically relevant predictors from longitudinal electronic healthcare data, developing algorithms to use this information in multivariate modeling through massive parallelization using graphics processing units, optimized for data sparsity, and evaluating performance based on accuracy in predicting outcomes at the patient level. As a proof-of-concept, the grant will develop an approach to predict stroke risk and apply this approach across five disparate data sources (80+ million patients, including drugs, lab values, procedures, emergency room visits, primary care visits, inpatient encounters, etc) that reflect diverse patient populations across the US, including the privately insured, Medicare-eligible, and Medicaid beneficiaries. The underlying goal of the grant is to apply innovative statistical and machine learning techniques using advancing computer technology to large-scale observational data to develop accurate and well-calibrated patient-level predictive models enabling the prediction of future medical events for individual patients.
A large fraction of the ever-growing internet content is found in social media such as (micro)blogs. Users access it to both form and share their opinions about events and people, election preferences, product and brand recommendations. This situation provides opportunities to create added layers of data mining and analysis regarding users' views on developing events, products, services, or government actions; at the same time, it raises challenges for Entity Linking (EL) in social media. EL is the task of linking an extracted mention to a specific definition of the entity. The definition of an entity is usually a pointer to a Web page that defines the entity. Information extraction from social media generally faces many challenging issues due to: message volume, message speed (Twitter alone generates over 500 million messages per day), variety, free-form language, lack of context, large reference variation and language diversity. Hashtags are an essential part of the ethos of social networks. They are used to denote brands, events, people, social rallies, etc. The hashtag disambiguation problem is to detect synonymous hashtags and recognize the polysemic ones. For example, the hashtag '#BHaram' refers to the entity 'Boko Haram', defined at Wikipedia page en.wikipedia.org/wiki/Boko_Haram or at National Counterterrorism Center Web web page www.nctc.gov/site/groups/boko_haram.html. The purpose of this project is to perform EL in social media. This work will benefit multiple segments of society that rely on applications using data from microblog systems, such as targeted monitoring of Twitter and Facebook to collect and understand users' opinions about a recent product or a world event; data aggregation (e.g., reviews about products and services); and data mining for early crisis detection and response as well as national security. This project is one more step towards addressing the government's latest initiative of fighting crime using big data.<br><br>The goals of this project are to research algorithms to detect in near real-time those pieces of text in messages that reference entities, Web pages that describe entities, and to link entity references to Web pages and across microblog systems so that together a broad, more complete characterization of each entity can be automatically generated. The proposed approaches are based on innovative techniques that include: incremental, iterative message analysis; smart indexing techniques with live updates to support fast incremental entity reference detection; computationally light soft-clustering of messages to improve entity reference detection; and fast incremental K-partite graph clustering. The resulting artifacts (e.g., software tools) will be made available to benefit researchers in academe and industry. Distribution of free, open-source software for implementing the techniques developed will enhance existing research infrastructure. The project will support and train at least three PhD students, as well as involve undergraduate students in research at Temple University and Binghampton University. The project web site (http://cis.temple.edu/~edragut/projects/nimel.htm) includes more information on the project, software, datasets, educational materials, and publications.
The potential for upward mobility from one generation to the next is fundamental to the wellbeing of a democratic society, and to that society's long-term economic productivity. Poverty at birth is a condition affecting more than 1 in 4 American children. It is a critical barrier to children's subsequent development and life chances, and therefore to breaking intergenerational cycles of disadvantage. Both mother's and father's characteristics contribute to the chance that a child will be born into poverty. Therefore it is important to incorporate both the mother and father into the scientific modeling of the experience of poverty at birth from one generation to the next. Existing data and methods do not allow for this modeling in representative samples of the U.S. population, especially as it evolves as an increasingly multi-ethnic society. Limited data are collected on the characteristics of every birth in the United States. Limited additional data on all individuals and their households are collected every 10 years in the Census. Larger amounts of data per individual and household are collected every year from random samples that are representative of the U.S. population. These samples include the large-scale American Community Survey and numerous medium- and small-scale sample surveys. This research develops and evaluates statistical estimation and simulation methods to combine data from all these sources to answer questions about intergenerational mobility. The research will answer questions about the degree of persistence of poverty at birth from one generation to the next across different race and ethnic groups, and about the roles of education and family formation in creating upward mobility versus persistence of disadvantage. Open-source, user-friendly software for the statistical methods developed in the project will be made available to researchers. The project also develops graduate students' skills in Big Data methods in statistics and the social sciences. <br><br>The project has as its goal the development of a transformative, Big Data approach to exploiting the rich "traditional" data sources to build social-scientific theory in a statistically-rigorous and empirically-comprehensive way. In no single nationally-representative data source is poverty at birth observed for the mother-father-child triad. The triad's poverty statuses at each one's birth are instead linked in a model that simulates four connected processes: (1) educational progress predicted from the birth conditions of household poverty and parents' education, race, ethnicity, and immigrant statuses; (2) couple formation and dissolution; (3) couple fertility and unpartnered women's fertility; and (4) household poverty when their own children are born. The "Big Data" of this project consist of more than 100 million births, combined with census, microcensus, large-scale cross-sectional survey, and medium-scale and smaller-scale longitudinal survey data sources that together include millions of years of exposure to schooling, to partner-matching, and to partnered and (co-residentially) unpartnered births. These multiple sources of data of the study, unlike in many Big Data applications, are all either complete enumerations or probability samples of a well-specified population. The project develops combined-survey and combined population-and-survey estimation methods to estimate with enhanced precision the individual behavioral parameters of the process, and develops a simulation-modeling approach to generating inference about causal associations that emerge from the four connected processes, integrating the multiple sources of uncertainty about each component process. Results and methodological advances will be disseminated to the scholarly community through presentations and peer-reviewed journal articles. Additional, broader dissemination will occur through project investigator contact with the news media and other forums for engagement with the broader policy community about the project results and their significance.
Contemporary data-driven science and engineering problems require the development of statistical methods that do not compromise statistical accuracy, yet are computationally feasible. Data quality, particularly the heterogeneity in data measurements, is a critical factor that affects statistical accuracy in the analysis of large datasets. This project will explore and demonstrate the impact and feasibility of improving computational and statistical performances simultaneously for Big Data problems with massive datasets. The research will advance the state of knowledge in predictive statistical learning with Big Data, and be extremely valuable in applications related to financial risk management or commercial operations employing recommender systems, biology, and image analysis. <br><br> A key phenomenon motivating this project is the notion that some refined ensemble methods combined with random projections can simultaneously enable the fast analysis of massive data while enhancing statistical performance. Specifically, the aims of the project are: (1) Develop new classification methods based on random projections and the random forest. By defining appropriate projections, the proposed method is shown to improve statistical accuracy for massive datasets with a large number of irrelevant noisy measurements. The theoretical properties of this method will be analyzed, and an adaptive version of the algorithm developed to optimize the computational and statistical efficiency gains; (2) Propose boosting algorithms with random projections. The statistical properties, practical performance, and implementation of the proposed random projected boosting algorithms will be investigated; (3) Develop classification methods with heterogeneities. A classification method that involves the weighted bootstrap and ensemble learning to handle heterogeneity or covariate shifts in measurements in large datasets will be developed. The random projection method will be applied to improve the proposed method for high-dimensional datasets.
This is a comprehensive research proposal on the statistical modeling and analysis for educational assessment. This research addresses issues concerning fundamental statistical problems that arise in the analysis of Big Data in education. The research focus is on modeling and inference for large-scale data with complex dependence and structures (such as high-dimensional response and process data). These data arise from the introduction of new methods of testing student knowledge that rely on scenarios presented to the students and on simulation-based environments where student responses to a simulated environment are tested. This research is collaborative between Columbia University and the Educational Testing Service.<br><br>The topics studied include latent graphical modeling for high-dimensional item response data, modeling and segmentation of process data via dictionary models, estimation of item-attribute relationship, dimension reduction, theoretical analysis and computational methods for the proposed models. The analysis combines techniques and concepts from mathematics and probability and applies them to nonlinear statistical models and data analysis. The proposed model combines latent variable and graphical approaches for high-dimensional data; for modeling process data, recent advances in modeling and segmenting techniques for natural language processing will be investigated. In the theoretical development, several algebraic concepts to formulate model identifiability and perform combinatorial analysis on high-dimensional discrete spaces will be studied. In addition, optimization algorithms will be developed using recent advances in numerical methods.
Although big data has had a huge impact in several areas, this impact is limited by the high cost and poor quality of analyzing unstructured data, and the costs of integrating data of multiple types. Lowering these costs will bring the benefits of big data based research to many new areas. Against this background, this project aims to develop machine-learning methods that read, analyze, and integrate web-scale collections of text and other data. The project can be expected to yield fundamental advances in data integration, machine learning, natural language understanding, and automated inference. <br><br>The project includes research thrusts in (1) robust semi-supervised bootstrap learning algorithms that can cope with ambiguity in text, (2) algorithms for detecting and aligning the schemas implicit in semi-structured sources relative to a shared common ontology, (3) NLP algorithms that perform deeper analysis on text to extract infrequently mentioned yet important facts, and (4) targeted reading agents capable of pursuing specific queries or conjectures based on the scientist's current focus. <br><br>Anticipated results of the project include fundamental advances in each of the research thrusts and their synergistic integration into software system (NESSIE) designed to help scientists in exploring scientific hypotheses in their respective domains of interest, by supporting targeted extraction of knowledge from large amounts of textual sources in relevant areas. <br><br>Broader impacts of the research include advanced techniques for extracting and organizing structured knowledge from text, and integrate the learned information with existing structured knowledge in multiple domains. The Additional broader impacts of the research include enhanced opportunities fore advanced research-based training of graduate students. The softare and data resulting from the research will be made freely available to the larger scientific community.
Modeling and simulating physical phenomena with computers is now an important tool for development and discovery in almost all fields of science and engineering. Joining theory and experimentation, computation is now recognized as the "third pillar" of scientific research. More recently, data analytics (the science of examining raw data with the purpose of drawing conclusions about that information) has emerged as an important computational tool for scientific discovery - a tool that is likely to be as important as, if not more important than, modeling and simulation. Within the broad domain of data analytics, the use of graphs is a powerful conceptual tool that describes relationships between discrete objects. Because of the growing importance of data analytics, many research groups have turned their attention to developing new approaches for solving large-scale graph problems. While the research results in this area have been valuable, the software products that have been produced tend to be limited in scope and/or not of sufficient quality to be reused. This project will address this problem by creation of GraphPack, a comprehensive unified graph library with a coherent user interface and support for multiple state-of-the-art compute platforms. This work will have broad impacts in scientific and engineering application areas, larger social and economic areas depending on graph analytics, and in education. GraphPack will improve the ease of use and broaden the applicability of graph algorithms. Application areas include such diverse areas as knowledge discovery, genomics, proteomics, electronic design automation, forest management, Internet routing, power grid management, and many more.<br><br>GraphPack will be a reliable and comprehensive toolkit applicable across a wide variety of problems and architectures that will unleash the capabilities of the community by making the current state of the art readily available. GraphPack will develop a consistent and comprehensive set of abstractions necessary to express a wide variety of (generic) graph algorithms and data structures in the context of unimodal as well as hybrid parallelism. These abstractions will be incorporated as abstract concepts, and selected concrete efficient implementations will be provided. While genericity is an important goal, GraphPack will also provide a simplified user interface for graph algorithms for the situations where simplicity is more important than fully tuned performance. GraphPack will also provide a GraphBLAS interface based on the recent efforts to provide a standardized set of graph operations based on the concepts of linear algebra. By providing multiple interfaces with efficient parallel implementations, GraphPack will enable a wide variety of applications to take advantage of high-performance graph algorithms.
Data-driven modeling has moved beyond the realm of consumer predictions and recommendations into areas of policy and planning that have a profound impact on our daily lives. The tools of data analysis are being harnessed to predict crime, select candidates for jobs, identify security threats, determine credit risk, and even decide treatment plans and interventions for patients. Automated learning and mining tools can crunch incredible amounts and variety of data in order to detect patterns and make predictions. As is rapidly becoming clear, these tools can also introduce discriminatory behavior and amplify biases in the systems they are trained on. In this project, the PIs will study the problems of discrimination and bias in algorithmic decision-making. By studying all aspects of the data pipeline (from data preparation to learning, evaluation, and feedback), they will develop tools for analyzing, auditing, and designing automated decision-making systems that will be fair, accountable, and transparent. As specific goals to broaden the impact of this research, the PIs will develop a course curriculum to educate the next generation of data scientists on the ethical, legal, and societal implications of algorithmic decision-making, with the intent that they will then take this understanding into their jobs as they enter the workforce. Initial efforts by the PIs have attracted students from underrepresented groups in computer science, and they will continue these efforts. The PIs will also explore the legal and policy ramifications of this research, and develop best practice guidelines for the use of their tools by policy makers, lawyers, journalists, and other practitioners.<br><br>The PIs will explore the technical subject of this project in three ways. Firstly, they will develop a sound theoretical framework for reasoning about algorithmic fairness. This framework carefully separates mechanisms, beliefs, and assumptions in order to make explicit implicitly held assumptions about the nature of fairness in learning. Secondly, by examining the entire pipeline of tasks associated with learning, they will identify hitherto unexplored areas where bias may be unintentionally introduced into learning as well as novel problems associated with ensuring fairness. These include the initial stages of data preparation, various kinds of fairness-aware learning, and evaluation. They will also investigate the problem of feedback: when actions based on a biased learned model might cause a feedback loop that changes reality and leads to more bias.
Recent decades have seen the development of computational science where modeling and data analysis are critical to exploration, discovery, and refinement of new innovations in science and engineering. More recently the techniques have been applied to arts, social, political and other fields less traditionally reliant on high performance computing. This innovation has grown out of realization some 20 years ago that I/O (input/output) support for high performance parallel and distributed architectures had lagged behind that of pure computational speed, and further that bring I/O up to speed was both critical, and a rather difficult problem. The core hurdle of contemporary I/O on large HPC machines relates to issues of latency in large parts caused by the deficiencies of the historical I/O model that was relevant when computers were exclusively large, centralized, single processor systems shared by many time-sharing programs. In order to improve I/O on scalability on future hardware architectures novel approaches are required.<br><br>This project is conducting research on an extension of ParalleX, a new highly innovative parallel execution model. The extension provides a powerful I/O interface that allows researchers to create highly efficient data management, discovery, and analysis codes for Big Data applications. This new extension, known as PXFS, is based on HPX, an implementation of ParalleX based on C++, and OrangeFS, a high performance parallel file system. The research goal driving PXFS is to extend HPX objects into I/O space so that the objects become persistent and storage becomes another class of memory, all accessed as a single virtual address space and managed by an event driven dynamic adaptive computation environment. Critical aspects of this approach include futures-based synchronization, dynamic locality management, dynamic resource management, hierarchical name space, and an active global address space (AGAS). The overall goals of PXFS are to eliminate the division of programming imposed by conventional file system through the unification of name spaces and their management, and to minimize global synchronization in order to support asynchronous concurrency. The research methodology is to implement a Map/Reduce application framework using PXFS and evaluate its effectiveness in both performance and ease of use.<br><br>This project is conducted at three major research universities involving undergraduate and graduate students, post-docs, and high-school teachers and their students. The project includes a PI from the functional genomics field acting as domain science expert in order to focus the development efforts on real world problems. Graduate students and post-docs involved in the project are trained in these areas to promote scientists who understanding both aspects of Big Data problems. The project engages under represented minorities with the goal to inspire them to pursue a career in computer science or genomics. The software developed by the project is available open-source and archived using an integrated source code revision repository, wiki, and bug tracking software system in addition to code releases with accompanying documentation.
Multipole methods, including the fast multipole method and the Barnes-Hut algorithm, contribute to a broad range of end-user science applications extending from molecular dynamics to galaxy formation. Multipole methods are widely applied to N-body like problems where the individual interactions of a large number of distant objects can be treated as a single interaction under the appropriate conditions. This simplification eliminates the need for computing individual pairwise interactions and results in a drastic speed-up of computation. However, conventional parallel multipole methods are facing serious challenges to remain competitive as computational resources approach Exascale. Many applications employing multipole methods describe very dynamic physical processes, both in their time dependence and in their range of relevant spatial scales, while conventional implementations of multipole methods are essentially static in nature leading to computational inefficiencies. <br>This project provides a fine-grained data-driven approach for multipole methods in order to address the limitations of conventional practices and improve scalability and efficiency. The software library employs dynamic adaptive execution methods with multipole-specific strategies for fault tolerance and exception handling while simplifying the implementation of the fast multipole method and the Barnes-Hut algorithm for end-users. The project software library immediately impacts science applications based on multipole methods by improving application scalability and efficiency and providing fault tolerance, a global address space, and an Exascale-ready execution model which integrates the entire system stack. The software library provides a portable and easy-to-use interface that allows scientists to work more efficiently and take advantage of high performance computing resources more effectively. The software library also serves to inform the evolution and development of other languages and programming models aiming to improve performance by shifting to message-driven techniques.
Natural fractures act as major heterogeneities in the subsurface that controls flow and transport of subsurface fluids and chemical species. Their importance cannot be underestimated, because their transmissivity may result in undesired migration during geologic sequestration of CO2, they strongly control heat recovery from geothermal reservoirs, and they may lead to induced seismicity due to fluid injection into the subsurface. Advanced computational methods are critical to design subsurface processes in fractured media for successful environmental and energy applications. This project will address the following key BIG data and computer science challenges: (1) Computation of seismic wave propagation in fractured media; (2) BIG DATA analytics for inferring fracture characteristics; (3) High Performance Computation of flow and transport in fractured media; and (4) Integration of data from disparate sources for risk assessment and decision-making. This will enable design of technologies for addressing key societal issues such as safe energy extraction from the surface, long-term sequestration of large volumes of greenhouse gases, and safe storage of nuclear waste. The project will provide interdisciplinary training for a team of graduate students and postdoctoral fellows. Outreach to high schools teachers and minorities through a planned workshop will inspire interest in environmental green-engineering, mathematics, and computational science. Numerous applications will benefit from this research, including Computer and Information Science and Engineering (CISE), Geosciences (GEO), and Mathematical and Physical Sciences (MPS).<br><br><br>The proposed research will emphasize high performance computation (HPC) approaches for characterizing fractures using large subsurface seismic data sets, BIG data analytics for extraction of fracture related information from seismic inversion results and long-duration dynamic data, and advanced computational approaches for modeling flow, transport, and geomechanics in fractured subsurface systems. The specific objectives are to: Develop an efficient forward modeling algorithm for seismic wave propagation in fractured media using efficient computational schemes. Compute flow and transport in fractured media using an efficient computational scheme implemented on GPUs such as mimetic finite differences. Perform efficient multiphysics simulation of flow and geomechanics in fractured media. Integrate information from time-lapse seismic inversion and flow/transport simulation using novel statistical schemes. Joint inversion of seismic and fluid flow data and uncertainty quantification using efficient computational schemes. Develop and deploy a scalable hybrid-staging based substrate that can support targeted workflows using staging-based in-situ/in-transit approaches. Computational simulation is critical to design subsurface processes for successful environmental and energy applications. Project URL: http://csm.ices.utexas.edu/current-projects/
This award will support a 1.5 day workshop in Arlington, VA to bring together the community of SI2 awardees with the aims of: 1) serving as a forum for focused PI technical exchange, through an early evening poster session; 2) serving as a forum for discussion of topics of relevance to the PIs from topics emerging both from within NSF and from the broader community, by informing the attendees of emerging best practices, and stimulating thinking on new ways of achieving sustainability and of ensuring that the foundation laid by SI2 is preserved into the future; and 3) gathering experiences and a shared sense of best practice that results in a published workshop report.<br> <br>The workshop will bring together researchers who are a proto-community of NSF open source software developers. The meeting will examine the characteristics of the community, and consider whether the products from the program can be enhanced by giving the community a new identify and new way of looking at itself. The meeting will also address citation, attribution, and reproducibility, which are three related topics often discussed in the context of data, but less so in the context of software. The attendees will consider practical steps that could be taken to advance software citation and science reproducibility. Finally, sustainability of software is a major topic for NSF and for the SI2 PIs. The meeting will highlight new ways of thinking about software sustainability, drawing on experts in the field and on recent SI2 EAGER funded projects that are studying the community to help the workshop attendees in their thinking about sustainability.<br><br>The community outputs of the workshop will be: posters developed by the SI2 PIs that will be shared amongst the attendees and shared more broadly on the workshop web site; an experiences report (licensed under a Creative Commons license) produced by the award PIs, distributed via the workshop web site, via email to participants who will be asked to disseminate among their project colleagues and peers, and via an archive repository through which it will be accessible through a persistent ID; and attendee journalism during the event in the form of a public Google doc and public Twitter stream.
High-Throughput Connectomics <br><br>Connectomics is the science of mapping the connectivity between neuronal structures to help us understand how brains work. Using the analogy of astronomy, connectomics researchers wish to build 'telescopes' that will allow scientists to accurately view the brain. However, as in astronomy, the raw data collected by microtomes and electron microscopes, the instruments of connectomics, is too large to store effectively, and must be analyzed at very high computation rates. Our goal is to research, develop, and deploy a software architecture that enables high-throughput analysis of connectomics data at the speed at which it is being acquired. We will develop the first computational infrastructure to support high-throughput connectomics without human intervention. If successful, this system will allow for the first time the mapping of a cortical column of a small mammalian brain (1 cubic millimeter), and hopefully within a few years the mapping of significant sections of a mammalian cortex. <br><br>The solution to the big data problem of connectomics is a new high-throughput connectomics software architecture that we call MapRecurse. MapRecurse, named so because it bears some resemblance to the widely used MapReduce framework, will provide a unified way of specifying sequences of computational steps and validation tests to be applied to the collected data. Key to MapRecurse will be the ability to layout data and computation in a structured way that preserves locality. Using it, programmers will be able to apply fast, less accurate segmentation algorithms to low resolutions of the data in order to quickly compute a first version of the output neural network graph. Domain-specific graph theoretical methods will then check for correctness of the graph and identify areas of inconsistencies that are in need of further refinement. MapRecurse will then apply bottom-up, local processing with slower, more accurate segmentation and reconstruction algorithms to higher resolutions of the data, verifying and correcting any errors. The iterations progress recursively and in parallel across multiple cores, giving the approach its name. We believe that MapRecurse and the data structures and algorithms developed here will find applications in other high-throughput applications, such as, in astronomy, biology, social media applications, or economics.
High-Throughput Connectomics <br><br>Connectomics is the science of mapping the connectivity between neuronal structures to help us understand how brains work. Using the analogy of astronomy, connectomics researchers wish to build 'telescopes' that will allow scientists to accurately view the brain. However, as in astronomy, the raw data collected by microtomes and electron microscopes, the instruments of connectomics, is too large to store effectively, and must be analyzed at very high computation rates. Our goal is to research, develop, and deploy a software architecture that enables high-throughput analysis of connectomics data at the speed at which it is being acquired. We will develop the first computational infrastructure to support high-throughput connectomics without human intervention. If successful, this system will allow for the first time the mapping of a cortical column of a small mammalian brain (1 cubic millimeter), and hopefully within a few years the mapping of significant sections of a mammalian cortex. <br><br>The solution to the big data problem of connectomics is a new high-throughput connectomics software architecture that we call MapRecurse. MapRecurse, named so because it bears some resemblance to the widely used MapReduce framework, will provide a unified way of specifying sequences of computational steps and validation tests to be applied to the collected data. Key to MapRecurse will be the ability to layout data and computation in a structured way that preserves locality. Using it, programmers will be able to apply fast, less accurate segmentation algorithms to low resolutions of the data in order to quickly compute a first version of the output neural network graph. Domain-specific graph theoretical methods will then check for correctness of the graph and identify areas of inconsistencies that are in need of further refinement. MapRecurse will then apply bottom-up, local processing with slower, more accurate segmentation and reconstruction algorithms to higher resolutions of the data, verifying and correcting any errors. The iterations progress recursively and in parallel across multiple cores, giving the approach its name. We believe that MapRecurse and the data structures and algorithms developed here will find applications in other high-throughput applications, such as, in astronomy, biology, social media applications, or economics.
Gaining big insight from big data requires big analytics, which poses big usability problems. Analyses of big data often rely on several computational and statistical models that operate on multiple levels of data scale to discover and characterize noteworthy patterns. The models work jointly or in sequence to filter, group, summarize, and visualize big data so that analysts may assess the data. As a simple example in big text analytics, massive text is first sampled for relevant or representative words, then further reduced by a complex form of modeling (e.g., topic modeling), then visualized by applying a dimension reduction algorithm. As the size of data increases, so does the number of models and, likewise, the need for human interaction in the analytical process. By interacting, humans include expert judgment into the analytical process, and efficiently explore and make sense of big data from varying perspectives. However, for a variety of reasons, interacting with any individual model is difficult, let alone a growing number of models. Thus, current human-computer-interaction research is merged with complex statistical methods and fast computation to develop a usable, multi-model analytic framework for big data. Wrapped in software, the framework will be accessible to both professional and student users alike; i.e., available to make new discoveries in current government and industrial big datasets, as well as, educate future analysts at the undergraduate and graduate levels given new teaching modules. <br><br>The new analytic framework extends Visual-to-Parametric Interaction (V2PI) to Multi-scale V2PI (MV2PI). V2PI currently supports usable small-data analytics, and enables users to adjust model parameters by interacting directly with data in visualizations. That is, V2PI interprets visual interactions quantitatively to update underlying model parameters and produce new visualizations. MV2PI now links together several models that operate at multiple levels of data-scale in a unified interactive space. In MV2PI, small-scale data interactions in visualizations propagate to larger scale models (by inverting them and updating their parameters) and new visualizations are generated. In the text analytics example, if users drag several data points together to hypothesize a cluster, the inverted dimension reduction model computes updated dimension weights, queries relevant new hits at the large scale, identifies changed topics, and updates the layout to show big-data support for the new cluster. With MV2PI, users may interactively explore large-scale data and complex inter-relationships between models in real time, and in a usable fashion that directly supports their natural cognitive sensemaking process. Development of MV2PI involves: (1) formulation of an explicitly stated framework ; (2) creation of new interactive models (e.g., Interactive K-means and Interactive Latent Dirichlet Allocation) that cover different levels of scale and support MV2PI model inversion; (3) implementation of computational methods to support high-performance, real-time model updates; and (4) evaluation of MV2PI software framework for usability and effectiveness. The project web site (http://www.apps.stat.vt.edu/bava/mv2pi.html) will include information on MV2PI development, access to software, datasets, educational materials, and publications.
While statistical machine learning has seen major advances over the past two decades, rigorous approaches for high-dimensional spatio-temporal scientific data analysis have not received as much attention. On the other hand, several core scientific areas, including climate science, ecology, environmental sciences, and neuroscience, are generating increasing amounts of high-resolution spatio-temporal data. It is vital to develop rigorous machine learning approaches for such complex high-dimensional spatio-temporal data in order for key scientific breakthroughs in these areas in the next few decades. The project contributes to these endeavors by focusing on two key technical and scientific areas: spatio-temporal big data analysis and climate science. The project systematically develops the statistical machine learning foundations for the analysis of large scale complex high-dimensional spatio-temporal data, and applies such advances to problems arising in climate science, where the total amount of data is set to cross an Exabyte (1 Exabyte = 1000 Petabytes) soon. <br><br>The technical work in the project has three broad and interacting components: structured probabilistic graphical models for spatio-temporal data analysis, generalized graphical models for multivariate heavy tailed distributions, and physics-guided models with a richer class of structural constraints and capturing multi-scale phenomena. The project applies these technical advances to climate science, by generating climate projections at high-resolutions. Currently, the lack of requisite spatial resolution of current climate models makes automatic assessments of impacts, adaptation and vulnerability (IAV) difficult for a variety of sectors, including urban planning, freshwater resources, food security, energy, transportation systems, human health, and coastal systems.
During the last decade, the study of complex networks has diffused through many branches of science. How do we characterize the connectivity structure of the Internet, the power grid, or the human brain? Are there universal principles underlying the structure of these diverse systems? The availability of massive databases and reliable tools for data analysis provide a powerful framework to explore these structural questions. Furthermore, as the structure of most real-world networks is inherently evolving, an understanding of the dynamical complexity of networks is needed to provide a realistic description of such networks.<br><br>This project will develop efficient algorithms to analyze structural properties of large-scale networks. The PIs will also explore the connection between local structural properties and global spectral graph properties of relevance, such as the spectral radius of the adjacency matrix or the spectral gap of the Laplacian. The analysis will be extended to time-evolving networks and dynamic models of network evolution will be developed. Three scientific objectives of this proposal are: (1) designing algorithms to efficiently estimate local and global structural properties of large-scale networks, (2) relating local structural properties of a graph with its global spectral properties, using tools from spectral graph theory and convex optimization, and (3) developing predictive models of network evolution, as well as control strategies to drive the evolution of the network structure towards desirable spectral properties. <br><br>Networks are ubiquitous (the Internet, the web, biological, and social networks to name a few), and are continually evolving. Thus, developing efficient tools for understanding the evolution of structural and spectral properties of networks is of great relevance to many scientific disciplines. The project will support and train one PhD student, as well as involve undergraduate students in research at the University of Pennsylvania.<br><br>For further information see the project web site at: <http://sites.google.com/site/victormpreciado/research-projects/nsf_bigdata_2014>
Current bioacoustic monitoring of natural environments requires processing by humans to extract information content from recordings. Thus human processing creates a fundamental bottleneck in which data collection far outpaces capabilities to extract relevant and desired information. Bioacoustic research on automatic species classification in natural environments can be broadly divided into two groups: distinguishing a predefined set of known species from audio clips and extracting species as events that occur in a continuous audio stream. Both classification techniques have their specific problems--many of the data used distinguishing predefined species are recorded under "studio" conditions and not extensible to natural conditions, while processing of continuous audio streams generate many false positives. <br><br>To overcome these challenges we will take a multi-tiered approach: Analyzing a data set consisting of full-night recordings from 10 recording units over 100 nights. Building a web-enabled software to engage citizen scientists to identify the flight calls, providing us with a large and extensive model training dataset. Developing novel convolutional deep-learning networks, which are well suited for analysis of complex auditory scenes. Visualizing patterns detected and classified flight calls in space and time to produce novel information about the bird migration. Comparing model-generated acoustic data with radar, video, and direct visual citizen science datasets to produce the most comprehensive accounts of nocturnal bird migration possible. The combination of domain knowledge in bird vocalizations, engaging citizen scientists to allow development of large well annotated training datasets, and taking a novel deep-learning approach, will finally resolve the machine classification of acoustic signals in natural environments.
Science Gateways are virtual environments that dramatically accelerate scientific discovery by enabling scientific communities to utilize distributed computational and data resources (that is, cyberinfrastructure). Successful Science Gateways provide access to sophisticated and powerful resources, while shielding their users from the resources' complexities. Given Science Gateways' demonstrated impact on progress in many scientific fields, it is important to remove barriers to the creation of new gateways and make it easier to sustain them. The Science Gateway Platform (SciGaP) project will create a set of hosted infrastructure services that can be easily adopted by gateway providers to build new gateways based on robust and reliable open source tools. The proposed work will transform the way Science Gateways are constructed by significantly lowering the development overhead for communities requiring access to cyberinfrastructure, and support the efficient utilization of shared resources.<br><br>SciGaP will transform access to large scale computing and data resources by reducing development time of new gateways and by accelerating scientific research for communities in need of access to large-scale resources. SciGaP's adherence to open community and open governance principles of the Apache Software Foundation will assure open source software access and open operation of its services. This will give all project stakeholders a voice in the software and will clear the proprietary fog that surrounds cyberinfrastructure services. The benefits of SciGaP services are not restricted to scientific fields, but can be used to accelerate progress in any field of endeavor that is limited by access to computational resources. SciGaP services will be usable by a community of any size, whether it is an individual, a lab group, a department, an institution, or an international community. SciGaP will help train a new generation of cyberinfrastructure developers in open source development, providing these early career developers with the ability to make publicly documented contributions to gateway software and to bridge the gap between academic and non-academic development.
High Performance Computing System Acquisition: Jetstream - a self-provisioned, scalable science and engineering cloud environment<br><br>Jetstream will be a new type of computational research resource open for the national (nonclassified) research community - a data analysis and computational resource that US scientists and engineers will use interactively to conduct their research anytime, anywhere. Jetstream will complement current NSF-funded computational resources and bring a cloud-based system to the NSF computational resources incorporating the best elements of commercial cloud computing resources with some of the best software in existence for solving important scientific problems. This system will enable many US researchers and engineers to make new discoveries that are important to understanding the world around us and will help researchers make new discoveries that improve the quality of life of American citizens.<br><br>In terms of technical details, Jetstream will be a configurable large-scale computing resource that leverages both on-demand and persistent virtual machine technology to support a much wider array of software environments and services than current NSF resources can accommodate. As a fully configurable "cloud" resource, Jetstream bridges the obvious major gap in the current ecosystem, which has machines targeted at large-scale High-Performance Computing, high memory, large data, high-throughput, and visualization resources. As the open cloud for science, Jetstream will:<br> <br>*Provide "self-serve" academic cloud services, enabling researchers or students to select a VM image from a published library, or alternatively to create or customize their own virtual environment for discipline- or task-specific personalized research computing.<br><br>*Host persistent VMs to provide services beyond the command line interface for science gateways and other science services. For example, Jetstream will become a primary host of the popular Galaxy scientific workbench and its main datasets, bringing many Galaxy users to the NSF ecosystem from day one.<br> <br>*Enable new modes of sharing computations, data, and reproducibility.<br> <br>*Expand access to the NSF XSEDE ecosystem by making virtual desktop services accessible from institutions with limited resources
Successfully tackling many urgent challenges in socio-economically critical domains (such as sustainability, public health, and biology) requires obtaining a deeper understanding of complex relationships and interactions among a diverse spectrum of entities in different contexts. In complex systems, (a) it is critical to discover how one object influences others within specific contexts, rather than seeking an overall measure of impact, and (b) the context-aware understanding of impact has the potential to transform the way people explore, search, and make decisions in complex systems. This project establishes the foundations of big data driven Context-Sensitive Impact Discovery (CSID) in complex systems and fills an important hole in big data driven decision making in many critical application domains, including epidemic preparedness, biological pathway analysis, climate, and resilient water/energy infrastructures. Thus, it enables applications and services with significant economic and health impact. The educational impacts of this project include the mentoring of graduate and undergraduate students, and the enhancement of graduate and undergraduate Computer Science curricula at both Arizona State University (ASU) and New Mexico State University (NMSU) through the incorporation of research challenges and outcomes into existing classes. <br><br>The technical goal of this project is to establish the theoretical, algorithmic, and computational foundations of big data driven context-sensitive impact discovery in complex systems. This project develops probabilistic and tensor-based models to capture context-sensitive impact from complex systems, often modeled as graphs, and designs efficient learning algorithms that can capture both the contexts and the impact scores among entities within these different contexts. The modeling of the context sensitive impact considers dynamic nature of relevant contexts and the diverse applications. This requires addressing several major challenges, including latent contexts of impact, heterogeneous networks of entities, dynamicity of impact in varying contexts, and high computational and I/O costs of context-sensitive impact discovery. Therefore, this project designs novel scalable probabilistic and tensor-based algorithms to capture and represent context-sensitive impact. These algorithms and the novel data platforms they are deployed in are efficient and scalable in terms of off-line and on-line running times and their space requirements. To achieve necessary scalabilities, the developed platforms employ novel multi-resolution data partitioning and resource allocation strategies and the research enables massive parallelism and efficient data access through new non-volatile memory based data management techniques.
Honey bees exhibit highly complex behavior and are vital for our agriculture. Due to the rich social organization of bees, the overall performance and health of a bee colony depends both on a successful division of labor among the bees and on adequate reaction to the environment, which involves complex behavioral patterns and biological mechanisms. Much remains to be discovered on these matters as research is currently limited by our ability to effectively collect and analyze individual?s behavior at large scale, out of the laboratory. The technology developed in this project will enable biologists to study the individual behavior of thousands of bees over extended periods of time. It builds on innovative algorithms and software to analyze big data collected from colonies in the field. Study of behavioral patterns at such scale will provide unique information to advance knowledge on biological processes such as circadian rhythms that influence bee behavior in addition to playing an important role in animals and humans. The models developed will help better understand factors involved in colony collapse disorder, thus guiding future research on threats to such an important pollinator. This work will be performed through the tight collaboration of a multi-disciplinary team of researchers to combine the latest advances in computer science and data science with expertise in biology. It will provide the opportunity to train students from underrepresented minority on research at the intersection of these fields and to reach more than 600 undergraduate students, high school students, and the general public about how the Big Data approach can contribute to current scientific and ecological challenges.<br><br>The project will develop a platform for the high-throughput analysis of individual insect behaviors and gain new insights into the role of individual variations of behavior on bee colony performance. Joint video and sensor data acquisition will monitor marked individuals at multiple colonies over large continuous periods, generating the first datasets of bee activities of this kind on such a scale. Algorithms and software will be developed to take advantage of a High Performance Computing facility to perform the analysis of these massive datasets. Semi-supervised machine learning will leverage the large amount of data available to facilitate the creation of new detectors for parameters such as pollen carrying bees or fanning behavior, currently annotated manually. Predictive models and functional data analysis methods will be developed to find patterns in individual behavior based on multiple parameters and over large temporal scales. These advances are expected to help uncover mechanisms of individual variations previously unobservable. They will enable the first large scale biological study on the circadian rhythms of the bee based on the variations in behavior of individuals in multiple activities instead of reasoning on single activities or averages. Progress, datasets and software will be shared with the community on the project website (sites.google.com/a/upr.edu/bigdbee).
The field of visual recognition, which focuses on creating computer algorithms for automatically understanding photographs and videos, has made tremendous gains in the past few years. Algorithms can now recognize and localize thousands of objects with reasonable accuracy as well as identify other visual content, such as scenes and activities. For instance, there are now smart phone apps that can automatically sift through a user's photos and find all party pictures, or all pictures of cars, or all sunset photos. However, the type of "visual understanding" done by these methods is still rather superficial, exhibiting mostly rote memorization rather than true reasoning. For example, current algorithms have a hard time telling if an image is typical (e.g., car on a road) or unusual (e.g., car in the sky), or answering simple questions about a photograph, e.g., "what are the people looking at?", "what just happened?", "what might happen next?" A central problem is that current methods lack the data about the world outside of the photograph. To achieve true human-like visual understanding, computers will have to reason about the broader spatial, temporal, perceptual, and social context suggested by a given visual input. This project is using big visual data to gather large-scale deep semantic knowledge about how events, physical and social interactions, and how people perceive the world and each other. The research focuses on developing methods to capture and represent this knowledge in a way that makes it broadly applicable to a range of visual understanding tasks. This will enable novel computer algorithms that have a deeper, more human-like, understanding of the visual world and can effectively function in complex, real-world situations and environments. For example, if a robot can predict what a person might do next in a given situation, then the robot can better aid the person in their task. Broader impacts will include new publicly-available software tools and data that can be used for various visual reasoning tasks. Additionally, the project will have a multi-pronged educational component, including incorporating aspects of the research in the graduate teaching curriculum, undergraduate and K-12 outreach, as well as special mentoring and focused events for advancement of women in computer science.<br><br>The main technical focus of this project is to advance computational recognition efforts toward producing a general human-like visual understanding of images and video that can function on previously unseen data, unseen tasks and settings. The aim of this project is to develop a new large-scale knowledge base called the visual Memex that extracts and stores vast set of visual relationships between data items in a multi-graph representation, with nodes corresponding to data items and edges indicating different types of relationships. This large knowledge base will be used in a lambda-calculus-powered reasoning engine to make inferences about visual data on a global scale. Additionally, the project will test computational recognition algorithms on several visual understanding tasks designed to evaluate progress on a variety of aspects of visual understanding, including: linguistic (evaluating our understanding about imagery through language tasks such as visual question-answering), to purely visual (evaluating our understanding of spatial context through visual fill-in-the-blanks), to temporal (evaluating our temporal understanding by predicting future states), to physical (evaluating our understanding of human-object and human-scene interactions by predicting affordances). Datasets, knowledge base, and evaluation tools will be hosted on the project web site (http://www.tamaraberg.com/grants/bigdata.html).
An Academies study will set forth a vision for the emerging discipline of data science at the undergraduate level. It will emphasize core, underlying principles, intellectual content, and pedagogical issues specific to data science, including core concepts that distinguish it from neighboring disciplines. It will not consider the practicalities of creating materials, courses, or programs.<br><br>The study will develop this vision considering applications of, and careers in, data science. The focus will be at the undergraduate level, while addressing related issues at the middle school, high school and community college levels, as appropriate, and drawing upon experiences in creating Master's-level programs. It will consider opportunities created by the emergence of this new STEM field to engage underrepresented student populations and consider ways to reduce the "leakage" seen in existing STEM pathways.<br><br>Information gathering will center around two workshops, the first likely focused on principles and intellectual content, and the second likely focused on pedagogy and implications for middle and high schools and community colleges. To get material on the record quickly and spark community feedback, a rapporteur-authored workshop summary report will be issued following deliberations setting forth a vision for undergraduate education in data science.<br><br>The intellectual merit of this study is that it will articulate a vision for data science at the undergraduate level by exploring the needs in this area across multiple sectors, and drawing upon experiences to date on fashioning undergraduate programs. The study will draw on the expertise and experience of the study committee, briefings and discussion at workshops convened by the committee, and input received from the relevant communities in response to the study's interim report. The study process is expected to yield a consensus view of intellectual content and pedagogical approaches.<br><br>This project and its reports will have broader impact by providing and sharing valuable information for those designing and implementing undergraduate data science programs at colleges and universities, and by fostering the development of such programs and building data science expertise in the workforce.
This research will leverage ideas from algebraic and differential geometry to address core problems in modern high-dimensional and massive data science. The project will develop statistical methods and numerical tools, grounded in solid mathematical, statistical, and computational foundations, to extract low dimensional geometry from massive data with applications in clustering, data summarization, prediction, dimension reduction, and visualization. The solutions developed as part of this project can result in fundamental advances in practical applications across fields as diverse as biology, medicine, social sciences, communication networks, and engineering. In addition to internal validation via statistical and mathematical theory and simulation studies, the methods developed in the project will involve external validation via interdisciplinary applications. These applications include: (1) inference of population structure from genomic data; (2) document analysis via topic models; and (3) inference of subsets of putative gene networks relevant to drug resistance in melanoma.<br><br>The research is motivated by the central premise that, even though the amount of data may be massive, a compact model can represent these data. Specifically, high-dimensional and/or massive data can be reasonably approximated by a mixture of subspaces, for which sparse representations exist. A mixture of subspaces of potentially different dimensions is a flexible, rich representation of data with nice mathematical properties that can scale to large data. There are several fundamental challenges in modeling mixtures of subspaces that will be addressed in this research: 1) the subspaces will be of different dimensions, 2) both the subspace parameters and the mixing parameters need to be inferred, 3) efficient algorithms for inference are required for both high-dimensional and massive data. The central foundational impediment in all of these challenges is that the model is a stratified space (a union of manifolds), and therefore has singularities. The key insight in this research is that there exist embeddings and representations of the model space that mitigate these singularities. These ideas are implemented as concrete Bayesian, frequentist, and numerical algorithms and models to address the real world examples listed above.
Many scientific problems depend on the ability to analyze and compute on large amounts of data. This analysis often does not scale well; its effectiveness is hampered by the increasing volume, variety and rate of change (velocity) of big data. This project will design, develop and implement building blocks that enable a fundamental improvement in the ability to support data intensive analysis on a broad range of cyberinfrastructure, including that supported by NSF for the scientific community. The project will integrate features of traditional high-performance computing, such as scientific libraries, communication and resource management middleware, with the rich set of capabilities found in the commercial Big Data ecosystem. The latter includes many important software systems such as Hadoop, available from the Apache open source community. A collaboration between university teams at Arizona, Emory, Indiana (lead), Kansas, Rutgers, Virginia Tech, and Utah provides the broad expertise needed to design and successfully execute the project. The project will engage scientists and educators with annual workshops and activities at discipline-specific meetings, both to gather requirements for and feedback on its software. It will include under-represented communities with summer experiences, and will develop curriculum modules that include demonstrations built as 'Data Analytics as a Service.'<br><br>The project will design and implement a software Middleware for Data-Intensive Analytics and Science (MIDAS) that will enable scalable applications with the performance of HPC (High Performance Computing) and the rich functionality of the commodity Apache Big Data Stack. Further, this project will design and implement a set of cross-cutting high-performance data-analysis libraries; SPIDAL (Scalable Parallel Interoperable Data Analytics Library) will support new programming and execution models for data-intensive analysis in a wide range of science and engineering applications. The project addresses major data challenges in seven different communities: Biomolecular Simulations, Network and Computational Social Science, Epidemiology, Computer Vision, Spatial Geographical Information Systems, Remote Sensing for Polar Science, and Pathology Informatics. The project libraries will have the same beneficial impact on data analytics that scientific libraries such as PETSc, MPI and ScaLAPACK have had for supercomputer simulations. These libraries will be implemented to be scalable and interoperable across a range of computing systems including clouds, clusters and supercomputers.
This project develops a new set of techniques from topological data analysis (TDA) to enrich the analytical toolkit for big data problems. In particular, TDA is well-suited at picking up repetitive (even quasi-repetitive) patterns that exist at many different scale levels within a dataset. The developed techniques can be applied to many multimedia applications. For example, a system that can correctly recognize certain motion patterns from a large set of surveillance data can help to identify threatening situations as they arise. Or a methodology that takes short song snippets and extract indicators of genre similarity may eventually be used to suggest new sound patterns. <br><br>This project constructs an analytical pipeline for using TDA-ML (machine-learning) methods on features already in use in the multimedia research communities. Topological Data Analysis (TDA) is almost fifteen years old. One of its key tools is the persistence diagram (PD), a compact and robust summary of the low-dimensional multi-scale topological and geometric information in a high-dimensional point cloud. Crucially, this information is extracted without need for dimension reduction. Over the last few years, two exciting developments have enriched TDA. First, theoretical and practical work on algorithms and implementations has enabled the fast computation of large numbers of PDs. Second, a coherent methodology has developed to do machine-learning (ML) with PDs as features, with several examples showing that one can augment more-standard feature sets with PD features, and find interesting signal that was not apparent before. This research discovers compelling signals in these features which are not previously apparent, but are immediately understandable because of the choice of features. The research team investigates both video and audio features. The ML methods are used to further measure importance of the features in a given context.
This project focuses upon robust, persistent identification of data, which could greatly improve scientific discovery and reuse of datasets. Persistent identifiers of data (PIDs) enhance scientific discovery and are an important element of research data sharing. This project creates a testbed to evaluate new capabilities for persistent identifiers. The initial stage of the project will include four diverse repositories containing millions of PIDs, and the second stage will allow any NSF-eligible institution to use the testbed to evaluate their own work. The project would enhance research interoperability.<br><br>Currently, there are several persistent identifier options for data (such as Digital Object Identifiers, Handles, the Archive Resource Key, and Uniform Resource Names). The existing environment is limited by multiple solutions, weak interoperability, and procedures translating PID to data object that are inconsistent. This project provides several new capabilities:<br> - A testbed to research new capabilities and interoperability for persistent identifiers, which builds upon Indiana University cyberinfrastructure and instances on Amazon Web Services;<br> - The ability to prototype and evaluate PID types, allowing study of the difficulties and advantages of relating types to one another across a distributed system; and<br> - Approaches to mapping from PIDs to Canonical Text Services Uniform Resource Names (CTS URNs). Combining URNs with Handles should allow a precise CTS URN referencing capability, with the flexible resolution of the existing widely-used Handle System.<br>The goal is to standardize the results of PID resolution, allowing various PID services to interoperate at a higher level.
Data are often modeled as matrices; and, as a result, linear algebraic algorithms such as matrix decompositions have proven extremely successful in the analysis of many data sets. Randomized Numerical Linear Algebra (RandNLA) integrates the complementary perspectives that Theoretical Computer Science and Numerical Linear Algebra bring to matrix computations, and it is a new paradigm for the design and analysis of such algorithms and for using the resulting insight to solve important scientific and societal problems. Current RandNLA algorithms extract linear structure from data matrices. The proposed work will extend RandNLA methods to multi-linear and other non-linear structure in data matrices.<br><br>In more detail, the proposed work will investigate two important, non-linear, structural settings in order to start making progress towards using RandNLA approaches in situations where the underlying data exhibit non-linear structure: it will investigate how to design the next generation of RandNLA algorithms that can handle data that exhibit multi-linear structures captured by tensors; and it will investigate the applicability of RandNLA approaches to data that exhibit non-linear structure, as captured by non-linear dimensionality reduction techniques, local spectral methods, and related semi-supervised eigenvector tools. In addition, it will evaluate the proposed approaches on data applications where the PIs have significant expertise, such as the statistical analysis of population genetics data and astronomical data. Broader impacts of the project include graduate and undergraduate training, workshops and code development for RandNLA. For further information see the project web site at:http://www.stat.berkeley.edu/~mmahoney/projects/nsf-multilinear/
This project will facilitate and research the institutional transformation of two Indiana University-Purdue University at Indianapolis (IUPUI) departments, Biomedical Engineering and Earth Sciences. Specifically, it will (i) promote the Integration of Community-Engaged Learning and Ethical Reflection (I-CELER) in these STEM curricula, (ii) explore the organizational impact of the project on institutional change, and (iii) analyze individual changes associated with students' and educators' ethical development. This project will increase faculty's ability to integrate philosophical reflection and community engagement within their departmental curriculum through their participation in Faculty Learning Community (FLC) meetings designed to explore the I-CELER framework. In turn, this will improve their undergraduate students' learning outcomes related to ethical development. Through a research to practice cycle, investigators will promote, explore, and iterate on techniques for embedding and teaching STEM ethics in community-engaged environments. This will provide the context in which undergraduates will design potential solutions, establish empathic relationships with community members, and simultaneously reflect upon the meanings and values affecting those relationships through the philosophical lenses of John Dewey's moral philosophy and an ethic of care. By integrating community-engaged ethical instruction into departmental curricula and investigating these effects, STEM ethics education at the investigators' institution will be infused with a new vitality leading to ethically-literate, civic-minded, and empathic cohorts of undergraduate students, educators who are confident about integrating ethics and community-engaged pedagogy in their courses, and transformed departments that incorporate ethics instruction throughout their curriculum. <br><br>At a theoretical level, this project will inform a largely lacking ontological discourse about the ethical development of STEM students and faculty. Many prominent pedagogies in STEM ethics focus on ethical reasoning or sensitivity of students, but rarely have scholars investigated how the enactment of care practices and an authentic engagement with diversity influences the ethical subjectivities of STEM students and educators. By utilizing the I-CELER framework, Earth Sciences and Biomedical Engineering faculty will integrate ethical reflection and community engagement in their courses, thereby transforming the way disciplinary ethics are taught across the curricula. <br><br>The project will be researched using a convergent mixed methods design and will use multiple surveys, including the DIT2 and the Civic-Minded Graduate and Professional scales, along with data derived from ethnographic methods. By situating this design within an educational research and practice cycle, annual research insights will improve the next year's intervention, which will inform refined questions and hypotheses. In sum, this project will create a tested model for transforming the teaching and learning of STEM ethics.
The tremendous growth of information in the data-intensive world and a new wave of big data are creating a promising future for global ultra-large-scale data sharing, where widely-scattered massive data will be pooled and shared globally. A distributed data intensive information system is a critical component for realizing this future. The system will allow users to efficiently and effectively search similar data. However, the unprecedented amount of data, along with the large-scale environment and autonomous nature of participants pose high efficiency and effectiveness challenges to the development of such a system. This research will provide collaborative research opportunities for faculty, graduate and undergraduate students, as well as K-12 students in South Carolina.<br><br>A growing need persists for developing an efficient and effective information searching system, and this challenge represents one of the more formidable hurdles facing data-intensive computing. This proposal is aimed at addressing this need through the development of a distributed information system supporting efficient and effective data searching. This system achieves both high efficiency and effectiveness. Efficiency means the speed and overhead of sorting and searching date, while effectiveness means the ability to find all matching data in the system with fewer false positives and false negatives. This system translates data items to IDs, maps the data items to nodes in a distributed system and enables the similarity searching in a distributed manner. First, previous data translation methods relying on a multi-dimensional space to hash a data item to one index achieve high efficiency but suffer from low effectiveness due to the curse of dimensionality in data dimension reduction. Previous exact mapping methods that hash each keyword of a data item for data search are highly effective but inefficient. By eliminating the need of a multi-dimensional space, this system is both highly efficient and effective. Second, unlike some previous systems relying on a centralized or hierarchical structure for data searching, this system builds a distributed hash table (DHT) structure, which provides highly efficient data searching in a distributed manner. Unlike most traditional DHT-based data sharing which provides only exact matching services, this system offers similarity searching.
Data of questionable quality have led to significantly negative economic and social impacts on organizations, leading to overrun in costs, lost revenue, and decreased efficiencies. The issues on data reliability, credibility, and provenance have become even more daunting when dealing with the variety of data, especially data that are not directly collected by an organization, but from the third-party sources such as social media, data brokers, and crowdsourcing. To address such issues, this project aims to develop a Data Valuation Engine (DVE) that solves the critical problem of data reliability, credibility and provenance, and provides accountability and quality processes right from data acquisition. The DVE leverages and innovates techniques in estimation theory, data fusion and machine learning to fill a critical gap in data accountability and quality, thereby providing a transformative step in countering the ubiquitous data quality issues found in almost every application domain from business to environment to health to national security. The DVE will be integrated in the Hadoop ecosystem and will be agnostic to the data source, application or analytics, and provided as a hosted solution to the community. The user will interact with DVE by providing the data sources and relevant data necessary to solve a problem. <br><br><br>The DVE in this project will be developed in a largely application-independent manner. The key challenges to develop this engine include: (i) How to generate the data quality indication labels to score data sources and the content of data based on various factors such as reliability, credibility, uncertainty and confidence? (ii) How to integrate data from various sources with different labeled scores? (iii) How to robustly evaluate the proposed engine in a broad spectrum of applications that serve as a proxy of a variety of real-world scenarios? The research plan has been designed to synergistically address the above challenges with a robust evaluation plan. Given the generality of the proposed methods, models and system, the project will potentially impact variety of applications of science, engineering, and social science and have broad environmental, economic, and health benefits. The PIs will release open source software and applicable data. The PIs will also provide a hosted DVE platform for a broad user and participant base. This project is also providing students with greater exposure to the areas of big data analytics, cloud computing, data fusion and data mining, both in courses and research experiences.
A fundamental problem in the analysis of large datasets consists of finding one or more data items that are as similar as possible to an input query. This situation occurs, for example, when a user wants to identify a product captured in a photo. The corresponding computational problem, called Nearest Neighbor (NN) Search, has attracted a large body of research, with several algorithms having significant impact. Yet the state of the art in NN suffers from important theoretical and practical limitations. In particular, it does not provide a natural way to exploit data *structure* that is present in many applications. For example, although the identity of a depicted object does not change when one varies the lighting or the position of the object, the current NN algorithms will treat the resulting images as completely different from each other and thus will mis-identify the object. To overcome this difficulty, in this project the PIs will develop new efficient algorithms that incorporate problem structure into NN search. The PIs expect that such methods will produce substantially better results for many massive data analysis tasks.<br><br>To ensure that the work is grounded in an important application, the PIs will focus on computer vision, an area where Internet-scale datasets are having a substantial impact. NN search is vital for computer vision, and in fact many senior computer vision researchers view improved NN techniques as their top algorithmic priority. Image and video have significant structure, often spatial in nature, which algorithmic techniques such as graph cuts have been able to exploit with considerable success. The proposed work will formulate new variants of NN search that make use of additional structure, and will design efficient algorithms to solve these problems over large datasets. In particular, the PIs will investigate three structured NN problem formulations. Simultaneous nearest-neighbor queries involves multiple queries where the answers should be compatible with each other. Nearest-neighbor under transformations considers distances that are invariant to a variety of image transformations. Nearest-neighbors for subspaces involves searching a set of linear or affine subspaces for the one that comes closest to a query point. Broader impacts of the project include graduate training in both algorithms and image processing.<br><br>For further information see the project web site at: http://cs.brown.edu/~pff/SNN/
This award establishes a new Research Experiences for Undergraduates (REU) site at Illinois Institute of Technology and the University of Chicago. The site, which is named BigDataX, focuses on undergraduate research in both the theory and practice of big data computing at extreme scales. BigDataX includes a diverse group of 8 undergraduate students and 4 mentors spread out over the two institutions. Students will conduct research in the area of big data and how it will address issues related to the design, analysis, and implementation of run-time systems and storage systems to support big data applications. This work includes making extreme scale computing more tractable, touching every branch of computing in high-end computing and datacenters. These advancements will impact scientific discovery and economic development at the national level, and they will strengthen a wide range of research activities enabling efficient access, processing, storage, and sharing of valuable scientific data from many disciplines. <br><br>The primary focus of this award is to promote a data-centric view of scientific and technical computing, at the intersection of distributed systems theory and practice. The project team has identified various data-intensive applications from many disciplines such as astronomy, bioinformatics, medical imaging, that demonstrate characteristics of big-data applications. This work focuses on the design, implementation, and optimization of runtime systems to support parallel programming systems for both Many-Task Computing and High-Performance Computing. The work centers on distributed scheduling, dynamic provisioning, improved fault tolerance, and support for heterogeneous computing. To better support big data applications, the team is exploring distributed file systems and improvements to a variety of critical components such as metadata management, I/O access pattern coalescing, distributed provenance as well as exploring novel interfaces into distributed storage systems. This work involves real applications, real data, and real testbeds ranging from small clusters at IIT and UChicago, supercomputers at Argonne National Laboratory, to the Amazon AWS cloud.
This project develops a new framework that enables machine learning (ML) systems to automatically comprehend and mine massive and complex data via parallel Bayesian inference on large computer clusters. The research has a profound impact on the practice and direction of Big Learning. The developed technologies have a catalytic effect on both ML research and applications: ML scientists are able to rapidly experiment on novel, cutting-edge ML models with minimal programming effort, unhindered by the limitations of single machines. Researchers from other fields, like biology and social sciences, are able to run contemporary advanced ML methods that transcend the capabilities of simple models, yielding new scientific insights on data whose size would otherwise be daunting. Data scientists at small start-ups are able to conduct ML analytics with complex models, putting their capabilities on par with huge companies possessing dedicated engineering and infrastructure teams. Students and beginners are able to witness distributed ML in action with just a few lines of code, driving ML education to new heights. <br><br>Technically, this research focuses on scaling up and parallelizing Bayesian machine learning, which provides a powerful, elegant and theoretically justified framework for modeling a wide variety of datasets. The research team develops a suite of complementary distributed inference algorithms for hierarchical Bayesian models, which cover most commonly used Bayesian ML methods. The project focuses on combining speed and scalability with theoretical guarantees that allow us to assess the accuracy of the resulting methods, and allow practitioners to make trade-offs between speed and accuracy. Rather than focus on a few disconnected models, the project develops techniques applicable to a broad spectrum of hierarchical Bayesian models, resulting in a toolkit of building blocks that can be combined as needed for arbitrary probabilistic models - be they parametric or nonparametric, discriminative or generative. This is in contrast to much existing work on parallel inference, which tends to focus on parallelization in a specific model and cannot be easily extended. The project provides a solid algorithmic foundation for learning on Big Data with powerful models. The research contributes to democratizing advanced and large-scale ML methods for broad applications, by offering the user and developer community a library of general-purpose parallelizable algorithms for working on diverse problems using computer clusters and the cloud, bridging the gap between practical needs from data and basic research in ML.
Neuroscience is advancing by dissolving disciplinary boundaries and promoting transdisciplinary research between psychologists, cognitive neuroscientists, computer scientists, and engineers, to name a few. The success of this scientific endeavor would be enhanced by establishing software mechanisms to improve reproducibility of scientific results. This project develops a software platform that facilitates publication of publicly-accessible data and implementation of data-analysis algorithms. Both functions will be achievable within high-performance computing environments. The platform will enable publication of reproducible code, and access to national supercomputers. It will also make available reference datasets for validating results and data quality. It is expected that the open online platform will promote voluntary data submissions in exchange for access to the system. In addition, this platform will provide a reusable database of "data derivatives," which are data at different stages of preprocessing, including cortical segmentations, meshes, functional maps, brain connectivity matrices, or white-matter tracts. This open-derivatives database will allow computer scientists, mathematical scientists and engineers to use these data to develop and improve methods in their domains. Most generally, providing easy-to-use published data and methods will promote understanding the brain and allow diverse communities of scientists to use reproducible methods, and reuse the "long tail" of neuroimaging data.<br><br>The project focuses on providing seamless public access to data, computing, and reproducible algorithms, while promoting code sharing and upcycling the long tail of neuroscience data. It has three main objectives. First, to develop a platform to capture brain data, publish algorithms as reproducible applications, and perform data-intensive computing on high-performance compute clusters, as well as public clouds. Second, to develop novel algorithms for mapping brain-connectome individuality and variability. The algorithms will enhance discovery by leveraging the online platform for data intensive processing of large datasets. Third, to collate a large data set of brain data and data derivatives (processed data), such as connectome matrices, multi-parameters tractography models, cortical segmentation and functional maps. These derivatives will benefit scientists to develop algorithms for functional mapping, anatomical computing, and model optimization. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE). It has also received funding from the CISE Office of Advanced Cyberinfrastructure.
Networks of cortical neurons are clearly organized into layers and columns, but relatively little is known about how these arrangements affect cortical computations. To approach this issue, a 512 micro-electrode array will be used to stimulate and record activity from hundreds of cortical neurons. With this, the inputs and outputs of a cortical network can be experimentally controlled. A recently-developed framework for understanding neural computation known as "reservoir computing" permits the computational power of neural networks to be quantified based on knowledge of their inputs and outputs. The 512-electrode system allows input stimulation to be localized to different cortical layers or columns. Similarly, outputs can be selected by recording from different layers or columns. Thus, the contributions of layers and columns to computations, and the types of computations they perform, can be measured and compared. The results of this research are expected to increase the understanding of how the cortex attains its remarkable computational power. In addition, the results of this work are expected to inform future designs of brain-like computing circuits. To promote scientific education and outreach, an existing software package called "Simbrain" will be further developed and disseminated. This package will allow students from high school level and above to understand how cortical networks transform inputs into outputs as they perform computations.<br><br>Three specific aims will be pursued. First, the measurement of computational capacity must be based on realistic levels of random background stimulation. The high-conductance state is a well-known phenomenon in vivo resulting from constant random synaptic inputs, and is also a common feature in many (particularly reservoir computing) neural circuit models. The 512-electrode array will be used to deliver background stimulation to determine levels that will improve computational performance. Second, layer input and output locations will be studied. Using kernel quality and VC-dimension metrics, the computational power and role of each layer taken individually or as a whole will be assessed. It is possible that some layers more strongly generalize input patterns while others separate them. Thus it will be possible to dissect the computational contribution of each layer. Third, the same metrics will be applied to stimulation to one column which feeds to another. Here the computational power and role of multiple columns will be assessed, and any computational differences between columns directly stimulated by the array and columns stimulated by other columns can be observed.
A wealth of digital information is being generated daily through social networks, blogs, online communities, news sources, and mobile applications in an increasingly sensed world. Organizations and researchers recognize that tremendous value and insight can be gained by capturing this emerging data and making it available for querying and analysis. First-generation Big Data management efforts have been passive in nature -- queries, updates, and/or analysis tasks were mainly scaled to handle very large volumes of data. In contrast, this project will develop new techniques for continuously and reliably capturing Big Data collections (arising from social, mobile, Web, and sensed data sources) and will enable timely delivery of the right information to the relevant end users. In short, this project will provide a scalable foundation for moving from Big Passive Data to Big Active Data. Techniques should be developed to enable the accumulation and monitoring of petabytes of data of potential interest to millions of end users; when "interesting" new data appears, it should be delivered to end users in a time frame measured in (100's of) milliseconds. This project will build such an Active Big Data Management system and make it available as open source to the community. Students will be trained in technologies related to Big Active Data management and applications; such training is critical to addressing the information explosion that social media and the mobile Web are driving today. The general-purpose foundation for active information dissemination from Big Data will have broader impacts in areas such as public safety and public health. <br><br>There are many challenges involved in building a foundation for Big Active Data. On the "data in" side, these include resource management in very large scale, LSM-based storage systems and the provision of a highly available, elastic facility for fast data ingestion. On the "data processing" side, challenges include the parallel evaluation of a large number of declarative data subscriptions over multiple) highly partitioned data sets. Amplifying this challenge is a need to efficiently support spatial, temporal, and similarity predicates in data subscriptions. Big Data also makes result ranking and diversification techniques critical in order for large result sets to be manageable. On the "data out" side, challenges include the reliable and timely dissemination of data of interest to a sometimes-connected subscriber base of unprecedented scale. As a software base, this project will be jump-started by using AsterixDB(http://asterixdb.ics.uci.edu/), an open-source Big Data Management System that supports the scalable storage, searching, and analysis of mass quantities of semi-structured data. <br><br>For further information see the project web sites at https://www.ics.uci.edu/BigActiveData and http://www.cs.ucr.edu/~tsotras/BigActiveData
Abstract<br><br>Research in big data involves analyzing growing data sets with huge numbers of samples, very high-dimensional feature vectors, and complex and diverse structures. The ever-growing volume and complexity of these data sets make many traditional techniques inadequate to extract knowledge from them. An emerging area, known as sparse learning, has achieved great success in learning from big data by identifying a small set of explanatory features and/or samples. Typical examples include selecting features that are most indicative of users? preferences for recommendation systems, identifying brain regions that are predictive of neurological disorders based on imaging data, and extracting semantic information from raw images for object recognition. However, training sparse learning models can be computationally prohibitive due to the sparsity-inducing regularization, which is non-smooth and can be highly complex when incorporating complex structures. This project aims at developing algorithms and tools to significantly accelerate the training process of sparse learning models for big data applications. The key idea is to efficiently identify redundant features and/or samples, which can be removed from the training phase without losing useful information of interests. Success in these unique techniques is expected to dramatically scaling up sparse learning for big data by orders of magnitude in terms of both time and space. The PIs plan to integrate the big data reduction tools developed in this project into their education and outreach activities, including development of new courses and integration of project components into existing courses. The PIs will make special efforts to recruit female and underrepresented students to this project.<br><br>The major technical innovations of this project include the following components: (1) the PIs will develop efficient feature reduction methods for the generic scenario where the structures of both input and output can be represented by directed acyclic graphs; the proposed formulations include many existing approaches as special cases; (2) the PIs will develop efficient methods to reduce the numbers of features and samples simultaneously under a unified formulation, which can also incorporate various structures; (3) the PIs will develop efficient methods to discard irrelevant data subspaces to accelerate the process of uncovering low-rank structures commonly seen in big data. All the proposed data reduction methods are exact, i.e., the models learned on the reduced data sets are identical to the ones learned on the full data sets. This project heavily relies on optimization theory, especially on sensitivity analysis and convex geometry. The outcome of this project includes a unified approach to accelerate sparse learning and provide a systematic framework for developing efficient and exact data reduction methods. The systematic study and in-depth exploration of redundant data identification is expected to deepen the understanding of sparse learning techniques and dramatically enhance their applications in big data analytics.
Detailed three-dimensional models of urban environments provide critical information for many applications, including emergency response preparation, security analysis, urban planning, and augmented-reality maps. For example, if 3D models of complete cities were publicly available with detailed labels for all semantic objects (e.g., buildings, fire hydrants, fire escapes, doors, windows, trees, etc.), then fire fighters, police forces, and other emergency response teams could use them to make plans for rescue operations, taking into account possible access points, lines of sight, and risks to the neighborhood. Or, if the 3D model contained labeled representations of stop lights, traffic signs, parking spaces, store locations, mailboxes, and ATMs, then augmented reality displays could help people navigate their daily lives.<br><br>The research goal of this project is to develop algorithms to build detailed, labeled 3D models from currently available data. Several companies (e.g., Google, Nokia, Microsoft, etc.) are currently collecting photographic imagery and LIDAR data with scanners mounted on cars driving up and down streets of cities throughout the world. This data contains a vast amount of information about our world, but in a very primitive form: pixels and points. The PI is developing algorithms to analyze this raw data to build semantically labeled 3D models: 1) new methods for discovering correspondence relationships between heterogeneous data types, focusing on LIDAR, images, and 3D polygonal models found in online repositories, 2) new ways to infer surface geometry, segmentations, and labels simultaneously based on a model learned from examples, 3) new interactive systems to allow users to visualize and guide the algorithms as they operate by incorporating user input into incrementally updated solutions, and 4) data management algorithms for multiresolution storage, compression, and retrieval of massive scanned 3D data sets.<br><br>The broader goals of the project include educational programs, industrial collaboration, free distribution of software and data sets, and outreach activities. Besides the published research results, the PI will disseminate 3D models of major cities that can be used directly in applications developed by other people. He will also distribute code, benchmark data sets, and statistical models that could benefit researchers in a variety of disciplines. This proposed work is integrated with educational programs, including interdisciplinary workshops and courses at the graduate, undergraduate, and professional levels, and diversity enhancement programs that promote opportunities for disadvantaged groups
Association analysis is a fundamental problem in Big Data analytics. Emerging applications require computationally efficient association models and scalable association mining techniques to find regularities of graph data. Conventional association analysis for transactional data is hard or infeasible to be adapted to effectively support the next generation of graph data analytics, especially under limited computing resources. In this project, the PIs develop models, algorithms and tools to support association analysis over large-scale graph data under resource constraints. The project formulates new variants of the conventional association model that are enhanced by advanced capability of graph queries. Both exact and approximate querying and mining paradigms are explored to support effective association analysis over multi-source, large-scale, and fast-changing graph data. The PIs instantiate the generic framework to two practical association analysis scenarios, notably, a) multi-graph association analysis, and b) association detection over graph streams. The project develops a package of distributed and stream association mining techniques supported by the proposed generic model and algorithms.<br><br>The enhanced model and algorithms enable scalable association analysis in a wide range of massive data applications. The principles learned from this project can be applied to big data analytics and system design in general. The study of new association analysis framework has immediate applications in emerging areas, including data quality, affinity marketing, and network security. Application collaborators of the project include Pacific Northwest National Laboratory, LogicMonitor, and Facebook. Broader impacts of the project also include research training and education of students including women and minorities, and design of new curricula and education tools that target both CS and non-CS students.
Communities are adversely affected by social harm events such as crime, traffic crashes, medical emergencies, and drug usages. This proposal aims to develop algorithms and software systems for the collection, analysis, and dynamic prediction of social harm events to facilitate appropriate government interventions to improve the quality of life in communities. The project has a significant community engagement component and software developed through the research will be used by the Indianapolis Metropolitan Police Department (IMPD), Indianapolis Emergency Medical Services (EMS), National Alliance of Mental Illness, the Indiana prosecutor's office, and individual citizens for sharing of social harm analytics and collaboration in social harm intervention. This objective will be achieved by: i) creating software systems for cross-agency social harm data integration, ii) developing mathematical models for capturing social harm event dynamics along with public trust and grievance towards police, and iii) conducting a field trial of the developed software system in Indianapolis. The methods developed in the project will also be applicable to other smart and connected communities across the country and could be used for data analytics integration and allocation of resources across government departments. Graduate students from both social science and computing disciplines will be trained in interdisciplinary research methods that span criminal justice, statistics, and computer science. Research interests in the domain of algorithms for heterogeneous data in smart cities will be encouraged through a workshop hosted by the investigators at Indiana University-Purdue University Indianapolis (IUPUI). <br><br>Social harm data resides within a disconnected set of community databases and current methodologies for modeling social harm neglect space-time dynamics altogether or focus on a small related subset of event types. Furthermore, interventions are designated in spatial locations for several weeks or months at a time, failing to account for the daily changes in risk of social harm events where crime, traffic crashes, and medical emergencies cluster in different times and locations in communities. Current policing interventions that focus on spatial risk (i.e., hotspots) are often too narrow and seek only to optimize crime reductions. In order to address some of these limitations, this project will develop: i) software systems for heterogeneous social harm data integration, ii) new marked point processes for modeling heterogeneous social harm event dynamics including trust and grievances towards police, iii) optimal control methods for space-time point processes that are lacking in current point process research, and iv) near real time software-human systems for deploying hourly interventions to dynamically changing risk. During phases one and two, the project team will work collaboratively with IMPD's community policing unit and leverage this unit's relationships with local neighborhood watch, faith-based, juvenile diversion, and volunteer groups that are predominantly comprised of minority community members serving largely minority neighborhoods. This collaboration will facilitate broad community buy-in for phase three and enable communication with and recruitment of community groups disproportionately exposed to social harm risk. The last phase of the project will include a randomized controlled trial of heterogeneous data driven policing in Indianapolis in collaboration with IMPD, Indianapolis EMS, Indianapolis Mayor's Office, National Alliance of Mental Illness, Marion County Prosecutor's Office, the Indy Public Safety Foundation, and the general public who will be encouraged to download a version of the application through a press release prior to the trial launch. In the trial, the extent to which police in partnership with community stakeholders can respond to dynamic, heterogeneous social harm hotspots will be investigated and the impact across four types of social harm (crime, traffic crashes, EMS calls for service, and community trust in police within high risk communities) will be measured.
In today's digital world, huge amounts of data, i.e., big data, can be found in almost every aspect of scientific research and human activity. These data need to be managed effectively for reliable prediction and inference to improve decision making. Statistical learning is an emergent scientific discipline wherein mathematical modeling, computational algorithms, and statistical analysis are jointly employed to address these challenging data management problems. Invariably, quantitative criteria need to be introduced for the overall learning process in order to gauge the quality of the solutions obtained. This research focuses on two important criteria: data fitness and sparsity representation of the underlying learning model. Potential applications of the results can be found in computational statistics, compressed sensing, imaging, machine learning, bio-informatics, portfolio selection, and decision making under uncertainty, among many areas involving big data.<br><br>Till now, convex optimization has been the dominant methodology for statistical learning in which the two criteria employed are expressed by convex functions either to be optimized and/or set as constraints of the variables being sought. Recently, non-convex functions of the difference-of-convex (DC) type and the difference-of-convex algorithm (DCA) have been shown to yield superior results in many contexts and serve as the motivation for this project. The goal is to develop a solid foundation and a unified framework to address many fundamental issues in big data problems in which non-convexity and non-differentiability are present in the optimization problems to be solved. These two non-standard features in computational statistical learning are challenging and their rigorous treatment requires the fusion of expertise from different domains of mathematical sciences. Technical issues to be investigated will cover the optimality, sparsity, and statistical properties of computable solutions to the non-convex, non-smooth optimization problems arising from statistical learning and its many applications. Novel algorithms will be developed and tested first on synthetic data sets for preliminary experimentation and then on publicly available data sets for realism; comparisons will be made among different formulations of the learning problems.
Sensor data of diverse types and large volumes need to be combined with the current standard SQL databases, which provide context and metadata for the sensor data. The combination will lead to a new generation of analytics in a number of areas, such as smart buildings that are based on building and environmental data collected by sensors. The project argues that this new generation of analytics must be based on the same healthy database technology cornerstones that the prior (non-sensor) business intelligence platforms were based on: Declarative queries, automatic optimization, efficient storage representations and multiple layers of abstraction lead to high productivity for the developer and the analyst. Such productivity is currently absent from sensor data analytics because database technology and sensor data processing currently do not mix well. Productivity is especially low in cases involving (a) many types of sensor data, (b) combinations of sensor data with conventional database data that provide context and (c) many types of analyses. Besides low productivity, the current (limited) state of the art poses very high expertise requirements on the analysts: They must be simultaneously experts in signal processing, statistics and big data management. The project will deliver a database system for sensor data, where the analyst can rapidly develop declarative queries that are automatically optimized. By doing so, the project will deliver the envisioned productivity gains and will lower the technical sophistication bar needed for acting in the space, therefore enabling many scientists and domain specialists to engage in analytics.<br><br>This project argues that at the core of the failure of SQL databases in the management and analytics of sensor spatiotemporal data is the lack of a critical abstraction, which is the real world models, which capture the stochastic processes that generate the measurements. The proposed Plato database system will bring the real world model concept into SQL databases by using models (spatiotemporal continuous functions) as first class citizens. The delivery of Plato requires innovative solutions to multiple problems: The project will design and <br>implement (a) a model-aware data model and respective query language features that allow seamless combination of conventional SQL querying with statistical signal processing, (b) learning algorithms that learn the model components of reduced-noise, additive model representations, which are naturally compressions of the original, (c) query processing algorithms that operate directly on the compressed representations and utilize the the relatively few bits necessary for the required confidence of the analytics, and (d) semiautomated algorithms that further compress the model representations by considering the dependencies (mutual entropy) between the models. Finally, the project will exercise the resulting system on large scale statistical sensor data processing cases, such as the ones presented by the UCSD Energy Dashboard. The exercise will measure the lines-of-code as well as the runtime efficiency of the analyses.<br><br>For further information see the project web site at http://www.db.ucsd.edu/NSF14Plato
Big data today is stored in a distributed fashion across many different machines or data sources. This poses new algorithmic and system challenges to performing efficient analysis on the full data set. To address these difficulties, the PIs are building the MIDDLE (Mergeable and Interactive Distributed Data LayEr) Summarization System and deploying it on large real-world datasets. The MIDDLE system builds and maintains a special class of summaries that can be efficiently constructed and updated while still allowing fine-grained analysis on the heavy tail. Mergeable summaries can represent any data set with a guaranteed tradeoff between size and accuracy, and any two such summaries can be merged to create a new summary with the same size-accuracy tradeoff.<br><br>Interactive summaries can be quickly adapted to a specified query range of data while maintaining the same size-accuracy tradeoffs relative to the data in that range. This allows accurate efficient analysis to zero-in on small subsets of big data.<br>The MIDDLE system enables different big data users to develop a wide spectrum of efficient and scalable data analytic tasks through the use of data summaries. The MIDDLE system is being evaluated and refined with the aid of domain experts. Since the prospect of data-summary-based analytics becoming a part of standard techniques in processing big data is tantalizing, this research generates broader impacts on the nation's government agencies, research institutes, education system, and high-tech industries. Our broad impacts also extend to academia and community outreach, through the design and development big data curriculum and education, and the involvement of general public in understanding and using big data through concise summaries.
The six-year higher-education graduation rate has been around 59% for over 15 years; less than half of college graduates finish within 4 years. This has high human, economic and societal costs. The National Research Council has identified a critical need to develop innovative approaches to improve student retention, graduation, and workforce-preparedness. The objective of this project is to develop new computational methods to analyze large and diverse types of education and learning data to help (a) discover successful academic pathways for students; (b) improve pedagogy for instructors; and (c) enhance student persistence and retention for institutions. The project outcomes are designed to help students select courses that fit their needs, capabilities, and learning styles, and are likely to lead to (faster) graduation; help instructors to better meet student needs; and give advisors and institutions the analytics needed to improve retention and persistence. <br><br>The proposed research will produce new dynamical system modeling, collaborative filtering, and multi-task learning methods. Modeling the evolution of a student's knowledge using a dynamical state-space system is a key innovation; the proposed research will develop novel collaborative system identification and collaborative Kalman filtering techniques for grade prediction. Technical innovations include supervised learning approaches for evolving datasets, such as linear and non-linear multi-task learning and collaborative multi-regression models with controlled grouping of the latent variables. These innovations will coalesce into three pilot applications: DegreePlanner for students, CourseInsights for instructors, and StudentWatch for academic advisors.
A fundamental problem in the analysis of large datasets consists of finding one or more data items that are as similar as possible to an input query. This situation occurs, for example, when a user wants to identify a product captured in a photo. The corresponding computational problem, called Nearest Neighbor (NN) Search, has attracted a large body of research, with several algorithms having significant impact. Yet the state of the art in NN suffers from important theoretical and practical limitations. In particular, it does not provide a natural way to exploit data *structure* that is present in many applications. For example, although the identity of a depicted object does not change when one varies the lighting or the position of the object, the current NN algorithms will treat the resulting images as completely different from each other and thus will mis-identify the object. To overcome this difficulty, in this project the PIs will develop new efficient algorithms that incorporate problem structure into NN search. The PIs expect that such methods will produce substantially better results for many massive data analysis tasks.<br><br>To ensure that the work is grounded in an important application, the PIs will focus on computer vision, an area where Internet-scale datasets are having a substantial impact. NN search is vital for computer vision, and in fact many senior computer vision researchers view improved NN techniques as their top algorithmic priority. Image and video have significant structure, often spatial in nature, which algorithmic techniques such as graph cuts have been able to exploit with considerable success. The proposed work will formulate new variants of NN search that make use of additional structure, and will design efficient algorithms to solve these problems over large datasets. In particular, the PIs will investigate three structured NN problem formulations. Simultaneous nearest-neighbor queries involves multiple queries where the answers should be compatible with each other. Nearest-neighbor under transformations considers distances that are invariant to a variety of image transformations. Nearest-neighbors for subspaces involves searching a set of linear or affine subspaces for the one that comes closest to a query point. Broader impacts of the project include graduate training in both algorithms and image processing.<br><br>For further information see the project web site at: http://cs.brown.edu/~pff/SNN/
Interest in Data Science has been increasing at a breathtaking pace, as a result of the vast amounts of data that are being generated and collected across all sectors of society and economy. Many Data Science Meetup groups have been created across the country, each with an active local membership and a vibrant set of community-driven activities. The objective of this workshop is to connect the rapidly growing number of participants in these Data Science Meetup groups, in order to take the best advantage of this wealth of data science talent across the nation in addressing some of the national priority goals, including the goal of creating a well-educated Data Science workforce.<br><br>This workshop will result in data science meetup groups collaborating with local governments and non-profits to advance their impact and create data science solutions to national priority issues, including socioeconomic issues. The workshop will allow participants to network with their peers, including meetup organizers, nonprofits, government agencies, in order to create a national data science network. The meeting organizers have an established track record and extensive experience working with governments and non-profits on the use of data science techniques to address social issues, and have created several open source systems to address education, health, energy, and economic development problems.
<br>The recent financial crisis has accentuated the need for effective monitoring, oversight and regulation of financial markets and institutions. Complex market structures involving intricate interconnected relationships among financial institutions can help propagate and amplify shocks and hence also foster systemic risk. This project develops an integrative framework, based on accounting principles, that leverages a wide array of diverse quantitative financial datastreams, complemented by metadata and market announcements for the purpose of identifying and predicting market participants that could endanger the overall financial system.<br><br>The proposed research builds upon modern statistics and computer science works, as well as recent financial and economic ideas aimed at assessing threats to financial stability and uncovering the complexity of financial systems in different market conditions. It will result in both new methods for complex Big Data and empirical results that can advance the state-of-the-art in financial research, as well as tools that support and enhance financial policymaking and decision-making. Key tasks of the project include: (1) Develop a rigorous accounting framework to integrate multiple financial and econometric data streams from many platforms and technologies. (2) Develop and customize a range of new network models and analysis tools for use with multiple financial data streams. An important idea will be to extend network and econometric tools in order to compare the structural evolution of different types of networks in response to external events and policy changes.<br>
Plankton play an essential role in the global ecosystem, forming the base of marine food webs, linking the atmosphere to the deep ocean, and regulating a myriad of ecologically and climatologically important processes. Despite their importance, however, the technology to assess abundances and distributions of plankton has been limited. Changes in abundances of individual species are particularly poorly resolved; this includes the harmful algal blooms that have profound economic, societal, and ecosystem effects in many coastal systems. Traditional tools such as nets and bottles can destroy fragile organisms during sampling. Underwater microscopes, on the other hand, allow observation of the organisms undisturbed, and in their natural setting. New underwater microscopes are generating many thousands of high-resolution images of individual plankton each day. Before these images can be used for scientific analyses, the imaged organisms must be identified and classified. However, the vast number of images generated by such microscopes has led to a serious bottleneck: identification and classification of the images takes an impossibly long time for individuals to accomplish. Fortunately, advances in computer vision science have shown great promise in accurately performing such classification tasks. The main goal of this award is to explore and develop computer vision approaches for plankton image classification. A team of instrumentation specialists, an ocean ecologist, and a computer scientist, including two graduate students and one post doctoral student, will formulate, implement, and test methods to advance the goal of efficient and accurate automated plankton image classification. The advances made in this award will enable both improved classification algorithms in computer science, and vast new data streams for plankton ecology.<br><br>Plankton form the base of marine food webs, link the atmosphere to the deep ocean, and regulate global biogeochemical cycles. Plankton are often studied either through bulk measures, or by manual enumeration of individual taxa. Novel underwater microscope systems such as the Scripps Plankton Camera System (SPCS) are generating tens of thousands of images of individual plankton daily. However, without accurate annotation of the images, the potential science is limited. This project will explore the use of many-layer, deep Convolutional Neural Nets (CNN) as automated computer recognition methods; these techniques hold promise for classifying the nearly one trillion underwater microscope images that have been collected by a variety of research groups around the globe. The primary source of images will be a pair of microscopes that have been operating for 2 years from the Scripps Inst. of Oceanography's pier, yielding 200 million regions of interest. The project will build a large data base of training sets using a novel approach: a bench-top imaging system that is capable of rapidly producing thousands of annotated images showing organisms in all orientations and configurations identical to that in the field. Based on these automatically collected training sets, and hand annotation of in situ images from experts, a deep (many layer) CNN will embed taxonomic and attribute constraints, and will be used to classify the organisms imaged. With success, this massive, growing, taxonomically classified dataset will enable unprecedented, transformative, taxon-specific explorations of the dynamics of the planktonic ecosystem on time scales from hours to decades.
In the era of big data, across numerous application domains, large amounts of data are being collected, integrated, and analyzed to support rich application semantics and enable data-driven science discovery. While having the access to more data leads to more opportunities for analytics, mining, learning, and knowledge discovery, at the same time, it also increases the chance of security breach and privacy infringement. In essence, adversaries are able to gain more insights into an application or system, and equipped with more background knowledge, when more (relevant) data are made available to him/her. This award supports the organization of a workshop to bring together researchers and practitioners from different sub-fields of data science and security/privacy to discuss the vision, challenges, and opportunities for the protection of security and privacy in big data management and mining.<br><br>The agenda of the workshop has broader impacts on the scientific communities and the society at large by identifying the challenges for data science research related to security and privacy, and foster the vision for secure and privacy-aware data management and mining through an interdisciplinary data science approach. More specifically, the workshop increases the interactions among several related communities, including cryptography, database and data management, mining and learning, systems, social and behavior sciences, and applied security.
Data-driven modeling has moved beyond the realm of consumer predictions and recommendations into areas of policy and planning that have a profound impact on our daily lives. The tools of data analysis are being harnessed to predict crime, select candidates for jobs, identify security threats, determine credit risk, and even decide treatment plans and interventions for patients. Automated learning and mining tools can crunch incredible amounts and variety of data in order to detect patterns and make predictions. As is rapidly becoming clear, these tools can also introduce discriminatory behavior and amplify biases in the systems they are trained on. In this project, the PIs will study the problems of discrimination and bias in algorithmic decision-making. By studying all aspects of the data pipeline (from data preparation to learning, evaluation, and feedback), they will develop tools for analyzing, auditing, and designing automated decision-making systems that will be fair, accountable, and transparent. As specific goals to broaden the impact of this research, the PIs will develop a course curriculum to educate the next generation of data scientists on the ethical, legal, and societal implications of algorithmic decision-making, with the intent that they will then take this understanding into their jobs as they enter the workforce. Initial efforts by the PIs have attracted students from underrepresented groups in computer science, and they will continue these efforts. The PIs will also explore the legal and policy ramifications of this research, and develop best practice guidelines for the use of their tools by policy makers, lawyers, journalists, and other practitioners.<br><br>The PIs will explore the technical subject of this project in three ways. Firstly, they will develop a sound theoretical framework for reasoning about algorithmic fairness. This framework carefully separates mechanisms, beliefs, and assumptions in order to make explicit implicitly held assumptions about the nature of fairness in learning. Secondly, by examining the entire pipeline of tasks associated with learning, they will identify hitherto unexplored areas where bias may be unintentionally introduced into learning as well as novel problems associated with ensuring fairness. These include the initial stages of data preparation, various kinds of fairness-aware learning, and evaluation. They will also investigate the problem of feedback: when actions based on a biased learned model might cause a feedback loop that changes reality and leads to more bias.
Association analysis is a fundamental problem in Big Data analytics. Emerging applications require computationally efficient association models and scalable association mining techniques to find regularities of graph data. Conventional association analysis for transactional data is hard or infeasible to be adapted to effectively support the next generation of graph data analytics, especially under limited computing resources. In this project, the PIs develop models, algorithms and tools to support association analysis over large-scale graph data under resource constraints. The project formulates new variants of the conventional association model that are enhanced by advanced capability of graph queries. Both exact and approximate querying and mining paradigms are explored to support effective association analysis over multi-source, large-scale, and fast-changing graph data. The PIs instantiate the generic framework to two practical association analysis scenarios, notably, a) multi-graph association analysis, and b) association detection over graph streams. The project develops a package of distributed and stream association mining techniques supported by the proposed generic model and algorithms.<br><br>The enhanced model and algorithms enable scalable association analysis in a wide range of massive data applications. The principles learned from this project can be applied to big data analytics and system design in general. The study of new association analysis framework has immediate applications in emerging areas, including data quality, affinity marketing, and network security. Application collaborators of the project include Pacific Northwest National Laboratory, LogicMonitor, and Facebook. Broader impacts of the project also include research training and education of students including women and minorities, and design of new curricula and education tools that target both CS and non-CS students.
Novel neuroscience tools and techniques are necessary to enable insight into the building blocks of neural circuits, the interactions between these circuits that underpin the functions of the human brain, and modulation of these circuits that affect our behavior. To leverage rapid technological development in sensing, imaging, and data analysis new ground breaking advances in neuroscience are necessary to facilitate knowledge discovery using data science methods. To address this societal grand challenge, the project will foster new interdisciplinary collaborations across computing, biological, mathematical, and behavioral science disciplines together with partnerships in academia, industry, and government at multiple levels. The Big Data Neuroscience Spoke titled Midwest: Advanced Computational Neuroscience Network (ACNN) is strongly aligned with the national priority area of neuroscience and brings together a diverse set of committed regional partners to enable the Midwest region to realize the promise of Big Data for neuroscience. The ACNN Spoke will build broad consensus on the core requirements, infrastructure, and components needed to develop a new generation of sustainable interdisciplinary Neuroscience Big Data research. ACNN will leverage the strengths and resources in the Midwest region to increase innovation and collaboration for the understanding of the structure, physiology, and function of the human brain through partnerships and services in education, tools, and best practices. <br><br>The ACNN will design, pilot and support powerful neuroscientific computational resources for high-throughput, collaborative, and service-oriented data aggregation, processing and open-reproducible science. The ACNN Spoke framework will address three specific problems related to neuroscience Big Data: (1) data capture, organization, and management involving multiple centers and research groups, (2) quality assurance, preprocessing and analysis that incorporates contextual metadata, and (3) data communication to software and hardware computational resources that can scale with the volume, velocity, and variety of neuroscience datasets. The ACNN will build a sustainable ecosystem of neuroscience community partners in both academia and industry using existing technologies for collaboration and virtual meeting together with face-to-face group meetings. The planned activities of the ACNN Spoke will also allow the Midwest Big Data Hub to disseminate additional Big Data technologies resources to the neuroscience community, including access to supercomputing facilities, best practices, and platforms.<br><br>This award received co-funding from CISE Divisions of Advanced Cyberinfrastructure (ACI) and Information and Intelligent Systems (IIS).
Increasing volume and variety of data opens opportunities, but much of these data are not carefully curated, leading to uncertainty. Data analysis techniques are needed that accurately characterize uncertainty. This project develops principled approaches to managing uncertainty, particularly through clustering and subsetting data, and then combining results from analysis of the subsets. Dividing data into smaller problems promises scalability to Big Data, while the ability to combine results in a theoretically sound manner manages the uncertainty inherent in large data collections.<br><br>The key idea is that Wasserstein barycenter of subset posteriors can be used to efficiently perform posterior approximation. The project extends the theoretical understanding of Wasserstein barycenters, enhancing ability to model uncertainty. New mathematical tools are being developed to bound the accuracy of approximations in terms of the problem's size and nature, and computational time. The algorithms are evaluated on a rich variety of massive data sets, ranging from large-scale networks to biomedical data sets collecting huge numbers of biomarkers. In addition, the project provides interdisciplinary training to young talent in big data analytics to improve competitiveness of the workforce and increase the cohort of data science researchers.
In today's digital world, huge amounts of data, i.e., big data, can be found in almost every aspect of scientific research and human activity. These data need to be managed effectively for reliable prediction and inference to improve decision making. Statistical learning is an emergent scientific discipline wherein mathematical modeling, computational algorithms, and statistical analysis are jointly employed to address these challenging data management problems. Invariably, quantitative criteria need to be introduced for the overall learning process in order to gauge the quality of the solutions obtained. This research focuses on two important criteria: data fitness and sparsity representation of the underlying learning model. Potential applications of the results can be found in computational statistics, compressed sensing, imaging, machine learning, bio-informatics, portfolio selection, and decision making under uncertainty, among many areas involving big data.<br><br>Till now, convex optimization has been the dominant methodology for statistical learning in which the two criteria employed are expressed by convex functions either to be optimized and/or set as constraints of the variables being sought. Recently, non-convex functions of the difference-of-convex (DC) type and the difference-of-convex algorithm (DCA) have been shown to yield superior results in many contexts and serve as the motivation for this project. The goal is to develop a solid foundation and a unified framework to address many fundamental issues in big data problems in which non-convexity and non-differentiability are present in the optimization problems to be solved. These two non-standard features in computational statistical learning are challenging and their rigorous treatment requires the fusion of expertise from different domains of mathematical sciences. Technical issues to be investigated will cover the optimality, sparsity, and statistical properties of computable solutions to the non-convex, non-smooth optimization problems arising from statistical learning and its many applications. Novel algorithms will be developed and tested first on synthetic data sets for preliminary experimentation and then on publicly available data sets for realism; comparisons will be made among different formulations of the learning problems.
The project develops and hosts hands-on advanced technology workshops for campus network engineering staff in the US. Each CC-OIN workshop is being hosted in partnership with regional networks and tailored to their region's needs. Participants gain the practical understanding they need to support data-intensive science projects on their campuses, and learn how to improve science performance using state-of-the-art network technology.<br><br>CC-OIN builds on past work with similar workshops and is open to participants around the country and abroad. Over the previous three years, collaborators have shared detailed technical content on the Science DMZ paradigm, the perfSONAR network performance measurement system, and the use of open Software Defined Networking (SDN) technologies. The project also broadens and updates content related to emerging areas of need for supporting science on campuses. New topics include advanced cybersecurity, new SDN methods, orchestration of networks with scientific cloud applications, and an SDN-based Science DMZ for increased performance and security. Finally, the project explores ways to broaden the reach of the workshops through alternative delivery methods like videos and cloud-based, hands-on exercises.<br><br>The CC-OIN project advances the expertise large and small campuses in every region of the country needs, supports technical staff to become regional resources supporting science, and brings each region's community together to collaborate on improving network capabilities for better science outcomes.
Important problems in the big-data era involve predictions based on heterogeneous sources of information and the dependency structures in data. In recommendation systems, for example, predictions need to be made not only based on observed user ratings over items (movies, books, music, shopping products, etc.), but also based on information such as demographical data of users and textual descriptions of items. In event detection from textual data (news stories, tweets, maintenance reports, legal documents, etc.), joint inference must be based on who (agents), what (event types or topics), where (locations) and when (dates), and also based on the connections among agents (in social networks), topics (in an event-type ontology), locations (in a map) and temporal co-occurrences. The fundamental research questions therefore include: (1) how to develop a unified optimization framework for predictions based on heterogeneous information and dependency structures in various kinds of tasks; (2) how to make the inference computationally tractable when the combined space of model parameters is extremely large; and (3) how to significantly enhance the prediction power of the system by leveraging massively available unlabeled data in addition to human-annotated training data which are often sparse.<br><br>This project will address the three challenges via the following four approaches.<br><br>(1) A unified representation of heterogeneous information sources using product graphs: This framework aims to represent heterogeneous sources of data and intra-source dependencies, such as social connections among users, semantic similarities among items, contextual correlations among keywords, topical similarities among documents, hierarchical relations among topic labels, and so on. Each data source will be represented using a graph, and the individual graphs of multiple sources will be combined into a product graph where each node corresponds to a tuple of nodes in the individual graphs, and each link aggregates the links in the individual graphs. <br><br>(2) Transductive learning over graph products: This project plans to reduce the inference problems in a broad range of prediction tasks to semi-supervised transductive learning problems over the product graphs mentioned above. The training data in each task (of classification, regression or link prediction) will be represented as a subset of labeled (or scored) nodes in the product graph, and the labels (or scores) of those nodes will be propagated over the links in the product graph until convergence. This project will study various kinds of graph transductions theoretically and empirically.<br><br>(3) Large-scale optimization algorithms: The induced product graphs are typically extremely large. To address the computational bottlenecks, this project will develop new scalable algorithms based on theoretical properties and computational characteristics of spectral graph products, including adapted versions of rank-reduced matrix factorization, aggressive basis pruning, and sampling-based low-rank approximation.<br><br>(4) Thorough evaluations in multiple important applications: The proposed new approach will be evaluated on benchmark data collections for context-aware collaborative filtering, semi-structured event detection and tracking, and expert finding via multi-source social network analysis.<br><br>The proposed work, if successful, will offer principled solutions for enhancing the prediction power of systems in a broad range of tasks, whenever recommendation, classification and regression are involved. Technical impacts of the proposed work are expected in multiple research fields. For further information see the project web site at: http://nyc.lti.cs.cmu.edu/gp-trans/index.html
The Focused Technical Workshop on Improving Data Mobility & Management for International Climate Science (FTW for Climate Science) will enable an active dialogue between climate scientists, climate data managers, and cyberinfrastructure engineers with the goal of setting longer-term relationship building in motion. The workshop also hopes to provide climate researchers with information about a set of broad, concrete, and immediately useful tools and resources for improved data transport and management. The FTW on Climate Science is sponsored by ESnet, Internet2, Indiana University (IU), National Center for Atmospheric Research (NCAR), and National Oceanic and Atmospheric Administration (NOAA) and will be hosted at the NOAA Boulder Labs, in Boulder, Colorado, in July 2014.<br><br>The workshop will bring together experts to discuss recent research technology advances and research techniques in data management for climate science. The format is being designed to encourage lively, interactive discussions with the goal of developing a set of tangible next steps for supporting this data-intensive science community. Participation key stakeholders from multiple agencies and programs provides the climate science community with the knowledge, tools, and partners necessary to improve data transfer performance as data scale continues to increase. This has the potential to have broad reaching effects in a science area that is critical to society. By increasing performance to match increased data scale, scientific productivity for this community is expected to increase. This workshop will leverage existing NSF supported projects, including work with EarthCube.
This project develops a new framework that enables machine learning (ML) systems to automatically comprehend and mine massive and complex data via parallel Bayesian inference on large computer clusters. The research has a profound impact on the practice and direction of Big Learning. The developed technologies have a catalytic effect on both ML research and applications: ML scientists are able to rapidly experiment on novel, cutting-edge ML models with minimal programming effort, unhindered by the limitations of single machines. Researchers from other fields, like biology and social sciences, are able to run contemporary advanced ML methods that transcend the capabilities of simple models, yielding new scientific insights on data whose size would otherwise be daunting. Data scientists at small start-ups are able to conduct ML analytics with complex models, putting their capabilities on par with huge companies possessing dedicated engineering and infrastructure teams. Students and beginners are able to witness distributed ML in action with just a few lines of code, driving ML education to new heights. <br><br>Technically, this research focuses on scaling up and parallelizing Bayesian machine learning, which provides a powerful, elegant and theoretically justified framework for modeling a wide variety of datasets. The research team develops a suite of complementary distributed inference algorithms for hierarchical Bayesian models, which cover most commonly used Bayesian ML methods. The project focuses on combining speed and scalability with theoretical guarantees that allow us to assess the accuracy of the resulting methods, and allow practitioners to make trade-offs between speed and accuracy. Rather than focus on a few disconnected models, the project develops techniques applicable to a broad spectrum of hierarchical Bayesian models, resulting in a toolkit of building blocks that can be combined as needed for arbitrary probabilistic models - be they parametric or nonparametric, discriminative or generative. This is in contrast to much existing work on parallel inference, which tends to focus on parallelization in a specific model and cannot be easily extended. The project provides a solid algorithmic foundation for learning on Big Data with powerful models. The research contributes to democratizing advanced and large-scale ML methods for broad applications, by offering the user and developer community a library of general-purpose parallelizable algorithms for working on diverse problems using computer clusters and the cloud, bridging the gap between practical needs from data and basic research in ML.
Randomized methods have recently proven highly useful in efficiently analyzing big data sets, and this project covers mathematically rigorous techniques for developing such algorithms to analyze and store such data efficiently. In particular this project focuses on furthering applications of recent randomized methods for large-scale computational linear algebra. Applications of this research include: randomized linear algebra, manifold learning, and model-based compressed sensing. Many of the developed technologies on problems in these areas are unified by the common tool of randomized "oblivious subspace embeddings."<br><br>This research attacks the big data problem in randomized linear algebra, manifold learning, and model-based compressed sensing. In randomized linear algebra one imagines that the input is an extremely large matrix A, and the goal is to efficiently process this input, e.g., in the form of regression, principal component analysis, (approximate) matrix multiplication, eigenvalue estimation, k-means clustering, etc. First proposed by Sarlos was the idea of using "oblivious subspace embeddings" to speed up computation, i.e., picking a random matrix S (from an appropriate distribution) such that solving the problem on SA instead of A still yields an almost optimal solution to the original problem (where S is chosen so that SA has many fewer rows than A, thus compressing the massive data). This project develops novel methods to obtain more efficient such S, as well as to find new applications to kernelized and regularized regression problems.In manifold learning one imagines that the input data lies on a low-dimensional manifold in a high-dimensional space. For example, pixelated handwritten images can be viewed as high-dimensional vectors (indexed by pixels), whereas empirically it has been observed that such images tend to lie near a much lower dimensional manifold. By learning these parameters ("manifold learning"), one can do more efficient classifier training as well as achieve data compression. This project explores more efficient ways to use randomized methods to do manifold learning, e.g., by using efficient subspace embeddings. In model-based compressed sensing one wishes to acquire sparse signals with structured sparsity patterns efficiently using few linear measurements, for later (approximate) recovery. Organizing these measurements as the rows of a measurement matrix S, it is known that such S are closely connected to subspace embeddings. This project aims to explore this connection to obtain more efficient model-based compressed sensing and recovery algorithms.
While statistical machine learning has seen major advances over the past two decades, rigorous approaches for high-dimensional spatio-temporal scientific data analysis have not received as much attention. On the other hand, several core scientific areas, including climate science, ecology, environmental sciences, and neuroscience, are generating increasing amounts of high-resolution spatio-temporal data. It is vital to develop rigorous machine learning approaches for such complex high-dimensional spatio-temporal data in order for key scientific breakthroughs in these areas in the next few decades. The project contributes to these endeavors by focusing on two key technical and scientific areas: spatio-temporal big data analysis and climate science. The project systematically develops the statistical machine learning foundations for the analysis of large scale complex high-dimensional spatio-temporal data, and applies such advances to problems arising in climate science, where the total amount of data is set to cross an Exabyte (1 Exabyte = 1000 Petabytes) soon. <br><br>The technical work in the project has three broad and interacting components: structured probabilistic graphical models for spatio-temporal data analysis, generalized graphical models for multivariate heavy tailed distributions, and physics-guided models with a richer class of structural constraints and capturing multi-scale phenomena. The project applies these technical advances to climate science, by generating climate projections at high-resolutions. Currently, the lack of requisite spatial resolution of current climate models makes automatic assessments of impacts, adaptation and vulnerability (IAV) difficult for a variety of sectors, including urban planning, freshwater resources, food security, energy, transportation systems, human health, and coastal systems.
Open source software is an engine for innovation and a critical infrastructure for the nation and yet it is implemented by communities formed from a loose collection of individuals. With each software project relying on thousands of other software projects, this complex and dynamic supply chain introduces new risks and unpredictability, since, unlike in traditional software projects, no contractual relationships with the community exist and individuals could simply lose interest or move on to other activities.<br>The big data-based approach to software supply chains will stimulate academic and practical work. The tools and practices to quantify and mitigate risks in the rapidly changing global environment with no centralized control or authority will lead to dramatic reductions in risk manifested in, for example, the spread of vulnerabilities thus making the nation both safer and more innovative. The theoretical frameworks and approaches developed will likely influence research and practice in other supply chain contexts.<br><br>The objective of this research is to advance the state of knowledge of software supply chains by collecting and integrating massive public operational data representing development activity and source code from all open source projects and using it to develop novel theories, methods, and tools. The construction and analysis of the entire open source supply chain provides static and dynamic properties of the network, risk propagation, and system-level risks. Novel statistical and game-theoretic models are used to assess and mitigate these risks, while methods to contextualize, augment, and correct operational data provide ways to cope with data?s size, complexity, and observational nature.
This research seeks to develop novel machine learning algorithms that enable real-time video and sensor data analysis on large data streams given limited computational resources. The work focuses on healthcare as an application domain where real-time video analysis can prevent user-errors in operating medical devices or provide immediate alerts to caregivers about dangerous situations. The research will develop algorithms to automatically adapt data analysis approaches to maximize accuracy of analysis within a short time period despite limited available computing resources. Today's healthcare environment is significantly more technologically sophisticated than ever before. Many medical devices are now frequently used in patient's homes, ranging from simple equipment such as canes and wheelchairs to sophisticated items such as glucose meters, ambulatory infusion pumps and laptop-sized ventilators. The rapidly growing home health industry raises new safety concerns about devices being used inappropriately in the home setting. The proposed research is designed to reduce medical device related use-errors by developing computational algorithms that perform real-time video analysis and alert the patient or caregiver when medical devices are not used appropriately. The real-time video and sensor data analysis is also critical to the healthcare systems that monitor the activities of the elderly or those with disabilities in order to allow a caregiver to react immediately to an incident. <br><br>New machine learning theories and algorithms will automatically adapt to hardware limitations, with the aim to learn from a large number of training examples, a prediction function that (i) is sufficiently accurate in making effective predictions and (ii) can be run efficiently on a specified computer system to deliver time critical results. Three types of prediction models are studied to address the problem of automatic hardware adaptation, including a vector-based model, a matrix-based model, and a prediction model based on a function from a Reproducing Kernel Hilbert Space (RKHS). A general framework and multiple optimization techniques are being developed to learn accurate prediction models that match limited memory and computational capacity. The new learning algorithms will be evaluated in several medical scenarios through real-time prediction of a patient's activities from observations in the large video archives collected by several healthcare related projects. The intellectual merit of the proposed work is in bridging the gap between the high complexity of a prediction model and limited computational resources, a scenario that is encountered in many application domains besides healthcare. The proposed research in machine learning algorithms and theories will make it possible to run complicated prediction algorithms on big data within the limitation of a given computing infrastructure. The developed techniques for automatic hardware adaptation will be applied to a large dataset of continuous video and sensor recordings for medically-critical activity recognition. The project's broader impacts include providing medical experts with algorithms and tools supporting novel approaches to analyzing observational data in their quest to recognize and characterize human behavior. Surveillance systems with continuous observations will be able to categorize salient events with co-located, limited hardware. Researchers with complex data from continuous streams will be able to explore their domains with greater accuracy within constrained time using their available computing resources. Similarly, large archives can be exploited as rapidly as possible with limited hardware.
Data-driven modeling has moved beyond the realm of consumer predictions and recommendations into areas of policy and planning that have a profound impact on our daily lives. The tools of data analysis are being harnessed to predict crime, select candidates for jobs, identify security threats, determine credit risk, and even decide treatment plans and interventions for patients. Automated learning and mining tools can crunch incredible amounts and variety of data in order to detect patterns and make predictions. As is rapidly becoming clear, these tools can also introduce discriminatory behavior and amplify biases in the systems they are trained on. In this project, the PIs will study the problems of discrimination and bias in algorithmic decision-making. By studying all aspects of the data pipeline (from data preparation to learning, evaluation, and feedback), they will develop tools for analyzing, auditing, and designing automated decision-making systems that will be fair, accountable, and transparent. As specific goals to broaden the impact of this research, the PIs will develop a course curriculum to educate the next generation of data scientists on the ethical, legal, and societal implications of algorithmic decision-making, with the intent that they will then take this understanding into their jobs as they enter the workforce. Initial efforts by the PIs have attracted students from underrepresented groups in computer science, and they will continue these efforts. The PIs will also explore the legal and policy ramifications of this research, and develop best practice guidelines for the use of their tools by policy makers, lawyers, journalists, and other practitioners.<br><br>The PIs will explore the technical subject of this project in three ways. Firstly, they will develop a sound theoretical framework for reasoning about algorithmic fairness. This framework carefully separates mechanisms, beliefs, and assumptions in order to make explicit implicitly held assumptions about the nature of fairness in learning. Secondly, by examining the entire pipeline of tasks associated with learning, they will identify hitherto unexplored areas where bias may be unintentionally introduced into learning as well as novel problems associated with ensuring fairness. These include the initial stages of data preparation, various kinds of fairness-aware learning, and evaluation. They will also investigate the problem of feedback: when actions based on a biased learned model might cause a feedback loop that changes reality and leads to more bias.
Understanding the structure and dynamics of social networks is crucial for detecting any anomalous behavior and for managing its impacts. Most existing approaches view a network as a series of snapshots, where a snapshot represents the state of a network in a given time period. Therefore, different network operations need to be individually performed over each snapshot. In reality, online social networks are continuously evolving and therefore, network operations should be automatically performed as networks evolve and need to be done efficiently and reliably. Viewing the problem from this perspective allows us to create a solution that supports advanced, real-world use cases such as tracking the neighborhood of a given node or tracking how network connections evolve in time to determine effective marketing campaigns. These examples indicate the need for efficient computing techniques for important network statistics as the large networks evolve over time. To address this problem, the researchers in this project complement existing distributed evolving social graph analysis techniques with bootstrap and other statistical re-sampling based approaches. The ultimate goal is to develop novel data-driven tools so that when needed, not only certain estimates of statistical network models could be computed efficiently but their estimation errors are reliably quantified. <br><br>This project primarily targets development of new efficient and robust methods for anomaly and outlier detection on large sparse networks. The resulting methodology provides the following functions: 1) a computationally efficient finite sample inference for an extensive range of network topology statistics; 2) a flexible data-driven characterization of network structure and dynamics, and 3) comprehensively quantifying uncertainty in modeling and estimation of large networks, without imposing restrictive conditions on network model specification. The expected advances are both in research methods - new approaches to data-driven nonparametric inference for large sparse networks and in substantial enhancement of knowledge of network dynamics and formation in the era of digital communication. The project can significantly benefit students by providing a broad exposure to interdisciplinary applications of large network and fostering awareness of interdisciplinary relationships -- hence enhancing their capacity for critical thinking and opening up new career paths.
This project enhances the perfSONAR network measurement system to improve the application impact and utility of network performance information. The perfSONAR system monitors and measures the network cyberinfrastructure that connects scientists with resources and ever-increasing data. This project increases the impact of this network telemetry on the performance of large-scale data applications by calibrating network data and making it actionable.<br><br>While it can be determined when the network is behaving correctly and when it is lightly or heavily loaded, scientific workflows have yet to be provided the same level of performance estimation that car drivers can get from a navigation system in a car. This project calibrates and quantifies data from scientific data networks and applications in order to provide reasonable predictions for the logistics of moving scientific data. This includes controlled experiments under repeatable conditions as well as longitudinal studies with high performance networks and applications.<br><br>In addition, efforts are made to scale the perfSONAR ecosystem by orders of magnitude, and to move toward a more scalable service model for subscribing components and developing autonomic configuration and management of measurement activities. As the perfSONAR system moves outside the network operations community, many aspects of scalability will need to be addressed.
While the most significant projects in modern observational astrophysics generate very large data sets, the computational methodology lags behind, and has trouble effectively analyzing these data. Although current and future astronomical surveys will produce the world's largest public databases, the methods to turn these data into scientific discoveries do not yet exist. This project will develop an automatic query-by-example system for classifying galaxies by their similarities to other galaxies, using unsupervised machine learning techniques. This capability does not currently exist and it can substantially enhance the experience and discovery power of digital sky surveys. The project has an educational component, focusing in particular on undergraduate research for under-represented minority students.<br><br>Existing, and especially planned, surveys can image billions of galaxies, making the ability to study rare galaxies through computer analysis absolutely essential. These uncommon objects are critical for understanding the most fundamental questions about the early, present, and future universe, as they carry crucial information on the history of the interactions of objects, their formation, and their evolution. The system to be developed will take an image of a certain (normally peculiar) galaxy, identified by the researcher as being of interest, and will search through millions of galaxies to find the visually most similar galaxies to the query galaxy. Because studying unusual galaxies and making scientific conclusions about their nature requires a certain population from which to derive properties that can be compared to other systems, this capability and the resulting listings will greatly increase the ability to make discoveries from sky surveys, optimizing the scientific return of these important and expensive research instruments.<br><br>This project connects with existing efforts to attract under-represented minorities, adding more advanced research training in the later years of their undergraduate degree. Studies like this always include opportunities for public outreach, and the team expects to contribute to the forming big data hub in their area.
We interact with online shopping and banking websites on a daily basis. Many of these websites are powered by data-driven applications. Such application often consists of two parts: an application hosted on an application server, and a database management system (DBMS) hosted on a separate server from the application server that maintains persistent data. Unfortunately, many data-driven applications suffer from performance problems, such as taking a long time to load a page or inability to scale up to serve large number of clients simultaneously. The state of the art in discovering and fixing performance problems in data-driven applications is to examine the two parts of the application separately, and doing so misses many opportunities in discovering and fixing such problems. Unlike prior approaches, in this project we will treat the DBMS and the application in tandem. In particular, we will devise new techniques and tools to help identify performance problems, understand the cause of such problems, and fix them automatically. This project will open up new opportunities in cross-layer program compilation and optimization, with the practical goal of improving the performance of data-driven applications that will have a significant impact in many aspects of our daily lives. The findings from this project will be incorporated into undergraduate and graduate software engineering, introduction to data management, and compiler classes to be offered at the University of Chicago and the University of Washington. The outreach activities of this project will include engaging and advising students through special programs geared toward under-represented groups such as the Distributed Research Experiences for Undergraduates (DREU) organized by CRA-W (Computing Research Association -- Women) and Diversity Workshops organized by CRA-W.<br><br>Specifically, the proposed research consists of three thrusts: (1) a new cross-layer program analysis framework that produces an end-to-end profile of data-driven applications by understanding the application code, the queries that the application sends to the DBMS, and how the DBMS processes such queries; (2) a program analysis and testing framework that identify performance problems in data-driven applications by leveraging the end-to-end profile created from (1); and (3) new means to optimize data-driven applications by transforming both the application code and the queries that are issued. These three thrusts will work together to improve the performance of data-driven applications and help programmers detect performance problems during development. Software developed by this project, benchmarks used for evaluation, and performance comparison with existing techniques will be released to public domain through the project website. Further information will be available at the project website (http://db.cs.washington.edu/projects/coopt.html).
The collective efforts in aerospace, civil, electrical, and mechanical engineering areas have led to remarkable progresses in wind energy. Larger turbines are designed and installed, and wind farms are nowadays built at locations where wind is even more intermittent and maintenance equipment is less accessible. This adds new challenges to ensuring operational reliability. To cope with these challenges, along with the rapid advancement in microelectronics, modern wind farms are equipped with a large number and variety of sensors, including, at the turbine level, anemometers, tachometers, accelerometers, thermometers, strain sensors, and power meters, and at the farm level, anemometers, vanes, sonars, thermometers, humidity meters, pressure meters, among others. It is worth noting that all these data are currently analyzed/utilized only in their respective domains. The big data challenges in this project include how to best use spatio-temporal data for wind forecast, how to use data of different nature (wind, power, load etc.) and data of different sources (physical data versus computer simulation data) for power production assessment in a computationally efficient manner, and finally how to integrate these three sets of solutions into a reliable and efficient computational platform. The proposed research and education activities will make a paradigm shift in the wind industry by demonstrating how dramatically data science innovations can benefit the industry. The PIs will disseminate the research findings through classroom teaching, journal/conference publications, industry workshops, and data/software sharing. The summer internship opportunities and undergraduate research help train the next generation workforce to be better versed with data science methodologies.<br><br>The critical barrier to cost effective wind power and its general adoption is partly rooted in wind stochasticity, severely complicating wind power production optimization and cost reduction. The long-term viability of wind energy hinges upon a good understanding of its production reliability, which is affected in turn by the predictability of wind and power productivity of wind turbines. Furthermore, the productivity of a wind turbine comprises two aspects: its ability of converting wind into power during its operation and the availability of wind turbines. Three inter-related research efforts will enhance wind energy reliability and productivity): (1) spatio-temporal analysis (for wind forecast) (2) conditional density estimation (for wind-to-power conversion assessment); and (3) importance sampling (for turbine reliability assessment and improvement). Significant data resourced provided by industry partners in the research, coupled with models and computational resources, will enable better prediction of wind profiles and utilization. In addition, the team will develop dedicated reconfigurable field programmable gate array (FPGA) processors that will be 50 to 500 times faster than general-purpose CPUs for both on-site and central control processing and have small form-factor, low cost and energy efficient to enable agile development under severe outdoor conditions at wind farms.
With the rapid advances in information technology, an age of rich data has dawned in nearly every scientific field. Such data hold the potential to guide decision-making and accelerate understanding of complex processes such as human development and disease progression. For instance, massive databases on gene expression and other molecular processes can be used to build models to predict the drivers of a disease. Predictive models are an important step in understanding these complex systems, but equally important is the human interpretability of such models, e.g. to derive mechanistic insights into what factors drive disease onset in order to identify an appropriate course of treatment. Next Generation Sequencing (NGS) technologies have led to a profound shift in how biological data are collected, assaying individual genomic elements that act as part of organized, stereospecific groups to drive emergent biological phenomena. These modern data call for new statistics/data science principles and scalable algorithms to advance the frontier of science.<br><br>This project focuses on developing novel scalable statistical machine learning algorithms that are predictable, stable and interpretable, and can be used to guide decision-making and discovery in biological systems. This project aims to build insights into how individual genomic elements act in concert by developing interpretable and stable supervised learning algorithms with state of the art predictive accuracy along with scalable, open source software. Many machine learning algorithms with state of the art predictive accuracies are capable of learning complicated rules that might govern complex systems but are difficult for humans to interpret. The research builds on iterative Random Forests (iRF), an algorithm recently developed by the PIs that recovers the high-order, human interpretable, Boolean type interactions that are important parts of the state-of-the-art predictive accuracy in Random Forests. The proposed work will develop and validate approaches for refining interactions recovered by iRF to produce testable hypotheses for follow-up studies, along with inference methods to assess the uncertainty associated with these hypotheses. These approaches and methods will be implemented in Apache Spark to ensure scalability to massive datasets in genomics and beyond. Implementation of the methods for the large-scale applications will leverage cloud computing resources provided through an agreement between commercial cloud service providers and NSF for the BIGDATA solicitation.
Big Data often results from multiple sources, giving collections that contain multiple, often partial, "views" of the same object, space, or phenomenon from various observers. Extracting information robustly from such data sets calls for a joint analysis of a large collection of data sets. The project is developing a novel geometric framework for modeling, structure detection, and information extraction from a collection of large related data sets, with an emphasis on the relationships between data. While this approach clearly applies to data with a clear geometric character (e.g., objects in images), the work is also applied to datasets as diverse as computer networks (identifying common structure in subnets) and Massive Open Online Course homework data (automatically carrying grader annotations to similar problems in other students' homeworks).<br><br>The novel framework is based on the construction of maps between the objects under considerations (point clouds, graphs, images, etc...), and on the analysis of the networks of maps that result as a way of extracting information, generating latent models for the data, and transporting or inferring functional / semantic information. These tasks define a new field of map processing between data sets and require tool sets with new ideas from functional analysis, non-convex optimization, and homological algebra in mathematics, and geometric algorithms, machine learning, optimization, and approximation algorithms in computer science. Sophisticated algorithmic techniques for attacking the large-scale non-linear optimization problems that emerge within the framework will also be investigated.
A cyberphysical system (CPS) in biology requires sensor input that represents, as closely as possible, cell activity. Much work is expended on the development of wearable sensors that detect the expression of cell activity filtered through many processes. Recent work discloses that gene transcription can be thought of as a signal, with periodic oscillations over time. The well-known 24 hour light-dark cycle has protean effects however shorter and longer cycles not only exist but have important roles to play in health and disease. Detection of these signals and their perturbation is likely to be of great use in a robust health focused CPS. The exact nature of these signals and the mathematical structure underlying them will form the basis of this proposal. The societal impacts go beyond the new sensors to include the development of open source methods allowing the dissemination of new mathematical models and insights. into measurement of cellular processes. <br><br><br>This proposal addresses the critical problem of generating cell-level physiologic data as a substrate for an effective CPS in health. Applying new, unbiased signal processing techniques, the team has recently identified new periodicity in RNA over time. This signal provides a robust insight into cell function and its changes. The team will address the ability of the new techniques in specific situations to uncover signals to be used as inputs for a human health CPS sensor. This signal processing technique will be used to identify oscillations in genes associated with defined chronic metabolic diseases of humans such as diabetes, inflammation, and cancer). These candidate genes will be used to construct a precision signature for input into a CPS sensor. The concepts and data will be used to construct mathematical equations describing the longitudinal DNA transcripts previously identified. Taken together, these two activities will provide an integrated mathematical picture of periodic gene transcription that then sets the stage for novel sensor design that will provide prediction and control in a human-based CPS. The project will develop a new platform for understanding the cell that will be made widely available via a Web-based open source platform.
Big networks are constantly growing in both size and relevance: from social networks such as Facebook and Twitter, to brain networks, gene regulatory networks, and health/disease networks. The traditional approach to analyzing such big datasets is to use powerful supercomputers (clusters), ideally large enough to store the data in main memory. The downsides to this approach are that many potential users of big data lack such powerful computational resources (e.g. point-of-sale Bitcoin blockchain analysis), and it can be difficult to solve unexpected problems within such a large infrastructure (e.g. image analysis after the Boston Marathon Bombing). The algorithms developed in this project will enable the processing of huge datasets on computational devices with a limited amount of fast memory, connected to a relatively slow external data source.<br><br>This project will investigate the extent to which complex network analysis can be performed on a single computer, even a mobile device such as a smartphone. To this end, the project will develop external-memory, cache-oblivious, and streaming algorithms for analyzing and understanding big network data, even on relatively weak computational devices. These algorithms will make big data analysis accessible to a much broader audience, enabling new applications. The approach uniquely combines advanced algorithmic techniques, including approximation algorithms, parameterized algorithms, graph algorithms, graph structure theory, and computational geometry, to solve real-world problems on big networks.
Big Data have become one of the key challenges in many research areas. Big Data Computing, Applications and Technologies, BDCAT 2017, serves as a platform for researchers to share with the community their discoveries in various aspects of big data computing, including big data science, infrastructures and platforms, big data applications, big data trends and challenges, as well as visualization of big data. The conference will also provide an education opportunity for students participants, where they will be exposed to novel techniques and learn state-of- the-art methodologies. In addition, the travel award recipients will have opportunities to closely interact with a group of faculty mentors, who will provide constructive feedback on their research projects, as well as career guidance.
Connections between computers on the internet, between people on social media, between cell regulation mechanisms and diseases: each of these networks is represented in the computer as an abstraction called a graph. Questions about connections - shortest or least congested paths between computers, clusters of friends or people with influence, best location to disrupt or promote cell growth - become graph optimization questions and need algorithms for their repeated solution. <br><br>For huge graphs, optimization algorithms may demand more time and memory than is available. The past decade has seen significant advances in processing huge lists or tables of numbers (vectors and matrices) as more compact "sketches." (One technique for "linear sketches" takes inner products with pseudorandom matrices to make them smaller: this keeps similar data similar, and mathematical analysis shows that disparate data has a good chance of remaining separate.) There has not been similar progress for processing graphs, and converting graph data to vectors or matrices increases their size and/or loses their structure. <br><br>This project extends the concept of linear sketches for graphs, and develops methods for solving large scale convex optimization problems using linear sketches. Most computational platforms easily calculate inner products, and the linearity allows data updates by algorithms that are naturally parallel or distributed, and that use simple communication. Development of algorithms and insights using linear sketching are intellectually compelling, and useful in practice. There has been nascent progress towards linear-sketch-based graph algorithms, however much more algorithmic development is necessary.<br><br>The goal is to design algorithms that operate in small space and have provable guarantees and efficient implementations. The specific problems targeted are clustering, matching and assignment problems, and their generalizations to stochastic input. The project seeks to develop iterative algorithms that are easily adapted to a variety of computational models, to implement and validate the new algorithms on publicly available datasets, and to make the algorithms widely available.
Understanding how the brain works is arguably one of the most significant scientific challenges of our time and the focus of the BRAIN initiative. It is widely believed that neural circuit function is emergent, the result of complex interactions between constituents with individual neurons forming synaptic connections with thousands of other neurons. Mapping of these complex circuits has been virtually impossible because of the reliance on electrophysiological recordings which sample these networks extremely sparsely. These tools for extracellular spike recordings are only able to simultaneously record from several tens to a few hundred neurons. Raw signals from these recording electrodes are first filtered to remove out-of-band signals. Putative spike events are then detected and extracted. Finally, these snippets of time-series event are sorted, typically on the basis of waveform shapes, into clusters. Even at the very modest bandwidths for these systems, computing systems struggle to save the data and process the resulting data sets. Scalability of these measurement techniques by many orders of magnitude in recording density and channels will be essential to future progress in understanding neuron circuits.<br><br>This project is exploiting emerging electrophysiological recording systems in which the electrode (and channel) count is increased by almost three orders of magnitude over conventional systems with data bandwidths exceeding 1GB/sec. To handle these data bandwidths and resulting data volumes and deliver scalability, this project will develop dedicated hardware and associated algorithms for spike detection and sorting that allow these tasks to be performed in real-time in close proximity to the recording system. Compression by more than three orders of magnitude is possible by these means by taking advantage of the special spatiotemporal local structure in these data sets; by exploiting strong prior information about the spiking signal and reducing the dimensionality of the problem accordingly; and by adapting and extending modern scalable nonparametric Bayesian inference methods. In addition to providing important new tools for neuroscience, the tools developed here for scalable real-time event detection and annotation have broad applicability to other spatiotemporal data sets (or more generally, any data set comprising multiple streams of data, in which the streams could involve different data modalities) in which objects of interest are spatially and temporally localized with fixed spatial footprints. Examples abound in cell and molecular biology, particle and solid-state physics, financial monitoring, monitoring of power networks, and sensor networks.
While many disciplines have become increasingly exploratory given that large-scale and multi-source data collection has become prevalent, we find that volumes of data that were carefully collected and studied to answer project-specific questions, are neglected and unstudied, even if they hold key answers to tomorrow's questions. This project addresses this challenge by developing novel data analysis, alternative clustering, data visualization and acceleration solutions to enable exploration and identification of connections hidden in diverse data sets, leading to new discoveries and knowledge. In particular, the data analysis algorithms will be applied to a large dataset taken from an ongoing National Institute of Environmental Health Sciences (NIEHS) project that is assessing the impact of water-borne pollutants on premature birth rates in Puerto Rico. The exploratory analysis will focus on discovering the unknown underlying environmental factors and processes that may more broadly impact health and the environment. As such, this study promotes progress in data science, environmental science and health. Note that this project will address women?s health in an under-served population. In addition, this project supports education through graduate research support, development of inter-disciplinary tutorials, and creation of a new undergraduate class that addresses the intersection between machine learning approaches and parallel computing.<br> <br>The environmental health data comprises of multiple heterogeneous sources with varying temporal and spatial resolutions: mass spectrometer readings to identify targeted and non-targeted compounds in well and tap water, participant surveys detailing personal care and household products use in the home, and analyzed placental, blood and urine samples. Such complex data challenges traditional clustering algorithms in the following ways. The first challenge is in defining the appropriate similarity measure for each type of data source. The second step involves how to integrate information from these multiple sources for clustering. The third challenge is that in exploratory analysis, the solution found may not be what the analyst is looking for. How can one discover alternative solutions given this knowledge? In real world applications, data can often be interpreted in many different ways. However, existing multi-source fusion methods can only find a single solution. This study will develop new alternative clustering approaches, exploring multiple heterogeneous information sources. The project will deliver both visual and scalable solutions to enable sifting through the mountains of data efficiently. Moreover, the project will produce parallel libraries within Spark, and demonstrate the power of these new methods to this environmental health application.
Scientific Bigdata sets are becoming too large and complex to fit in RAM, forcing scientific applications to perform a lot of slow disk and network I/O. This growth also makes scientific data more vulnerable to corruptions due to crashes and human errors. This project will use recent results from algorithms, database, and storage research to improve the performance and reliability of standard scientific data formats. This will make scientific research cheaper, faster, more reliable, and more reproducible.<br><br>The Hierarchical Data Format (HDF5) standard is a container format for scientific data. It allows scientists to define and store complex data structures inside HDF5 files. Unfortunately, the current standard forces users to store all data objects and their meta-data properties inside one large physical file; this mix hinders meta-data-specific optimizations. The current storage also uses data-structures that scale poorly for large data. Lastly, the current model lacks snapshot support, important for recovery from errors.<br><br>A new HDF5 release allows users to create more versatile storage plugins to control storage policies on each object and attribute. This project is developing support for snapshots in HDF5, designing new data structures and algorithms to scale HDF5 data access on modern storage devices to Bigdata. The project is designing several new HDF5 drivers: mapping objects to a Linux file system; storing objects in a database; and accessing data objects on remote Web servers. These improvements are evaluated using large-scale visualization applications with Bigdata, stemming from real-world scientific computations.
Recent developments and availability of commoditized White Box (WB) and Bare Metal switch designs along with open network operating systems have opened the door for new and open source approaches to network software development. Interest is growing in the research community in these devices and the extraordinary development possibilities these devices enable, which may have long term implications for greatly expanding the national infrastructure at lower cost and with increased programming flexibility. Potential advantages of this emerging movement to the research and education networking community include; lower cost of ownership for commercial off the shelf hardware; development on widely available Linux-based network operating system; easier integration of network provisioning into available cloud orchestration tools; reduced time in deployment and provisioning; and increased intelligence throughout the network.<br><br>This exploratory project at Indiana University investigates the scalability, functionality, and performance of WB platforms in combination with network operating systems and software defined networking technologies including OpenFlow implementations. The project includes creation of a testbed that is shared with network researchers.
With the increased availability, prominence, and applicability of data in all of our lives, the emerging<br>field of Translational Data Science is critical to harnessing societal benefit from advances in data-related<br>scientific disciplines. The unprecedented growth in the creation and use of data offers new opportunities<br>for fostering more effective bridges between researchers, industry and government colleagues, and a<br>diverse community to enable new scientific progress and tangible advances for societal benefit. This workshop will focus on academic research and industry expertise to further cooperation and partnerships.<br><br>Translational data science is an emerging field that applies data science principles, techniques, and<br>technologies to scientific challenges that hold the promise of having an important societal impact. It<br>focuses on the interface and interactions between foundational aspects of data science and their use in<br>advancing scientific frontiers. By convening a diverse community of stakeholders who can contribute to the strategic development of a Translational Data Science roadmap, this workshop will build and strengthen connections across sectors. The perspectives and insights shared from industry, government, nonprofits, and academia, coupled with discussions focused on actionable challenges and measurable outcomes, will serve to advance the field of data science as well as related fields and application areas. The workshop provides a mechanism for identifying high-priority topics and high-impact opportunities for future research, training, and collaboration.
This research seeks to develop novel machine learning algorithms that enable real-time video and sensor data analysis on large data streams given limited computational resources. The work focuses on healthcare as an application domain where real-time video analysis can prevent user-errors in operating medical devices or provide immediate alerts to caregivers about dangerous situations. The research will develop algorithms to automatically adapt data analysis approaches to maximize accuracy of analysis within a short time period despite limited available computing resources. Today's healthcare environment is significantly more technologically sophisticated than ever before. Many medical devices are now frequently used in patient's homes, ranging from simple equipment such as canes and wheelchairs to sophisticated items such as glucose meters, ambulatory infusion pumps and laptop-sized ventilators. The rapidly growing home health industry raises new safety concerns about devices being used inappropriately in the home setting. The proposed research is designed to reduce medical device related use-errors by developing computational algorithms that perform real-time video analysis and alert the patient or caregiver when medical devices are not used appropriately. The real-time video and sensor data analysis is also critical to the healthcare systems that monitor the activities of the elderly or those with disabilities in order to allow a caregiver to react immediately to an incident. <br><br>New machine learning theories and algorithms will automatically adapt to hardware limitations, with the aim to learn from a large number of training examples, a prediction function that (i) is sufficiently accurate in making effective predictions and (ii) can be run efficiently on a specified computer system to deliver time critical results. Three types of prediction models are studied to address the problem of automatic hardware adaptation, including a vector-based model, a matrix-based model, and a prediction model based on a function from a Reproducing Kernel Hilbert Space (RKHS). A general framework and multiple optimization techniques are being developed to learn accurate prediction models that match limited memory and computational capacity. The new learning algorithms will be evaluated in several medical scenarios through real-time prediction of a patient's activities from observations in the large video archives collected by several healthcare related projects. The intellectual merit of the proposed work is in bridging the gap between the high complexity of a prediction model and limited computational resources, a scenario that is encountered in many application domains besides healthcare. The proposed research in machine learning algorithms and theories will make it possible to run complicated prediction algorithms on big data within the limitation of a given computing infrastructure. The developed techniques for automatic hardware adaptation will be applied to a large dataset of continuous video and sensor recordings for medically-critical activity recognition. The project's broader impacts include providing medical experts with algorithms and tools supporting novel approaches to analyzing observational data in their quest to recognize and characterize human behavior. Surveillance systems with continuous observations will be able to categorize salient events with co-located, limited hardware. Researchers with complex data from continuous streams will be able to explore their domains with greater accuracy within constrained time using their available computing resources. Similarly, large archives can be exploited as rapidly as possible with limited hardware.
The size and complexity of these "Big Data" graphs have always posed significant challenges, limiting the scope of their analysis and thus also limiting the implications that one can draw from them. Mining data from large real-world graphs typically poses two challenges: one of computational resources and another of incomplete information. A comprehensive analysis of these graphs has usually required access to large distributed computing platforms and sophisticated software. This project aims to address a portion of these challenges by investigating a new method, based in statistics and spectral graph theory, to infer essential properties of the full graph through extracting a representative sample of small subgraphs from the full graph. The goal is to reduce the computational burden on researchers interested in large graphs and thus broaden participation in "Big Data" activities. As is now well-understood, the analysis of large graphs has many applications in a variety of fields including business, economics, public policy development, law enforcement, public health, sociology and, of course, computer science. This breadth of applicability and the proposed curriculum development activities have the potential to draw and retain a greater diversity of students into computer science and engineering and increasing the participation by under-represented groups.<br><br>Many of the principal properties of a graph can be inferred from the graph spectrum (eigenvalues of its adjacency or the normalized Laplacian matrix). In particular, a rich set of interlacing results in spectral graph theory allows one to bound the eigenvalues of the full graph using the eigenvalues of its subgraphs. This project will develop new algorithms for generating subgraph samples, and then use basic estimation theory from statistics and the interlacing results from spectral graph theory to discern properties of a large graph. The new method based on subgraph sampling (as opposed to node or edge sampling) uses results from spectral graph theory and statistics to estimate the spectrum (eigenvalues) of the graph based on the spectrum of the sampled subgraphs. The goal is to allow a meaningful analysis of extremely large graphs without the use of anything beyond a typical desktop computer. The data collected and the algorithms developed as part of this project will be made available to the larger research community through a data repository hosted by Drexel University. The project will also make contributions to open-source software.
Indiana University's regional campuses enroll over 30,000 students each year, addressing the need to provide higher education opportunities to citizens of Indiana who for various reasons are unable to enroll at IU's core campuses in Bloomington and Indianapolis. These students are often non-traditional and/or first generation college students. The resources needed to provide high-quality scientific research and educational opportunities are concentrated at IUís Bloomington and Indianapolis core campuses. High-performance and high-speed data networks are required to support transfer of large data sets and access to national scientific resource for each of IU's regional campuses. <br> <br>This project improves the campus cyberinfrastructure at Indiana Universityís five regional campuses and one center in three areas to support unmet research needs: 1) it increases IU regional campusesí connection to Internet2 and other national research networks from 1Gbps to 10Gbps via Indiana's regional network provider, I-Light; 2) it increases the connection speed from IUís network core to the IU regional campuses to 10Gbps; and 3) the installed Data Transfer Nodes at the five larger regional campuses ensures unimpeded 10Gbps-capable high-performance data transfer for researchers across the regional and national research networks. <br> <br>These infrastructure improvements significantly benefit all researchers and students in STEM disciplines at Indiana University regional campuses. They address immediate research needs for projects in physics, geology, chemistry, biochemistry, and biology, including work at the National Superconducting Cyclotron Laboratory (NSCL). <br>Further, they enable future regional research projects heretofore impossible due to slow data transfer rates, thereby forwarding the advancement of science.
DataBridge<br><br>There are currently thousands of scientists creating millions of data sets describing an increasingly diverse matrix of social and physical phenomena. This rapid increase in both amount and diversity of data implies a corresponding increase in the potential of data to empower important new collaborative research initiatives. However, the sheer volume and diversity of data presents a new set of challenges in locating all of the data relevant to a particular line of research. Taking full advantage of the unique data managed by the "long-tail of science" requires new tools specifically created to assist scientists in their search for relevant data sets. DataBridge is an e-science collaboration environment tool designed specifically for the exploration of a rich set of sociometric tools and the corresponding space of relevance algorithms, and their adaptation to define semantic bridges that link large numbers of diverse datasets into a sociometric network. Data from several large NSF funded projects will be analyzed to develop relevance-based data discovery methods. Sociometric network analysis (SNA) algorithms will be used to explore the space of relevancy (different ways data can be related to each other) by metadata and ontology, by pattern analysis and feature extraction, and via human connections. By linking data, human interactions, and usage methods and practices, rich models of social networks inter-connecting massive long tail science data can be created that enhance scientific collaboration and discovery. DataBridge supports advances in Science and Engineering by directly enabling and improving discovery of relevant scientific data across large, distributed and diverse collections. The system will also provide an easy means of publishing data to the DataBridge and incentivize data producers to do so by enabling collaboration and citation. The design will be domain-agnostic and highly extensible and adaptive, supporting inclusion of new relevance algorithms and indexing techniques. DataBridge will be distributed under an open source license enabling wider use and crowd-sourced improvements of the technology. The concepts developed in the project - semantically linking data through sociometric network analysis - will have an impact on non-scientific data collections and will effectively improve access and discovery of information over the web.
Scientific Bigdata sets are becoming too large and complex to fit in RAM, forcing scientific applications to perform a lot of slow disk and network I/O. This growth also makes scientific data more vulnerable to corruptions due to crashes and human errors. This project will use recent results from algorithms, database, and storage research to improve the performance and reliability of standard scientific data formats. This will make scientific research cheaper, faster, more reliable, and more reproducible.<br><br>The Hierarchical Data Format (HDF5) standard is a container format for scientific data. It allows scientists to define and store complex data structures inside HDF5 files. Unfortunately, the current standard forces users to store all data objects and their meta-data properties inside one large physical file; this mix hinders meta-data-specific optimizations. The current storage also uses data-structures that scale poorly for large data. Lastly, the current model lacks snapshot support, important for recovery from errors.<br><br>A new HDF5 release allows users to create more versatile storage plugins to control storage policies on each object and attribute. This project is developing support for snapshots in HDF5, designing new data structures and algorithms to scale HDF5 data access on modern storage devices to Bigdata. The project is designing several new HDF5 drivers: mapping objects to a Linux file system; storing objects in a database; and accessing data objects on remote Web servers. These improvements are evaluated using large-scale visualization applications with Bigdata, stemming from real-world scientific computations.
Separating speech from background noise is crucial for many speech-based applications, including hearing prostheses, robotics, and multimedia communication. Many speech separation algorithms perform reasonably well when they are tested in simulated environments, but this level of performance does not always carry over to real environments that are more nuanced. For example, a common complaint of many hearing aid users is that their hearing aid is not effective in noisy environments such as restaurants. Current computational measures do not enable practical or convenient speech assessment in everyday environments, and this is a major hurdle for improving real-world separation performance. In addition, the end-user has largely been left out of the development and evaluation process, which is not ideal since an approach's usefulness is ultimately determined by people. The objective of this project is to develop computational evaluation algorithms to better assess speech quality and intelligibility in real environments. <br><br>A key area of research focuses on developing novel, data-driven assessment algorithms that use deep learning to predict human assessment scores, which enables testing in real environments. Considering the recent success that deep learning has had in speech processing, this new assessment approach is promising and offers substantial differences from prior approaches. The relationship between spectral-temporal speech attributes and human assessment scores are determined as a result of this project. Quantifying this relationship ensures that assessment algorithms are accurate and have strong agreement with human evaluations. An effective integration of human assessment in speech separation algorithm development should result in improved separation algorithms, which ultimately benefits users and applications. This is expected since accurate assessment enables researchers to more easily identify and correct weaknesses based on real-world environmental factors. The research activities lay the foundation for the emerging research area of improving realism in speech processing applications and offer key insights on human perception to the larger scientific community.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
Unsupervised learning of useful features, or representations, is one of the most basic challenges of machine learning. Unsupervised representation learning techniques capitalize on unlabeled data which is often cheap and abundant and sometimes virtually unlimited. The goal of these ubiquitous techniques is to learn a representation that reveals intrinsic low-dimensional structure in data, disentangles underlying factors of variation by incorporating universal AI priors such as smoothness and sparsity, and is useful across multiple tasks and domains. <br><br>This project aims to develop new theory and methods for representation learning that can easily scale to large datasets. In particular, this project is concerned with methods for large-scale unsupervised feature learning, including Principal Component Analysis (PCA) and Partial Least Squares (PLS). To capitalize on massive amounts of unlabeled data, this project will develop appropriate computational approaches and study them in the ?data laden? regime. Therefore, instead of viewing representation learning as dimensionality reduction techniques and focusing on an empirical objective on finite data, these methods are studied with the goal of optimizing a population objective based on sample. This view suggests using Stochastic Approximation approaches, such as Stochastic Gradient Descent (SGD) and Stochastic Mirror Descent, that are incremental in nature and process each new sample with a computationally cheap update. Furthermore, this view enables a rigorous analysis of benefits of stochastic approximation algorithms over traditional finite-data methods. The project aims to develop stochastic approximation approaches to PCA and PLS and related problems and extensions, including deep, and sparse variants, and analyze these problems in the data-laden regime.
Instant by instant, we take in all of the information that we can gather with our senses, and we organize that information into objects and events. This is the foundation for our ability to function in the real world. While we can talk in general terms about how and why we function with such effectiveness and efficiency, a satisfactory scientific explanation requires much more. In particular, it requires a way of relating the things we can measure---specifically, the frequency with which we choose certain to choose certain actions and the time it takes to make those choices---to each other and to our hypotheses for how and why we do these things. Currently, there is no general way of doing this: the work to be accomplished with this support will fundamentally change this state of affairs.<br><br>The creation of a unified theoretical approach to characterizing the ways in which we organize our perception of the world will open up numerous avenues of research linking behavior and neurobiology. With the aid of the theoretical language that this project will produce, there will be systematic and well-defined ways of testing competing hypotheses for both what we do with perceptual information and how we do it. Critically, because this language will be extremely general and will not be tied to a particular set of ideas or theory, scientists from competing perspectives will be able to frame their ideas using a common vocabulary, something that is not currently possible. In addition, since this language will be mathematical, it will possess an exceptional level of rigor and internal consistency. Finally, this language will demonstrate its utility and power by being applied to a set of thorny issues in the contemporary study of perceptual organization.
Contemporary data-driven science and engineering problems require the development of statistical methods that do not compromise statistical accuracy, yet are computationally feasible. Data quality, particularly the heterogeneity in data measurements, is a critical factor that affects statistical accuracy in the analysis of large datasets. This project will explore and demonstrate the impact and feasibility of improving computational and statistical performances simultaneously for Big Data problems with massive datasets. The research will advance the state of knowledge in predictive statistical learning with Big Data, and be extremely valuable in applications related to financial risk management or commercial operations employing recommender systems, biology, and image analysis. <br><br> A key phenomenon motivating this project is the notion that some refined ensemble methods combined with random projections can simultaneously enable the fast analysis of massive data while enhancing statistical performance. Specifically, the aims of the project are: (1) Develop new classification methods based on random projections and the random forest. By defining appropriate projections, the proposed method is shown to improve statistical accuracy for massive datasets with a large number of irrelevant noisy measurements. The theoretical properties of this method will be analyzed, and an adaptive version of the algorithm developed to optimize the computational and statistical efficiency gains; (2) Propose boosting algorithms with random projections. The statistical properties, practical performance, and implementation of the proposed random projected boosting algorithms will be investigated; (3) Develop classification methods with heterogeneities. A classification method that involves the weighted bootstrap and ensemble learning to handle heterogeneity or covariate shifts in measurements in large datasets will be developed. The random projection method will be applied to improve the proposed method for high-dimensional datasets.
With an ever increasing ability to collect and archive data, massive data sets are becoming increasingly common. These data sets are often too big to fit into the main memory of a single computer, and so there is a great need for developing scalable and sophisticated machine learning methods for their analysis. In particular, one has to devise strategies to distribute the computation across multiple machines. However, stochastic optimization and inference algorithms that are so effective for large-scale machine learning appear to be inherently sequential.<br><br>The main research goal of this project is to develop a novel "nomadic" framework that overcomes this barrier. This will be done by showing that many modern machine learning problems have a certain "double separability" property. The aim is to exploit this property to develop convergent, asynchronous, distributed, and fault tolerant algorithms that are well-suited for achieving high performance on commodity hardware that is prevalent on today's cloud computing platforms. In particular, over a four year period, the following will be developed: (i) parallel stochastic optimization algorithms for the multi-machine cloud computing setting, (ii) theoretical guarantees of convergence, (iii) open source code under a permissive license, (iv) application of these techniques to a variety of problem domains such as topic models and mixture models. In addition, a cohort of students who can transfer their skills to both industry and academia will be trained, and a graduate level course on scalable machine learning will be developed.<br> <br>The proposed research will enable practitioners in different application areas to quickly solve their big data problems. The results of the project will be disseminated widely through papers and open source software. Course material will be developed for the education of students in the area of Scalable Machine Learning, and the course will be co-taught at UCSC and UT Austin. The project will recruit women and minority students.
The project aims to leverage the massive corpus of online photos, text, and maps to create a semantic 3D labeled model of the world, e.g., detailed representations of the world's top cultural and historical sites. While breakthroughs in computer vision enable creating detailed 3D models from millions of online 2D images, the resulting models capture only geometry. Consequently, they lack semantics; they don't provide information about the contents of the scene. The vast treasure trove of online text such as Wikipedia meticulously catalogs the scenes that are captured in photos and models. Modern Natural Language Processing (NLP) techniques can now process such data, opening up the opportunity to extract knowledge from the online text corpus and use it to label 3D geometry. This project seeks to jointly analyze the massive corpus of online text, maps, and photos to create labeled 3D models of the world's sites. Achieving this goal will require fundamental research advances at the interface of natural language processing and computer vision that impact both the scientific research community and the world at large. <br><br>The project addresses two key technical challenges: (1) automatic scene labeling: mapping semantics onto geometry, and (2) solving the 3D jigsaw puzzle: mapping pieces of geometry into the world. Many clues to these mapping problems lie in the text and other online datasources such as floorplans. Other clues lie in the content of the photos. Decoding this mapping therefore involves an interplay between NLP and computer vision. The key research advances center around new ways to jointly leverage computer vision and NLP to solve problems to solve challenging problems in both fields, specifically, 1) recognizing objects through joint NLP and 3D visual analysis, 2) placing objects in the world by correlating geometry with spatial text in maps and webpages, and 3) using semantics to improve geometry by augmenting visual cues with textual spatial relations.<br><br>Broader Impacts: The primary research outcomes are: (1) technology for creating labeled 3D models at a massive scale, and (2) labeled models for many top tourist sites. Both the algorithms and models will be made freely available for the research community. These algorithms and models will provide the foundation for a range of exciting applications of major practical impact on the world at large. The resulting tools could make it possible for resources such as Wikipedia to link the text directly to 3D models and vice-versa, with attendant benefits to online learning and education. The same technology could enable automated labeling of 2D photographs. In the context of real-time applications (e.g., augmented reality), the technology could provide visual overlays and instant feedback on what you are currently looking at, and enable augmented reality-style guided tours. Other applications include using labeled geometry for navigation (walking directions), and converting images to text for the visually impaired. The research is tightly integrated into education and training of students at the University of Washington. Additional information about the project can be found at: http://grail.cs.washington.edu/projects/label3d/
The University of Washington will host a national workshop where graduate students in data science disciplines will interact to explore data science grand challenges in a collaborative environment. The project will implement a novel idea and advance the understanding of how to develop data science communities by engaging graduate students, academia, and industry. It also addresses an important national need for researchers with cross-disciplinary training in data science and serves as a catalyst for other institutions to integrate data science skills more broadly throughout the curriculum. <br><br>The goal of the project is to help create a highly connected workforce that is adept at cross-disciplinary communication and idea synthesis, primed to solve a new generation of data science and big data challenges. To accomplish this goal, the investigators will conduct a 2.5-day workshop for approximately 100 attendees that is designed to (1) introduce graduate students to new data science concepts and applications, (2) enable students to interact with experts from industry, domain, and methodology fields, and (3) initiate the establishment of a professional community using team building activities. The investigators will conduct a pre-workshop promotional campaign and develop a web site where users can connect and share their ideas. Following the workshop, a set of white papers, team reports, and a workshop report will be available to the public.
Understanding how the brain works is arguably one of the most significant scientific challenges of our time and the focus of the BRAIN initiative. It is widely believed that neural circuit function is emergent, the result of complex interactions between constituents with individual neurons forming synaptic connections with thousands of other neurons. Mapping of these complex circuits has been virtually impossible because of the reliance on electrophysiological recordings which sample these networks extremely sparsely. These tools for extracellular spike recordings are only able to simultaneously record from several tens to a few hundred neurons. Raw signals from these recording electrodes are first filtered to remove out-of-band signals. Putative spike events are then detected and extracted. Finally, these snippets of time-series event are sorted, typically on the basis of waveform shapes, into clusters. Even at the very modest bandwidths for these systems, computing systems struggle to save the data and process the resulting data sets. Scalability of these measurement techniques by many orders of magnitude in recording density and channels will be essential to future progress in understanding neuron circuits.<br><br>This project is exploiting emerging electrophysiological recording systems in which the electrode (and channel) count is increased by almost three orders of magnitude over conventional systems with data bandwidths exceeding 1GB/sec. To handle these data bandwidths and resulting data volumes and deliver scalability, this project will develop dedicated hardware and associated algorithms for spike detection and sorting that allow these tasks to be performed in real-time in close proximity to the recording system. Compression by more than three orders of magnitude is possible by these means by taking advantage of the special spatiotemporal local structure in these data sets; by exploiting strong prior information about the spiking signal and reducing the dimensionality of the problem accordingly; and by adapting and extending modern scalable nonparametric Bayesian inference methods. In addition to providing important new tools for neuroscience, the tools developed here for scalable real-time event detection and annotation have broad applicability to other spatiotemporal data sets (or more generally, any data set comprising multiple streams of data, in which the streams could involve different data modalities) in which objects of interest are spatially and temporally localized with fixed spatial footprints. Examples abound in cell and molecular biology, particle and solid-state physics, financial monitoring, monitoring of power networks, and sensor networks.
We interact with online shopping and banking websites on a daily basis. Many of these websites are powered by data-driven applications. Such application often consists of two parts: an application hosted on an application server, and a database management system (DBMS) hosted on a separate server from the application server that maintains persistent data. Unfortunately, many data-driven applications suffer from performance problems, such as taking a long time to load a page or inability to scale up to serve large number of clients simultaneously. The state of the art in discovering and fixing performance problems in data-driven applications is to examine the two parts of the application separately, and doing so misses many opportunities in discovering and fixing such problems. Unlike prior approaches, in this project we will treat the DBMS and the application in tandem. In particular, we will devise new techniques and tools to help identify performance problems, understand the cause of such problems, and fix them automatically. This project will open up new opportunities in cross-layer program compilation and optimization, with the practical goal of improving the performance of data-driven applications that will have a significant impact in many aspects of our daily lives. The findings from this project will be incorporated into undergraduate and graduate software engineering, introduction to data management, and compiler classes to be offered at the University of Chicago and the University of Washington. The outreach activities of this project will include engaging and advising students through special programs geared toward under-represented groups such as the Distributed Research Experiences for Undergraduates (DREU) organized by CRA-W (Computing Research Association -- Women) and Diversity Workshops organized by CRA-W.<br><br>Specifically, the proposed research consists of three thrusts: (1) a new cross-layer program analysis framework that produces an end-to-end profile of data-driven applications by understanding the application code, the queries that the application sends to the DBMS, and how the DBMS processes such queries; (2) a program analysis and testing framework that identify performance problems in data-driven applications by leveraging the end-to-end profile created from (1); and (3) new means to optimize data-driven applications by transforming both the application code and the queries that are issued. These three thrusts will work together to improve the performance of data-driven applications and help programmers detect performance problems during development. Software developed by this project, benchmarks used for evaluation, and performance comparison with existing techniques will be released to public domain through the project website. Further information will be available at the project website (http://db.cs.washington.edu/projects/coopt.html).
BIGDATA: Small: DA: Classification Platform for Novel Scientific Insight on Time-Series Data<br><br>Abstract<br><br>The deepest insights into the nature of complex physical systems arise from the measurement of how observables of those systems change with time. Such dynamism - witnessed on scales ranging from atomic to Universal - reveals the underlying forces that govern the interaction of the constituents of those systems. The temporal sampling of data from sensors and from simulations, then, may be seen as a primary vector towards the deepest scientific insight. In this respect, mechanisms to quickly and robustly extract and mine knowledge from diverse time-series data can be fundamental tool of modern data-driven science. <br> <br>This project will build a webservice portal for scientific teams to train state-of-the-art machine-learning algorithms on existing data and receive autonomously generated classification statements on new data, whatever the scale. Massive data storage and the scaling/parallelism of computational algorithms (using commodity cloud services) will be abstracted from the end users. The envisioned framework will act both to simplify the algorithm selection and application processes as well as to educate the broad user base in modern machine-learning approaches. <br> <br>This project will lead to the implementation of novel and efficient feature extraction algorithms on irregularly sampled time-series data, and will make them available in the context of a robust and scalable platform integrated with classification and cross-validation, that will lead to informed use of the algorithms for reliable scientific insight. This learning and prediction platform will accelerate data-intensive decision-making, and will be a new data analytics tool for the autonomous discovery of knowledge across a diverse range of scientific disciplines. Geo-scientists may use it to find new robust earthquake trigger algorithms, enabling on-the-fly decision-making to improve emergency response times. Astronomers may rapidly detect anomalies, identifying a class of new variable stars buried within data from a time-domain imaging survey. Neuroscientists could incorporate improved real-time feedback and prediction into prosthetics control systems. As an intelligent agent, the platform could be used as an automated annotator for streaming biomedical data.<br> <br>This work will deliver a new open-source toolkit and web platform that can serve as a fundamental tool for time-domain science. By design, it will grow organically as user-contributed code is integrated into the platform. With burgeoning adoption among some data-driven science disciplines the webservice will emerge as an educational platform in the use of learning algorithms for time-series data and as a societal service that can be used by anyone (even outside of traditional scientific disciplines) to test hypotheses on large scales with minimal effort. The website will also act as a public repository for large, well-described datasets useful for validating new time-series classification and prediction algorithms. A series of short and semester-long courses will be developed (and broadly disseminated) to teach a new generation of scientists how to use the platform (and other widely available resources) as central 21st century research instruments.
Scientific Bigdata sets are becoming too large and complex to fit in RAM, forcing scientific applications to perform a lot of slow disk and network I/O. This growth also makes scientific data more vulnerable to corruptions due to crashes and human errors. This project will use recent results from algorithms, database, and storage research to improve the performance and reliability of standard scientific data formats. This will make scientific research cheaper, faster, more reliable, and more reproducible.<br><br>The Hierarchical Data Format (HDF5) standard is a container format for scientific data. It allows scientists to define and store complex data structures inside HDF5 files. Unfortunately, the current standard forces users to store all data objects and their meta-data properties inside one large physical file; this mix hinders meta-data-specific optimizations. The current storage also uses data-structures that scale poorly for large data. Lastly, the current model lacks snapshot support, important for recovery from errors.<br><br>A new HDF5 release allows users to create more versatile storage plugins to control storage policies on each object and attribute. This project is developing support for snapshots in HDF5, designing new data structures and algorithms to scale HDF5 data access on modern storage devices to Bigdata. The project is designing several new HDF5 drivers: mapping objects to a Linux file system; storing objects in a database; and accessing data objects on remote Web servers. These improvements are evaluated using large-scale visualization applications with Bigdata, stemming from real-world scientific computations.
One of the central challenges of neuroscience is understanding how animals operate as integrated wholes, that is, how their neural activity, working in concert with the properties of their bodies and environments, coordinates their behavior. When faced with such a daunting challenge, it makes sense to first study simpler instances of the general problem of interest. In this regard, the nematode worm Caenorhabditis elegans is a uniquely qualified target for investigating the operation of integrated brain-body-environment systems. It is the only animal for which the connectivity of its entire nervous system is known. In fact, the anatomical structure of its entire body has been characterized to the level of individual cells. In addition, its genome has been completely sequenced and its entire developmental lineage has been characterized, from fertilized egg to adult animal. The goal of this project is to draw upon these many resources in order to construct integrated brain-body-environment models of C. elegans locomotion, a behavior that serves as the foundation for all other behaviors that this animal exhibits.<br><br>Although the entire connectome of C. elegans is known, detailed knowledge of the electrophysiology of its nervous system is far less complete. For this reason, the approach has two components: constrained stochastic optimization and ensemble analysis. The investigators will construct computational models constrained by the known connectivity of the C. elegans ventral cord circuitry, the known layout of its body wall musculature and the partially-known electrophysiological properties of the neurons involved. They will then apply a stochastic optimization technique (evolutionary algorithms) in order to find values of the unknown electrophysiological parameters of this model that maximize a measure of locomotion performance. In general, different optimizations will result in different values for these parameters, all of which are consistent with the known experimental constraints. Thus, the object of study is not an individual model, but rather the entire ensemble of models that result from repeated optimizations. A detailed study of this ensemble will suggest specific new experiments whose results can then be used to further constrain future optimizations. The particular focus of these modeling efforts is on understanding the relative roles that proprioceptive feedback from body stretch receptors and the intrinsic dynamics of ventral cord circuitry play in the generation and propagation of the locomotion pattern.
As machine learning (ML) permeates all areas of science and technology, demands in diverse data domains, inference questions, resource limitations and reliability fuel several new conceptual and algorithmic challenges. Examples of current shortcomings that limit the full use of machine learning include suboptimal use of data and algorithms; painstaking hand-tuning and model search; validation of results and difficulties in generalization; limited interactivity with humans; encoding of domain knowledge; and lack of interpretability, among others. Progress on these questions has the potential to impact the successful adoption and use of machine learning in a broad range of fields. With the above motivation, the goal of this project is to create a novel suite of models and algorithms for analyzing complex datasets, with a particular focus on the following three factors crucial for next-generation machine learning: (1) interpretability; (2) interactivity; and (3) automated learning. The overarching technical concept underlying this proposal is the concept of negative dependence in discrete probability. This project lays theoretical foundations for a new set of tools grounded in this concept. Besides practical impacts, the methods to be studied in the project motivate new theoretical questions, and will help increase interest in the underlying mathematics.<br><br>The practical impact of the proposed work has the potential to benefit society on multiple fronts. Via collaborations, the PIs will evaluate the developed methods in healthcare (seeking to ultimately impact patient care and well-being), systems biology (to help with research on cancer and diabetes, among others), and materials science (to help discover safer, functional materials more efficiently). The project will also directly have educational impact: training of graduate students, providing material for data science courses at all levels, and outreach to the community via general talks as well as focused lectures at conferences and workshops, including workshops and events targeted at women in Data Science. <br><br>Technically, the PIs will develop: (1) New tools, models, and algorithms for interactive data analysis, especially for experimental design, information collection, interpretable machine learning, hypothesis testing, performance validation, and architecture learning; (2) Theoretical analysis, such as convergence and complexity (statistical and computational); and (3) Open-source implementations of all key algorithms and frameworks.
The collective efforts in aerospace, civil, electrical, and mechanical engineering areas have led to remarkable progresses in wind energy. Larger turbines are designed and installed, and wind farms are nowadays built at locations where wind is even more intermittent and maintenance equipment is less accessible. This adds new challenges to ensuring operational reliability. To cope with these challenges, along with the rapid advancement in microelectronics, modern wind farms are equipped with a large number and variety of sensors, including, at the turbine level, anemometers, tachometers, accelerometers, thermometers, strain sensors, and power meters, and at the farm level, anemometers, vanes, sonars, thermometers, humidity meters, pressure meters, among others. It is worth noting that all these data are currently analyzed/utilized only in their respective domains. The big data challenges in this project include how to best use spatio-temporal data for wind forecast, how to use data of different nature (wind, power, load etc.) and data of different sources (physical data versus computer simulation data) for power production assessment in a computationally efficient manner, and finally how to integrate these three sets of solutions into a reliable and efficient computational platform. The proposed research and education activities will make a paradigm shift in the wind industry by demonstrating how dramatically data science innovations can benefit the industry. The PIs will disseminate the research findings through classroom teaching, journal/conference publications, industry workshops, and data/software sharing. The summer internship opportunities and undergraduate research help train the next generation workforce to be better versed with data science methodologies.<br><br>The critical barrier to cost effective wind power and its general adoption is partly rooted in wind stochasticity, severely complicating wind power production optimization and cost reduction. The long-term viability of wind energy hinges upon a good understanding of its production reliability, which is affected in turn by the predictability of wind and power productivity of wind turbines. Furthermore, the productivity of a wind turbine comprises two aspects: its ability of converting wind into power during its operation and the availability of wind turbines. Three inter-related research efforts will enhance wind energy reliability and productivity): (1) spatio-temporal analysis (for wind forecast) (2) conditional density estimation (for wind-to-power conversion assessment); and (3) importance sampling (for turbine reliability assessment and improvement). Significant data resourced provided by industry partners in the research, coupled with models and computational resources, will enable better prediction of wind profiles and utilization. In addition, the team will develop dedicated reconfigurable field programmable gate array (FPGA) processors that will be 50 to 500 times faster than general-purpose CPUs for both on-site and central control processing and have small form-factor, low cost and energy efficient to enable agile development under severe outdoor conditions at wind farms.
Financial stock market manipulators can profit illegally by misleading investors about market conditions. For example, in several recent incidents, manipulators successfully spoofed markets by inserting orders that deceived investors about supply or demand for the security. This kind of behavior has increased with the prevalence of algorithmic trading. It imposes substantial harm to the economy, by reducing the efficiency of capital allocation, and more seriously, threatening to compromise the integrity and stability of financial markets. Spoofing is difficult to detect because the underlying actions have legitimate purposes as well as nefarious ones. This project will apply innovative approaches to improve detection and deterrence of market manipulation.<br><br>The project will integrate data-driven methods, including calibration of detectors with normal background activity and extraction of manipulation signatures from enhanced time series, with model-based techniques for characterizing manipulation strategies based on strategic analysis of market microstructure. The key idea is to use simulation and optimization to generate successful manipulation strategies for trading models calibrated from available market data streams. These strategies will then be injected into the trading models, to produce enhanced data streams that include labeled manipulation activity. Having labeled activity enables the application of machine learning techniques to extract signatures of spoofing activity, which can be used to construct surveillance and audit algorithms. Methods produced in this project in conjunction with guidance on market design and regulation policy can contribute to reducing the threat from increasingly capable market manipulators.
This proposal outlines a research and educational plan to advance decision-making techniques for robots that cooperate with human operators. Because humans far exceed the abilities of state-of-the-art robots in vision, creativity, and adaptability, interest is rapidly growing in a human-centered approach to robotics: combining the strengths of humans with the superior precision and repeatability of robots. And yet, our available motion planning tools, while powerful at computing motions for complex autonomous tasks, are poorly suited for human-centered applications that demand responsive and natural motions. This proposal hypothesizes that a new cooperative motion planning paradigm will support major advances in intuitiveness and task performance of human-operated robots such as intelligent vehicles, tele-surgery systems, search and-rescue robots, and household robots. This hypothesis is echoed in an educational plan that aims to train engineers with cross-disciplinary strengths that bridge both the technical and social dimensions of robotics. Initial human subjects studies on novice operators with the PI's cooperative motion planning algorithms suggest that the technique leads to dramatic reductions in task completion time and collision rate in cluttered environments. The proposed work will conduct further investigations along this line of research to 1) identify characteristics of cooperative planners - such as optimality, responsiveness, and completeness - that yield effective human-operator systems, both in terms of objective performance metrics and subjective preferences, 2) to design planners that optimize cooperativity metrics under computational resource and communication constraints, and 3) to enhance the capabilities of such planners to assist operators in complex manipulation tasks.<br><br>The planners developed in this research and the rich datasets acquired via user studies will serve as resources to help human-robot interaction (HRI) researchers design safe and socially acceptable robot behaviors. Moreover, advances in cooperative motion planning may have long-term social and economic impact by enabling new applications of robotics in driver assist systems, space exploration, medicine, household robotics, manufacturing, and construction. Research is integrated with education in a range of activities that include CS curriculum development, development of a new graduate course on optimization and machine learning, and in new software libraries for robotics education. New modules on motion planning, behavior recognition, and HRI will be incorporated in AI and robotics courses. An REU is requested for each summer of the grant and will be recruited from a minority-serving institution in cooperation with the Alliance for the Advancement of African-American Researchers in Computing (A4RC). One or more IU undergraduates will be involved in research and mentored according to the Undergraduate Research Opportunities in Computing (UROC) program, with preference given to minority and women students.
Molecular dynamics simulations studying the classical time evolution of a molecular system at atomic resolution are widely recognized in the fields of chemistry, material sciences, molecular biology and drug design; these simulations are one of the most common simulations on supercomputers. Next-generation supercomputers will have dramatically higher performance than do current systems, generating more data that needs to be analyzed (i.e., in terms of number and length of molecular dynamics trajectories). The coordination of data generation and analysis cannot rely on manual, centralized approaches as it does now. This interdisciplinary project integrates research from various areas across programs such as computer science, structural molecular biosciences, and high performance computing to transform the centralized nature of the molecular dynamics analysis into a distributed approach that is predominantly performed in situ. Specifically, this effort combines machine learning and data analytics approaches, workflow management methods, and high performance computing techniques to analyze molecular dynamics data as it is generated, save to disk only what is really needed for future analysis, and annotate molecular dynamics trajectories to drive the next steps in increasingly complex simulations' workflows. <br><br>The investigators tackle the data challenge of data analysis of molecular dynamics simulations on the next-generation supercomputers by (1) creating new in situ methods to trace molecular events such as conformational changes, phase transitions, or binding events in molecular dynamics simulations at runtime by locally reducing knowledge on high-dimensional molecular organization into a set of relevant structural molecular properties; (2) designing new data representations and extend unsupervised machine learning techniques to accurately and efficiently build an explicit global organization of structural and temporal molecular properties; (3) integrating simulation and analytics into complex workflows for runtime detection of changes in structural and temporal molecular properties; and (4) developing new curriculum material, online courses, and online training material targeting data analytics. The project's harnessed knowledge of molecular structures' transformations at runtime can be used to steer simulations to more promising areas of the simulation space, identify the data that should be written to congested parallel file systems, and index generated data for retrieval and post-simulation analysis. Supported by this knowledge, molecular dynamics workflows such as replica exchange simulations, Markov state models, and the string method with swarms of trajectories can be executed ?from the outside? (i.e., without reengineering the molecular dynamics code).
Big Data technology promises to improve people's lives, accelerate scientific discovery and innovation, and bring about positive societal change. Yet, if not used responsibly, this same technology can reinforce inequity, limit accountability and infringe on the privacy of individuals: irreproducible results can influence global economic policy; algorithmic changes in search engines can sway elections and incite violence; models based on biased data can legitimize and amplify discrimination in the criminal justice system; algorithmic hiring practices can silently reinforce diversity issues and potentially violate the law; privacy and security violations can erode the trust of users and expose companies to legal and financial consequences. The focus of this project is on using Big Data technology responsibly -- in accordance with ethical and moral norms, and legal and policy considerations. This project establishes a foundational new role for data management technology, in which managing the responsible use of data across the lifecycle becomes a core system requirement. The broader goal of this project is to help usher in a new phase of data science, in which the technology considers not only the accuracy of the model but also ensures that the data on which it depends respect the relevant laws, societal norms, and impacts on humans. <br><br>This project defines properties of responsible data management, which include fairness (and the related concepts of representativeness and diversity), transparency (and accountability), and data protection. It complements what is done in the data mining and machine learning communities, where the focus is on analyzing fairness, accountability and transparency of the final step in the data analysis lifecycle, and considers the problems that can be introduced upstream from data analysis: during dataset selection, cleaning, pre-processing, integration, and sharing. This project develops conceptual frameworks and algorithmic techniques that support fairness, transparency and data protection properties through all stages of the data usage lifecycle: beginning with data discovery and acquisition, through cleaning, integration, querying, and ultimately analysis. The contributions are structured along three aims. Aim 1 considers responsible dataset discovery, profiling, and integration. Aim 2 considers responsible query processing and develops a general framework for declarative specification, checking and enforcement of fairness, representativeness and diversity. Aim 3 incorporates data protection into the lifecycle, develops techniques to facilitate sharing of sensitive data, and considers the tradeoffs between privacy and transparency. This project is poised to establish a multidisciplinary research agenda around responsible data management as a critical factor in enabling fairness, accountability and transparency in decision-making and prediction systems. Additional information about the project is available at DataResponsibly.com.
Big Data technology promises to improve people's lives, accelerate scientific discovery and innovation, and bring about positive societal change. Yet, if not used responsibly, this same technology can reinforce inequity, limit accountability and infringe on the privacy of individuals: irreproducible results can influence global economic policy; algorithmic changes in search engines can sway elections and incite violence; models based on biased data can legitimize and amplify discrimination in the criminal justice system; algorithmic hiring practices can silently reinforce diversity issues and potentially violate the law; privacy and security violations can erode the trust of users and expose companies to legal and financial consequences. The focus of this project is on using Big Data technology responsibly -- in accordance with ethical and moral norms, and legal and policy considerations. This project establishes a foundational new role for data management technology, in which managing the responsible use of data across the lifecycle becomes a core system requirement. The broader goal of this project is to help usher in a new phase of data science, in which the technology considers not only the accuracy of the model but also ensures that the data on which it depends respect the relevant laws, societal norms, and impacts on humans. <br><br>This project defines properties of responsible data management, which include fairness (and the related concepts of representativeness and diversity), transparency (and accountability), and data protection. It complements what is done in the data mining and machine learning communities, where the focus is on analyzing fairness, accountability and transparency of the final step in the data analysis lifecycle, and considers the problems that can be introduced upstream from data analysis: during dataset selection, cleaning, pre-processing, integration, and sharing. This project develops conceptual frameworks and algorithmic techniques that support fairness, transparency and data protection properties through all stages of the data usage lifecycle: beginning with data discovery and acquisition, through cleaning, integration, querying, and ultimately analysis. The contributions are structured along three aims. Aim 1 considers responsible dataset discovery, profiling, and integration. Aim 2 considers responsible query processing and develops a general framework for declarative specification, checking and enforcement of fairness, representativeness and diversity. Aim 3 incorporates data protection into the lifecycle, develops techniques to facilitate sharing of sensitive data, and considers the tradeoffs between privacy and transparency. This project is poised to establish a multidisciplinary research agenda around responsible data management as a critical factor in enabling fairness, accountability and transparency in decision-making and prediction systems. Additional information about the project is available at DataResponsibly.com.
When something happens in the world -- such as a natural disaster, an election, a protest, or a policy change -- many types of media record different accounts of the same event. Newspapers, social media posts and government documents all provide unique versions of events stored in different formats. Because each source provides its own perspective, synthesizing these stories vastly increase our ability to learn about both events and the dynamics of the media environment. Yet, social scientists are limited in their capacity to access these myriad perspectives because there are few tools for automatically combining these accounts into one integrated analysis. This project will provide a rich infrastructure for integrating texts from diverse sources documenting the same social phenomenon. Such integration often reveals much about underlying social dynamics.<br><br>This project will develop a tool to integrate documents with different formats with accounts of the same or closely related events through four main methods. First, the tool will allow users to align documents by topic, while accounting for structural and stylistic differences between documents. Second, the tool will compile different types of documents by a shared event or entity. Third, the tool will allow for user-provided schema to combine semi-structured documents. Last, the tool will facilitate data fusion, by identifying and resolving contradictions from multiple sources. The tool will be sufficiently flexible to fit multiple research purposes, allow for human feedback to assist with integration, and facilitate reproducibility by creating a common resource that can be the basis of future research by a whole community of scholars. The system itself will be applicable to almost any set of unstructured text data and will have broad applicability for questions across the social sciences.
Honey bees exhibit highly complex behavior and are vital for our agriculture. Due to the rich social organization of bees, the overall performance and health of a bee colony depends both on a successful division of labor among the bees and on adequate reaction to the environment, which involves complex behavioral patterns and biological mechanisms. Much remains to be discovered on these matters as research is currently limited by our ability to effectively collect and analyze individual's behavior at large scale, out of the laboratory. The technology developed in this project will enable biologists to study the individual behavior of thousands of bees over extended periods of time. It builds on innovative algorithms and software to analyze big data collected from colonies in the field. Study of behavioral patterns at such scale will provide unique information to advance knowledge on biological processes such as circadian rhythms that influence bee behavior in addition to playing an important role in animals and humans. The models developed will help better understand factors involved in colony collapse disorder, thus guiding future research on threats to such an important pollinator. This work will be performed through the tight collaboration of a multi-disciplinary team of researchers to combine the latest advances in computer science and data science with expertise in biology. It will provide the opportunity to train students from underrepresented minority on research at the intersection of these fields and to reach more than 600 undergraduate students, high school students, and the general public about how the Big Data approach can contribute to current scientific and ecological challenges.<br><br>The project will develop a platform for the high-throughput analysis of individual insect behaviors and gain new insights into the role of individual variations of behavior on bee colony performance. Joint video and sensor data acquisition will monitor marked individuals at multiple colonies over large continuous periods, generating the first datasets of bee activities of this kind on such a scale. Algorithms and software will be developed to take advantage of a High Performance Computing facility to perform the analysis of these massive datasets. Semi-supervised machine learning will leverage the large amount of data available to facilitate the creation of new detectors for parameters such as pollen carrying bees or fanning behavior, currently annotated manually. Predictive models and functional data analysis methods will be developed to find patterns in individual behavior based on multiple parameters and over large temporal scales. These advances are expected to help uncover mechanisms of individual variations previously unobservable. They will enable the first large scale biological study on the circadian rhythms of the bee based on the variations in behavior of individuals in multiple activities instead of reasoning on single activities or averages. Progress, datasets and software will be shared with the community on the project website (sites.google.com/a/upr.edu/bigdbee).
This project develops a new class of accelerated learning techniques for reinforcement learning. Reinforcement learning is an approach to autonomous decision-making through trial-and-error interaction with an unknown environment, with a focus on learning incrementally from this stream of data. Reinforcement learning has significant industrial potential, particularly for real-time control systems, such as active network management for energy and search-and-rescue robots, and is already used in a wide range of fields, including robotics, psychology, animal learning and neuroscience. To improve the practical application of reinforcement learning, this project proposes a new class of algorithms with the goal to balance computational complexity and the sample efficiency of learning, which often requires significant computation and memory. This space of algorithms that attempt to balance both requirements has been under-explored for reinforcement learning, and provide exciting opportunities to impact industrial applications and the growing area of computational sustainability. An important aspect of this project will be to implement and study these algorithms on a wide-range of simulated environments, and engage a diverse group of students through courses and summer research.<br><br>This project develops efficient incremental approximations to summarize gathered samples for improved sample efficiency and an empirical framework to evaluate these algorithms. This new class of accelerated learning techniques formally trade-off computation and accuracy and have many promising extensions and research directions, through a variety of accelerated stochastic gradient descent techniques and incremental matrix approximations. Further, another focus is to develop tools and novel measures for the reinforcement learning community that evaluate this balance between sample efficiency and computational complexity, with the code framework released through an existing open-source platform. This initial systematic exploration of these novel optimization variants will lay the foundation for the long-term goal of improving efficacy of reinforcement learning in industry and for practical autonomous agents.
Representations of real-world phenomena as graphs (a.k.a. networks) are ubiquitous, ranging from social and information networks, to technological, biological, chemical, and brain networks. Many graph mining tasks -- including clustering, anomaly detection, nearest neighbor, similarity search, pattern recognition, and transfer learning -- require a distance measure between graphs to be computed efficiently. The existing distance measures between graphs leave a lot to be desired. They are overwhelmingly based on heuristics. Many do not scale to graphs with millions of nodes; others do not satisfy the metric properties of non-negativity, positive definiteness, symmetry, and triangle inequality. This project studies a formal mathematical foundation covering a family of graph distances that overcome these limitations, focusing on real-world applications in biology and social network analysis. It also provides a universal methodology for parallelizing the computation of graph distance metrics within this family over massive graphs with millions of nodes, and scaling it over cloud computing resources.<br><br>This project studies, designs, and evaluates graph distances that satisfy the following six properties: (1) They are scalable -- i.e., they are strictly subquadratic in runtime and achieve a speedup when computed in parallel. (2) They are metrics -- i.e., they satisfy<br>non-negativity, positive definiteness, symmetry, and triangle inequality. (3) They are discriminative, as measured by comparisons to the "chemical distance", which finds the optimal mapping between two graphs that minimizes edge discrepancies. (4) They are statistically<br>robust -- i.e., they have confidence intervals. (5) They can incorporate auxiliary information available on nodes and links. (6) They are interpretable to subject matter experts. Rather than providing a single metric, this project explores a family of such graph distance metrics. It also provides a universal methodology, using the Alternating Directions Method of Multipliers (ADMM), to parallelizing the computation of graph distance metrics within this family over massive graphs with millions of nodes. The proposed metrics are evaluated over massive real-world graphs using Apache Spark on a cloud computing infrastructure.
Scientists develop descriptions of models that explain their observations. But how many observations are needed to verify the validity of a model? When the model is probabilistic, the resulting question is this: How many samples from a distribution are needed to test whether it has a certain property? Arguably this problem lies at the foundations of scientific thought, and recent years have seen a tremendous body of work in the Computer Science literature trying to close in on the precise sample and time complexity needed to test distribution properties. Often data is high dimensional -- for example, medical records for patients have many entries. However, high dimensional distribution data is notoriously hard to deal with. This project will find new ways of overcoming the difficulties of dealing with high dimensional data, by isolating properties of data occurring in practice that aid in simplifying the distribution testing problems.<br><br>The broader impact of this project includes advancing the interface of Computer Science, Statistics and Learning. Our methods will be tested on a healthcare dataset, including over 3.7 million patients, and will test the accuracy of common models used to improve healthcare outcomes. Broader impact of this project also includes engagement in Computer Science activities for elementary school children, MIT PRIMES mathematical research with high school students, and participation in activities for promoting women in research. <br><br><br>Current work on distribution property testing has focused on properties of single-dimensional distributions such as uniformity, monotonicity, log-concavity, and others, with only a few results on testing properties of high-dimensional distributions. Unfortunately, testing properties of high-dimensional distributions quickly runs into exponential sample complexity lower bounds. The goal of the project is to develop new analysis frameworks for overcoming these lower bounds. Typically the lower bounds construct highly-complex distributions that do not possess a property but are really hard to distinguish from those that do. Our thesis is that such rich structure may not be present in many practical settings of interest. The overarching question of our research then is this: <br>are there reasonable assumptions that one could make about the unknown distribution under which high-dimensional testing problems are more tractable? <br><br>This research will (1) explore how the expressive language of graphical models can be used to restrict the correlation structure of high-dimensional distributions in ways that can be leveraged for faster testing; and (2) develop analysis frameworks that allow testing generating models of combinatorial structures, such as social networks, from a single or a constant number of samples; this sounds like an oxymoron but it will be made possible with adequate assumptions about the model generating the combinatorial structure. (1) will reveal important connections to Bayesian networks and their use in healthcare decision making, as well as to computational biology and phylogenetics, while (2) will have connections to social network modeling.
Identifying variables that are good for prediction, especially in the context of BIG DATA, is an important challenge. The scientific literature currently lacks research that directly considers a variable set's potential ability to predict, referred to as "predictivity", as a parameter to be estimated. This project sets out to lay down statistical foundations for measures of predictivity, and proposes a novel framework for maximizing predictivity in big data learning. The research includes an application to big data in urban planning, addressing prediction problems in New York City's Vision Zero project. In collaboration with the NYC Department of Transportation, the PI and his team will identify risk factors and their combinations that are associated with traffic accidents and their outcomes, and improve accident prevention and victim outcome prediction. <br><br>A novel sample-based measure of predictivity, the I-score, that is effective in differentiating between noisy and predictive variables in big data is proposed. This measure can be related to a lower bound for the correct prediction rate. Guided by this I-score, variable sets of high potential predictivity can be identified. This high predictivity often resides within complex interactions among the variables. To fully leverage the predictivity in an identified variable set, powerful classifiers based on deep architectures will be constructed. Novel strategies are proposed for scalable computational implementation of the proposed framework. Systematic evaluation of the proposed methods, comparing with current strategies, will be carried out using simulations and benchmark real data sets.
The Internet has enabled new kinds of interaction among people at a wide variety of scales, ranging from small groups to global social networks. The data arising from these new forms of interaction have been challenging to integrate because of how they span this wide range of scales; yet without this integration, we cannot understand how micro-level group interactions build up to macro-scale behavior or how macro-level factors shape small group interaction. A key data-science challenge is to bridge this gap between the micro- and macro-levels; and a crucial but relatively unexplored part of this challenge resides in the lack of conceptually useful models and techniques at the intermediate scales in between. This project investigates online social interaction data at different levels of scale, and develops methods for bridging the extremes by taking into account not just the global scales but also the intermediate meso-scale interaction (constituting interactions among hundreds or thousands of participants). Developing methods for handling the meso-level of data not only poses scientifically rich questions in its own right but also allows for transformative theory building across micro- and macro-level phenomena. <br><br>The project brings together researchers from a wide range of backgrounds to develop new ways of understanding and designing online interaction across different levels of scale. The research seeks to identify new forms of sub-structure that arise as the scale of the group increases to meso-scale and on to global scale; to identify new ways of maintaining an effective flow of ideas and processes for reaching consensus when the number of participants in a discussion grows signi&#64257;cantly; and to develop techniques for addressing the increased potential for conflict and polarization when people can participate at a boundary between recognizability and anonymity. <br><br>The project team combines multiple research perspectives, with broad expertise in analyzing social interaction data and developing models of social network dynamics; opinion extraction, summarization and argument mining; modeling conversational behavior; large-scale data analysis of pragmatics of language, including persuasion and information spread; and computer-mediated communication, social computing and human-computer interaction. In addition to the underlying research questions, the project also seeks to provide new knowledge that companies and organizations building meso-scale platforms can adopt to maximize the effectiveness of their sites; to add to research infrastructure through the release of datasets, code, and working applications; to impact education through the interdisciplinary training of graduate and undergraduate students, including students from underrepresented groups; and more generally to create mechanisms that can make online interactions more productive.
The ubiquity of information-sensing devices has opened up abundant sources for Big Sensory Data (BSD), which span over Internet of Things, wireless sensor networks, RFID, cyber physical systems, to name a few. Such diverse BSD-rich systems are the building blocks for smart cities where smart devices are deployed in every corner of a city. The analytical use of BSD is essential to smart cities in managing a city's assets and monitoring air conditions, pollution, climate change, traffic, security and safety, etc. The high demand for smart cities and the pivotal role of sensing devices in smart cities accelerate the explosion of BSD. Unfortunately, the size and dynamic nature of BSD overwhelm current capability to capture, store, search, mine and visualize BSD, and hence have become a major hindrance to the widespread development of smart city applications. To tackle these challenges, this project will investigate fundamental issues regarding acquisition, collection and computation of BSD with principled quality control. The goal is to cost-effectively collect and manage BSD for efficient utilization in smart city applications. A set of foundational principles, algorithms and tools for BSD management will be developed in response to the four challenging characteristics of BSD, which are large scale, correlated dynamics, mode diversity and low quality. The outcomes of this research will contribute to the vision of smart and resilient cities, which broadly impact the nation's emerging smart city infrastructure and citizens' mobile quality of life. This project also offers an opportunity to collaborate with the Government of the District of Columbia on the Smarter DC Initiative, and hence impacts not only the research community but also the society at large. <br><br>This project aims at tackling major challenges in task-cognizant BSD management at the critical phase of data acquisition, collection and computation. The overarching goal is to alleviate the high computational cost and improve the utilization efficiency of BSD in smart city applications. First, approximate BSD acquisition methods will be developed that automatically adjust the sensing frequency based on the changing trend of the physical world. Such acquisition methods can effectively reduce the data volume at an early stage during periodic and long-term monitoring of smart cities. Second, approximate sampling algorithms, knowledge discovery methods, and integration methods will be developed for task-specific multimodal BSD, in order to reduce the transmission cost associated with delivering otherwise raw and redundant BSD from sensing devices to end users. Finally, new metrics for evaluating BSD quality will be investigated and then applied to properly assess the tolerance of low-quality BSD and provide deep understanding of the fundamental impact of data quality on various design aspects of BSD acquisition, collection and computation. Besides theoretical analysis, simulation and experimental studies will be carried out on real BSD, including experimentation on real-world Smart City projects at Washington DC. The corresponding code, datasets, and educational materials will be released via a dedicated project website.
Big Data technology promises to improve people's lives, accelerate scientific discovery and innovation, and bring about positive societal change. Yet, if not used responsibly, this same technology can reinforce inequity, limit accountability and infringe on the privacy of individuals: irreproducible results can influence global economic policy; algorithmic changes in search engines can sway elections and incite violence; models based on biased data can legitimize and amplify discrimination in the criminal justice system; algorithmic hiring practices can silently reinforce diversity issues and potentially violate the law; privacy and security violations can erode the trust of users and expose companies to legal and financial consequences. The focus of this project is on using Big Data technology responsibly -- in accordance with ethical and moral norms, and legal and policy considerations. This project establishes a foundational new role for data management technology, in which managing the responsible use of data across the lifecycle becomes a core system requirement. The broader goal of this project is to help usher in a new phase of data science, in which the technology considers not only the accuracy of the model but also ensures that the data on which it depends respect the relevant laws, societal norms, and impacts on humans. <br><br>This project defines properties of responsible data management, which include fairness (and the related concepts of representativeness and diversity), transparency (and accountability), and data protection. It complements what is done in the data mining and machine learning communities, where the focus is on analyzing fairness, accountability and transparency of the final step in the data analysis lifecycle, and considers the problems that can be introduced upstream from data analysis: during dataset selection, cleaning, pre-processing, integration, and sharing. This project develops conceptual frameworks and algorithmic techniques that support fairness, transparency and data protection properties through all stages of the data usage lifecycle: beginning with data discovery and acquisition, through cleaning, integration, querying, and ultimately analysis. The contributions are structured along three aims. Aim 1 considers responsible dataset discovery, profiling, and integration. Aim 2 considers responsible query processing and develops a general framework for declarative specification, checking and enforcement of fairness, representativeness and diversity. Aim 3 incorporates data protection into the lifecycle, develops techniques to facilitate sharing of sensitive data, and considers the tradeoffs between privacy and transparency. This project is poised to establish a multidisciplinary research agenda around responsible data management as a critical factor in enabling fairness, accountability and transparency in decision-making and prediction systems. Additional information about the project is available at DataResponsibly.com.
Genomes contain the complete set of instructions for building an organism. Structural variants are rearrangements in the genome such as insertions and deletions, whose discovery advances the understanding of the evolution and the adaptability of species. Recent advances in high-throughput sequencing technologies have led to the collection of vast quantities of genomic data. Because of this, fast and robust algorithms are needed to identify structural variants, which are rare and are prone to noise. This research will contribute fundamentally to optimization methods for large-scale problems in computational genomics. The algorithms will be disseminated publicly for use within and outside the biology, mathematics, and computer science community. Graduate students will be trained in scientific research and programming through this interdisciplinary research, and the participation of students from under-represented backgrounds will be highly encouraged. <br><br>The research objective of this award is to develop computational tools for large-scale data-driven problems arising in computational genomics. These problems are especially difficult to solve since they are high-dimensional and the data are noisy and inexact. This study will take advantage of known relationships in sequenced genomes to improve the accuracy of identifying genomic variants in population studies when there is both low coverage in the data and multiple related individuals are sequenced. Specifically, the proposed research will (i) explore statistical models for describing the presence of structural variants in genomes, (ii) develop and implement novel sparse optimization methods for genomic structural variant detection, and (iii) validate on existing genomic data sets and predict on new data.
Representations of real-world phenomena as graphs (a.k.a. networks) are ubiquitous, ranging from social and information networks, to technological, biological, chemical, and brain networks. Many graph mining tasks -- including clustering, anomaly detection, nearest neighbor, similarity search, pattern recognition, and transfer learning -- require a distance measure between graphs to be computed efficiently. The existing distance measures between graphs leave a lot to be desired. They are overwhelmingly based on heuristics. Many do not scale to graphs with millions of nodes; others do not satisfy the metric properties of non-negativity, positive definiteness, symmetry, and triangle inequality. This project studies a formal mathematical foundation covering a family of graph distances that overcome these limitations, focusing on real-world applications in biology and social network analysis. It also provides a universal methodology for parallelizing the computation of graph distance metrics within this family over massive graphs with millions of nodes, and scaling it over cloud computing resources.<br><br>This project studies, designs, and evaluates graph distances that satisfy the following six properties: (1) They are scalable -- i.e., they are strictly subquadratic in runtime and achieve a speedup when computed in parallel. (2) They are metrics -- i.e., they satisfy<br>non-negativity, positive definiteness, symmetry, and triangle inequality. (3) They are discriminative, as measured by comparisons to the "chemical distance", which finds the optimal mapping between two graphs that minimizes edge discrepancies. (4) They are statistically<br>robust -- i.e., they have confidence intervals. (5) They can incorporate auxiliary information available on nodes and links. (6) They are interpretable to subject matter experts. Rather than providing a single metric, this project explores a family of such graph distance metrics. It also provides a universal methodology, using the Alternating Directions Method of Multipliers (ADMM), to parallelizing the computation of graph distance metrics within this family over massive graphs with millions of nodes. The proposed metrics are evaluated over massive real-world graphs using Apache Spark on a cloud computing infrastructure.
Over the last decade, 'big data' technologies have allowed the acquisition of vast amount of data (e.g. through smartphones) and their accumulation into large scale databases. Powerful hardware and software systems have been developed to crunch these data and extract statistical models. For instance, the outcome of a certain medical procedure can be modeled in terms of the features of the patient, thus in principle providing a personalized risk score for that procedure. Unfortunately, the increasing complexity of these data and of the algorithms used has made statistical models significantly less transparent. How certain are we of these statistical predictions? What is their limit of validity? How biased is the resulting model?<br><br>This project focuses on four main challenges that are ubiquitous in big-data, and are crucial to extract reliable insights: reproducibility; data sharing; missing data; data heterogeneity. <br><br>(1) Reproducibility requires being able to compare two models extracted from different data sets (e.g. after additional data have been accumulated). This is in turn impossible unless we have reliable procedures to quantify uncertainty and confidence in complex high-dimensional models. Recently proposed ideas in this direction are still insufficient to cope with realistic large-scale applications.<br><br>(2) Data sharing is a key feature of modern data analysis, whereby a single massive data set is being studied by hundreds of independent researchers. Unguarded statistical inference by such a population of researchers unavoidably leads to large numbers of false discoveries. The project builds on false discovery rate-controlling methods to propose safe approaches for decentralized data analysis.<br><br>(3) Missing data are ubiquitous in big data. While several methods have been developed in the past to deal with missing data, it is unclear to what extent they are applicable to modern scenarios. The project aims at developing principled guidelines based on a rigorous comparison of various approaches, and developing new algorithms based on maximum likelihood.<br><br>(4) Data heterogeneity. Big data are often produced by the aggregation of multiple data sources. How can we prevent standard statistical procedures to be critically affected by such heterogeneities? The project uses new regularization schemes to fusion information across multiple sources.
In contrast to the production, modeling, and machine recognition of adult speech, which have been studied for decades, the production, acoustic modeling and recognition of child speech have not received the same level of attention. The lack of scholarly resources for dealing with children's speech is problematic as new applications for child speech and language development become increasingly important and commonplace. This is especially true for elementary school children. As children grow, their articulators grow as well, resulting in variations in their speech sounds. For example, the waveform of the word 'sunny' spoken by a 6-year old can be quite different than that of the same child when she is 9 years old. This is why current machine recognition of children's speech does not perform well for young children and does not scale up as the child grows. That is, these systems tend to be age dependent. Understanding and modeling child speech as children grow is important not only to developing better recognition systems but also for better understanding and diagnosis of speech-language pathology (SLP). As the negative long-term ramifications of deficits in early childhood development gain increasingly broad recognition, the opportunities and the need for social and health services and technological applications targeted toward young children are growing. In particular, it is now understood that early deficits in language development and literacy persist into adulthood, and the demand for SLP services in public schools is significantly outpacing supply. As a result, it is no longer feasible for clinicians and teachers to provide the most effective treatments or the necessary attention to every child. Better speech recognition systems would provide an opportunity for improved diagnosis and more intense computer-based therapy. This Early Grant for Exploratory Research project aims to model how speech and language develop during elementary school and how children with speech disorders differ in their articulation of speech sounds. Models of child speech will lead to the development of computer programs which can be used for educational as well as therapeutic purposes.<br><br>Scientifically, the exploratory project will 1) reveal processes of speech production development in 20-26 elementary school-aged children through a unique combination of articulatory and acoustic analyses, and 2) develop acoustic models and eventually automatic speech recognition systems for children's speech which can be scalable with age (as opposed to being age-dependent systems). This can only be achieved by understanding how the articulation and corresponding acoustics develop with age. The different aspects of the project are therefore synergistic: findings from articulation and acoustic experiments will inform the development of algorithms essential to automatic speech recognition. Production data will include real-time 3D ultrasound recordings of the tongue, video recordings of the lips, palate impressions, microphone recordings, and accelerometer recordings of neck skin vibrations which have been shown to be beneficial in automatic speech and speaker recognition applications. The causal relationship between articulatory and acoustic variability will be explored, as will their relationship to misrecognition of child speech. Articulatory features will be incorporated into new automatic speech recognition systems along with acoustic features. The exploratory project will contribute to knowledge of variability between children, as well as variability over time as children grow and will provide, for the first time, normative data and scientific models. These can lead to robust child speech recognition systems as well as tools that will be useful for a variety of applications such as educational games, training of speech-language pathologists, automatic or semi-automatic transcription systems, and speech articulation visualization systems. It will train undergraduate and graduate students in important cross-disciplinary activities of technological and scientific significance. We believe that the proposed project is transformative in its advancement of the scientific and technological state of the art related to child speech.
Big data poses big challenges. Perhaps the biggest challenge is to extract small but useful information from big noisy data. What approach should be used to do that, and for what data, so that this extraction is scalable, and yields not spurious artifacts but provably reliable predictive knowledge? Numerous data science applications are blocked on these questions. For example, the prediction and control of opinions, (fake) news, and (mis)information is a practical problem that is becoming of increasingly high and broad impact these days of pervasion of online social media into everyday human life. This particular problem is largely blocked on general impossibility of disentangling those who naturally bond with others like themselves from those influenced by peers in social networks, except in some specific settings. The specific settings of this project -- real networks with latent-space structure -- are exactly the settings in which these theoretical and practical difficulties can be resolved.<br><br>The project will make a series of contributions in two areas. First, it will resolve a long-standing problem of obtaining a class of random graph models satisfying four requirements of realism: sparsity, exchangeability, projectivity and unbiasedness/maximum-entropy. Within this class, a set of graph-structural properties will be determined such that unbiased random graphs that have these properties are proved to have latent-geometric structure, thus rigorously linking discrete combinatorial structure of random graphs to smooth geometry of latent manifolds. The framework that the project will develop to prove this, will be quite general and applicable to other types of big data. The properties responsible for latent geometricity of random graphs are expected to characterize many real networks, meaning that such networks will be guaranteed to have latent geometries. The second part of the project will focus on developing scalable algorithms and software, with optimal computational complexity scaling linearly with the data size, and with proved accuracy guarantees, to learn the latent structure of a real network if the network has it, and apply these algorithms to large real networks. The outcomes of this latent-geometric learning will make it possible to map dynamical processes in real networks, such as spreading phenomena in social networks, to latent dynamics, while the knowledge of latent statistical factors behind this dynamic can then be used to predict and control it in practice with known accuracy bounds.
Every day, millions of people across the world take photos and upload them to social media websites. Their goal is to share photos with friends and others, but collectively they are creating vast repositories of visual information about the world. Each photo is an observation of how the world looked at a particular point in time and space. Aggregated together, these photos could provide new sources of observational data for use in disciplines like biology, earth science, social science or history. This project is investigating the algorithms and technologies needed for mining these large collections of photographs and noisy metadata to draw inferences about the physical world. The project has four research thrusts: (1) investigating techniques for identifying and correcting noise in metadata like geo-tags and timestamps, (2) developing algorithms for extracting semantic information from images and metadata, (3) creating methods for robust aggregation of noisy evidence from multiple photos, (4) validating these techniques on interdisciplinary applications in biology, sociology, and earth science.<br><br>The project is laying the foundation for using visual social media as a new source of observational data for a variety of scientific disciplines. The educational component is preparing students for the next generation of "big data" jobs through new undergraduate and graduate courses and online instructional materials. Undergraduate students (particularly from under-represented groups) are recruited to participate in the research program and encouraged to pursue scientific careers. An annual workshop is planned to educate general audiences, particularly senior citizens, about data mining and social media. Source code, datasets, course materials, and other results of the project will be disseminated to the public via the project web site (http://vision.soic.indiana.edu/career/).
Understanding scenes around us, i.e., recognizing objects, human actions and events, and inferring their spatial, temporal, correlative and causal relations, is a fundamental capability in human intelligence. Similarly, designing computer algorithms that can understand scenes is a fundamental problem in artificial intelligence. Humans consciously or unconsciously use all five senses (vision, audition, taste, smell, and touch) to understand a scene, as different senses provide complimentary information. For example, watching a movie with the sound muted makes it very difficult to understand the movie; walking on a street with eyes closed without other guidance can be dangerous. Existing machine scene understanding algorithms, however, are designed to rely on just a single modality. Take the two most commonly used senses, vision and audition, as an example, there are scene understanding algorithms designed to deal with each single modality. However, no systematic investigations have been conducted to integrate these two modalities towards more comprehensive audio-visual scene understanding. Designing algorithms that jointly model audio and visual modalities towards a complete audio-visual scene understanding is important, not only because this is how humans understand scenes, but also because it will enable novel applications in many fields. These fields include multimedia (video indexing and scene editing), healthcare (assistive devices for visually and aurally impaired people), surveillance security (comprehensive monitoring of the suspicious activities), and virtual and augmented reality (generation and alternation of visuals and/or sound tracks). In addition, the investigators will involve graduate and undergraduate students in the research activities, integrate research results into the teaching curriculum, and conduct outreach activities to local schools and communities with an aim to broader participation in computer science. <br><br>This project aims to achieve human-like audio-visual scene understanding that overcomes the limitations of single-modality approaches through big data analysis of Internet videos. The core idea is to learn to parse a scene into elements and infer their relations, i.e., forming an audio-visual scene graph. Specifically, an element of the audio-visual scene can be a joint audio-visual component of an event when the event shows correlated audio and visual features. It can also be an audio component or a visual component if the event only appears in one modality. The relations between the elements include spatial and temporal relations at a lower level, as well as correlative and causal relations at a higher level. Through this scene graph, information across the two modalities can be extracted, exchanged and interpreted. The investigators propose three main research thrusts: (1) Learning joint audio-visual representations of scene elements; (2) Learning a scene graph to organize scene elements; and (3) Cross-modality scene completion. Each of the three research thrusts explores a dimension in the space of audio-visual scene understanding, yet they are also inter-connected. For example, the audio-visual scene elements are nodes in the scene graph, and the scene graph, in turn, guides the learning of relations among scene elements with structured information; the cross-modality scene completion generates missing data in the scene graph and is necessary for good audio-visual understanding of the scene. Expected outcomes of this proposal include: a software package for learning joint audio-visual representations of various scene elements; a web-deployed system for audio-visual scene understanding utilizing the learned scene elements and scene graphs, illustrated with text generation; a software package for cross-modality scene completion based on scene understanding; and a large-scale video dataset with annotations for audio-visual association, text generation and scene completion. Datasets, software and demos will be hosted on the project website.
The ubiquity of information-sensing devices has opened up abundant sources for Big Sensory Data (BSD), which span over Internet of Things, wireless sensor networks, RFID, cyber physical systems, to name a few. Such diverse BSD-rich systems are the building blocks for smart cities where smart devices are deployed in every corner of a city. The analytical use of BSD is essential to smart cities in managing a city's assets and monitoring air conditions, pollution, climate change, traffic, security and safety, etc. The high demand for smart cities and the pivotal role of sensing devices in smart cities accelerate the explosion of BSD. Unfortunately, the size and dynamic nature of BSD overwhelm current capability to capture, store, search, mine and visualize BSD, and hence have become a major hindrance to the widespread development of smart city applications. To tackle these challenges, this project will investigate fundamental issues regarding acquisition, collection and computation of BSD with principled quality control. The goal is to cost-effectively collect and manage BSD for efficient utilization in smart city applications. A set of foundational principles, algorithms and tools for BSD management will be developed in response to the four challenging characteristics of BSD, which are large scale, correlated dynamics, mode diversity and low quality. The outcomes of this research will contribute to the vision of smart and resilient cities, which broadly impact the nation's emerging smart city infrastructure and citizens' mobile quality of life. This project also offers an opportunity to collaborate with the Government of the District of Columbia on the Smarter DC Initiative, and hence impacts not only the research community but also the society at large. <br><br>This project aims at tackling major challenges in task-cognizant BSD management at the critical phase of data acquisition, collection and computation. The overarching goal is to alleviate the high computational cost and improve the utilization efficiency of BSD in smart city applications. First, approximate BSD acquisition methods will be developed that automatically adjust the sensing frequency based on the changing trend of the physical world. Such acquisition methods can effectively reduce the data volume at an early stage during periodic and long-term monitoring of smart cities. Second, approximate sampling algorithms, knowledge discovery methods, and integration methods will be developed for task-specific multimodal BSD, in order to reduce the transmission cost associated with delivering otherwise raw and redundant BSD from sensing devices to end users. Finally, new metrics for evaluating BSD quality will be investigated and then applied to properly assess the tolerance of low-quality BSD and provide deep understanding of the fundamental impact of data quality on various design aspects of BSD acquisition, collection and computation. Besides theoretical analysis, simulation and experimental studies will be carried out on real BSD, including experimentation on real-world Smart City projects at Washington DC. The corresponding code, datasets, and educational materials will be released via a dedicated project website.
The ubiquity of information-sensing devices has opened up abundant sources for Big Sensory Data (BSD), which span over Internet of Things, wireless sensor networks, RFID, cyber physical systems, to name a few. Such diverse BSD-rich systems are the building blocks for smart cities where smart devices are deployed in every corner of a city. The analytical use of BSD is essential to smart cities in managing a city's assets and monitoring air conditions, pollution, climate change, traffic, security and safety, etc. The high demand for smart cities and the pivotal role of sensing devices in smart cities accelerate the explosion of BSD. Unfortunately, the size and dynamic nature of BSD overwhelm current capability to capture, store, search, mine and visualize BSD, and hence have become a major hindrance to the widespread development of smart city applications. To tackle these challenges, this project will investigate fundamental issues regarding acquisition, collection and computation of BSD with principled quality control. The goal is to cost-effectively collect and manage BSD for efficient utilization in smart city applications. A set of foundational principles, algorithms and tools for BSD management will be developed in response to the four challenging characteristics of BSD, which are large scale, correlated dynamics, mode diversity and low quality. The outcomes of this research will contribute to the vision of smart and resilient cities, which broadly impact the nation's emerging smart city infrastructure and citizens' mobile quality of life. This project also offers an opportunity to collaborate with the Government of the District of Columbia on the Smarter DC Initiative, and hence impacts not only the research community but also the society at large. <br><br>This project aims at tackling major challenges in task-cognizant BSD management at the critical phase of data acquisition, collection and computation. The overarching goal is to alleviate the high computational cost and improve the utilization efficiency of BSD in smart city applications. First, approximate BSD acquisition methods will be developed that automatically adjust the sensing frequency based on the changing trend of the physical world. Such acquisition methods can effectively reduce the data volume at an early stage during periodic and long-term monitoring of smart cities. Second, approximate sampling algorithms, knowledge discovery methods, and integration methods will be developed for task-specific multimodal BSD, in order to reduce the transmission cost associated with delivering otherwise raw and redundant BSD from sensing devices to end users. Finally, new metrics for evaluating BSD quality will be investigated and then applied to properly assess the tolerance of low-quality BSD and provide deep understanding of the fundamental impact of data quality on various design aspects of BSD acquisition, collection and computation. Besides theoretical analysis, simulation and experimental studies will be carried out on real BSD, including experimentation on real-world Smart City projects at Washington DC. The corresponding code, datasets, and educational materials will be released via a dedicated project website.
Over 30,000 people are killed in motor vehicle crashes on US roadways every year. Driver distraction from secondary in-vehicle activities, particularly among young drivers, has emerged as a major cause of motor vehicle crashes. A substantial amount of research has been focused on analyzing small sets of naturalistic driving or simulated data to study a small number of features for detecting the driver's engagement. However, many meaningful dependencies and patterns can only be discovered by large collections of data. In this project, the goal is leveraging the two petabytes federal database of naturalistic driving data to develop predictive analytics for detecting a driver's disengagement from the driving tasks in order to provide alerts to drivers and reduce the risk of motor vehicle crashes. <br><br>In this project, data pre-processing techniques are investigated for the large volume of heterogeneous data with over 100 variables in Strategic Highway Research Program 2 (SHRP 2). Two scalable predictive analytics algorithm families based on instance-based learning and heterogeneous network mining for predictive modeling are developed. In addition, a novel distributed computing infrastructure to support the scalable predictive analytics in performing pattern mining of driving behavior analysis, modeling, and prediction are developed. The research outcomes of this project shed a significant amount insight into current work of injury prevention due to motor vehicle crashes. The project extends the capability of machine learning, sensor informatics, and driving behavior analytics. The integrated education plan includes incorporating the research findings in courses offered at the Master of Science program in Health Informatics. The outreach plan involves organizing workshops, conferences, and seminars to disseminate the research outcomes.
Recent technological and scientific advances have allowed the acquisition of vast amounts of various types of data. Such an abundance of information should lead to new scientific understanding and breakthroughs. However, the large-scale nature of this data introduces serious complications that choke classical data analysis techniques, leading to a stagnation of scientific progress in many areas. This issue requires novel mathematical techniques in order to effectively extract and analyze the information. This project will use Lyme disease data (through a collaboration with LymeDisease.org) as a motivating example in the design and testing of the methods, as it serves as a prime example of complex large-scale data with very significant impact to a fast growing community. The results of this project will thus have swift societal impact; for example, analysis on the LymeData will not only further the understanding of the disease itself, but will also lead to more accurate and precise diagnoses, and more personalized and effective treatments for patients. In addition, this proposal will support the education of postdoctoral, graduate and undergraduate students, and facilitate outreach efforts aimed especially at increasing the participation of under-represented populations. To accomplish this task, in addition to the activities funded by this proposal, the PIs will utilize existing programs such as the Women In Technology Sharing Online (WitsOn) program, Women in Data Science and Mathematics Research Collaboration Workshop (WiSDM), and MAPS 4 College of Los Angeles, all in which the PIs are already actively involved, to recruit under-represented populations and to promote the mathematical and technical sciences.<br><br>The fundamental research in this project will center around three main objectives, each addressing a particularly important challenge that arises in large-scale data applications. The first goal is to design innovative data completion techniques that are practical for big data; this will involve the design and theoretical development of data completion methods using non-random (and non-uniform) observation patterns, adaptive sampling schemes, and utilizing additional structures hidden in the observations. Rather than using classical (computationally expensive) convex programming techniques, the project will focus on extremely efficient simple solvers that can be run in real-time during an inference task. Secondly, the team proposes two novel deep learning approaches for inferential tasks that (i) are extremely computationally efficient and can thus be applied to massive datasets, and (ii) achieve the accuracy benefits of modern deep learning approaches, which improve upon state of the art methods. Third, the project will develop critical data fusion techniques that allow data from a wide variety of sources to be analyzed in an aggregated manner. Lastly, the team proposes to combine these three data analysis tasks in a novel multi-stage feedback design where outputs from data completion, deep learning inferences and fusion will be cycled back as inputs to these mechanisms for an iterative and robust inference framework. Progress on these goals will yield new mathematical frameworks in data science, and provide techniques that will be directly applied to large-scale data to allow efficient and powerful data analysis.
Research data and information are critical parts of science. As science becomes more international, so does the need for active engagement internationally. The Council on Data for Science and Technology, as part of the International Council on Science, provides a platform for top-down planning, development and integration of data, data standards, and data access.<br><br><br>The National Academy of Sciences, NAS, is the adhering body to the International Council for Science and its Committee on Data for Science and Technology (CODATA). The U.S. CODATA, housed at the NAS, represents the U.S. data community and coordinates with CODATA's<br>international activities. The U.S. CODATA will participate in the International Council for Science and conduct a meeting of U.S. CODATA to identify further activities. These might include consensus studies, workshops, conferences, and other activities within its mission to advance data management challenges in the U.S.; fulfill a convening function to encourage and facilitate collaboration across disciplines, sectors, and nations with regard to common interests in research data and information activities; monitor, assess, and contribute to the development of U.S. government and research community positions on research data and information programs and policies; and broadly disseminate and communicate the results of the U.S. CODATA's activities to the U.S. scientific community and to the general public.
Bioinformatic data sets are large and complicated. Marshalling and managing necessary resources (e.g., hardware; computer and programmer time) requires significant skill. Effective analysis and comprehension involves sophisticated statistical understanding. Domains of application and available data types change rapidly, requiring flexible and familiar programming environments. Collaborations involve diverse research groups of heterogeneous size and expertise. This project develops and disseminates new and efficient approaches to solving present and emerging problems in statistical analysis and interpretation of very large data. The project combines the strengths of two very widely used and complementary bioinformatics projects, Bioconductor and Galaxy.<br><br>The project has three components. The first, providing scalable access, develops R programming paradigms appropriate for scalable analysis. R/Bioconductor software will be developed for efficient reduction of large data to statistical descriptions by iterating data through transformation kernels. Bioconductor will be deployed for use in an accessible cloud-based environment, and will be integrated into the Galaxy deployment scheme. The second component is to provide statistical methods for big genomic data bydeveloping high performance statistical methodologies for analysis of large bioinformatics data. This applies the initial technical achievements to specific requirements of statistical analysis in genomics. Domains of application include: quality assessment and normalization of very large raw data; data reduction and uncertainty measure calculation for downstream interrogation; and discovery, reporting and auditing of novel biological findings. Developments require novel computational approaches that avoid all-data-in-memory computational models (prevalent in current algorithm implementations), and that re-express monolithic algorithms as concurrently executable independent components. This emphasizes extensible and composable elements to yield a richer toolkit for statistical genomics. The aim leverages R?s strength as a language for rapid development of statistical methodologies, and emphasizes areas of proven strength in the Bioconductor project. The third component addresses decision making. This aspect provides integration of R / Bioconductor work flows into Galaxy. We will deploy key results from Aim 2 as Galaxy work flows. New real-time feedback for streaming analytics will be introduced to Galaxy, and leveraged by Bioconductor.<br><br>The project includes very significant capacity building. The Bioconductor project successfully solicits, tests, and disseminates over 600 R packages for the statistical analysis and comprehension of high-throughput genomic data. All packages include extensive documentation, including vignettes describing intent, function, and interoperability. Packages reflect contributions from a broad scientific community, and enable national and international graduate, post-graduate, and commercial research activities in statistical, bioinformatic, and computational domains. This project furthers the capacity building impact of Bioconductor by addressing memory and performance limitations to statistical analysis of large and complicated bioinformatic data. Galaxy enables broad access to computational resources for data intensive biomedical research. This project enhances the capacity building impacts of Galaxy by providing scalable processing of big bioinformatic data, and enabling exploratory analysis by a broad bioinformatic community. The coupling of Bioconductor and Galaxy provides significant synergy, facilitating rapid translation of statistical and bioinformatic research developed in R to broad use through Galaxy.
A key challenge in natural language processing is defining the computational representation of words. Data-driven distributional approaches use corpora to induce vector-space representations for words, based on the contexts they occur in. This project goes beyond traditional approaches (e.g., latent semantic analysis; Deerwester et al., 1990), which use words that tend to occur near a word in corpora to define the context, by extending the types of contexts used in constructing semantic vectors. First, this project incorporates translation contexts, i.e., words readily available in multilingual parallel corpora, alongside traditional monolingual corpora. This allows evidence-sharing across languages, most importantly from resource-rich languages with large corpora to more resource-poor languages. Second, this project incorporates social context inferable from social network platforms, captured through author, time, geographic, and social connection metadata. Taken together, these additional features give a broader definition of a word's context and lead to a more unified approach to the distributional approach to modeling human language, moving in the direction of a language-independent semantics. The project focuses on ten typologically diverse languages representing several major language families (English, Arabic, Chinese, Spanish, Russian, German, Portuguese, Swahili, Malagasy, and Farsi). A key emphasis is scaling up algorithms for inferring distributional representations to web-scale corpora and dealing with much larger contextual vectors representing the expanded notion of context. The approach also leverages noisy syntactic processing to enable syntactic information, rather than just information about neighboring words, to be considered when defining context.<br><br>In addition to improving the quality of the learned lexico-semantic representations by including richer contextual information, this project creates lexical semantic representations that link word types across languages. These have direct use in text processing applications such as text categorization, machine translation, information extraction, and semantic analysis of text, and they will enable the construction of robust lexical semantic resources in lower-resource languages that benefit from the richness of resources in languages they are paired with. The multilingual vector representations produced will be released to the research community and will be used in undergraduate class projects. The project provides integrated educational and research experience for two graduate students in a dynamic research environment. The project website (http://www.ark.cs.cmu.edu/BigMultilinguality) will be used for dissemination of results.
The growth in wind farm installations in the past years has led to an increase in the number of wind turbines reaching the end of their manufacturing warranties. Therefore, the wind industry is now faced with a rising cost of unscheduled maintenance which is increasing operation and maintenance expenditures. This research project will develop new operation and maintenance strategies for improving the reliability of wind farm systems so that wind energy cost can be reduced. Wind turbines operate under harsh conditions that lead to wind turbine component failures, which are difficult to predict. Consequently, it is challenging to schedule maintenance actions so that such component failures can be avoided or minimized. Because of the continuously escalating cost of wind farm operation and management in the United States, devising methods for using available wind turbine sensors data is critical to decreasing wind farms operational costs. To accomplish this objective, this research considers new maintenance scheduling models and algorithms that take into account data uncertainties in turbines status, weather conditions, and the availability of the resources needed to perform maintenance. If successful, this exploratory research will enable faster initial maintenance response and better utilization of limited maintenance resources in wind energy systems. The efficient utilization of costly resources will foster competitiveness and will contribute towards reducing the cost of wind energy, achieve electricity price stability, and reduce dependency on global fuel markets. <br><br>There is a need to establish guidelines to reduce operation and maintenance costs in wind energy systems. In pursuit of this goal, the objective of this research is to establish how stochastic online data-enabled models and algorithms can lead to wind turbine rapid damage detection and failure reduction. Stochastic online optimization is a suitable framework for this problem since it explicitly assimilates stochastic data that evolve over time into the optimization model, enabling robust decisions to be made sequentially prior to observing the entire stochastic data stream. The project motivation comes from the need for a data-driven methodology for maintenance planning in wind energy. The proposed work will address basic scientific and engineering challenges toward the successful derivation of a data-driven stochastic online optimization algorithm for the operation and maintenance of wind energy systems. This research will advance the state-of-the-art in wind farm operation and maintenance by contributing computational and data-enabled concepts, models and algorithms. The outcomes of this research will extend how maintenance is scheduled in wind energy systems to a new level beyond the current state of practice by introducing: 1) data-driven optimization models for maintenance and resource scheduling and 2) new algorithms for stochastic online optimization. In particular, the new data-driven methodology, integrating stochastic programing with stochastic online optimization, which are usually treated in isolation, will give rise to a new and viable approach for stochastic data assimilation into decision-making under uncertainty for complex multi-entity engineered systems such as wind farms.
As a part of a White House sponsored "Data to Knowledge to Action" event held in November 2013, dozens of public and private organizations met to announce an array of Big Data related collaborations. To sustain the forward momentum of the Data2Action event, the National Science Foundation has been working to establish a national network of "Big Data Regional Innovation Hubs." These hubs will stimulate, track, and help sustain new regional and grassroots partnerships around Big Data. This series of 5 workshops will support four Big Data Regional Innovation Hubs centered in the Northeast, West, Midwest, and South regions the United States. These hubs will help Big Data stakeholders from different sectors (e.g. industry, academia, non-profits, local government) partner around collaborative projects that will further Big Data innovation in their geographic region. The Hubs could take on activities including but not limited to accelerating development of Big Data solutions, forging collaborations across sectors, help share best practices, speed up technology transfer, instigate dialogue between thought leaders on social impacts of Big Data, and supporting the education and training of the Big Data workforce. The first four events will provide a space for stakeholders to exchange ideas, discuss potential projects, and devise a set of actionable goals within their region. The final summary event will bring together members of each of the four regions together to synthesize their conclusions and develop action items, as well as discuss cross regional-collaboration. As a part of this workshop series, a virtual community platform will be established so that interested stakeholders that are not able to attend the live events can connect and collaborated with other interested parties in their region; this platform will be made available and open to users for one year. The primary outcome of this meeting will be a consensus on the design and governance of each regional Hub by major Big Data stakeholders in the region and plan of action for implementing the Hub. A summary of this information will be made available in written form by workshop organizers; supplemental information will be available on the virtual platform and supplied by workshop participants.
This research will leverage ideas from algebraic and differential geometry to address core problems in modern high-dimensional and massive data science. The project will develop statistical methods and numerical tools, grounded in solid mathematical, statistical, and computational foundations, to extract low dimensional geometry from massive data with applications in clustering, data summarization, prediction, dimension reduction, and visualization. The solutions developed as part of this project can result in fundamental advances in practical applications across fields as diverse as biology, medicine, social sciences, communication networks, and engineering. In addition to internal validation via statistical and mathematical theory and simulation studies, the methods developed in the project will involve external validation via interdisciplinary applications. These applications include: (1) inference of population structure from genomic data; (2) document analysis via topic models; and (3) inference of subsets of putative gene networks relevant to drug resistance in melanoma.<br><br>The research is motivated by the central premise that, even though the amount of data may be massive, a compact model can represent these data. Specifically, high-dimensional and/or massive data can be reasonably approximated by a mixture of subspaces, for which sparse representations exist. A mixture of subspaces of potentially different dimensions is a flexible, rich representation of data with nice mathematical properties that can scale to large data. There are several fundamental challenges in modeling mixtures of subspaces that will be addressed in this research: 1) the subspaces will be of different dimensions, 2) both the subspace parameters and the mixing parameters need to be inferred, 3) efficient algorithms for inference are required for both high-dimensional and massive data. The central foundational impediment in all of these challenges is that the model is a stratified space (a union of manifolds), and therefore has singularities. The key insight in this research is that there exist embeddings and representations of the model space that mitigate these singularities. These ideas are implemented as concrete Bayesian, frequentist, and numerical algorithms and models to address the real world examples listed above.
This 1.5 day invitation-only workshop will be held in Washington DC in early 2013, and will address challenges in information sharing and coordination in financial market regulation. Topics to be addressed include the challenges created through the volume and complexity of the data as well as the dynamic relationship between markets, financial instruments, technologies, and institutions involved in the markets and their regulatory processes. Therefore, computational scientists as well as information and social scientists will be included among the participants, and participants from industry, academia, and government will be invited. A workshop report will be published a s a result of this workshop.<br><br>The 1.5 day invitation-only workshop, to be held in Washington DC in early 2013, will address challenges in information sharing and coordination in financial market regulation. Topics to be addressed include the challenges created through the volume and complexity of the data as well as the dynamic relationship between markets, financial instruments, technologies, and institutions involved in the market and the regulatory process. Experts in computational science, information science, and social science will be invited from industry, academia, and government. The multi-disciplinary approach will increase the likelihood of impact on future regulatory practices.
The past decade has seen dramatic growth in systems that collect data from human activities. Online social networks record not just friendships, but interactions, messages, photos, and interests. Mobile devices track location via GPS information. Online stores monitor millions of customers as they explore and transact. Sensors, wearable and otherwise, produce detailed behavioral data. Collectively, this provides ever-larger collections of human social-activity information -- we refer to this as Big Social Data. While Big Social Data is growing rapidly, the available processing resources -- CPU, memory, communication -- are growing at a slower pace. To realize the promise of big social data, we need algorithms that use only sublinear resources, that is, resources growing much less than the growth of the data in suitable parameters. Designing these algorithms will be the core activity of this research project. This work will be in consultation with practitioners handling Big Social Data, leading to many opportunities for technology transfer. The research program both enables and benefits from an education and outreach program that will help develop the new breed of algorithmically-trained data scientists for Big Social Data.<br><br>Emerging systems -- MapReduce, Hadoop, Spark, Storm, etc. -- use large scale distributed computation: clusters of machines not only gathering and storing data in parallel, but also working together to perform computations. Often, these systems and applications work via incremental processing, storing and returning only approximate solutions, trading off quality and certainty for efficiency. In addition, these systems take a data-centric view, wherein the data is stored as <Key, Value> pairs. This project will address fundamental problems with Big Social Data -- search, ranking, and optimization, etc. in these modern computing and data models. For these problems, this project will design algorithms that are sublinear in the relevant parameter -- number of keys, size of values, computing time per key or over all keys, and other variations that map to underlying storage, number of machines, bandwidth and other computational constraints.<br><br>For further information, see the project web site at http://www.stanford.edu/~ashishg/socialdata.html .
This research will leverage ideas from algebraic and differential geometry to address core problems in modern high-dimensional and massive data science. The project will develop statistical methods and numerical tools, grounded in solid mathematical, statistical, and computational foundations, to extract low dimensional geometry from massive data with applications in clustering, data summarization, prediction, dimension reduction, and visualization. The solutions developed as part of this project can result in fundamental advances in practical applications across fields as diverse as biology, medicine, social sciences, communication networks, and engineering. In addition to internal validation via statistical and mathematical theory and simulation studies, the methods developed in the project will involve external validation via interdisciplinary applications. These applications include: (1) inference of population structure from genomic data; (2) document analysis via topic models; and (3) inference of subsets of putative gene networks relevant to drug resistance in melanoma.<br><br>The research is motivated by the central premise that, even though the amount of data may be massive, a compact model can represent these data. Specifically, high-dimensional and/or massive data can be reasonably approximated by a mixture of subspaces, for which sparse representations exist. A mixture of subspaces of potentially different dimensions is a flexible, rich representation of data with nice mathematical properties that can scale to large data. There are several fundamental challenges in modeling mixtures of subspaces that will be addressed in this research: 1) the subspaces will be of different dimensions, 2) both the subspace parameters and the mixing parameters need to be inferred, 3) efficient algorithms for inference are required for both high-dimensional and massive data. The central foundational impediment in all of these challenges is that the model is a stratified space (a union of manifolds), and therefore has singularities. The key insight in this research is that there exist embeddings and representations of the model space that mitigate these singularities. These ideas are implemented as concrete Bayesian, frequentist, and numerical algorithms and models to address the real world examples listed above.
With an ever increasing ability to collect and archive data, massive data sets are becoming increasingly common. These data sets are often too big to fit into the main memory of a single computer, and so there is a great need for developing scalable and sophisticated machine learning methods for their analysis. In particular, one has to devise strategies to distribute the computation across multiple machines. However, stochastic optimization and inference algorithms that are so effective for large-scale machine learning appear to be inherently sequential.<br><br>The main research goal of this project is to develop a novel "nomadic" framework that overcomes this barrier. This will be done by showing that many modern machine learning problems have a certain "double separability" property. The aim is to exploit this property to develop convergent, asynchronous, distributed, and fault tolerant algorithms that are well-suited for achieving high performance on commodity hardware that is prevalent on today's cloud computing platforms. In particular, over a four year period, the following will be developed: (i) parallel stochastic optimization algorithms for the multi-machine cloud computing setting, (ii) theoretical guarantees of convergence, (iii) open source code under a permissive license, (iv) application of these techniques to a variety of problem domains such as topic models and mixture models. In addition, a cohort of students who can transfer their skills to both industry and academia will be trained, and a graduate level course on scalable machine learning will be developed.<br> <br>The proposed research will enable practitioners in different application areas to quickly solve their big data problems. The results of the project will be disseminated widely through papers and open source software. Course material will be developed for the education of students in the area of Scalable Machine Learning, and the course will be co-taught at UCSC and UT Austin. The project will recruit women and minority students.
Institutional Review Boards (IRBs) have become understood and widely used in technical fields, especially those relating to information security and privacy, as necessary to protect human subjects in computer studies. However, IRBs do not address all issues. This workshop explores the notion of a broader ethical review procedure in white papers, opinion pieces, and public comments. This multidisciplinary workshop develops how organizations can develop ethical review boards for data uses outside the Common Rule.<br><br>The workshop considers how ethical guidelines, based on the foundational Belmont principles for human subject research, can help entities make careful decisions to balance data experimentation against risks to individual privacy and civil liberties broadly. It surveys lessons drawn from the medical research ethics community and existing institutional review boards (IRBs). The purpose of this workshop is to bring together experts in academia and industry, as well as ethicists, privacy officials, and government regulators, to develop a blueprint for ethical reviews for computer science research, and provide guidance to those who might seek an ethical opinion to engage in important research, and find a balance to promote research.
Machine learning algorithms are now routinely used to build predictive models from data in wide range of applications. However, current approaches to machine learning have an important limitation: They assume that the set of classes observed in a training data set is exhaustive and that new data samples originate from one of the existing classes represented in the training data set. This assumption is unrealistic in many real-world applications in which previously unobserved classes of interest emerge. <br><br>This study explores a new class of machine learning algorithms that produce self-adjusting models that can accommodate new classes observed in data in offline as well as online learning scenarios. The project aims to (i) use non-parametric models to dynamically incorporate the changing number of classes; (ii) develop new online and offline inference techniques to accommodate new classes as they emerge (iii) automatically associate newly discovered classes with higher-level groups of classes in an attempt to identify potentially interesting class formations, and (iv) develop partially-observed tree models containing observed and unobserved nodes, where observed nodes represent existing classes and unobserved nodes are introduced online to fill the gaps in the existing data hierarchy that become evident only with the arrival of new data.<br><br>The broader impacts of this work could extend to several real world applications: Bio-security and bio-surveillance, information retrieval, and remote sensing among others in settings where all of the classes are not known a priori. The educational plan includes outreach to K-12 students and enhanced research opportunities for undergraduate and graduate students in computer science as well as at the intersection of computational and life sciences. All the software, publications, and data sets resulting from the project will be freely disseminated to the larger research and educational community. Additional information about the project can be accessed through the project website at http://www.cs.iupui.edu/~dundar/career.html
Due to the globalization of the integrated circuit (IC) supply chain, the reduction of manufacturing costs and the need for shorter time to market, commercial-off-the-shelf ICs are now prevalent in modern electronic systems. However, the wide usage of such components breeds major security and trust concerns. Validating the security and trustworthiness of these components is extremely challenging since the end user does not have access to the design details. Furthermore, the cost to patch hardware level design flaws and/or hardware Trojans always costs more than patching eventual software vulnerabilities.<br><br>This project develops an automated trustworthiness and security analysis framework to help end-users address their concerns by reconstructing the behavioral description of commercial-off-the-shelf ICs and analyzing such description for functionality identification and detection of design flaws and/or potentially inserted hardware Trojans and backdoors. This tool suite offers an all-in-one technology to allow engineers to quickly go from physical circuit structure/netlists to behavior/specification and validate the security and trustworthiness of any digital ICs, through data-path and state register identification, state transition graph construction and decomposition, data flow recovery, high-level behavioral design reconstruction, and whitelist- and blacklist-based functionality determination and hardware Trojan/backdoor detection. As a Transition to Practice (TTP) project, the research team is also closely collaborating with an industrial partner in developing, integrating, and validating the tool suite, so that a holistic and practice-oriented hardware security tool suite is provided for protecting the IC supply chain.
Software is a critical element in a wide range of real-world applications. Attacks against computer software can cause substantial damage to the cyber-infrastructure of our modern society and economy. In fact, many new software security vulnerabilities are discovered on a daily basis. Therefore, it is vital to identify and resolve those security issues as early as possible. This research aims to investigate a scientific foundation and a novel methodology for automated detection, prevention, and resolution of prior-known software security vulnerabilities in software systems. The results will help to detect and prevent prior-known security vulnerabilities from recurring in other software systems.<br> <br>In this research, the key philosophy is that the software systems having the same/similar software security vulnerabilities share the protocols, algorithms, procedures, libraries, frameworks, modules, or source code with the same flaws, and they suffer the same/similar exploitation mechanisms. Based on that, empirical studies are conducted to investigate the nature and the characteristics of recurring software vulnerabilities in different software systems, and to validate that hypothesis. Based on the knowledge gained from the studies, new vulnerability models, representations, and similarity measurements are developed to capture recurring software security vulnerabilities, and the corresponding vulnerable code and exploitation mechanisms. Novel algorithms and techniques are designed to (semi-)automatically build graph-based vulnerability models from vulnerability reports and from vulnerable code and patches, aiming to construct a database of prior-known vulnerabilities. A new methodology is developed to help to identify the prior-known vulnerabilities in other systems and to suggest the resolution. Specifically, the automated methods and advances include 1) an algorithm to compare and match against vulnerability models in the database, 2) a technique to map software concepts between security reports and from a report to the corresponding source code fragments, modules, or components; 3) an algorithm to determine the modules and source file locations in the new system that correspond to the vulnerable modules and locations in a system with a prior-known vulnerability; and 4) a technique to suggest the patch to the new system from the prior fixes. In brief, the results of this research help to resolve early software security vulnerabilities. They will lead to more reliable software because the process of detecting and patching for recurring security vulnerabilities will be more efficient and effective.
On-line sharing of images has become a key enabler of users' connectivity. Various types of images are shared through social media to represent users' interests and experiences. While extremely convenient and socially valuable, this level of pervasiveness introduces acute privacy concerns. First, once shared images may go anywhere, as copying / resharing images is straightforward. Second, the information disclosed through an image reveals aspects of users' private lives, affecting both the owner and other subjects in the image. Malicious attackers can take advantage of these unnecessary leaks to launch context-aware attacks (e.g., spearfishing) or even impersonation attacks. This project is developing methods to help users appropriately control access to their shared images.<br><br>The investigators are developing new techniques to tackle image privacy based on the image content as well as images and users' meta-data, by (a) inferring the sensitivity of a given image based on the visual properties of the images and the users' image sharing patterns, and then automatically applying the appropriate privacy settings for that image, and (b) by using discovered users' sharing patters to define access policies according to the locally enforceable controls on the domain of interest. Beyond the technical results, this project is developing a framework for understanding the common classes and categories of images with respect to the users' understanding of privacy. This framework will enable an understanding of the images that need protection and help improve user awareness of classes of images that are often unintentionally or accidentally under-protected.
Organizations need to protect their computer systems from attackers. They often group their own computers into risk pools to reduce threat propagation and monitor the communication between these groups. Unfortunately, this boundary monitoring is unable to see traffic within groups and, since each monitor is segmented, they cannot form a holistic picture of the entire network. Finally, modern approaches must examine network traffic in isolation, without the ability to know what action on the originating computer caused it.<br><br>This project addresses these limitations in network control and understanding by creating a centralized access control system for all network traffic. With monitoring software on each computer, the access controller learns about the originating host's operating context and the application that initiated the network traffic. This empowers the access controller to make informed decisions.<br><br>To achieve these goals, the project investigates three directions: 1) it monitors computer requests to translate human-readable host names into computer-routable addresses, 2) it forces all traffic, even within a risk pool, to receive approval from a router and access controller, and 3) it instruments each computer with software that monitors each application's network traffic and interactions with the human operator to provide a context to the access controller. <br><br>This project will increase the security of computer systems and networks, which will have a direct impact on government, military, educational, and industrial organizations. The project will improve educational experiments at both the graduate and undergraduate levels while also supporting extracurricular educational activities, such as cyber security competitions.
Next-generation sequencing (NGS), which allows sampling millions of short DNA sequences from a genome, has revolutionized the field of genomics. One area of particular importance is the reconstruction of genomes (haplotypes) from a viral population, which is a fundamental problem in virology, evolutionary biology, and human health. Though there have been several methods developed to take advantage of NGS data, those are limited to populations for which a reference genome is available. This excludes many important cases, such as RNA viruses or certain HIV/HCV viral populations. In such situations, the haplotypes are sufficiently divergent as to render the reference meaningless. Moreover, most algorithms are not robust in the presence of recombination, which is a common occurrence in many viral populations. The achievement of this project's aims will allow for the full potential of NGS data to be realized in the field of virology. In particular, it will help to propel the understanding of viral population dynamics and give biologists powerful tools to understand disease progression and enable novel treatment and prevention strategies. The algorithms and software developed will be made freely available for use through software sharing platforms like GitHub or Galaxy. The PIs will offer a strong educational component including (a) graduate and undergraduate classes that use the output of the proposed research, and (b) development of a seminar series. The PIs will (a) train future generations of scientists and engineers to enhance and use bioinformatic/genomic cyber resources; (b) facilitate creative, cyber-enabled boundary-crossing collaborations, including those with industry and international dimensions, to advance the frontiers of science and engineering and broaden participation in STEM fields.<br><br>This project?s aim is to develop probabilistic De Bruijn graphs and network flow on such graphs for the reconstruction of viral population when a reference is not available. Given NGS data, the algorithms should determine the number, sequences, and relative frequencies of the haplotypes. This project's proposed algorithms are based on a unique combination of established techniques (e.g. maximum likelihood, expectation-maximization, clustering, Lander Waterman statistics) with novel propositions for probabilistic De Bruijn graphs, machine learning, and network flows that are of interest in other applications. The PI and Co-PIs have complementary backgrounds in virology, machine learning, network flow, and genome reconstruction problems.
Secure Sockets Layer (SSL)/Transport Layer Security (TLS) protocols are critical to internet security. However, the software that implements SSL/TLS protocols is especially vulnerable to security flaws and the consequences can be disastrous. A large number of security flaws in SSL/TLS implementations (such as man-in-the-middle attacks, denial-of-service attacks, and buffer overflow attacks) result from incorrect error handling. These errors are often hard to detect and localize using existing techniques because many of them do not display any obvious erroneous behaviors (e.g., crash, assertion failure, etc.) but they cause subtle inaccuracies that completely violate the security and privacy guarantees of SSL/TLS. This project aims to improve error handling mechanisms in SSL/TLS implementations by building novel tools that reduce developer effort in writing and maintaining correct error handling code while making SSL/TLS implementations more secure and robust. <br><br>This project develops a framework for improving the robustness of error handling code in SSL/TLS implementations. The framework has three main objectives. First, error specifications for different SSL/TLS functions are automatically inferred to learn how they communicate the failures. Next, the inferred specifications are used to build a tool for automatically detecting error handling bugs. Finally, the framework also provides new program repair tools that can automatically fix the detected bugs. Therefore, the framework provides end-to-end assistance in maintaining error-handling code in SSL/TLS implementations and thus significantly improves internet security.
Our world has become increasingly reliant on integrated circuits (ICs). Mobile phones are deeply enmeshed in our everyday lives, we drive cars equipped with hundreds of ICs, and have come to depend on the power grid and other cyber physical systems that are controlled by ICs. Not surprisingly, the issue of securing hardware has become increasingly vital. A reverse engineering adversary may, for example, be motivated by extracting intellectual property from a circuit, cloning a design for product piracy, or creating a targeted backdoor for stealing cryptographic keys. In many real-world settings, we have to assume a strong attacker who has full access to the IC and can analyze all hardware features therein. Numerous hardware attacks over the last few years have shown that reverse engineering is a surprisingly easy task. The goal of this project is to develop strong and quantifiable protection mechanisms for ICs. <br><br>This interdisciplinary project combines security engineering, formal verification and circuit design, with the aim of creating strong obfuscation techniques that thwart IC reverse engineering. The approach is based on integrated circuits that perform a substantially different function than the one an attacker would infer from its physical structure. The investigators will explore a broad design space of low-level stealthy circuit manipulations and higher-level obfuscation techniques that remove structural and functional boundaries. A crucial component of the project is the development of sound metrics to measure the level of achieved security. As part of community engagement, this project envisions a De-obfuscation Challenge that will involve research groups from academia and industry.
In the current Internet-connected world, most companies, government agencies, and the public heavily rely on the cyber world for information and data management, processing, and exchange. Information leakage and data breaches have become increasingly damaging to businesses, the government, and people's lives. Correspondingly, hackers have more incentive to attack for financial and political gains. While the existing cybersecurity curricula focus on defensive solutions, this proposed online program from the University of Central Florida attempts to provide both defensive and post-attack digital forensics curriculum for dedicated digital forensics students and professionals. This project will enrich the future cybersecurity workforce with both preventative and post-attack digital forensics skills to effectively counter the cause and effect of cyber-attacks. This program will also help alleviate shortages of qualified digital forensic researchers and practitioners in cybersecurity areas.<br><br>Specifically, in this project, the researchers will build an online digital forensics program including two introductory courses and seven hands-on labs. The program will help build the necessary background for students and professionals to perform high pressure, skilled post-attack digital forensics analysis and incident responses. Students and professionals will acquire digital forensics knowledge to tackle future challenges in emerging cyber-systems such as networked critical infrastructures. Meanwhile, as computers and smart devices penetrate every aspect of our life, digital forensics training should not only cover traditional personal computers but also emerging smart devices, including smart phones and Internet of Things (IoT). Upon this request, this program also includes course materials and hands-on labs on forensic analysis of smart phones and IoT devices. The principal outcomes of the project will be enhancing cybersecurity curricula to include digital forensics courses and hands-on lab modules that focus on evaluating and analyzing cyber-attacks and countermeasures at the post-attack stage. Through this project, students and professionals will be prepared with the digital forensics knowledge necessary for them to undertake specific roles in future cybersecurity and digital forensics careers. Further, hands-on labs are emphasized in the project since these can help students solidify their knowledge from coursework and will eventually prepare them for real-world cybersecurity challenges.
The interaction between computer processors -- the hardware at the heart of our computers, tablets, and phones -- and software -- apps, web browsers, and other applications -- is governed by an Instruction Set Architecture (ISA). The ISA is the specification that defines how the processor will respond to commands from the software. It is large and complex, too large for a person to understand and reason about all the interactions between different parts completely. As a result, security vulnerabilities exist in the ISA. These vulnerabilities can sometimes be exploited by attackers to steal data or take control of the machine. This research is about detecting security vulnerabilities that exist in the ISA. Finding and removing these vulnerabilities will create a more secure foundation for all our computing activities. This will benefit government agencies that require high assurance environments, cloud providers that rely on hardware features for the security for their service, and users who, more and more, are relying on diverse hardware components from a variety of hardware design companies to handle their private and sensitive data.<br><br>The researchers posit that vulnerabilities in the ISA happen in one of two ways: 1) Erroneous specification: the ISA prescribes behavior that is dangerous; or 2) Nondeterminism in the specification: the ISA is incomplete and one of the possible behaviors allowed by the specification is dangerous. The hypothesis of this research is that it is possible to focus on a relatively small subset of the ISA for which these types of errors are likely to occur. The researchers are developing a practical methodology for discovering for which instructions vulnerabilities are most likely to occur. With that information, they are developing tools to detect and correct security-critical errors in the ISA. In addition to making a practical contribution, the research activities are improving understanding in the computer science community of what a vulnerability in an ISA looks like and where and under what conditions it is likely to occur. This will enable future verification efforts to concentrate on the most security-critical aspects of the ISA.
Common shared keys, which can be used for encryption/decryption, authentication and various other security primitives, plays a fundamental role in securing modern digital systems. Due to such significant importance, there has been a tremendous amount of work on the design of key generation/distribution schemes. Despite of these efforts, significant challenges, such as scalability and availability, remain to be fully addressed. This project investigates information theoretic approaches for secret key generation with focuses on fundamental and challenging issues under more realistic models. The resulting schemes are anticipated to be more easily applied to the design of practical wireless networks. The project will leverage collaboration with industries and will actively involve students with various backgrounds.<br><br>In particular, the project will develop key generation schemes under the framework of key generation via public discussion. The standard scheme under this framework is a so-called "omniscience" scheme. However, such a scheme requires all nodes in the network to transmit, assumes the public discussion is heard noiselessly by all nodes in the network, and does not take the implementation complexity into consideration. While these assumptions enable the tractability of the problems and facilitate to obtain crucial insights, in order for such studies to provide useful and accurate guidance in practice, realistic constraints must be taken into consideration, which pose three fundamental directions that this project will explore. In this project, thrust 1 focuses on key generation with vocality constraints that addresses the following fundamental question: for a general source network, is it possible to design schemes that involve only a subset of nodes to talk but still achieve the key capacity? Thrust 2 focuses on key generation with physical channel constraints. In particular, motivated by constraints associated with physical channels, the project will design key generation scheme for scenarios when the public discussion of each node can only be received by nodes in its transmission range and the simultaneous transmission of multiple nodes will interfere with each other. Thrust 3 focuses on key generation with complexity constraints and investigates how to minimize the complexity in the design of key generation schemes and how to reduce computational resource consumption required for key generation schemes.
Informally speaking, Secure Multi-Party Computation (SMPC) allows two or more parties to jointly compute some function on their private inputs in a distributed fashion (i.e., without the involvement of a trusted third party) such that none of the parties learns anything beyond its dedicated output and what it can deduce from considering both this output and its own private input. Since its inception in 1982 by Yao, SMPC has advanced greatly and over the years a large body of work has been developed. To date, prominent applications for SMPC include private set intersection, auctions, and data mining. However, despite all advances, there still are many areas of application for which the use of SMPC has not yet been explored. Considering the fact that SMPC allows one to achieve strong security guarantees, the use of SMPC should be further advanced into fields of application which require the handling of highly-sensitive information of multiple parties in a centralized fashion and as such exhibit great promise to substantially benefit from the use of SMPC techniques. Such an area of application is organ donation. Currently, more than 120,000 patients in the U.S. alone are waiting to receive a lifesaving organ transplant and the need by far outweighs the number of available organs. Increasing the pool of organ donors is challenging and reports of organ scandals have even resulted in a decline in the number of potential organ donors. On one hand, transparency and fairness in the allocation process was shown to influence the willingness to donate organs. In turn, it is argued that in the case of living donations (where a patient has a willing donor but the donor's medical characteristics are not compatible with those of the patient), the recipient of the organ donation should have the right for the transparency to be limited. As such this project seeks to explore whether it is possible to effectively and efficiently introduce SMPC into the context of organ donation with the goal to ensure suitable transparency and privacy guarantees for donors and recipients alike. The potential impact of this work is substantial---for individual patients and society at large---in that addressing common attacks on traditional organ donation systems may not only help rebuild lost trust but may even lead to a greater buy-in than ever before.<br><br>For living donations, the project seeks to devise initial protocols which allow the determination of donors in a cyclic fashion such that (a) it does not require a trusted third party, (b) the attributes of all patients and donors are kept private at all times, (c) all parties are satisfied with the exchange, (d) application-specific requirements are met, and (e) it is secure even in the presence of adversaries. For post-mortem donations, the project will explore the suitability of traditional privacy-preserving matching approaches---recognizing that matching the characteristics of organs come with unique challenges and requirements. Also, the project will investigate whether it is feasible to introduce a systemic change to how post-mortem organ donation is carried out today.
This award will support student travel to the 2015 New Security Paradigms Workshop to be held in Twente, the Netherlands, in September 2015. The New Security Paradigms Workshop (NSPW) provides a stimulating, safe, and highly interactive forum for innovative approaches to computer security. NSPW encourages graduate students and junior faculty to examine long-held ideas within computer security. It also strongly encourages non-computer security experts from economics, sociology, psychology, and other disciplines to bring their expertise to bear on computer security paradigms. The support from NSF will be used to sponsor travel expenses for graduate students and junior faculty to attend the workshop. Supporting junior researchers' travel to attend professional conferences and workshops is a very important mission of the NSF. Broader impacts include training the next generation of researchers in this important research area.
With billions of smart wireless devices being ubiquitously deployed, safeguarding their networking from cyber attacks has become a challenge. Not only can the devices deployed in a network can be heterogeneous in terms of available computing resources and interfaces, but ordinary users typically have limited technical expertise to perform complicated security configurations. What's more, trust among the devices is often lacking because of the different vendors or distribution channels they have traversed. This project addresses these challenges and proposes a suite of lightweight protocols for initial trust establishment and secure networking of wireless devices. Intrinsic properties of wireless channels, which are available to most wireless devices, are utilized to minimize the dependence on user engagement, prior secrets or any hardware not commonly seen in most smart devices. <br><br>Three research thrusts are proposed to achieve the project's objectives, which take into consideration devices with limited cryptographic capabilities and those with no cryptography at all. The first task aims at minimizing user involvement in the trust initialization process without assuming any extra resources, which is achieved with an obfuscated in-band message authentication protocol. The second task puts forward a mobility-aided authenticated secret key extraction technique without any explicit user involvement. The third task explores key-free wireless security utilizing friendly jamming; a geometry-based computational model is proposed for optimizing the network deployment. The results of this project will lay the foundation for designing extremely lightweight and highly usable secure trust initialization and networking protocols that are compatible with most commercial off-the-shelf smart wireless devices.
Critical to the health and resiliency of the Internet is the underlying security of the systems that make our online world a reality. By bringing together leaders in cyber security, including leading-edge security researchers and implementers, globally recognized security-technology experts, and users from both the private and public sectors, the Network and Distributed System Security (NDSS) Symposium fosters information exchange among researchers and practitioners of network and distributed system security. The target audience (usually around 300 people) includes those interested in practical aspects of network and distributed system security, with a focus on system design and practical implementation. The February 2017 conference in San Diego will be the 24th NDSS symposia, demonstrating its longevity and its importance as the leading conference in network and distributed system security.<br><br>Students often have limited sources of funds for travel to conferences and limited opportunities to interact with in-the-field practitioners. NSF financial support will assist nineteen (19) US-based graduate and undergraduate students so that they may attend this meeting. Each travel grant is intended to cover conference registration, lodging during the conference, and as much as possible of the student?s travel (e.g., economy airfare). <br><br>Participation in symposia like the NDSS is a critical part of the students' educational experiences, providing them the opportunity to interact with senior researchers and to be exposed to leading edge work in the field. Regardless of the field, investing in the development of human capital is crucial for the future. Supporting and nurturing the next generation of network security experts, providing them with an opportunity to learn from and engage with established experts benefits the entire community. Each provides the other with lessons learned, fresh ideas, and infuses a spirit of collaboration among a rather small sub-section of the technical space.
The critical role of spectrum as a catalyst for economic growth was highlighted in the 2010 National Broadband Plan (NBP). A challenge for the NBP is realizing optimal spectrum sharing in the presence of interference caused by rogue transmissions from any source, but particularly secondary users who share the spectrum. This complex problem straddles wireless technology, industrial economics, international standards, and regulatory policy. <br><br>This interdisciplinary, multi-university collaborative project studies the many dimensions of the problem from algorithms to law enforcement. The investigators study (1) ex-ante spectrum rule enforcement mechanisms (i.e., preventive) such as spectrum access control via policy reasoners, (2) ex-post spectrum rule enforcement schemes (i.e., punitive) with policy conformance monitoring that employ cryptographic commitments, (3) ex-post enforcement schemes that can uniquely identify rogue transmitters, and (4) the economic viability of spectrum sharing with different enforcement schemes.<br><br>The project provides a broad range of education and industry outreach activities in order to rapidly insert research advances into curriculum and university-industry partnerships. Specifically, the investigators will present short courses and tutorials at the annual Virginia Tech Wireless Symposium and Summer School, and widely disseminate findings through NSF Industry & University Collaborative Research Centers (I/UCRC) at the Virginia Polytechnic Institute and State University.
The objective of this project is to enable archives and libraries to securely deliver born-digital materials to networked patrons. Examples of such materials include commercial and academic publications such as interactive CDROMs as well as the archived materials of citizens. Archives are increasingly accepting disk drives or even entire computers, yet access to such materials requires the use of obsolete software designed for archaic platforms. Further, access to these materials may be restricted to authorized researchers. This project will project will make it possible to deliver such materials over the Internet while retaining institutional control. This will provide further access to materials, many of which may be products of Federally funded research.<br><br>This project will develop and evaluate viable emulator architectures supporting remote access to born-digital materials while addressing three major issues: (1) portability and maintenance of emulator platforms, (2) principled control of required system software, and (3) principled control of digital artifacts. The definition of "principled control" may vary with the materials being accessed -- from copyright control, to secure access to sensitive materials. This project will weave together existing technologies (e.g. trusted platform modules) in potentially novel ways to solve a pressing societal problem.
Software vulnerabilities are a substantial problem that exists in part due to programmer errors. A common cause is that programmers have a cognitive gap between their understanding of what actions code will perform and the actual actions the code performs. This work takes a first step toward rigorously understanding how humans think about code to (eventually) help to dramatically reduce bugs by building more human understandable programming languages and programs. This project will perform a pilot study to determine how to understand such security bugs, tease out the key aspects of them, and integrate this understanding into expert tutoring systems to help programmers detect them.<br><br>Cognitive science techniques will be used to derive the core contributing issues in existing security vulnerabilities by slicing vulnerabilities into their component parts and evaluating the resulting bugs. This will create a generalized understanding of security issues which will enable easy reproduction and replication of similar source code, which is ideal input for an expert tutoring tool. The resulting expert tutoring tool will be used to evaluate the effectiveness of tutoring in helping programmers reduce reduce their susceptibility to similar bugs.
Many systems ranging from consumer electronics to military equipment are dependent on integrated circuits (ICs). Thus, if the underlying IC in a system is maliciously manipulated by a hardware trojan, then the security of the entire system can be compromised. This project investigates hardware Trojans that do not rely on additional logic to affect security.<br><br>The researchers study a class of Trojans that can be realized using low-level manipulations like subtle changes in logic, circuit or manufacturing process. They investigate scenarios where an attacker may take advantage of such manipulations, and develops countermeasures to protect ICs against hardware Trojans. This project explores new threat assessments for many applications of practical relevance. Considering society's reliance on integrated circuits, understanding the threat posed by low-level Trojans in IC design and manufacturing supply chain is of great importance.
This research examines how and why members of the public are using technology to work with nonprofit organizations and begins to explore how new technologies might be designed to foster more productive partnerships between nonprofit organizations and the public. Mobile information and communication technologies have fundamentally changed the nature of grassroots organizing, enabling members of the public to rapidly and flexibly organize themselves in order to accomplish a variety of goals. However, nonprofit organizations have often failed to leverage the public's innovative and civically-engaged uses of technology for their benefit. This research will undertake two synergistic lines of inquiry to address such issues, one consisting of empirical research, and the other developing design principles.<br> <br>A three-phase empirical study will examine the role of technologies in fostering partnerships between the public and nonprofits. The first phase will explore the use of social media, a technology foregrounding social context, for online advocacy. The second will examine distributed work technologies, predominantly foregrounding temporal context, for virtual volunteering. The third will investigate the use of mobile technologies, foregrounding physical context, for mobile giving. Each phase will be motivated by the same high-level research questions, allowing synthesis across phases and generalization about the role of technology in bridging between the public and nonprofit organizations.<br> <br>In the design inquiry, a series of low-fidelity and medium-fidelity prototypes will be developed that embody design recommendations derived from the empirical inquiry, taking advantage of new permutations of social, physical and temporal contexts. A series of focus groups and design workshops will provide feedback to help guide iteration on the design of the prototypes.<br> <br>This research will provide empirical evidence of how technologies used for online advocacy, virtual volunteering and mobile giving influence the dynamics between nonprofit organizations and members of the public. It will advance theoretical knowledge about the role of nonprofits in a changing technological landscape of public civic engagement. This research will also derive theory about the roles of social, physical, and temporal contexts in civically-engaged technology use. <br><br>Understanding the way that members of the public are using technology to work with nonprofit organizations is critical for fostering and designing technologies to support productive partnerships moving forward. This research also provides an opportunity for students to participate in civically engaged scholarship, the kind of scholarship that has been shown to attract the participation of minorities in computing disciplines.
Advances in privacy-enhancing technologies, including cryptographic mechanisms, standardized security protocols, and infrastructure, significantly improved privacy and had a significant impact on society by protecting users. At the same time, the success of such infrastructure has attracted abuse from illegal activities, including sophisticated botnets and ransomware, and has become a marketplace for drugs and contraband; botnets rose to be a major tool for cybercrime and their developers proved to be highly resourceful. It is contended that the next waves of botnets will extensively attempt to subvert privacy infrastructure and cryptographic mechanisms, which has the potential of both undermining their legal basis and future performance. <br><br>This project will develop the theoretical and experimental foundations for analyzing, monitoring and mitigating the next generation of botnets that subvert privacy-enhancing technologies. Towards that goal, the project will develop tools for: 1) Analytical framework: the project develops a concrete strategy for approaching the detection, characterization, and mitigation of abuse of privacy infrastructure by crystallizing an analytical framework for reasoning about such botnets. This includes the identification&#8232;and formalization of their key properties (e.g., traceback and tomography resiliency, stealthy monetization), enabling mechanisms (e.g., IP address de-coupling, control/data traffic indistinguishability), fundamental limitations, and evaluation metrics. The project will explore analogous scenarios of abuse in future Internet architectures where anonymity is facilitated by design. 2) Monitoring and analysis: the project develops an experimental framework to track activities of the next generation of botnets for scalable and effective mitigation. Such framework will exploit their ideal design and behavioral properties, and draws on various preliminary measurement results in related contexts. 3) Mitigation: The project has the ultimate&#8232;goal of proactively developing an arsenal of mitigation techniques grounded in a sound theoretical foundation, analyzed within the theoretical framework, and evaluated within the experimental framework. The mitigation techniques span the gamut of increasing the cost of operating such botnets, to actively containing&#8232;and neutralizing bots, to proposing modifications to the privacy-enhancing protocols. The results of this project will be communicated with the concerned communities for having a direct and immediate impact on existing and future privacy infrastructure. The project will also develop educational material to train students in the foundations and systems for enabling privacy enhancing technologies.
This grant encourages the careers of new researchers by providing travel support for student authors of accepted papers at the Financial Cryptography 2016 conference. The FC conference, now in its 20th year, is prestigious, and the students' work will stand alongside some of the most impactful research in the field. FC's research agenda includes SaTC's Trustworthy Computing System Perspective and Social, Behavioral and Economic Sciences Perspective. The nature and inspiration of the field encompasses at its foundations the invention of cryptographic means to support social protocols such as contracts, exchange, and information intimacy. A new workshop this year on privacy for ubiquitous devices ("1st Workshop on Wearable Security and Privacy") will draw researchers involved in the emerging area of Internet of Things.<br><br>The effect of the proposed activity is to sustain and expand the vibrancy of Financial Cryptography research, and research of allied fields, by connecting promising young students of the field to the research community. Their presence at the Financial Cryptography conference will establish relationships that will continue for decades, and guide the young researchers' careers.
This study concerns the evolving collection of information technology practices that have been grouped under the umbrella of "making," which includes end-user experimentation with emerging forms of hardware and software such as open hardware, digital fabrication, Internet of Things, and more. "Making" has been widely envisioned to enable a transition from tinkering to prototyping and entrepreneurship and, finally, to help revive manufacturing industries in the United States. Making in the US remains largely a hobbyist practice, and the transition from making-as-hobby to a new wave of economy-building technology innovation is not easy. Yet it can be done and indeed is already being done in other parts of the world, including the cities of Shenzhen, China and Taipei, Taiwan. Through empirical research, hands-on design workshops and international comparison, this project will examine and document successful pathways from making as hobby to socioeconomic driver, and how they are supported by technological, policy, economic, and pedagogical infrastructures.<br> <br>Broadly, this research will provide a contribution to studies of technology innovation in regions beyond more familiar technology hubs like Silicon Valley: Asia and the American Midwest. It will contribute to discussions that place models of technology innovation and design in relationship to local histories, cultures, and sociopolitical contexts. This includes debates around non-linear stories of technological progress, creativity, and design. This research will also contribute to a growing body of research focused on investigating the tools, techniques, and social organization of maker collectives, hackerspaces, and repair practices by providing both an ethnographic foundation and technological insights for emerging issues concerning making's transition into production and entrepreneurialism. Making provides the means, tools, and educational culture for developing novel and multidisciplinary approaches in STEM learning. Computation when taught through hands-on making has the potential to open up STEM fields and careers to underrepresented groups and minorities. Prior research has documented, however, that challenges remain; for instance the number of women in makerspaces remains low and professional maker communities are only indirectly brought into STEM education. This project will contribute to a broader national interest in transforming hands-on making into a sustainable model by facilitating interdisciplinary and international collaborations and engaged learning inclusive of the sciences, technology, engineering, arts and design as well as industry and expert amateurs.
Dynamic languages such as JavaScript, Python, and Ruby are ubiquitous; they are employed in critical infrastructure on clients, servers, and desktops, from browsers to the operating systems. The security, maintainability, correctness, and performance of programs written in these languages is becoming increasingly important. Static analysis is a valuable tool to help achieve these goals. However, static analysis of dynamic languages is a significant challenge due to their inherent dynamism, complicated semantics, and obscure corner cases, all of which conspire to make most static analyses incorrect, intractable, or both. The objective of this research is to extend the state of the art in terms of correctness, precision, and performance for static analysis of dynamic languages.<br><br>The intellectual merits of this research involve novel contributions in three areas: (1) ensuring the correctness of a static analysis via analysis testing, enabling high correctness assurance with low cost; (2) exploring the tradeoffs between analysis performance and precision by a novel framework for tunable analysis sensitivity, enabling empirical investigation into the most productive forms of static analysis for dynamic languages; and (3) refinement and parallelization strategies to help optimize analysis performance and precision, combatting the challenges of dynamic languages outlined above. Beyond the technical contributions, the broader impacts of this research are in education, the research community, and in industry. The insights and artifacts resulting from this research will be used to create novel curricula for both undergraduate and graduate courses. All of the research artifacts will be made publicly available under an open license, and the PI will use his connections to industrial research labs to facilitate technology transfer to industry.
The world increasingly relies on computer systems and associated software, yet attackers continue to exploit vulnerabilities in this software to threaten security in new and sophisticated ways. This research views exploitations of software vulnerabilities as critical, but not unique, examples of innovations that society would like to discourage? many other examples (e.g., biological weapons, sports doping, terrorist devices, privacy intrusions) exist. Purely technical panaceas are unlikely; instead, given inherent residual risk, society needs to better understand how adversaries adopt technological innovation and the efficacy of measures to stem their diffusion. Using large-scale data analysis, this research builds on innovation diffusion theory to model how exploitations of security vulnerabilities spread through attacker populations. The study of the specific software security context (particularly regarding disclosure and transparency) can clarify the complex interaction between attack and countermeasure activity and help society benefit from technology while reducing concomitant negative consequences.<br><br>The project integrates a cohesive set of empirical studies based on a massive dataset of intrusion alerts augmented by the National Vulnerability Database and manual data collection. It combines theory from economics, computer science, and sociology with advances in analytical tools to build predictive models. While researchers recognize that deeper understandings of attacks and countermeasures are critical, they remain difficult problems. However, recent advances in analytical techniques combined with the availability of large datasets present an emerging opportunity to model and understand attacker behavior. The project also promotes awareness of security through a range of activities (including instructional modules, workshops, and course offerings), using the theoretical insights from the research program to promote diffusion of measures that counter security threats. Regardless of how the threat landscape continues to evolve, rigorous methods for modeling attacker behavior and diffusing information will remain crucial.
Users of software are all too familiar with its shortcomings: software<br>is slow, software is buggy and software is insecure. When a complex<br>software system fails, it is unhelpfully simplistic to blame the<br>implementors of the system as incompetent. The truth is that software<br>engineers are uniquely disadvantaged among the traditional engineering<br>disciplines because they lack a viable predictive model for the<br>systems they design and build. That is, a software engineer cannot<br>predict the behavior of software in practice in the same way that a<br>civil engineer can predict the behavior of a bridge under load. The<br>primary intellectual merit of this research is that it lays the<br>critical, systematic foundations for the science of prediction for<br>software. The broader impacts are to enable engineers to build better<br>software with the aid of predictivity. Moreover, this research also<br>seeks to develop courses and educational material to train the next<br>generation of software engineers in the art of constructing fast,<br>safe, reliable and secure software in this fashion. As this research<br>transfers into practice and engineers adopt this methodology, it will<br>significantly strengthen the foundation of national<br>cyberinfrastructure.<br><br>The core technical thrust of this research is the development of a<br>systematic method for the synthesis of static analyzers for complex,<br>modern programming languages. It also explores whether or not this<br>methodology can be automated in whole or in part. To motivate the<br>development of this method, this research applies the method to the<br>synthesis of intensional static analyzers for popular scripting<br>languages such as JavaScript, Perl, PHP, Ruby and Python?many of which<br>happen to be the languages powering modern, web-based software. The<br>foundational technical concept of this research is the systematic<br>transformation of small-step interpreters into static analyzers.<br>Small-step analyzers promise unique advantages over traditional<br>techniques, including more opportunities for optimizing speed and<br>precision, and clearer, easier reasoning about the soundness of the<br>results of the analysis.
The Internet was not designed with information controls, such as censorship or surveillance, in mind. However, its importance has led many nations to repurpose Internet protocols (e.g., the Domain Name System (DNS) and Border Gateway Protocol (BGP)), and network management products (e.g., Web proxies, traffic shapers) for information control. This unintended use of networking technologies can lead to unintended international impact of censorship, and raises many ethical issues when network management products are exported to countries that use them to violate human rights. <br><br>To address these challenges, this project: (1) develops a platform which enables repeatable measurements of Internet censorship while mitigating risks to individuals performing the measurements, (2) designs techniques to analyze data from the platform to detect different types of censorship and even specific network management products used for censorship, and (3) uses the platform to quantify instances of national censorship which have unintended international impact on the Internet. <br><br>The use of technology to restrict freedom of speech and persecute dissidents around the globe is a human rights concern. This project provides high fidelity technical data to inform policy discussions. Further, the technical analysis provides insights into the global impacts of national censorship on the Internet, and how proposed improvements to existing protocols (e.g., DNSSEC, BGPSEC) can mitigate these issues.
Cloud computing has emerged as one of the most successful computing models in recent years. However, lack of accountability and non-compliance with data protection regulations have prevented major users such as business, healthcare, and defense organizations from utilizing clouds for sensitive data and applications. Due to the lack of information about cloud internals and the inability to perform trustworthy audits, today's clouds are often not used in regulated industries, preventing their widespread adoption. <br><br>The main focus of this project is to make clouds more accountable by leveraging provenance or the history of data, applications, and cloud state as a first-class property of clouds. The cloud provenance architecture provides mechanisms for collecting, storing, and securing provenance, and creating a secure access mechanism for provenance. We implement our architecture using OpenStack - a popular cloud platform - and use standard benchmarks to evaluate performance. <br><br>A secure provenance based cloud advances the state-of-the-art in several ways: (i) it makes clouds more accountable, trustworthy, and secure; (ii) which leads to increased adoption of clouds by large organizations; (iii) this ultimately lowers the cost; (iv) it also provides law-enforcement with support for digital forensics investigations in clouds; and finally (v) it allows innovations such as novel authentication and access-control schemes. <br><br>This research is accompanied by an integrated educational component, including development of new curricula, textbook, and an online course. The project also includes mentoring of K-12, undergraduate, graduate, and postdoctoral researchers, summer camps, and active involvement of women and minorities in order to increase the diversity of our nation's workforce.
The goal of the Modular Approach to Cloud Security (MACS) project is to develop methods for building information systems with meaningful multi-layered security guarantees. The modular approach of MACS focuses on systems that are built from smaller and separable functional components, where the security of each component is asserted individually, and where the security of the system as a whole can be derived from the security of its components. The project concentrates on building outsourced, cloud-based information services with client-centric security guarantees. <br><br>The MACS project addresses a diverse set of security challenges. These include the design of hardware with built-in secrecy and integrity properties, small and versatile operating systems that offer minimal functionality but are simpler and easier to analyze, privacy-preserving and verifiable memory access for outsourced applications, security-preserving overlay and software-defined networks, and algorithms for privacy-preserving verifiable outsourced computations and database systems. Crucially, we combine all of these security mechanisms with their piecemeal analyses into a global security guarantee. Furthermore, the analysis is modular, allowing the substitution of components with others that provide potentially comparable guarantees based on different techniques and trust assumptions. The research team comprises experts in different aspects of information security and cryptography. The research is highly collaborative and pools together key areas of expertise in order to provide overall security guarantees. A key component of the project is the Massachusetts Open Cloud, which provides the research team with a test-bed for deploying and testing the developed mechanisms in a production cloud. <br><br>The project involves a significant outreach component with a number of goals. One goal is to introduce technology professionals to cybersecurity and its central role for our society and economy. Another goal is to introduce K-12 students to cybersecurity, and through it to computer science in general. The program targets students from both under-represented minorities and students with exceptional academic potential.
Pervasive and distributed computing decreases development time by allowing engineers to reuse software in third-party components, platforms and cloud-based services. Consequently, this software is subject to multiple policies and regulations that impose legal requirements on the behavior of these complex systems. Legal requirements create evolutionary pressure on system design as developers roll out new product features, enter new markets that cross geo-political boundaries, or when existing laws change or new laws are created. In response, software engineers must reconcile legal requirements with their system design to ensure their software complies with policy and law; a problem even more challenging when innovation occurs in the absence of existing law.<br><br>This research aims to address this problem by analyzing corpora of regulations that govern software: (1) to develop a set of heuristics and semi-formal, domain-specific languages needed to express and reason about legal requirements for the purpose of determining requirements coverage; (2) to empirically measure gaps among policies and regulations from different jurisdictions that indicate requirements trade-offs, trends and potential disruptions due to changing requirements; and (3) to enable developers to rationalize and select alternate requirements evolutions based on models of changing coverage. The outcomes include new theory to explain and predict requirements evolution across jurisdictions, and tools and techniques that regulators, legal professionals and software engineers can use to reduce the burden of responding to a globally evolving regulatory landscape. These outcomes will be evaluated using mixed-methods research that combines formal methods, information retrieval and human subject experiments aimed at furthering our understanding of how professionals express and interpret requirements and how they reconcile conflicting requirements in the presence of ambiguity and conflicting business and regulatory goals. In addition to training and education, the broader impact of this research aims to harmonize regulatory goals with software systems, to engage the professions of software engineering and law that have historically worked separately, and to inform policy and lawmakers about the impact of regulations on software design and development.
Applications that run on billions of mobile devices backed by enormous<br>datacenters hold the promise of personal, always-on healthcare; of intelligent<br>vehicles and homes; and thus of a healthier, more efficient society. It is<br>imperative to make such applications secure by protecting their integrity and<br>keeping their data confidential. However, malicious programs (``malware'')<br>today can subvert the best software-level defenses by impersonating benign<br>processes on mobile devices or by attacking victim processes through the<br>hardware on shared datacenter servers. Grappling with such intelligent malware<br>requires fundamental advances in the hardware-software organization of computer<br>systems.<br><br>The key observation behind the research project here is that, while seemingly<br>disparate, intelligent malware relies on hiding its hardware-level behaviors<br>from operating system-level monitors. By exposing instruction-level and<br>micro-architectural behaviors to software analysis, the proposed Exo-core<br>architecture enables a new class of malware detectors. In addition, Exo-core<br>introduces programmable hardware accelerators to synthesize run-time program<br>traces into robust models of benign programs. The project will also<br>integrate research in hardware-software foundations of computer security<br>into a new two-semester research course for undergraduate students.
Tools that create visualizations, or visual representations of large datasets, are increasingly important for making use of data in a number of domains from commerce to science. To date, most visualization tools have been designed to support open-ended exploration of patterns in data; though useful for some tasks, this exploratory model does not fit well when analysts have existing models or hypotheses. This project aims to support a "concept-driven" analysis style in which analysts can share their existing conceptual models with the system, which uses those models to generate visualizations that allow the analyst to explore places where the models and data disagree and develop revised models that reconcile those discrepancies. To do this, the research team will design a number of prototype techniques for communicating conceptual models, algorithms for selecting visualizations and data features that best match those models, and interfaces that highlight discrepancies and provide tools for analysts to dig into the data around them. If successful, these concept-driven analyses will provide better ways for scientists and other analysts with existing models to leverage data while reducing the risk of confirmation biases in which people choose analyses that don't show where their existing models are wrong. The project will also enable the research team to learn more about the ways people come to form and express expectations about data. Lastly, project will provide opportunities for graduate research training as well as tools to support K-12 outreach workshops that introduce younger students to data science.<br><br>The project has two main activities. The first involves prototyping three elicitation techniques that prompt users to externalize their mental models and expectations about a dataset: free text expressions combined with natural language processing techniques that extract both variables of interest and implied relationships between them; concept mapping tools that allow users to graphically express relationships between entities, ideas, and concepts as node-link diagrams in which the nodes represent key aspects of the data and links represent suspected relationships between them; and tools for sketching expected relationships between variables using existing visualizations such as line charts and heatmaps. The team will also develop interfaces that encourage analysts to develop several alternative models to reduce the chance of confirmation bias. The second main activity is using the captured models to generate relevant visualizations that support discrepancy exploration. To do this, the team will first use a taxonomy of best practices for choosing visualizations that best fit the concepts and relationships represented in the models. They will then design interfaces that highlight discrepancies in both the visualizations (for instance, by highlighting data that badly fits a model) and the models (for instance, by highlighting links in a concept map that are not supported by the data) to call attention to inconsistencies. Both the elicitation and feedback interfaces will be refined through a series of semi-structured visual analysis studies in which participants use them to analyze data in domains of general interest such as socioeconomic indices, crime statistics, and health risks. The refined versions will then be used to compare the effectiveness of the concept-driven approach with more traditional exploratory approaches, as well as against both structured and unstructured workflows that interleave exploratory and concept-driven elements, in a series of lab studies using participants drawn from a number of scientific disciplines and a case study with scientific partners at Argonne National Laboratory.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
Robots are projected to become ubiquitous in homes, hospitals, schools, and other everyday spaces, where they will have to interact not with experts but rather with ordinary people - adults, the elderly, and children, from different cultural backgrounds. But untrained users may have negative beliefs, emotions, and attitudes about robots, due to lack of familiarity, which present potential challenges to their acceptance. Furthermore, multiple people will interact with multiple robots. Interaction between human and robot groups may be especially problematic, because intergroup interactions among humans are generally more negative, uncooperative, and aggressive than interactions between individuals, and human reactions to technological artifacts often resemble their reactions to other humans. In this project the PI will draw upon research from social psychology that has examined stereotyping, prejudice, and intergroup conflict, and will apply established and validated theories and methods to develop: (a) measures that can be used to understand the extent, nature, and bases of people's negative reactions to robots; (b) theoretical models of the causes and consequences of these negative reactions; and (c) interventions that demonstrably reduce negative beliefs, attitudes, and behavior in intergroup human-robot interaction (HRI). Project outcomes will suggest ways to reduce or eliminate crucial barriers to future robotics applications that are due to people's beliefs, attitudes, and emotions. <br><br>Nine studies will be conducted over three years. In Year 1, online and in-person measures will be administered to understand participant attitudes toward robots, and investigate fundamental factors that contribute to negative reactions. In Year 2, group contact, perspective taking, and long term exposure will be explored as ways to reduce prejudice toward robots. In Year 3, two more approaches to prejudice reduction in HRI will be tested: recategorization and norm-based intervention. A final study will evaluate the interaction and design strategies found to be most successful in fostering positive intergroup HRI by implementing them in robots interacting with people in a naturalistic setting. The studies will involve participants of different ages, socio-economic status, and cultural background (including four studies in Japan). Because HRI has mostly focused to date on one-on-one interactions between people and robots, this application of psychological theory to HRI in groups has vast transformative potential.
Infrastructure systems (such as power, water and banking) have experienced a surge in cyberattacks over the past decade. These attacks are becoming more sophisticated and resilient, suggesting that the perpetrators are intelligent, determined and dynamic. Unfortunately, current cyberdefense measures are reactive and frequently ineffective. Defenders need to move to a proactive approach, which will require an understanding of the human characteristics and behaviors of the people behind these cyberattacks. At present, this absence of the human element in existing cyberattack analysis is a fundamental weakness in our infrastructure protection. This project will integrate observations from live cybersecurity exercises, interviews with infrastructure protection experts, and logs from real-time cyberattacks to understand adaptive adversarial processes. This research will offer a new understanding to the protection of digital infrastructure by bringing together a diverse set of multidisciplinary academics and national and international infrastructure cybersecurity experts.<br><br>This project will investigate the adaptive and evolving adversarial decision-making (ADM) process in critical infrastructure cyberattacks. Specifically, this project will apply a criminological perspective to achieve five research objectives: (1) Investigate adversary-defender interaction and identify adversarial attack paths, (2) Understand adversarial adaptability when attack paths are disrupted, (3) Investigate the importance and characteristics of the various stages in attack paths, (4) Identify which factors impact ADM at each stage of the attack path, and (5) Improve the transparency, consistency and validation of adversarial attack paths. The Rational Choice Perspective criminological theoretical framework will be exploited to comprehend how adversaries make decisions on target selection, exploit criminal environments, plan, design, and execute attacks, and manage preventative and reactive measures. Three methods will be triangulated to examine ADM: (i) interviews with infrastructure cybersecurity experts to identify attack paths and factors impacting ADM, (ii) observations of attacker-defender (red team-blue team) cybersecurity exercises to examine real-time and adaptive decision-making processes, and (iii) logs from real-time cyberattacks. Each of these datasets will yield unique perspectives on ADM processes and will be combined to better capture the human element in cyberattacks.
This project addresses how semiconductor designers can verify the correctness of ICs that they source from possibly untrusted fabricators. Existing solutions to this problem are either based on legal and contractual obligations, or use post-fabrication IC testing, both of which are unsatisfactory or unsound. As a sound alternative, this project designs and fabricates verifiable hardware: ICs that provide proofs of their correctness for every input-output computation they perform in the field. These proofs must be efficiently verifiable in less time and energy than it takes to re-execute the computation itself.<br><br>Building upon exciting recent theoretical and practical advances in verifiable outsourced computation for the cloud, this project develops new techniques that exploit the unique constraints and adversary models that relate to the verifiable hardware problem. In addition, the project also develops new practical approaches to the problem of general verifiable computation. As a broader impact, computing systems security is one of the greatest technological problems faced by society today. Verifiable hardware is an essential foundation for building future computing systems that are reliable and free from catastrophic security failures. The ultimate goal of this project is to make verifiable hardware practical and accessible for use in cryptographic and mission-critical hardware applications through open-source tools. The PIs are strongly committed to education and public outreach by producing widely-used course materials and taking active roles in outreach at minority-serving universities, community colleges, student organizations and high schools.
Heavy vehicles, such as trucks and buses, are part of the US critical infrastructure and carry out a significant portion of commercial and private business operations. Little effort has been invested in cyber security for these assets. If an adversary gains access to the vehicle's Controller Area Network (CAN), attacks can be launched that can affect critical vehicle electronic components. Traditionally, physical access to a heavy vehicle was required to access the CAN. However, wireless devices are also installed on heavy vehicles, which open trucks and busses to remote wireless cyber attacks. This project explores cyber security vulnerabilities related to wireless devices that communicate on the CAN. For identified threats, researchers determine the proper mitigation strategies, including where and how they are best deployed. To demonstrate potential exploits and subsequent trust in proposed mitigation strategies, this project designs and implements a scalable, high-fidelity test bed using actual heavy vehicle electronic control units, such as engine and brake controllers. The test bed includes built-in mechanisms for remote access and secure information delivery to allow for collaboration among researchers at different sites. The results of the research, including the potential to extend the test bed with other components, can impact cyber security analysis for other industries that use CAN, such as building automation, medical devices, and manufacturing.<br> <br>The SAE J1939 communication network in heavy vehicles is based on CAN and has open documentation for packet definition and transmission. This openness may be exploited for creating spoofed J1939 messages. Heavy vehicle owners utilize third-party systems, such as remote telematics, that introduce new J1939 enabled modules, which can potentially be subverted by an adversary. This project uses these systems to gain remote access and attack another CAN connected electronic control unit. Packet sniffing is performed as the telematics system connects wirelessly to the CAN to determine if fake packets can be inserted. Research includes examining different designs, configurations, and deployments of intrusion detection systems to best thwart such remote attacks using the developed test bed. One challenge is to develop algorithms that can act in real-time with deployed test bed hardware. Research includes developing scientific strategies to measure the temporal response of the cyber actions in the test bed and the reaction time of any intrusion detection system, so that bounds can be determined based on the ability to conduct a remote cyber operation on a J1939 network.
Despite our growing reliance on mobile phones for a wide range of daily tasks, their operation remains largely opaque even for experts. Mobile users have little insight into how their mobile apps operate and perform in the network, into how (or whether) they protect the information that users entrust to them, and with whom they share user's personal information. A number of previous studies have addressed elements of this problem in a partial fashion, trading off analytic comprehensiveness and deployment scale. This project seeks to overcome the limitations of previous approaches by building a handset-, traffic-, and user-centric mobile measurement platform: the ICSI Haystack. Haystack offers a novel and flexible mobile vantage point capable of correlating real-world mobile traffic with user input and high-fidelity device activity at scale while also enabling mechanisms to aid mobile users to stay in control of their mobile traffic and personal data. The research community, operators and regulatory bodies will also benefit from the novel measurement mechanisms and from the data collected in order to safeguard mobile users and to increase the operational transparency of mobile apps and trackers.<br><br>To achieve this vision, this project develops novel techniques to perform high-fidelity mobile measurements by capturing user traffic in user-space on the device using native platform support. As a result, Haystack will be available for anyone to install from traditional app stores such as Google Play, thereby enhancing user reach. In order to gain a truly in-depth and broad understanding of the mobile ecosystem, Haystack takes advantage of its local operation to correlate network traffic with user input and local context, such as which app generated a particular network flow and device location, obtained from the operating system itself with real network and user stimuli. Critically, Haystack's system design must be flexible and extensible in order to enable researchers to conduct a wide range of mobile measurements, to cope with new mobile technologies, and to reach a broad cross-section of mobile users. The ability to combine all these features together in user devices makes Haystack an ideal vantage point to conduct a wide range of mobile measurements such as mobile traffic characterization in the wild, privacy leak detection, identifying online tracking services, auditing app security, and network performance measurements.
More and more objects used in daily life have Internet connectivity, creating an "Internet of Things" (IoT). Computer security and privacy for an IoT ecosystem are fundamentally important because security breaches can cause real and significant harm to people, their homes, and their community. These security issues also are very challenging not only because of the properties of IoT devices themselves but also because the users are diverse, vary in their technical knowledge and access to technical support, and include vulnerable populations such as children and those using in-home care technologies. Moreover, additional risks emerge when users combine technologies in unexpected ways.<br> <br>Meeting the challenges of IoT security and privacy requires a large, interdisciplinary effort. An effective approach to IoT security and privacy is holistic, integrating human-computer interaction, network security, cryptography, and pervasive computing. Enforcing cryptographic requirements requires not only building systems that can function on low-capacity IoT devices, but also using threat models that incorporate human requirements. Translating security and privacy requirements and preferences requires understanding what people want, presenting the technologies in a manner people can understand, and knowing what is technologically realistic. This requires behavioral and organizational research, with discussions involving public and private sector stakeholders. The project is developing a foundation for IoT security and privacy that is intuitive, natural to the human experience, provides the necessary technical guarantees, and facilitates adoption by the larger IoT community of users and manufacturers.
Vast quantities of character-encoded text form the foundation for the information retrieval revolution of recent decades. In contrast, very little symbolically-represented music exists, preventing music from fully participating in the 21st century. The International Music Score Library Project (IMSLP) is a large and rapidly growing open library of public domain machine-printed classical music scores, actively used by many musicians, scholars, and researchers around the world. Optical music recognition (OMR) forms the natural bridge between the IMSLP and the missing symbolic music data. While there has been active OMR research since the 1960s, the state of the art still is not sufficiently well-developed to create symbolic data from realistic documents, as represented on the IMSLP. This is because music notation contains a thicket of special cases, exceptions to general rules, image pathologies, and interpretation challenges, whose recognition requires a deep level of content understanding. With this in mind, the PI has developed prototype software named Ceres for supporting a hybrid human-computer team, in which both machine and person partner in a collaborative recognition effort. The human guides the computer through the recognition task, identifying and providing crucial missing pieces of information, while allowing the computer to fill in the details, consistent with the human guidance. The ultimate goal is to build a Wikipedia-like community centered around Ceres and the IMSLP with the mission of creating a definitive, open access, symbolic music library that distributes music scores electronically and globally, allowing for adaptive display and automatic transformation and registration of scores with audio and video. The prevalence of symbolic music data would open up a world of possibilities to music-science researchers, including systems for music information retrieval, expressive performance, musical accompaniment, transcription and arranging, performance assistance, and many others. Last but not least, the symbolic music library would enable innovative commercial applications; tablet computers will likely be the sheet music "delivery system" of the future, allowing automatic page turning, performance feedback, and various kinds of content-based annotation. <br><br>The challenge of integrating both human and algorithmic intelligence to create a tractable and efficient OMR solution constitutes the heart of this project. The PI's approach is to adopt the interface paradigm of constrained optimization; the human uses domain understanding to supply crucial missing pieces of information when needed, and the computer uses this guidance to re-recognize and reinterpret subject to these user-supplied constraints. A preliminary experiment conducted by the PI using a medium-difficulty test set showed a 17% error rate on the part of his prototype system, accounting for both false positives and false negatives at the primitive level. The human-computer interface is where the recognition results become tangible and subject to manipulation, so its design is critical; this is an area where the PI expects to make contributions to HCI in general. The PI argues that to be useful for OMR the interface should be almost completely open, providing a set of tools and options, and imposing only the minimal required structure (e.g., staff recognition must be verified before we identify page structure, while the latter must be verified before it is worth continuing to the symbol recognition phase). The interface development strategy will be one of iterative refinement, the evaluation of each version to involve time- and effort-oriented metrics as well as open-ended user comments. For example, the Ceres user interface (the null hypothesis for the current project) superimposes the recognized results on the original image, making discrepancies readily apparent (in contrast to other systems that present side-by-side original and recognized notation which is cognitively more difficult to compare), but maybe even better solutions are possible? Other aspects of the work will include exploration of the roles of visualization (including directing the user's attention) and music playback (hearing the score). OMR is just one of many computer vision problems that fall into the constrained optimization category, and the approach also applies to natural language processing, machine listening, and others; the essential process to be explored here would extend to these domains as well, providing a general template with far-reaching significance. For OMR the constraints are individual pixel labels, but for other problem domains they could equally well refer to labelling of individual samples, words, or whatever fundamental units compose the data. In this way, the approach uses a generic and flexible view for human input that doesn't require the human to understand the inner workings of the recognition processes.
Crypto-currencies and smart contracts are a new wave of disruptive technology that will shape the future of money and financial transactions. Today, crypto-currencies are a billion-dollar market, and hundreds of companies are entering this space, promising exciting new markets and eco-systems. Unfortunately, usage of crypto-currencies outstrips our understanding. Currently most crypto currencies rely on heuristic designs without a solid appreciation of the necessary security properties, or any formal basis upon which strong assurance of such properties might be achieved.<br><br>This work aims to establish a rigorous scientific foundation for crypto-currencies. To achieve this, this work blends cryptography, game theory, programming languages, and systems security techniques. Expected outcomes include new crypto-currency designs with provable security properties, financially enforceable cryptographic protocols whose security properties are backed by enforceable payments in case of a breach, smart contract systems that are easy to program and formally verifiable, as well as high-assurance systems for storing and handling high-value crypto-currencies and transactions. The project will provide solutions to some of the most difficult and important technical questions surrounding the current digital-money revolution. The investigators will organize a crypto-currency speaker series that will bring together technologists, economists, social scientists, and policy-makers to foster collaborations that will shape the future of digital currencies.
The protection of cyber-physical critical infrastructures such as the power grid, water distribution networks, and transportation networks against computer attacks is a matter of national security, public safety, and economic stability; however, most of these critical assets are owned and operated by private companies with pressing operational requirements, tight security budgets, and aversion to regulatory oversight. As a result it is not clear that market incentives alone will create enough momentum to improve the security posture of these systems. This project studies how to incentivize investments and risk management for CPS security. A second related problem is that while current cyber-physical infrastructures are monitored by an operations center, this system does not currently help operators identify if a problem, alarm, or fault was the result of a physical accident or if there is any indication that a cyber-attack caused the problem. This second research focus aims to improve the assessment of the security states of these systems by developing the foundations towards an industrial security operations center to help operators identify the root cause (accident or cyber-attack) of alerts.<br><br>There is a large body of work focusing on interdependent security with models of firms participating in protection and insurance markets. Most of the security models and economic interdependent investment formulations focus solely on information technology infrastructures, and are meant to model cybercriminal activities, where attackers are rational profit-driven agents and defenders experience constant security breaches allowing them to generate risk models based on data. In contrast, computer attacks to critical infrastructure systems represent a completely different set of malicious agents. These agents may not be profit-driven and will attack only sporadically. In addition, interdependent physical infrastructures are managed by federated agents, and cyber-attacks will have physical consequences extending the domain of the single firm attacked. This project leverages and extends the literature of investment in reliability for large-scale critical infrastructures as well as insurance, contracts between firms with interdependent assets, and extreme risk. The second research focus leverages the interest of the CPS industry in analyzing the data collected by sensor networks. Security Information and Event Managers (SIEM) solutions were designed for enterprise IT, and do not include, aggregate, and correlate the sensor data from the physical world. To mitigate this gap this proposal investigates how to aggregate information for a new system incorporating the data from control centers and those from security operations centers, laying thus the foundation to create an Industrial Security Operations Center (ISOC).
Social media systems have transformed our societal communications, including news discovery, recommendations, societal interactions, E-commerce, as well as political and governance activities. However, the rising popularity of social media systems has brought concerns about security and privacy to the forefront. This project aims to design trustworthy social systems by building on the discipline of network science. First, the project is developing techniques for analysis of social media data that protect against risks to individual privacy; new research is needed since existing approaches are unable to provide rigorous privacy guarantees. Second, the project is developing new approaches to mitigate the threat of "fake accounts" in social systems, in spite of attempts by the creators of those accounts to elude detection. Both deployed and academic approaches remain vulnerable to strategic adversaries, motivating the development of novel defense mechanisms based on network science. The findings and new designs from this research will directly impact the security and privacy of a broad class of social network users.<br><br>The private network analytics thrust builds on the ideas of differential privacy, ensuring sufficient uncertainty in results to hide individual relationships. The project introduces dependent differential privacy, which protects against disclosure of information associated with an individual, as well as mutual information privacy, an entropy-based measure. The Sybil mitigation thrust is based on the idea of adversarial machine learning: the creators of fake accounts are presumed to adapt their mechanisms to changing detection approaches. This work exploits new features, such as temporal dynamics of the network, to address this problem. Finally, the project aims to integrate the research with an educational initiative for developing pedagogical approaches and content for trustworthy social systems.
Data structures have a prominent modern computational role, due to their wide applicability, such as in database querying, web searching, and social network analysis. This project focuses on the interplay of data structures with security protocols, examining two different paradigms: the security for data structures paradigm (SD) and the data structures for security paradigm (DS). The objectives of this project are, in the SD paradigm, to provide security and privacy both for data elements in data sets and also for the inter-relationships and distributions between such data elements, such as links between nodes in a social network, and, in the DS paradigm, to develop new data structures to improve the efficiency of algorithms for security and/or privacy applications.<br> <br>The project explores methods for achieving these objectives include algorithm design, theoretical analysis, rigorous proofs of security and correctness, and experimental validation of claims of practicality. This research focuses on the security and cybersecurity uses of three advanced data structures: tree structures, invertible Bloom filters and cascading tables. The project advances knowledge on (a) authenticated data structures and verifiable query execution within the SD paradigm, and (b) secure deduplication, searchable encryption, and privacy-preserving memory allocators within the DS paradigm.
One of the oldest and most challenging problems in cyber security is to enable secure information sharing (SIS) (i.e., maintaining some control over information even after it has been shared.) For example, a product manufacturer may need to share customer account information with a company that ships the products and bills the customers. The manufacturer cannot allow its partner to then misuse those customer records by direct marketing or selling customer records. This project focuses on the policy challenge of specifying, analyzing and enforcing SIS policies. The project is developing intuitive, usable, and mathematically sound models that can be used by organizations to specify and enforce SIS policies.<br><br>This project focuses on specifying, analyzing and enforcing group-centric secure information sharing (g-SIS) policies. The researchers are developing a theory of multiple, connected groups based on relationships such as subordination, conditional membership and mutual exclusion, with broad, real-world application. The approach separates policy layer specifications from enforcement layer specifications, and develops varying levels of formal consistency metrics between the two with respect to authorization decisions. The research team is working with organizations to prototype and use the information sharing platform in ongoing community cyber incident information sharing efforts.
Crypto-currencies and smart contracts are a new wave of disruptive technology that will shape the future of money and financial transactions. Today, crypto-currencies are a billion-dollar market, and hundreds of companies are entering this space, promising exciting new markets and eco-systems. Unfortunately, usage of crypto-currencies outstrips our understanding. Currently most crypto currencies rely on heuristic designs without a solid appreciation of the necessary security properties, or any formal basis upon which strong assurance of such properties might be achieved.<br><br>This work aims to establish a rigorous scientific foundation for crypto-currencies. To achieve this, this work blends cryptography, game theory, programming languages, and systems security techniques. Expected outcomes include new crypto-currency designs with provable security properties, financially enforceable cryptographic protocols whose security properties are backed by enforceable payments in case of a breach, smart contract systems that are easy to program and formally verifiable, as well as high-assurance systems for storing and handling high-value crypto-currencies and transactions. The project will provide solutions to some of the most difficult and important technical questions surrounding the current digital-money revolution. The investigators will organize a crypto-currency speaker series that will bring together technologists, economists, social scientists, and policy-makers to foster collaborations that will shape the future of digital currencies.
Information about individuals is collected by a variety of organizations including government agencies, banks, hospitals, research institutions, and private companies. In many cases, sharing this data among organizations can bring benefits in social, scientific, business, and security domains, as the collected information is of similar nature, of about similar populations. However, much of this collected data is sensitive as it contains personal information, or information that could damage an organization's reputation or competitiveness. Sharing of data is hence often curbed for ethical, legal, or business reasons. <br><br>This project develops a collection of tools that will enable the benefits of data sharing without having the data owners share the data. The techniques developed respect principles of data ownership and privacy requirement, and draw on recent scientific developments in privacy, cryptography, machine learning, computational statistics, program verification, and system security. The tools developed in this project will contribute to the existing research and business infrastructure, and hence enable new ways to create value in information whose use would have been otherwise restricted. The project supports the development of new curricula material and train a new generation of researchers and citizens with the multidisciplinary perspectives required to address the complex issues surrounding data privacy.
This project addresses how semiconductor designers can verify the correctness of ICs that they source from possibly untrusted fabricators. Existing solutions to this problem are either based on legal and contractual obligations, or use post-fabrication IC testing, both of which are unsatisfactory or unsound. As a sound alternative, this project designs and fabricates verifiable hardware: ICs that provide proofs of their correctness for every input-output computation they perform in the field. These proofs must be efficiently verifiable in less time and energy than it takes to re-execute the computation itself.<br><br>Building upon exciting recent theoretical and practical advances in verifiable outsourced computation for the cloud, this project develops new techniques that exploit the unique constraints and adversary models that relate to the verifiable hardware problem. In addition, the project also develops new practical approaches to the problem of general verifiable computation. As a broader impact, computing systems security is one of the greatest technological problems faced by society today. Verifiable hardware is an essential foundation for building future computing systems that are reliable and free from catastrophic security failures. The ultimate goal of this project is to make verifiable hardware practical and accessible for use in cryptographic and mission-critical hardware applications through open-source tools. The PIs are strongly committed to education and public outreach by producing widely-used course materials and taking active roles in outreach at minority-serving universities, community colleges, student organizations and high schools.
Information about individuals is collected by a variety of organizations including government agencies, banks, hospitals, research institutions, and private companies. In many cases, sharing this data among organizations can bring benefits in social, scientific, business, and security domains, as the collected information is of similar nature, of about similar populations. However, much of this collected data is sensitive as it contains personal information, or information that could damage an organization's reputation or competitiveness. Sharing of data is hence often curbed for ethical, legal, or business reasons. <br><br>This project develops a collection of tools that will enable the benefits of data sharing without having the data owners share the data. The techniques developed respect principles of data ownership and privacy requirement, and draw on recent scientific developments in privacy, cryptography, machine learning, computational statistics, program verification, and system security. The tools developed in this project will contribute to the existing research and business infrastructure, and hence enable new ways to create value in information whose use would have been otherwise restricted. The project supports the development of new curricula material and train a new generation of researchers and citizens with the multidisciplinary perspectives required to address the complex issues surrounding data privacy.
The need for accurate and unforgeable identity recognition techniques has become an issue of increasing urgency. Biometric approaches such as iris recognition hold huge promise but still have significant limitations, including susceptibility to 'spoofing'. This project seeks to advance our knowledge of security and accuracy of multibiometric systems by inventing, evaluating, and applying innovative methods and tools to combine highly accurate static traits, such as iris patterns, with novel traits based on the dynamics of eye movements. The strategy is to use existing iris recognition hardware to combine three different biometrics approaches related to the eye: measurement of iris patterns, unique characteristics of the eye globe and its muscles, and the brain's strategies for guiding visual attention. This multimodal ocular biometrics approach has the potential to improve liveness detection and resistance to sophisticated counterfeiting techniques and coercion attacks, while improving identification accuracy. This research tackles important questions related to the individuality, variability, scalability, and longevity of these ocular traits, building a foundation for security and accuracy improvement when those traits are combined with iris recognition. This project aims to benefit efforts such as the Unique Identification project in India, which seeks to use biometric information of 1.2 billion individuals to fight fraud.<br><br>Educational activities include three initiatives: 1) creation of a strong outreach activity to K-12 students, 2) expansion of an interdisciplinary research-oriented educational program previously created by the PI for undergraduate and graduate students, and 3) mentoring and guidance to interest undergraduate students in scientific careers and encourage more students from diverse backgrounds to pursue graduate study.
Embedded systems currently rely on local and often insecure state retention for process control and subsequent forensic analysis. As critical embedded control systems (e.g., smart grids, SCADA) generate increasing amounts of data and become ever more connected to other systems, secure retention and management of that data is required. Attacks such as Stuxnet show that SCADA and other systems comprising critical infrastructure are vulnerable to the compromise of controllers and sensing devices, as well as falsification of data to circumvent anomaly detection mechanisms. <br><br>This project develops techniques and architectures for securely storing and monitoring embedded system state in critical infrastructure. We are examining vulnerabilities relating to generating and storing data in critical embedded systems, which are often resource-constrained environments. We propose the design and deployment of 'autonomously secure storage devices' that act as resilient storage for embedded devices. We are designing logging, audit, and management architectures for resiliently storing system data and provenance in the face of malicious and compromised devices. Additionally, we explore how this data may be disseminated to other systems and to environments such as the cloud and aim to protect data through privacy-preserving communication and querying interfaces, and attempt to make data-driven inferences about system operation to detect anomalous behavior. Through these active protections to generated data and metadata, we aim to provide a new baseline for producing and storing data generated within critical infrastructures.
This grant supports student attendance to the IEEE Cyber Security Development (SecDev) conference. Research on software security usually focuses on detecting vulnerabilities in software and attacks on resources. However, there is not much attention to how programmers can develop secure software by construction. This new conference series on Secure Development (SecDev) focuses on this problem area. The support for the conference is important for educating/training the workforce in this area, and to help provide a pathway to research careers. The technical advances presented and nurtured by the conference are important to development of secure software, which is important to society.
This funding renews a Research Experiences for Undergraduates (REU) Site at the University of Connecticut focused on computer systems security research. This site is co-funded by the CyberCorps: Scholarship for Service Program and the Secure and Trustworthy Cyberspace (SaTC) program. Students will participate in research projects that are timely and in an area of national priority. Specific activities include collaborative projects in the Electrical and Computer Engineering Department and the Computer Science and Engineering Department, including research in hardware support for computer security, hardware Trojan detection, and IC authentication, and access control. A series of seminars will equip students with knowledge specific to the various research projects as well as general skills required in graduate school. In addition, the undergraduate students will have the opportunity to participate in the Hardware-Oriented Security and Trust Symposium. This will broaden students' vision by allowing them to witness research projects conducted worldwide. <br><br>The intellectual merit of this project lies with the strong research team and the focus on computer systems security, an area of national need and of interest to students. The students will participate in research initiatives that investigate algorithmic techniques, hardware and software design principles, computer architecture, and other aspects of trustable computing systems. A major goal of this project is to introduce such interdisciplinary research work to students in the early stages of their academic careers to spark their interests. At the same time, the research has the potential to contribute to the research core of the computing disciplines.<br> <br>This project is aimed at preparing undergraduate students for graduate study in a research area of vital national interest. Computer systems are integrated into every part of our national infrastructure, including financial systems, communication systems, transportation, and defense. A primary national need is research and researchers who can address the security of these systems. The research opportunities that this proposal provides will help develop the next generation of researchers investigating these important computer security issues.
There are at least two key features of the move to cloud computing that introduce the opportunity for significant leaps forward in computer security for tenant services. First, a compute cloud provides a common software, hardware and management basis for rolling out cross-cutting services en masse that have resisted incremental deployment in a one-service-at-a-time fashion. Second, compute clouds offer providers a broad view of activity across an unprecedented diversity of tenant services. This research project leverages these features to develop new approaches to a wide array of fundamental problems in computer security. By convening Cloud Security Horizons summits with industry stakeholders, this project further seeks to both contribute to industry directions in cloud computing and to be informed by them.<br><br>Particular longstanding security challenges addressed in this project include secure transport, authorization, user and software authentication, security monitoring, and incident analysis. Moreover, since modern clouds are not sufficiently extensible to support the envisioned capabilities, this project is constructing cloud software platforms that enable the flexibility, extensibility and security needed for this research to come to fruition in practice.
The evolution of data storage in modern operating systems (OSes) brings challenges for fine-grained data protection. While traditional OSes offer simple, relatively low-level data abstractions -- files and directories -- modern operating systems, including Android and iOS, embed much higher-level abstractions, such as relational databases and object-relational models. The new abstractions complicate file structures and access patterns, greatly challenging existing protection systems, such as encrypted file systems, deniable file systems, antiviruses, and anomaly detectors, which, fallen behind the times, continue to operate at file level.<br><br>In this project, we are investigating new data protection abstractions that are better attuned to modern OSes. One example is a logical data object (LDO). An LDO corresponds to an application-specific resource -- such as an email, a document, or a bank account -- and includes all the data related to it, no matter how or where it is persisted (e.g., rows in databases, objects in object-relational models, files in the file system, etc.). Protection systems use LDOs to acquire rich semantics about the data to refine their effectiveness. Using LDOs, we are building HideIt, a fine-grained object hiding system that lets users select, through the familiar UIs of their unmodified applications, arbitrary objects -- such as individual emails, documents, bank accounts -- and hide or unhide them. By creating new, convenient protection abstractions, and teaching students and the broader community about them, we hope to promote a responsible approach to data management, in which users manage their data carefully, minimizing its exposure to attacks.
This research is building an understanding of what data is useful to attackers and what data is private for its legitimate owners so that security systems can incorporate these values into a data-driven, defense-in-depth approach to securing our digital lives.<br> <br>We are exploiting the fact that both users and attackers must sift through vast amounts of data to find useful information. This system, called contextual data protection, enables users to passively manage their private and potentially lucrative stored data with minimal overhead, adding extra protection to private data which greatly lowers the risk inherent in long lived archives.<br> <br>Simultaneously, we are creating effective defenses for data by improving our understanding of cybercrime, information use habits, and acceptable usability tradeoffs for data access. Building on previous research analyzing the financial successes of spam-based cybercrime, we are developing a methodology and apparatus for understanding the illicit value of stolen information. By understanding what is discoverable and valuable to attackers, we can develop techniques to focus security efforts on lucrative information, thereby preventing cybercriminals from turning a profit.<br> <br>Ultimately, our goal is to create a set of general techniques that use tools from cryptography that defend users' data by exploiting a deeper understanding of its value to both the users and the attackers. This research will shed light on the meaning of information value, ownership, and protection in this era of long-lived digital storage.
The basic nature of encryption has always been all-or-nothing: anyone who is privy to the secret key can decode and recover the entire data; but, without the key, nothing can be revealed. In other words, the only useful action that could be performed on encrypted data was decryption using the secret key. In the modern world of cloud computing, we store much of our personal data in the cloud, and perform computations on them remotely. The numerous security concerns with cloud storage and computation raise a number of challenging questions: Can we encrypt data and run computations on it without decrypting? Can we encrypt programs and allow users to execute them without discovering any details about their internal operations, other than the eventual result? <br><br>This project is dedicated to the study of the paradigm of computing on encrypted data and programs, and the design of fundamental cryptographic primitives underlying this broad goal. Specifically, it focuses on three major cryptographic primitives: (i) fully homomorphic encryption, which enables computations on encrypted data; (ii) functional encryption, which enables expressive access control; and (iii) program obfuscation, which lets us hide the structure of programs while preserving their functionality. The overarching goal is to develop constructions of these cryptographic primitives that achieve a high degree of efficiency, but also guarantee security under well-studied cryptographic assumptions. Towards this end, the project explores both software and hardware techniques, and the use of novel mathematical tools from algebra, geometry and number theory.
In response to serious vulnerabilities that plague many of the Internet's core protocols, the last two decades have seen various security infrastructures layered on top of originally insecure protocols (DNSSEC on top of the domain name system, SSL and its public key infrastructure on top of TCP, the RPKI on top of interdomain routing). The security of each is derived from centralized authorities that are trusted to provide information about cryptographic keys or identities. When authorities behave correctly, each security infrastructure protects the underlying insecure system from attack. However, what happens if an authority abuses its power, or experiences a malfunction, misconfiguration, or a compromise by an external attacker?<br><br>This project is predicated on the observation that the scope, impact, and visibility of abuse by compromised authorities is determined by the architecture of a security infrastructure (e.g., the presence or absence of hierarchy, the scope of an authority's power, etc.). The project finds new ways to balance between the need to provide strong security guarantees for a vulnerable insecure system, and the need to limit the control that a centralized authority can exercise over that system. To do this, the project will use cryptography and mechanism design to design architectures that make abuse easier to detect, or harder to execute. The project has implications on the security of some of the Internet's most crucial systems, and also involves technology transfer to the practitioners involved in the standardization and adoption of Internet systems.
The goal of the Modular Approach to Cloud Security (MACS) project is to develop methods for building information systems with meaningful multi-layered security guarantees. The modular approach of MACS focuses on systems that are built from smaller and separable functional components, where the security of each component is asserted individually, and where the security of the system as a whole can be derived from the security of its components. The project concentrates on building outsourced, cloud-based information services with client-centric security guarantees. <br><br>The MACS project addresses a diverse set of security challenges. These include the design of hardware with built-in secrecy and integrity properties, small and versatile operating systems that offer minimal functionality but are simpler and easier to analyze, privacy-preserving and verifiable memory access for outsourced applications, security-preserving overlay and software-defined networks, and algorithms for privacy-preserving verifiable outsourced computations and database systems. Crucially, we combine all of these security mechanisms with their piecemeal analyses into a global security guarantee. Furthermore, the analysis is modular, allowing the substitution of components with others that provide potentially comparable guarantees based on different techniques and trust assumptions. The research team comprises experts in different aspects of information security and cryptography. The research is highly collaborative and pools together key areas of expertise in order to provide overall security guarantees. A key component of the project is the Massachusetts Open Cloud, which provides the research team with a test-bed for deploying and testing the developed mechanisms in a production cloud. <br><br>The project involves a significant outreach component with a number of goals. One goal is to introduce technology professionals to cybersecurity and its central role for our society and economy. Another goal is to introduce K-12 students to cybersecurity, and through it to computer science in general. The program targets students from both under-represented minorities and students with exceptional academic potential.
Virtual Machine Monitors (VMMs) and hypervisors have become a foundational technology for system developers to achieve increased levels of security, reliability, and manageability for large-scale computing systems such as cloud computing. However, when developing software at the VMM layer, developers often need to interpret the very low level hardware layer state and reconstruct the semantic meanings of the guest operating system events due to the lack of operating system level abstractions. This semantic gap problem has been a road block for a decade for many VMM level applications such as virtual machine introspection (VMI), malware analysis, and virtual machine management.<br><br>This research seeks to design and develop new approaches, practical techniques, and efficient implementations to automatically bridge the semantic gap for VMM layer programs including VMI. In particular, a dual-VM, binary code reuse based framework is formulated and applied to automatically bridge the semantic gap. Such a framework directly enables a large set of legacy utility software to automatically become VMI software. Meanwhile, the research includes developing a set of practical enabling techniques such as memory exclusive kernel version inference, and integrates these techniques with efficient implementations from binary rewriting. The results of this research are to significantly increase the productivity of virtualization software development as well as the security of virtualization software, and also open new opportunities for automated system administration, intrusion detection, and incident response.
Our society is becoming increasingly reliant on powerful and interconnected computing devices that store much of our personal information. These devices present an ever-growing tension between the desire for our personal information to be private, and the desire to put our personal information to good use for our own convenience. In cryptography, problems that involve requirements of useful computation and privacy are understood through the lens of secure multi-party computation (SMPC). Specifically, SMPC refers to the problem of how mutually distrusting parties can securely and collaboratively perform tasks that involve private information.<br><br>In this project, the PI will develop new techniques for understanding and overcoming the challenges and limitations posed by SMPC protocols. In particular, the following major themes will be explored: (1) is it possible in the real world to design protocols that remain secure regardless of other concurrently running protocols? (2) what security properties can be embedded into objects like ciphertexts and digital signatures? (3) how can shared data be maintained persistently while remaining private? The PI will develop new materials for undergraduate courses in cryptography and algorithms, based on principles of pedagogically sound visualization. The PI will also create resources for the cryptography research community, in the form of an online database of cryptographic constructions and primitives.
The Center for Encrypted Functionalities (CORE) tackles the deep and far-reaching problem of general-purpose "program obfuscation," which aims to enhance cybersecurity by making an arbitrary computer program unintelligible while preserving its functionality. This can in turn enable a host of applications, such as hiding from potential adversaries the existence of vulnerabilities that may have been introduced through human error in the design/development process, thereby preventing tampering or deterring reverse engineering, or hiding cryptographic keys within software, thereby strengthening encryption and information transfer. <br> <br>At the heart of the Center's research activities is the development of new and rigorous mathematical techniques to build faster and more secure general-purpose mechanisms enabling such software. In pursuit of this goal, the CORE team tackles many technical questions: Can secure general-purpose mechanisms avoid the inefficiency overhead that arises from Barrington's Theorem? Can the security of these mechanisms be proven to hold against idealized adversaries, or be based on natural non-interactive hardness assumptions? Can these approaches be securely leveraged to protect data from rogue insiders, who must be able to access some data in the clear? Finally, can these mechanisms be used to reduce the level of interaction required to accomplish secure communication and computation tasks? In addition to its direct research program, the Center organizes retreats and workshops to bring together researchers to carry out the Center's mission. The Center also engages in high-impact outreach efforts, such as the development of free Massive Open Online Courses (MOOCs).
The goal of the Modular Approach to Cloud Security (MACS) project is to develop methods for building information systems with meaningful multi-layered security guarantees. The modular approach of MACS focuses on systems that are built from smaller and separable functional components, where the security of each component is asserted individually, and where the security of the system as a whole can be derived from the security of its components. The project concentrates on building outsourced, cloud-based information services with client-centric security guarantees. <br><br>The MACS project addresses a diverse set of security challenges. These include the design of hardware with built-in secrecy and integrity properties, small and versatile operating systems that offer minimal functionality but are simpler and easier to analyze, privacy-preserving and verifiable memory access for outsourced applications, security-preserving overlay and software-defined networks, and algorithms for privacy-preserving verifiable outsourced computations and database systems. Crucially, we combine all of these security mechanisms with their piecemeal analyses into a global security guarantee. Furthermore, the analysis is modular, allowing the substitution of components with others that provide potentially comparable guarantees based on different techniques and trust assumptions. The research team comprises experts in different aspects of information security and cryptography. The research is highly collaborative and pools together key areas of expertise in order to provide overall security guarantees. A key component of the project is the Massachusetts Open Cloud, which provides the research team with a test-bed for deploying and testing the developed mechanisms in a production cloud. <br><br>The project involves a significant outreach component with a number of goals. One goal is to introduce technology professionals to cybersecurity and its central role for our society and economy. Another goal is to introduce K-12 students to cybersecurity, and through it to computer science in general. The program targets students from both under-represented minorities and students with exceptional academic potential.
The proliferation and increasing sophistication of censorship warrants continuing efforts to develop tools to evade it. Yet, designing effective mechanisms for censorship resistance ultimately depends on accurate models of the capabilities of censors, as well as how those capabilities will likely evolve. In contrast to more established disciplines within security, censorship resistance is relatively nascent, not yet having solid foundations for understanding censor capabilities or evaluating the effectiveness of evasion technologies. Consequently, the censorship resistance tools that researchers develop may ultimately fail to serve the needs of citizens who need them to communicate. Designers of these tools need a principled foundation for reasoning about design choices and tradeoffs. <br><br>To provide such a foundation, this project develops a science of censorship resistance: principled approaches to understanding the nature of censorship and the best ways to facilitate desired outcomes. The approach draws upon empirical studies of censorship as the foundation for models and abstractions to allow us to reason about the censorship-resistant technologies from first principles. The project aims to characterize and model censorship activities ranging from blocked search results to interference with international network traffic. The research develops theoretical models of censorship; reconciles these with large-scale empirical measurements; and uses these observations to design censorship-resistance tools to deploy in practice, as both components of Tor and standalone systems.
Research advances have enabled innovations in collaborative work information systems that can keep track of employees and contractors in domains such as ride sharing. For instance, after drivers login to begin a work session, riding sharing computers keep track of cars, customers, and ride locations. Such systems enable accurate payments to drivers and create work histories that are shared among managers, drivers, and clients. In many other work domains, such as home care, delivery, farm work, and child care, transparent collaborative information systems do not exist, leaving work environments open to inaccurate compensation, conflict over work requirements or behavior, or even exploitation. This project will examine the needs of workers, employers, and managers for collaborative and shared reporting, and opportunities for innovative technology to create such systems. The project will lead to fundamental understanding of collaboration in work information for traditional and new forms of work that currently lack accurate and transparent measures of the work hours, effort, or performance on which compensation is based. <br><br>This project requires fundamental research and application development in three potential key intervention areas: (1) technologies to enable worker education concerning worker and employer rights and responsibilities; (2) systems that could collect shared work data for workers, employers, and managers while protecting individual privacy and confidentiality, and (3) empirical evaluations to assess effectiveness as well as understand potential risks or undesirable indirect consequences of work-related data collection. Researchers will prototype and test these systems mainly in work environments, such as farm work, custodial work, and restaurants services. The project will lead to a better understanding of the potential for technology to help create better jobs for workers, and aid managers and employers to create responsive, transparent, and equitable business and work environments.
The resiliency of much of the modern information technology ecosystem is predicated on the strength of the cryptographic constructions at its core. Uncovering new intractable problems suitable for cryptosystem design enhances the robustness of the overall infrastructure to breakthroughs like the development of quantum computers or unforeseen cryptanalytic advances against any specific computational problem. This project develops the theory and practice of a novel approach to cryptography based on a class of learning problems over non-commutative groups, known collectively as Learning Homomorphisms with Noise (LHN). The appeal of non-commutative groups as a source of cryptographic hardness, due in part to the absence of significant quantum algorithms for this setting, has long been recognized, but isolating suitable intractability assumptions has proven elusive.<br><br>The project explores four main threads: (1) designing efficient cryptographic constructions based on the hardness of LHN; (2) establishing evidence of the intractability of the underlying learning problems, especially against quantum computing; (3) building a software library to manipulate instances of these learning problems efficiently, and evaluating the performance of learning-based non-commutative cryptography; and (4) exploring additional LHN variants to overcome any limitation encountered in the execution of the other threads. By diversifying the premises on which to base cryptography and creating training opportunities in information security for tomorrow's workforce, this project will strengthen a critical part of the modern information technology infrastructure.
Natural language privacy policies have become a de facto standard to address expectations of notice and choice on the Web. Yet, there is ample evidence that users generally do not read these policies and that those who occasionally do struggle to understand what they read. Initiatives aimed at addressing this problem through the development of machine implementable standards or other solutions that require website operators to adhere to more stringent requirements have run into obstacles, with many website operators showing reluctance to commit to anything more than what they currently do. This project offers the prospect of overcoming the limitations of current natural language privacy policies without imposing new requirements on website operators.<br><br>This frontier project builds on recent advances in natural language processing, privacy preference modeling, crowdsourcing, formal methods, and privacy interfaces to overcome this situation. It combines fundamental research with the development of scalable technologies to semi-automatically extract key privacy policy features from natural language website privacy policies and present these features to users in an easy-to-digest format that enables them to make more informed privacy decisions as they interact with different websites. Work in this project also involves the systematic collection and analysis of website privacy policies, looking for trends and deficiencies both in the wording and content of these policies across different sectors and using this analysis to inform ongoing public policy debates. An important part of this project is to work closely with stake holders in industry to enable the transfer of these technologies to industry for large-scale deployment.
In September of 2015, it was reported that hackers had stolen the fingerprint records of 5.6 million U.S. federal employees from the Office of Personnel Management (OPM). This was a severe security breach, and it is an even bigger problem because those fingerprints are now permanently compromised and the users cannot generate new fingerprints. This breach demonstrates two challenging facts about the current cybersecurity landscape. First, biometric credentials are vulnerable to compromise. And, second, biometrics that cannot be replaced if stolen are even more vulnerable to theft. This research will investigate a new type of biometric that avoids both of these problems. In particular, the research will evaluate the strengths and weaknesses of brain biometrics. Brain biometrics are more difficult to steal than fingerprints, since current technology for collecting brain biometrics is impossible to use without a person's knowledge and consent. Brain biometrics, importantly, can also be cancelled if stolen. This is because there are vast networks of the brain that generate unique activity, meaning that if a person's brainprint is stolen, they can generate a new one by tapping in to a different brain network. This investigation holds the potential to transform existing authentication systems into more secure and attack-resistant brain biometric solutions; critical for high-security applications.<br><br>Brain biometrics have recently been shown to be 100% accurate in identifying people, in a pool of 50 users and across a period of up to a year. This research project will systematically evaluate the potential vulnerabilities of brainprint biometrics, with the goals of 1) demonstrating the resistance and robustness of brainprints to the most likely attacks and 2) developing a comprehensive protection plan addressed at the most vulnerable aspects of this method. In particular, the interdisciplinary team plans to investigate psychological and computational attacks. Psychological attacks consist of attempting to force a user to provide their brainprints under duress, or attempting to impersonate a target brainprint through biofeedback entrainment process. Computational attacks consist of attempting to circumvent brainprint authentication system through presenting a counterfeit or stolen brainprint, with varying levels of obfuscation, such as the addition of noise, and attacking the stimuli database. This project will examine potential vulnerabilities in brain biometrics at an unprecedented level of detail, and convert the resulting knowledge into recommendations for implementation of brain biometrics to guard an increasingly vulnerable cyberspace.
Spurred by developments such as cloud computing, there has been considerable interest in the data-mining-as-a-service (DMaS) paradigm in which a client outsources his/her data mining needs to a third-party service provider. However, this raises a few security concerns. One of the security concerns is that the service provider may return plausible but incorrect mining results to the client. There is a crucial need for techniques that enable the client to verify, without much effort, that the service provider has performed the outsourced computations faithfully and returned correct mining results. Despite the recent intensive efforts on verifiable general-purpose computations, efficient result verification of data mining computations remains a largely unexplored territory. <br><br>This CAREER proposal aims at designing efficient and practical verification techniques for data mining computations outsourced to an untrusted service provider. Research activities include developing (1) innovative verification approaches for data mining computations without any privacy preservation mechanisms; (2) new verification approaches for privacy-preserving data mining computations; (3) novel methods for the analysis of attack types and modeling of the collusion behaviors of service providers; and (4) a full system approach in developing, deploying, and evaluating the proposed techniques.<br><br>Advances in verifiable outsourcing of data mining computations can spur wider adoption of cloud services. This project also includes curriculum development and the training of high school, undergraduate, graduate, women and students in underrepresented groups.
This is funding to support travel for a diverse group of U.S. PhD students and distinguished faculty mentors to participate in a doctoral colloquium (workshop) on research on information science that will be co-located with the 2013 iConference to be hosted by the University of North Texas in Fort Worth on February 11-15. The iConferences, the annual meetings of the iSchool community, are a leading forum that brings together faculty, students, research staff, and industry practitoners with a common interest in supporting and augmenting human engagement with information and technology. Open to broad participation, the iConferences have been successful in building a sense of community around the information field, bringing together people who otherwise might rarely interact with one another, and helping them share findings and exchange views relating to their interdisciplinary research. More information about the iConference may be found online at http://www.ischools.org/iConference13/participation, <br><br>The 2013 iConference Doctoral Colloquium, which will take place on February 15, 2013 (the final day of the iConference), will be a research-focused meeting of about 25 selected Ph.D. candidates studying all aspects of information science (IS), along with approximately 10 distinguished mentors. The primary objective of the Doctoral Colloquium is to help train the next generation of information science researchers. To this end, it will provide the student participants with an environment in which they can share and discuss their goals, methods and results at an early stage of their research. By participating in the doctoral colloquium, students will gain feedback on their work both from the mentors and from other students, which should allow them to enhance their research. Students will also develop a better understanding of the different research communities engaged in the study of information science, and learn how to position their work within the IS community. In addition, the colloquium will provide students with opportunities to make new professional connections beyond their own disciplines. <br><br>Broader Impacts: The iConference doctoral colloquia traditionally bring together the best of the next generation of researchers in information science and related areas, allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Participation is encouraged from a broad range of relevant disciplines and approaches, thereby broadening attendees' perspectives on their topics of study and promoting advancement of the field. No more than one student will be accepted from any given institution, and priority will be given to students who have not previously attended an iConference Doctoral Colloquium. The organizers will proactively work to include women and minority representation among the student participants to the extent possible. As a consequence of these steps, the student and faculty participants will constitute a diverse group across a variety of dimensions, which will help broaden the students' horizons to the future benefit of the field.
This frontier project tackles many of the fundamental research challenges necessary to provide trustworthy information systems for health and wellness, as sensitive information and health-related tasks are increasingly pushed into mobile devices and cloud-based services. The interdisciplinary research team includes expertise from computer science, business, behavioral health, health policy, and healthcare information technology to enable the creation of health & wellness systems that can be trusted by individual citizens to protect their privacy and can be trusted by health professionals to ensure data integrity and security. Although these problems are motivated by a nationally important application domain (health and wellness), the solutions have applications far beyond that domain.<br> <br>This project is developing methods to authenticate clinical staff to tablet computers in a continuous and unobtrusive way, and to provide patients a usable way to control the information that mobile sensors collect about them. One of the goals is to manage security of healthcare devices in the home and in remote clinics, without adding burden on the homeowner or clinical staff; towards this end the investigators are developing methods to verify medical directives issued to remote devices. One approach being investigated is segmenting access to medical records from mobile devices to limit information exposure, and developing methods to audit behavior of this complex ecosystem of devices and systems. The investigators will design tools to handle genomic data in the cloud while enabling patient control over information, detect malware in medical devices through power analysis, and provide contextual information to those who use health data collected in the field.
This is funding to support participation by 3 PhD students based in US educational institutions in the Student Consortium (workshop) to be held in conjunction with the 2014 ACM Conference on Designing Interactive Systems (DIS 2014), which will take place in Vancouver, Canada, on June 21-25. The annual DIS conferences represent the growing interest in next-generation interactive user interfaces. Sponsored by the Association for Computing Machinery, they bring together 200-300 researchers and corporate leaders from North America, Europe, and Asia to present and discuss the latest multidisciplinary work on the design and evaluation of user interfaces, systems, and applications. At this year's conference approximately 100 papers will be presented, all of which will be published in the DIS Conference Proceedings and also in ACM's Digital Library. The program will also include invited keynote talks, system demonstrations, poster sessions, and a variety of workshops. <br><br>Topics of particular interest to the conference span a broad range, including: methods, tools, and techniques for engaging people; researching, designing, and co-designing interactive systems; the use of critical and cultural theory to understand, critique, and reflect on design products and contexts as well as design practices; user experience; usability; engagement; empowerment; well-being; designing things that matter; diversity; participation; materiality; making; sensors and actuators; mobile devices; novel artifact design; hybrid materials and surfaces; bio-electric systems; multi touch and touchless interaction; social media; personal; community, and public displays; health informatics; information and communication technologies for development (ICT4D); children-computer interaction; sustainability; and new media. More information about the conference may be found online at http://dis2014.iat.sfu.ca/. <br><br>This year DIS is for the first time organizing a Student Consortium with the goal of expanding student attendance and training in this area. The Student Consortium will be held as a full-day event on June 22, in parallel with the other conference workshops, and will provide participating students with exposure to their research community, with an opportunity to present their work and receive constructive feedback from peers and senior researchers in the field, and with ample time to start building a professional support network of peers and mentors. There were over 20 applications from students requesting to participate in the event, and the conference has accepted 12 of these, 3 of whom are from the United States. Each student will make a short presentation, followed by an open discussion and feedback from their peers. A senior researcher will be appointed as a mentor for each student, to lead the discussion, ask questions, and provide specific feedback. At lunch, sandwiches will be available in the session room so students can engage in general discussion with peers, with posters available for reference; in the evening, students will attend a group dinner for follow-on discussion and community building. All student participants receive free conference registration, a shared hotel room accommodation for the duration of the conference, and need-based travel support. The event organizers made special efforts to recruit women and members of under-represented groups; to further increase participant diversity, no more than one student per university or research institution will be supported.
The proliferation and increasing sophistication of censorship warrants continuing efforts to develop tools to evade it. Yet, designing effective mechanisms for censorship resistance ultimately depends on accurate models of the capabilities of censors, as well as how those capabilities will likely evolve. In contrast to more established disciplines within security, censorship resistance is relatively nascent, not yet having solid foundations for understanding censor capabilities or evaluating the effectiveness of evasion technologies. Consequently, the censorship resistance tools that researchers develop may ultimately fail to serve the needs of citizens who need them to communicate. Designers of these tools need a principled foundation for reasoning about design choices and tradeoffs. <br><br>To provide such a foundation, this project develops a science of censorship resistance: principled approaches to understanding the nature of censorship and the best ways to facilitate desired outcomes. The approach draws upon empirical studies of censorship as the foundation for models and abstractions to allow us to reason about the censorship-resistant technologies from first principles. The project aims to characterize and model censorship activities ranging from blocked search results to interference with international network traffic. The research develops theoretical models of censorship; reconciles these with large-scale empirical measurements; and uses these observations to design censorship-resistance tools to deploy in practice, as both components of Tor and standalone systems.
There are at least two key features of the move to cloud computing that introduce the opportunity for significant leaps forward in computer security for tenant services. First, a compute cloud provides a common software, hardware and management basis for rolling out cross-cutting services en masse that have resisted incremental deployment in a one-service-at-a-time fashion. Second, compute clouds offer providers a broad view of activity across an unprecedented diversity of tenant services. This research project leverages these features to develop new approaches to a wide array of fundamental problems in computer security. By convening Cloud Security Horizons summits with industry stakeholders, this project further seeks to both contribute to industry directions in cloud computing and to be informed by them.<br><br>Particular longstanding security challenges addressed in this project include secure transport, authorization, user and software authentication, security monitoring, and incident analysis. Moreover, since modern clouds are not sufficiently extensible to support the envisioned capabilities, this project is constructing cloud software platforms that enable the flexibility, extensibility and security needed for this research to come to fruition in practice.
Since the seminal work of Shannon in 1949 cryptography has been founded on unproven computational complexity. The security of cryptographic systems could fall apart if the assumptions behind their design turn out to be false. Thus, it is crucial to base the security of crypto-systems on weakest possible assumptions. A main component of finding minimal assumptions is to ``separate'' cryptographic tasks from assumptions that are weaker than those used in constructions. In light of recent developments in cryptography, the following two directions will be pursued:<br><br>New Techniques: A formal model to abstract the properties of cryptographic proofs and techniques is necessary to prove separations. Previously studied models, however, do not consider some of the most useful recent techniques in cryptography and mainly focus on uniform, black-box, and classical (non-quantum) proof techniques. A major goal of this project is to develop new foundations to model these new cryptographic techniques.<br><br>New Tasks and Assumptions: Recently cryptography has gone through a revolution of exploring feasibility of highly structured crypto tasks, even if this comes at the cost of using newly introduced assumptions. The second major goal of this project is to deepen our understanding of the assumptions necessary for achieving these tasks. A closely related goal is to identify the relative power of these new tasks among themselves.<br><br>To disseminate the above ideas and achieve broader impact, the project will include educational activities such as: course development, outreach to high school students to motivate them pursue degrees in theoretical computer science and cryptography, and mentoring graduate as well as undergraduate students.
Natural language privacy policies have become a de facto standard to address expectations of notice and choice on the Web. Yet, there is ample evidence that users generally do not read these policies and that those who occasionally do struggle to understand what they read. Initiatives aimed at addressing this problem through the development of machine implementable standards or other solutions that require website operators to adhere to more stringent requirements have run into obstacles, with many website operators showing reluctance to commit to anything more than what they currently do. This project offers the prospect of overcoming the limitations of current natural language privacy policies without imposing new requirements on website operators.<br><br>This frontier project builds on recent advances in natural language processing, privacy preference modeling, crowdsourcing, formal methods, and privacy interfaces to overcome this situation. It combines fundamental research with the development of scalable technologies to semi-automatically extract key privacy policy features from natural language website privacy policies and present these features to users in an easy-to-digest format that enables them to make more informed privacy decisions as they interact with different websites. Work in this project also involves the systematic collection and analysis of website privacy policies, looking for trends and deficiencies both in the wording and content of these policies across different sectors and using this analysis to inform ongoing public policy debates. An important part of this project is to work closely with stake holders in industry to enable the transfer of these technologies to industry for large-scale deployment.
Heavy vehicles (e.g., trucks and busses) are a critical element of U.S. and worldwide logistics, often carrying cargo of high value or high risk (e.g., explosive liquids and gasses). Heavy vehicles often have hundreds of Electronic Control Units (ECUs) that communicate over an internal network to carry commands (such as "engage the brakes") or share sensor data (such as the temperature of pressurized cargo unit carrying petroleum). ECUs with access to the communication network can send any message they want. If the network or an ECU is compromised by an attack, the truck or a cargo container safety mechanism could malfunction. This project is gathering data from operational trucks to better understand communication among components of heavy vehicles and developing techniques to detect attacks in this environment.<br><br>The project is working to accomplish three main objectives: (1) Collect representative Controller Area Network (CAN) bus data from operational heavy vehicles, (2) Develop detection systems that can distinguish anomalous CAN bus network traffic, and (3) Test and verify the detection systems to reduce the number of false positives. The team is developing a log algebra to efficiently assess live CAN traffic using embedded devices with limited resources. Data is being gathered from truck traffic during highway operation, enabling the application of machine learning algorithms for anomaly detection. The team is evaluating the effectiveness of their intrusion detection techniques in their heavy vehicle testbed, using synthetic attacks against testbed ECUs and real-world CAN traffic data.
The Native American Graves Protection and Repatriation Act (NAGPRA, 43 CFR 10) enacted by Congress in 1990 establishes the rights of federally recognized U.S. tribes to ascertain the whereabouts of culturally affiliated ancestral human remains, funerary objects, sacred objects, and objects of cultural patrimony, and to request repatriation of these items. The law requires scientists in the archaeological, anthropological and museum sciences to consult with tribes on matter of research, documentation, and repatriation. Even after 20 years scientists in many cases remain unsure how best to proceed in order to comply with the regulations and still use materials subject to NAGPRA in research. This project will build a NAGPRA training toolkit by bringing interdisciplinary stakeholders together to study training and build curriculum. During the initial phase of the project funded by the award the team will conduct a survey to assess current training, will develop a database of contact information and extant training materials, produce a white paper on the alignment of NAGPRA requirements with the Code of Conduct of the Register of Professional Archaeologists, distribute a newsletter to tribal entities, colleges, and cultural resource personnel, and conduct the first of several planned Collegium meetings at which faculty, consultants, and students will participate in open and equitable dialogue and joint research to ascertain how the ethics of their fields of study are taught and learned with respect to NAGPRA including direct exposure in the classroom as part of undergraduate or graduate coursework, and through mentorship of students via faculty research committees, advising, and lab or field supervision and instruction. <br><br>NAGPRA mandates interpolating multiple ways of knowing about peoples of the past. Implementation of NAGPRA has brought scientists into close interaction with descendent communities who may reckon, view, and understand their past in ways that seem at odds with the epistemologies of Western science. Indigenous worldviews may use origin narratives, oral histories, cosmologies, and cultural traditions as sources of knowledge about the past. The ethical principles that come to play with NAGPRA require increased understanding and appreciation of multiple ways of knowing by both scientists and adherents to alternative views. Hence, analyzing how scientists learn about and cope with NAGPRA targets core values and philosophies held by scientists and juxtaposes these with indigenous impressions both about the past and about what scientists do. The collegium convened to study and improve on training materials takes a practical problem and uses it to address fundamental distinctions made between scientific and alternative world-views.
The Center for Encrypted Functionalities (CORE) tackles the deep and far-reaching problem of general-purpose "program obfuscation," which aims to enhance cybersecurity by making an arbitrary computer program unintelligible while preserving its functionality. This can in turn enable a host of applications, such as hiding from potential adversaries the existence of vulnerabilities that may have been introduced through human error in the design/development process, thereby preventing tampering or deterring reverse engineering, or hiding cryptographic keys within software, thereby strengthening encryption and information transfer. <br> <br>At the heart of the Center's research activities is the development of new and rigorous mathematical techniques to build faster and more secure general-purpose mechanisms enabling such software. In pursuit of this goal, the CORE team tackles many technical questions: Can secure general-purpose mechanisms avoid the inefficiency overhead that arises from Barrington's Theorem? Can the security of these mechanisms be proven to hold against idealized adversaries, or be based on natural non-interactive hardness assumptions? Can these approaches be securely leveraged to protect data from rogue insiders, who must be able to access some data in the clear? Finally, can these mechanisms be used to reduce the level of interaction required to accomplish secure communication and computation tasks? In addition to its direct research program, the Center organizes retreats and workshops to bring together researchers to carry out the Center's mission. The Center also engages in high-impact outreach efforts, such as the development of free Massive Open Online Courses (MOOCs).
The proliferation and increasing sophistication of censorship warrants continuing efforts to develop tools to evade it. Yet, designing effective mechanisms for censorship resistance ultimately depends on accurate models of the capabilities of censors, as well as how those capabilities will likely evolve. In contrast to more established disciplines within security, censorship resistance is relatively nascent, not yet having solid foundations for understanding censor capabilities or evaluating the effectiveness of evasion technologies. Consequently, the censorship resistance tools that researchers develop may ultimately fail to serve the needs of citizens who need them to communicate. Designers of these tools need a principled foundation for reasoning about design choices and tradeoffs. <br><br>To provide such a foundation, this project develops a science of censorship resistance: principled approaches to understanding the nature of censorship and the best ways to facilitate desired outcomes. The approach draws upon empirical studies of censorship as the foundation for models and abstractions to allow us to reason about the censorship-resistant technologies from first principles. The project aims to characterize and model censorship activities ranging from blocked search results to interference with international network traffic. The research develops theoretical models of censorship; reconciles these with large-scale empirical measurements; and uses these observations to design censorship-resistance tools to deploy in practice, as both components of Tor and standalone systems.
This project seeks to optimize emerging web protocols for a faster world wide web (WWW). As the key protocol that supports WWW, the Hypertext Transfer Protocol (HTTP) has been very successful. It accounts for more than half of the overall Internet traffic. Currently, the most widely deployed HTTP version is HTTP/1.1 standardized 16 years ago. Nonetheless, several new web protocols ("NWP") such as HTTP/2, SPDY, and QUIC have been proposed recently to overcome limitations of HTTP/1.1. In particular, HTTP/2, the next version of HTTP, has been standardized in 2015 and started replacing HTTP/1.1. NWP will become prevalent in the foreseeable future. Given the importance of these web protocols, the objective of this project is to understand them, and to propose effective solutions for improving web performance by leveraging their common new features. <br><br>Specifically, this project identifies key dimensions of NWP that were not explored before, and includes the following research tasks. (1) The principal investigator (PI) will conduct a comprehensive user study by collecting web traffic from voluntary participants, to understand NWP's performance "in the wild". The measurement results not only shed light on improving the performance, energy efficiency, and mobile-friendliness of current NWP, but also provide benchmarks for evaluating future NWP. (2) The PI will investigate how to strategically leverage Server Push, a new feature of many NWP, to improve web performance. Server push allows a server to preemptively send (push) resources to the client, thus overcoming many limitations of the conventional "request-response" resource fetching paradigm. (3) The PI will study how to optimize NWP performance by simultaneously leveraging multiple interfaces (e.g., Wi-Fi and cellular on mobile devices). A new framework promises to allow multipath to be adaptively utilized only when necessary, in order to reduce the energy consumption and cellular data usage for mobile devices. (4) The PI also explores mechanisms for improving the interaction between NWP and the underlying transport layer such as the Transmission Control Protocol (TCP).<br><br>Broader Impacts: Successful completion of this research will benefit the society, due to the importance of web protocols in our everyday computing. It is known that Internet users are very sensitive to web page load time. The proposed solutions will improve web users' experience, and they can be deployed on browser and server applications to yield immediate benefits. Note the proposed solutions do not rely on a specific web protocol, and can therefore yield long-term benefits. Dissemination of the research results will be done through academic publications, code/data distribution, industrial collaborations, and standardization. The PI has included HTTP/2 in the course he taught, and will incorporate more NWP materials into the undergraduate and graduate curriculum.
Computer programs and cryptographic protocols are increasingly being used to access confidential and private information on the Internet. Due to their complex nature, they often have subtle errors that can be exploited by malicious entities. As security flaws can have serious consequences, it is important to ensure that computer programs and cryptographic protocols achieve their security objectives. As such systems have a large (potentially infinite) number of states due to presence of malicious adversaries and the concurrent nature of Internet, `pen and paper' reasoning about their correctness is challenging. In addition to the state explosion, reasoning about correctness is also challenging within the context of security because standard security objectives such as confidentiality and privacy turn out to be hyperproperties. The challenge lies in the fact that when reasoning about hyperproperties, one has to reason about correctness of the set of all executions of a system as a whole instead of correctness of individual executions. Therefore, the development of techniques to automate this reasoning is of vital importance, and is the research focus of this project. <br><br>Formally, hyperproperties generalize properties that are used to express safety and liveness guarantees in classical automated verification. A property is a set of allowable executions. A system violates a property if it exhibits an execution that is not allowed. In contrast, security objectives such as confidentiality, non-interference, privacy, and anonymity are hyperproperties. A hyperproperty is a collection of allowable sets of executions. A system violates a hyperproperty if the set of its executions is not in the collection specified by the hyperproperty. Current state-of-the art automated tools for verifying security guarantees do not scale very well as they are often aimed at certain security guarantees and often make restrictive assumptions on the systems. This project aims to develop new scalable state-of-the-art techniques in automated verification of hyperproperties by undertaking primarily three research tasks. First, we will develop and implement new symbolic algorithms for verifying finite-state systems against an expressive set of hyperproperties. The second task shall be devoted to scaling the analysis by a novel combination of automated analysis and automated counterexample generation designed specifically for hyperproperties. Finally, we shall establish theoretical results that shall reduce the problem of verifying cryptographic protocols in the presence of unbounded message sizes and nonces to the finite case. The research aims of the proposal will be paired with curriculum development at the University of Missouri where a new concentration in security will be introduced in the undergraduate curriculum that will integrate security design with software development. The results of this project will be integrated in the courses, and the project will support both undergraduate and graduate student research.
Bioassay data represent an extremely valuable source of experimental Big Data with rich content that have been substantially produced in the early stages of drug discovery for testing chemical compound bioactivities and identifying promising drug candidates. However, the power of such Big bioassay data has not been fully unleashed, particularly for the purposes of discovering novel knowledge and improving drug development. This is largely due to the fact that the exploration of a much larger space of bioassays has been fundamentally hindered by the less developed ability to identify and utilize the relations across bioassays. In this project, the PI and her team will develop novel computational methods and tools that can effectively explore a wide range of heterogeneous bioassays, identify experimentally unrevealed relations among them, and utilize the novel knowledge derived from them so as to improve compound prioritization. The research will bring scientific impacts and shed light on fully utilizing the existing wealth of Big Data, stimulating knowledge distillation in innovative manners, establishing visionary conceptual hypotheses and developing novel analytical techniques correspondingly. This research aims to solve critical problems in drug discovery through Big Data means, and has a great potential to improve drug candidate identification through accurate compound prioritization, and thus it will have far-reaching economic and societal impacts. <br><br>The PI and her team will develop a computational framework to produce better compound ranking for each bioassay. This framework will consist of a local structure learning component and a global structure learning component to discover and leverage the compound ranking within a bioassay and ranking relations across bioassays, respectively. They will also develop new methods to better rank compounds under a combination of criteria. In particular, they will solve compound ranking based on activity and selectivity simultaneously by leveraging ranking difference across bioassays. The research will be innovative, both in terms of employing original computational models and methods into important problems in drug discovery, and in terms of developing unique methodologies and computational techniques for core Computer Science research. For drug discovery, the research will provide novel perspectives and methodologies as to how researchers can utilize the large-scale experimental data to solve important problems in drug discovery. For core Computer Science, the research will contribute a new solution framework and methods spanning the areas of data mining and machine learning. Specifically, the research will lead to novel methods for boosting ranking performance by actively including additional data, incorporating relevant information within a regularized optimization framework, deploying iterative procedures and greedy strategies for large-scale problems with multiple simultaneous tasks, etc. All these methods are generalizable to a variety of other Computer Science applications. For further information see the project web page: http://cs.iupui.edu/~xning/compRank.html
The Center for Encrypted Functionalities (CORE) tackles the deep and far-reaching problem of general-purpose "program obfuscation," which aims to enhance cybersecurity by making an arbitrary computer program unintelligible while preserving its functionality. This can in turn enable a host of applications, such as hiding from potential adversaries the existence of vulnerabilities that may have been introduced through human error in the design/development process, thereby preventing tampering or deterring reverse engineering, or hiding cryptographic keys within software, thereby strengthening encryption and information transfer. <br> <br>At the heart of the Center's research activities is the development of new and rigorous mathematical techniques to build faster and more secure general-purpose mechanisms enabling such software. In pursuit of this goal, the CORE team tackles many technical questions: Can secure general-purpose mechanisms avoid the inefficiency overhead that arises from Barrington's Theorem? Can the security of these mechanisms be proven to hold against idealized adversaries, or be based on natural non-interactive hardness assumptions? Can these approaches be securely leveraged to protect data from rogue insiders, who must be able to access some data in the clear? Finally, can these mechanisms be used to reduce the level of interaction required to accomplish secure communication and computation tasks? In addition to its direct research program, the Center organizes retreats and workshops to bring together researchers to carry out the Center's mission. The Center also engages in high-impact outreach efforts, such as the development of free Massive Open Online Courses (MOOCs).
<br>Infrastructure-as-a-service (IaaS) cloud computing systems are revolutionizing business, government, and science by providing easy access to scalable computing. These public services, as offered by Amazon, Google, Microsoft, and others, allow an arbitrary customer to rent, by the hour, the resources needed to run their applications within virtual machines (VMs) hosted on the provider?s compute infrastructure. With these new services, however, comes subtle new security issues. Prior work by the PI uncovered attacks that abuse two aspects unique to cloud computing: resource sharing among mutually distrustful customers and pricing that incentivizes malicious behavior. <br><br>The proposed research is organized along the two themes of resource sharing and pricing. In the first theme, the work explores whether cryptographic side channel attacks and resource-freeing attacks pose serious threats to cloud customers and then develops new placement and CPU scheduling algorithms that realize the security principle of soft isolation: minimization of potentially dangerous cross-user scheduling interactions (e.g., sharing a server or CPU core). Within the second theme, the work explores the implications of fine-grained pricing mechanisms on security. This includes developing pricemarks (mechanisms for accurately determining the true costs of a cloud service), understanding customer-controlled placement gaming that exploits cloud performance heterogeneity, and explores pricing-based security mechanisms that, in conjunction with the aforementioned scheduling mechanisms, will degrade fiscal incentivizes for adversarial behavior. <br><br>The impact of the proposed work will be deeper understanding of threats in cloud IaaS systems, new security design principles, deployable security technologies, and improvements in security education.
Embedded systems currently rely on local and often insecure state retention for process control and subsequent forensic analysis. As critical embedded control systems (e.g., smart grids, SCADA) generate increasing amounts of data and become ever more connected to other systems, secure retention and management of that data is required. Attacks such as Stuxnet show that SCADA and other systems comprising critical infrastructure are vulnerable to the compromise of controllers and sensing devices, as well as falsification of data to circumvent anomaly detection mechanisms. <br><br>This project develops techniques and architectures for securely storing and monitoring embedded system state in critical infrastructure. We are examining vulnerabilities relating to generating and storing data in critical embedded systems, which are often resource-constrained environments. We propose the design and deployment of 'autonomously secure storage devices' that act as resilient storage for embedded devices. We are designing logging, audit, and management architectures for resiliently storing system data and provenance in the face of malicious and compromised devices. Additionally, we explore how this data may be disseminated to other systems and to environments such as the cloud and aim to protect data through privacy-preserving communication and querying interfaces, and attempt to make data-driven inferences about system operation to detect anomalous behavior. Through these active protections to generated data and metadata, we aim to provide a new baseline for producing and storing data generated within critical infrastructures.
As was realized by Descartes, the solution of algebraic equations can be realized geometrically. This observation was the start of a rich interaction between algebra and geometry. This project will study two topics in number theory. The first concerns the shape of arithmetic manifolds -- i.e., certain geometries defined by their number theoretic symmetries. The PI has conjectured the existence of new structures that govern their shape (mathematically speaking their topology), which he will investigate in more detail. The second topic relates to lattices of high dimension. These are a topic of interest in modern cryptography; on the other hand, a satisfactory mathematical theory of them is not yet available, and this project aims to develop such a theory.<br> <br>More specifically, the PI has formulated a conjecture that specifies the values of "periods" of arithmetic locally symmetric spaces -- i.e., the numbers obtained by pairing homology classes with normalized differential forms. This conjecture is interesting because it suggests a relationship between these homology groups, and certain motivic cohomology groups. The PI will study this conjecture and attempt to give evidence for it. Concerning lattices, the PI will study in particular the following questions: What is the diameter of the space of n-dimensional lattices, how do the short vectors in a typical n-dimensional lattice behave, and why does the LLL lattice reduction algorithm behave so well? A basic tool will be the analysis of automorphic forms on GL(n) for large n, and the PI will also study related questions about automorphic forms in the high-dimensional limit.
The goal of the Modular Approach to Cloud Security (MACS) project is to develop methods for building information systems with meaningful multi-layered security guarantees. The modular approach of MACS focuses on systems that are built from smaller and separable functional components, where the security of each component is asserted individually, and where the security of the system as a whole can be derived from the security of its components. The project concentrates on building outsourced, cloud-based information services with client-centric security guarantees. <br><br>The MACS project addresses a diverse set of security challenges. These include the design of hardware with built-in secrecy and integrity properties, small and versatile operating systems that offer minimal functionality but are simpler and easier to analyze, privacy-preserving and verifiable memory access for outsourced applications, security-preserving overlay and software-defined networks, and algorithms for privacy-preserving verifiable outsourced computations and database systems. Crucially, we combine all of these security mechanisms with their piecemeal analyses into a global security guarantee. Furthermore, the analysis is modular, allowing the substitution of components with others that provide potentially comparable guarantees based on different techniques and trust assumptions. The research team comprises experts in different aspects of information security and cryptography. The research is highly collaborative and pools together key areas of expertise in order to provide overall security guarantees. A key component of the project is the Massachusetts Open Cloud, which provides the research team with a test-bed for deploying and testing the developed mechanisms in a production cloud. <br><br>The project involves a significant outreach component with a number of goals. One goal is to introduce technology professionals to cybersecurity and its central role for our society and economy. Another goal is to introduce K-12 students to cybersecurity, and through it to computer science in general. The program targets students from both under-represented minorities and students with exceptional academic potential.
Machine learning has emerged as an important area of computer science, which has a potential significantly to change our lives and society. In deep learning, one needs to rely on being able to quickly test the properties of objective functions. The goal of this project is to develop algorithms for testing analytic properties of high-dimensional functions. Better understanding of properties of optimization objectives used in deep learning will enable researchers in the field to make more educated decisions regarding the choice of optimization methods. It will simplify and introduce rigor in the art of parameter tuning that plays key role in achieving high performance in training deep neural nets. The framework for approximate algorithmic functional analysis (Lp-testing) developed by the PI that forms the starting point for this research has been taught in courses on learning theory and algorithms for big data at the University of Pennsylvania and University of Buenos Aires. Together with the outcomes of the research in this proposal it will be included into M.S./Ph.D. classes on foundations of data science and algorithms for big data at Indiana University taught by the PI.<br><br>The PI will develop ultra-efficient algorithms for assisting humans in their understanding of analytic properties of high-dimensional functions and objectives used in deep learning. Three main goals and related challenges in the design of such tools are:(1) Performing algorithmic analysis of local properties of deep learning objectives in the absence of clear global structure (2) Enabling rigorous analysis of analytic properties of functions based on noisy data (3) Introducing tolerance to sampling errors in function evaluations arising in deep learning applications for performance reasons. The project will involve development of new mathematical methods for understanding how global properties of noisy functions such as monotonicity, convexity and Lipschitzness are affected by projections onto random low-dimensional linear subspaces. It will suggest choices of distributions for generation of such subspaces in order to best preserve the desired properties. A rigorous study of fundamental advantages of data-dependent methods will be conducted as a separate part of the project.
Cyber-Physical Systems (CPS) integrate devices that can interact with each other and the physical world around them. With CPS applications, engineers monitor the structural health of highways and bridges, farmers check the health of their crops, and ecologists observe wildlife in their natural habitat. Using sensory side-channels (e.g., light, temperature, infrared, acoustic), an adversary can successfully attack CPS devices and applications by (1) triggering existing malware, (2) transferring malware, (3) combining multiple side-channels to increase the impact of a threat, or (4) leaking sensitive information. This project develops novel security tools and techniques to protect CPS devices and applications against sensory side-channel threats. The project results are released as an open source project, so interested software developers can extend and reuse them in other CPS research. Broader impacts include educational training and tools for the CPS field, and a collaboration with the Miami-Dade County Public Schools (M-DCPS), to expose underrepresented middle school students to state-of-the art technology topics to pique students' interests in cyber-security and cyber-physical systems. <br><br>The project investigates the sensory side-channel (e.g., acoustic, seismic, light, temperature) threats to CPS devices and applications and evaluates the feasibility and practicality of the attacks on real CPS equipment. The result is novel sensory side-channel-aware security tools and techniques for the CPS devices. Specifically, the principal investigator (1) analyzes the physical characteristics of the sensory CPS side-channels to understand how the physical world impacts the cyber world of CPS devices; (2) investigates the information leakage through the sensory side-channels on the CPS devices; (3) develops a novel IDS particularly designed to be aware of the sensory CPS side-channels; (4) designs and develops a CPS security testbed for test and experiments on real equipment and simulation tools.
In the last ten years virtual machines (VMs) have been extensively used for security-related applications, such as intrusion detection systems, malicious software (malware) analyzers and secure logging and replay of system execution. A VM is high-level software designed to emulate a computer's hardware. In the traditional usage model, security solutions are placed in a VM layer, which has complete control of the system resources. The guest operating system (OS) is considered to be easily compromised by malware and runs unaware of virtualization. The cost of this approach is the semantic gap problem, which hinders the development and widespread deployment of virtualization-based security solutions: there is significant difference between the state observed by the guest OS (high level semantic information) and by the VM (low level semantic information). The guest OS works on abstractions such as processes and files, while the VM can only see lower-level abstractions, such as CPU and main memory. To obtain information about the guest OS state these virtualization solutions use a technique called introspection, by which the guest OS state is inspected from the outside (VM layer), usually by trying build a map of the OS layout to an area of memory where these solutions can analyze it. We propose a new way to perform introspection, by having the guest OS, traditionally unaware of virtualization, actively collaborate with a VM layer underneath it by requesting services and communicating data and information as equal peers in different levels of abstraction. Our approach allows for stronger and more fine-grained and flexible security approaches to be developed and it is no less secure than the traditional model, as introspection tools also depend on the OS data and code to be untampered to report correct results.<br><br><br>We will design, implement and make available to the research community this collaborative architecture between a guest OS and a VM layer and employ such architecture to counter various types of kernel-level malware. The goal is to increase the cost for attackers by refining trust/integrity values for subjects and objects at OS/VM layers by leveraging social trust. In this architecture guest OS and a VM actively collaborate requesting services and exchanging data and information through special instructions protected from tampering. This will open up possibilities for malware analysis and defense that are not currently possible (due to the semantic gap problem) including, preventing the actions from privacy-invasion malware like keyloggers, mitigating certain types of DoS attacks in the kernel and return-oriented rootkits, increasing the costs for attackers by leveraging social trust to refine integrity levels and restrict systems resources based on them, just to name a few. This research will also lead to the creation of a cyber security laboratory at Bowdoin, a liberal arts college located in Maine.
This frontier project tackles many of the fundamental research challenges necessary to provide trustworthy information systems for health and wellness, as sensitive information and health-related tasks are increasingly pushed into mobile devices and cloud-based services. The interdisciplinary research team includes expertise from computer science, business, behavioral health, health policy, and healthcare information technology to enable the creation of health & wellness systems that can be trusted by individual citizens to protect their privacy and can be trusted by health professionals to ensure data integrity and security. Although these problems are motivated by a nationally important application domain (health and wellness), the solutions have applications far beyond that domain.<br> <br>This project is developing methods to authenticate clinical staff to tablet computers in a continuous and unobtrusive way, and to provide patients a usable way to control the information that mobile sensors collect about them. One of the goals is to manage security of healthcare devices in the home and in remote clinics, without adding burden on the homeowner or clinical staff; towards this end the investigators are developing methods to verify medical directives issued to remote devices. One approach being investigated is segmenting access to medical records from mobile devices to limit information exposure, and developing methods to audit behavior of this complex ecosystem of devices and systems. The investigators will design tools to handle genomic data in the cloud while enabling patient control over information, detect malware in medical devices through power analysis, and provide contextual information to those who use health data collected in the field.
This project aims to study the design of efficient query algorithms for noisy datasets in distributed and streaming applications. Noisy data is universal in today's world. Imprecise and varying references to the same real-world entities are ubiquitous in scientific and commercial databases. This noise poses significant obstructions to accurate data analytics. As an example of "noisy data," consider YouTube videos. YouTube tracks the views of individual videos. However, there are frequently many similar versions of the same event and answering a basic question such as "How many people viewed this event?" is challenging using current techniques. This project will provide new techniques and insights to combat the noisy nature of large datasets, and hence will enhance our ability to process the ever-increasing quantity of business and scientific data. The products of this project will be integrated into a trilogy of graduate and undergraduate courses on algorithms, databases, and data mining. The PI will disseminate research outcomes by giving talks at conferences/workshops, universities, industrial labs, as well as online media.<br><br>More technically, this project tries to answer the following question: can we run distributed and streaming algorithms directly on the noisy datasets, resolve the noise "on the fly", and retain communication and space efficiency compared with the noise-free setting? The PI plans to study statistical, relational and graph problems. This project has the potential to impact a wide range of active research areas in theoretical computer science, including distributed and streaming algorithms, group testing, compressed sensing, communication complexity, clustering, and locality sensitive hashing.
Determining the genomic makeup of individuals is crucial for understanding how certain genomic variants ultimately lead to disease (such as cancer). Determining genomic makeup of agriculturally important plants, trees, farm animals and wild life help improve agriculture, forestry, veterinary medicine and environmental science. Since the introduction of "next generation sequencing technologies" in 2008, the cost of genome sequencing has dropped by a factor of 1000. This has led to an increase in the speed genomic data is generated that far outpaces the improvements in our computing and data storage capability. With the advent of these cheap, and fast genome sequencing technologies, the scientific community has been able to launch mega-projects such as The Pan Cancer Analysis of Whole Genomes Project, which aim to determine the genome sequences of thousands of cancer patients. Our project aims to address the imminent data size challenges in these large scale genomic studies through new genomic data compression methods that aim to reduce the redundancy in how genomic sequences are represented. The source of this redundancy is the high similarity among genome sequences of individual patients, as well as the high similarity between regions across the genome of a single human genome. Since the main difficulty in extracting information from genome sequences is computational, reduction in the computational resources needed to manage and analyze genomic data through the compression methods will help genomics improve human life and the environment. <br><br>The impact of this project on student and personnel training will be in terms of two new graduate courses at Indiana University: a course on data management, access and processing for genomic data by PI Sahinalp, and a course on compressed algorithms with a focus on genomic data, emphasizing the effects of new big data paradigms compression, by PI Ergun. Both courses will fit into the CS PhD program, as well as into the existing Bioinformatics and Data Science Master's programs; they are also intended to attract the more curious undergraduates.<br><br>The rapid advancement of nucleic acid sequencing technology has re-shaped almost every field of life science, from agriculture to bioenergy, and from environmental science to biomedicine. Large-scale genome projects are producing petabyte-scale data from thousands of patients or by mobile sensors collecting environmental samples. As the technology marches forward, most people who visit hospitals will eventually have their (possibly tissue-specific) genomes sequenced. Genomic data will be collected from thousands to millions of non-model organisms and their populations in order to assess the biodiversity within the corresponding ecosystem. Complex microbial communities will be sampled from thousands of geographic locations to study the influence of environmental conditions. Furthermore, these studies will involve continuous data collection efforts, for the purpose of monitoring the dynamic changes in biosystems by the use of genome-wide or transcriptome-wide sequencing. As a result, genomic data generation is to occur at an unprecedented pace, necessitating the development of novel algorithms to help reduce the burden of genomic sequence data on computational, storage and transmission systems. <br><br>This project combines the unique strengths of the two investigators at Indiana University, bringing a principled, algorithmic approach to critical infrastructure problems in genomics. The project will address the needs of the next stage of genomic data generation by mega cancer projects, portable devices collecting environmental samples, and even smaller sensors to be embedded in the human body, through the use of new compression tools and compressed data structures for communicating, storing, managing, and accessing large collections of (streaming) genome data. For this purpose, we will employ and expand the existing algorithmic repertoire involving approximation algorithms, sublinear algorithms, lossless data compression, I/O efficient, memory hierarchy aware/oblivious and compressed data structures.
To date, the application of quantitative security and privacy metrics metrics has seen its greatest successes when exploring the worst-case properties of a system. That is, given a powerful adversary, to what extent does the system preserve some relevant set of properties? While such analyses allow experts to build systems that are resistant to strong attackers, many deployed systems were not designed in this manner. In fact, there is growing evidence that users' privacy is routinely compromised as a byproduct of using social, participatory, and distributed applications. Given that people find inherent utility in using systems that are not secure against worst-case adversaries, this project investigates a complementary question: Can we help users better manage their participation in systems that are not privacy-preserving in an absolute sense?<br><br>This project is developing a principled approach that enables individuals to (i) quantitatively specify and assess their security, privacy, and utility goals; (ii) qualitatively express preferences on the relative importance of these goals; (iii) explore the implications of their system interactions by leveraging the trade-off spaces resulting from these quantitative and qualitative specifications; and (iv) enact locally-enforceable changes to their system usage to better balance competing needs. This project is designing computational tools that enable everyday users to better manage their system participation by understanding the interplay between security, privacy, and utility. Educational materials are being developed to support two undergraduate courses---one for computer science majors and one for non-majors---that explore the social, technical, and privacy implications of our increasingly digitized society.
Natural language privacy policies have become a de facto standard to address expectations of notice and choice on the Web. Yet, there is ample evidence that users generally do not read these policies and that those who occasionally do struggle to understand what they read. Initiatives aimed at addressing this problem through the development of machine implementable standards or other solutions that require website operators to adhere to more stringent requirements have run into obstacles, with many website operators showing reluctance to commit to anything more than what they currently do. This project offers the prospect of overcoming the limitations of current natural language privacy policies without imposing new requirements on website operators.<br><br>This frontier project builds on recent advances in natural language processing, privacy preference modeling, crowdsourcing, formal methods, and privacy interfaces to overcome this situation. It combines fundamental research with the development of scalable technologies to semi-automatically extract key privacy policy features from natural language website privacy policies and present these features to users in an easy-to-digest format that enables them to make more informed privacy decisions as they interact with different websites. Work in this project also involves the systematic collection and analysis of website privacy policies, looking for trends and deficiencies both in the wording and content of these policies across different sectors and using this analysis to inform ongoing public policy debates. An important part of this project is to work closely with stake holders in industry to enable the transfer of these technologies to industry for large-scale deployment.
The Center for Encrypted Functionalities (CORE) tackles the deep and far-reaching problem of general-purpose "program obfuscation," which aims to enhance cybersecurity by making an arbitrary computer program unintelligible while preserving its functionality. This can in turn enable a host of applications, such as hiding from potential adversaries the existence of vulnerabilities that may have been introduced through human error in the design/development process, thereby preventing tampering or deterring reverse engineering, or hiding cryptographic keys within software, thereby strengthening encryption and information transfer. <br> <br>At the heart of the Center's research activities is the development of new and rigorous mathematical techniques to build faster and more secure general-purpose mechanisms enabling such software. In pursuit of this goal, the CORE team tackles many technical questions: Can secure general-purpose mechanisms avoid the inefficiency overhead that arises from Barrington's Theorem? Can the security of these mechanisms be proven to hold against idealized adversaries, or be based on natural non-interactive hardness assumptions? Can these approaches be securely leveraged to protect data from rogue insiders, who must be able to access some data in the clear? Finally, can these mechanisms be used to reduce the level of interaction required to accomplish secure communication and computation tasks? In addition to its direct research program, the Center organizes retreats and workshops to bring together researchers to carry out the Center's mission. The Center also engages in high-impact outreach efforts, such as the development of free Massive Open Online Courses (MOOCs).
There are at least two key features of the move to cloud computing that introduce the opportunity for significant leaps forward in computer security for tenant services. First, a compute cloud provides a common software, hardware and management basis for rolling out cross-cutting services en masse that have resisted incremental deployment in a one-service-at-a-time fashion. Second, compute clouds offer providers a broad view of activity across an unprecedented diversity of tenant services. This research project leverages these features to develop new approaches to a wide array of fundamental problems in computer security. By convening Cloud Security Horizons summits with industry stakeholders, this project further seeks to both contribute to industry directions in cloud computing and to be informed by them.<br><br>Particular longstanding security challenges addressed in this project include secure transport, authorization, user and software authentication, security monitoring, and incident analysis. Moreover, since modern clouds are not sufficiently extensible to support the envisioned capabilities, this project is constructing cloud software platforms that enable the flexibility, extensibility and security needed for this research to come to fruition in practice.
This project tackles the social and economic elements of Internet security: how the motivations and interactions of attackers, defenders, and users shape the threats we face, how they evolve over time, and how they can best be addressed. While security is a phenomenon mediated by the technical workings of computers and networks, it is ultimately a conflict driven by economic and social issues that merit a commensurate level of scrutiny. Today's online attackers are commonly profit-seeking, and the implicit social networks that link them together play a critical role in fostering the innovation and the efficiency underlying cybercrime markets. Further, the socio-economic lens can provide vital insights not only for understanding attackers, but victims too. Today's consumers, corporations, and governments make large investments in security technology with little understanding of their ultimate return-on-investment. And the ease with which we adopt online personas and relationships has created a collective blind spot that attackers exploit all-too-easily.<br><br>Grappling with these socio-economic dimensions is of fundamental importance for achieving a secure future information infrastructure, and developing a sound understanding of them requires research grounded in empiricism. Accordingly, the project has four key components: (1) pursue in-depth empirical analyses of a range of online criminal activities; (2) map out the evolving attacker ecosystem that preys on online social networks, and the extent to which unsafe online behavior is itself adopted and transmitted; (3) study how relationships among these criminals are established, maintained, and evolve over time; and (4) measure the efficacy of today's security interventions, both in the large and at the level of individual users. Across all of these efforts, the aim is to identify bottleneck elements where interventions might most effectively undermine entire ecosystems of abusive and criminal activities. Consequently, this research has the potential to dramatically benefit society by undermining entire cybercrime ecosystems: disrupting underground activities, infrastructure, and social networks through strategic intervention. The work will also create numerous educational opportunities, including undergraduate and graduate education as well as workforce education for security professionals, law enforcement, civil regulatory agencies, and legal scholars and professionals tasked with countering modern Internet threats.
Our physical world presents an incredibly rich set of observation modalities. Recent advances in wireless sensor networks (WSNs) enable the continuous monitoring of various physical phenomena at unprecedented high spatial densities and long time durations, hence opening exciting new opportunities for numerous scientific endeavors. Since sensor nodes are unattended and batterypowered, network monitoring/tomography from indirect measurements at the sink(s) and energy conservation are critical in the deployment of large-scale environmental WSNs. Therefore, a viable framework for energy-efficient network monitoring and data collection is fundamentally important to significantly improve WSN management/operations and reduce its deployment costs.<br><br>This project investigates the energy-efficient network monitoring/tomography and data collections in large-scale outdoor WSNs, based on the recent breakthrough of compressed sensing (CS) through an integrated theoretical and empirical approach. The project studies WSN topology tomography for dynamic routing under wireless link dynamics due to channel fading and interference. The objectives of this project are to develop a novel and rigorous framework of topology tomography for real-world WSNs operated in highly noisy communication environments. Dynamic routing topology recovery algorithms are devised for both complete indirect measurements and incomplete indirect measurements received at the sink(s). The accuracy of the tomography approach is studied both analytically and empirically. The developed WSN topology tomography framework can be essential not only for WSN's routing improvement, topology control, hot spot elimination, and anomaly detection in practice, but also for emerging CS-based data collection. This approach extends the current CS technology to form a unified framework for network tomography and data collection in large-scale WSNs, upon which energy-efficient WSN topology tomography and data gathering protocol suite is developed. The developed framework and protocol suite will be validated and evaluated in a real-world environmental WSN testbed in a hilly watershed.<br><br>The project intends to create a new paradigm of optimal design, development, and management/operations for large-scale WSNs to significantly extend their lifetime. This would lead to a substantial reduction of the prohibitive cost of large-scale WSN deployments for scientific, civic, national security, and military purposes in the near future. The project creates an interdisciplinary educational practice for both undergraduate and graduate students through hands-on experience with a real-world WSN testbed. The outreach includes summer camps and scientific projects for school students using the WSN testbed.
There are at least two key features of the move to cloud computing that introduce the opportunity for significant leaps forward in computer security for tenant services. First, a compute cloud provides a common software, hardware and management basis for rolling out cross-cutting services en masse that have resisted incremental deployment in a one-service-at-a-time fashion. Second, compute clouds offer providers a broad view of activity across an unprecedented diversity of tenant services. This research project leverages these features to develop new approaches to a wide array of fundamental problems in computer security. By convening Cloud Security Horizons summits with industry stakeholders, this project further seeks to both contribute to industry directions in cloud computing and to be informed by them.<br><br>Particular longstanding security challenges addressed in this project include secure transport, authorization, user and software authentication, security monitoring, and incident analysis. Moreover, since modern clouds are not sufficiently extensible to support the envisioned capabilities, this project is constructing cloud software platforms that enable the flexibility, extensibility and security needed for this research to come to fruition in practice.
An increasing amount of software depends on the network, and at the same time networks themselves are becoming more programmable via technologies like OpenFlow, opening a wide range of opportunities both for network efficiencies and in-network computation. While new programming models seek to make network reconfiguration easier, none provide tools to solve the joint problem of software-controlled routing and placement of in-network computational services. This project will design and build a domain specific language (DSL), called Flange, for managing services in networks. The project's approach marshalls configurable forwarding and computing devices in the network, with pervasive monitoring to support service adaptation. The project includes building and releasing a prototype compiler, runtime, system and front-ends that enable Flange programming both with dedicated syntax (standalone DSL) and embedded in host languages. <br><br>The success criteria for this project is that a network administrator using the prototype is able to set a new service (e.g. video-transcoding) using less than a page of Flange code. Using the same mechanism, a network engineer should be able to launch a persistent function that monitors network conditions and responds to saturation by redirecting traffic to an alternate path. The novelty of the project is twofold. First, the semantic foundation at the root of the project treats both hardware and software aspects of networks uniformly, as constituting a single process network. For example, the project models forwarding as an in-the-network service, while considering it in the same light as other potentially instantiated services in the network such as transcoding or compression. Second, the Flange language will provide novel global view programming abstractions for large networks. Flange programs will be able to inspect network entities, aggregate information, signal and respond to events, all without reference to their own place of execution (which is often physically distributed). <br><br>The work proposed here stands to impact network operational efficiency and flexibility for national science-focused cyberinfrastructure as well as in commercial applications, where the economic impact of networked computing is clear. In addition, the design decisions the underly Flange are pedagogically relevant and will be presented in courses taught by the PIs.
An operating system is the key software of a computer system that manages the hardware and software resources and provides essential services to computer programs. It plays a critical role in the security of the whole system. Unfortunately, modern operating systems are often bloated with millions of lines of source code, and serious vulnerabilities are routinely being discovered and exploited from them. Researchers have proposed various novel solutions based on the "one-layer-below" approach, in which a more privileged software component (i.e., a hypervisor) is introduced to monitor and/or regulate the operating system?s behavior. However, the large trusted computing base of modern hypervisors and the recent attacks against them put this approach into question. This project aims at developing a systematic approach to improve the trustworthiness of operating systems by enabling their self-defense, without resorting to other software layers that may be vulnerable themselves.<br><br>The goal of this project is being achieved in three key steps: first, the project develops a kernel-level security enclave that will provide a trusted, secure execution environment for other security systems and mechanisms. Second, based on the strong isolation provided by the enclave, the researchers design and implement several self-defense techniques for operating system kernels. Third, a cold-boot attack is a powerful physical attack that can extract sensitive information from the physical memory of a lost or stolen computer (including mobile devices). It has become a major security concern for corporations and governments. This project investigates a comprehensive defense against cold-boot attacks by encrypting the whole memory of a sensitive program on commodity hardware platforms. The results from this project could substantially improve our defensive capabilities against malicious and stealthy kernel-level malware and cold-boot attacks, and thus significantly improving the trustworthiness of computer systems. Research results are disseminated through publications, releasing of the tools developed, and integrating into the educational activities at both the graduate and undergraduate levels.
With the increasing reliability and pervasiveness of wireless networks, more and more critical systems such as vehicular networks, military systems, and first responder systems, rely on wireless networks. In modern hospitals, wireless technology will be used to interconnect medical, sensing, and computing devices, as well as the electronic health record system to enable smart medical applications, such as real-time patient monitoring, which can significantly improve quality of care. Researchers have accumulated abundant knowledge for designing network solutions for critical systems, however, most of them isolate the network designs from application context: very limited context of the application circumstances, e.g. location and user identity, is considered. Differently, in medical applications for connected hospitals, the network and security functionalities of medical systems are often tightly coupled with the medical context, such as patient's physiological state and caregiver's workflow. As much of those context information becomes available in real-time via connected medical devices and sensors, this project addresses this urgent challenge to investigate and integrate context into network control under safety requirements. If successful, the research results shall reduce hazards and deployment cost of wired networks in hospitals, and facilitate real-time and efficient information exchange among patients, doctors, and clinical support systems.<br><br>This work establishes fundamental network models that incorporate context information, and provides networking solutions for different medical applications under their safety and reliability requirements. Specifically, the intellectual contributions of this proposed work are: i) networked medical devices, sensors, electronic health record, and clinical decision support systems provide real-time and rich contextual information about the patients and the medical procedures. We investigate the relation between the medical context and the medical systems network and security functionalities, and create context based network and security control models. ii) Under the reliability and safety requirements of medical applications, we design and develop technologies to coordinate data collection across heterogeneous wireless networks, control electromagnetic interference, configure and optimize operations of medical devices. iii) Since trustworthy authentication to medical devices, networks, and electronic health record is vital to protect patient?s safety and privacy, we design access control algorithms based on patient specific medical context. iv) To integrate different control solutions into a consistent system in various contexts, we design control analysis algorithms and tools to identify hidden policy conflicts statically and dynamically. v) A reference wireless medical sensor and device testbed is created and deployed into real scenarios under a variety of contexts.
In September of 2015, it was reported that hackers had stolen the fingerprint records of 5.6 million U.S. federal employees from the Office of Personnel Management (OPM). This was a severe security breach, and it is an even bigger problem because those fingerprints are now permanently compromised and the users cannot generate new fingerprints. This breach demonstrates two challenging facts about the current cybersecurity landscape. First, biometric credentials are vulnerable to compromise. And, second, biometrics that cannot be replaced if stolen are even more vulnerable to theft. This research will investigate a new type of biometric that avoids both of these problems. In particular, the research will evaluate the strengths and weaknesses of brain biometrics. Brain biometrics are more difficult to steal than fingerprints, since current technology for collecting brain biometrics is impossible to use without a person's knowledge and consent. Brain biometrics, importantly, can also be cancelled if stolen. This is because there are vast networks of the brain that generate unique activity, meaning that if a person's brainprint is stolen, they can generate a new one by tapping in to a different brain network. This investigation holds the potential to transform existing authentication systems into more secure and attack-resistant brain biometric solutions; critical for high-security applications.<br><br>Brain biometrics have recently been shown to be 100% accurate in identifying people, in a pool of 50 users and across a period of up to a year. This research project will systematically evaluate the potential vulnerabilities of brainprint biometrics, with the goals of 1) demonstrating the resistance and robustness of brainprints to the most likely attacks and 2) developing a comprehensive protection plan addressed at the most vulnerable aspects of this method. In particular, the interdisciplinary team plans to investigate psychological and computational attacks. Psychological attacks consist of attempting to force a user to provide their brainprints under duress, or attempting to impersonate a target brainprint through biofeedback entrainment process. Computational attacks consist of attempting to circumvent brainprint authentication system through presenting a counterfeit or stolen brainprint, with varying levels of obfuscation, such as the addition of noise, and attacking the stimuli database. This project will examine potential vulnerabilities in brain biometrics at an unprecedented level of detail, and convert the resulting knowledge into recommendations for implementation of brain biometrics to guard an increasingly vulnerable cyberspace.
Streaming videos wirelessly on mobile devices is an increasingly important application. The objective of this project is to bring innovations to mobile video delivery for new content types and over emerging networks. Specifically, the project investigates three aspects: (1) 360-degree immersive video delivery, (2) video streaming over multiple network paths (multipath), and (3) video streaming over millimeter-wave (mmWave) links. These are expected to be the key building blocks of next-generation video streaming services. First, 360-degree videos provide users with unique panoramic viewing experience; however, 360-degree video content delivery is much more challenging compared to regular videos. Second, multiple network interfaces have become a norm on off-the-shelf mobile devices but their potential is far from being fully exploited. Third, mmWave is a key technology that will be integrated into 5G wireless networks; but adapting video streaming to mmWave largely remains an uncharted territory. The proposed solutions will benefit the society by enhancing the user experience and reducing the resource consumption for next-generation immersive video services. The research will also be integrated with an education plan that seeks to prepare computer science students with the knowledge of new technological trends in networking and systems, and stimulate the general public interest in Science, Technology, Engineering, and Mathematics.<br><br>This project includes three inter-connected research thrusts. (1) For 360 video streaming, based on the concept of field-of-view (FoV) guided streaming, the project uses big data analytics to facilitate accurate head movement prediction, a key prerequisite for FoV-guided streaming. It also uses a rate adaptation scheme with a "delta encoding" design allowing the quality of a fetched chunk to be incrementally upgraded. This substantially improves adaptability when facing randomness in head movements. (2) For multipath streaming, the project uses multiple network interfaces to be used simultaneously for streaming videos. The network framework supports video rate adaptation and allows users to flexibly configure each path's cost. The framework also supports delay-sensitive live streaming over multipath through strategic packet scheduling. (3) mmWave links bear unique characteristics of massive capacity and intermittent availability. The project first designs a transport layer for mmWave links. It then proposes several video streaming strategies tailored to mmWave, such as strategically combining mmWave and legacy omni-directional radios. For the above research thrusts, the project will develop algorithms, models, and systems, backed up by real implementation and evaluation.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
The Public Key Infrastructure (PKI), along with the Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols, are responsible for securing Internet transactions such as banking, email, and e-commerce; they provide users with the ability to verify with whom they are communicating online, and enable encryption of those communications. While the use of the PKI is mostly automated, there is a surprising amount of human intervention in management tasks that are crucial to its proper operation. As a result, there have been numerous instances where mismanagement of the PKI has harmed the security of end users. This project is developing techniques to better understand and improve the management of the PKI, helping to better secure the Internet.<br><br>This project has four research foci, each examining the management challenges faced by different players in the PKI: Content Distribution Network (CDN) administrators, Certificate Authorities (CAs), end-users, and non-Web protocols. First, the project is conducting measurements to better understand the frequency of sharing private keys between sites and their CDNs, and to improve the security of this practice. Second, the project is developing new incentives for CAs to ensure information about their revoked certificates reach end users. Third, the project is aiming to better understand how the PKI will evolve as the Internet of Things (IoT) grows and the PKI is forced to quickly scale up. Fourth, the project will expand existing measurement approaches to understand the difficulties of PKI management in non-Web protocols (e.g., IMAPS), which have traditionally been less-well maintained.
Side-channel attacks (SCA) have been a realistic threat to various cryptographic implementations that do not feature dedicated protection. While many effective countermeasures have been found and applied manually, they are application-specific and labor intensive. In addition, security evaluation tends to be incomplete, with no guarantee that all the vulnerabilities in the target system have been identified and addressed by such manual countermeasures. This SaTC project aims to shift the paradigm of side-channel attack research, and proposes to build an automation framework for information leakage analysis, multi-level countermeasure application, and formal security evaluation against software side-channel attacks.<br><br>The proposed framework provides common sound metrics for information leakage, methodologies for automatic countermeasures, and formal and thorough evaluation methods. The approach unifies power analysis and cache-based timing attacks into one framework. It defines new metrics of information leakage and uses them to automatically identify possible leakage of a given cryptosystem at an early stage with no implementation details. The conventional compilation process is extended along the new dimension of optimizing for security, to generate side-channel resilient code and ensure its secure execution at run-time. Side-channel security is guaranteed to be at a certain confidence level with formal methods. The three investigators on the team bring complementary expertise to this challenging interdisciplinary research, to develop the advanced automation framework and the associated software tools, metrics, and methodologies. The outcome significantly benefits security system architects and software developers alike, in their quest to build verifiable SCA security into a broad range of applications they design. The project also builds new synergy among fundamental statistics, formal methods, and practical system security. The automation tools, when introduced in new courses developed by the PIs, help improving students' hands-on experience greatly. The project also leverages the experiential education model of Northeastern University to engage undergraduates, women, and minority students in independent research projects.
By collecting sensor data from individuals in a user community, e.g., using their smartphones, it is possible to learn the behavior of communities, for example locations, activities, and events. Similarly, using data from personal health monitoring sensors, it is possible to learn about the health risks and responses to treatments for population groups. But is it possible to use the valuable information for the greater good without disclosing information about the individuals contributing the data? What about protecting this information from improper access? This project uses cloud computing augmented with a combination of data reduction techniques and methods from differential privacy and homomorphic encryption to address such questions. The key ideas are (1) to use coresets as a way of mitigating the computational challenges around the state of the art in differential privacy and homomorphic encryption and to ensure private secure computation on the server side and the client side, and (2) to give the data owners control over setting access to their data as a trade-off between data access control guarantees and computation accuracy. Combining coresets, differential privacy, and homomorphic encryption has the potential for practical private and secure computation in the cloud.<br><br>This proposal builds on previous results in coresets, private coresets, and their implementations for the cloud. Coresets are a data reduction technique for computing a function f on a large data set D efficiently by compressing the initial data into a small data set C (possibly on the cloud), and then solving the problem f on the reduced set C (now, possible also at the client). The reduced data set C is chosen so that it is fast to compute f(C) and f(C) ~ f(D). A particular type is coreset is the private coreset, which preserves privacy but must be constructed and sanitized on the client side. On the other hand, fully homomorphic encryption allows encrypted computation on the server side but it is usually impractical. This project develops (i) New private coresets for broad classes of practical problems, with focus on generic frameworks as for non-private coresets; (ii) Novel algorithms and techniques for efficient homomorphic encryption on the cloud using coresets; (iii) Private Encrypted Coresets which are new type of coresets that simultaneously preserve privacy and can be computed securely on the cloud; (iv) Life-logging systems that implement and combine the above techniques for simultaneous secure and private computation in the cloud, with appropriate benchmarks and real-world testing.
Data structures have a prominent modern computational role, due to their wide applicability, such as in database querying, web searching, and social network analysis. This project focuses on the interplay of data structures with security protocols, examining two different paradigms: the security for data structures paradigm (SD) and the data structures for security paradigm (DS). The objectives of this project are, in the SD paradigm, to provide security and privacy both for data elements in data sets and also for the inter-relationships and distributions between such data elements, such as links between nodes in a social network, and, in the DS paradigm, to develop new data structures to improve the efficiency of algorithms for security and/or privacy applications.<br> <br>The project explores methods for achieving these objectives include algorithm design, theoretical analysis, rigorous proofs of security and correctness, and experimental validation of claims of practicality. This research focuses on the security and cybersecurity uses of three advanced data structures: tree structures, invertible Bloom filters and cascading tables. The project advances knowledge on (a) authenticated data structures and verifiable query execution within the SD paradigm, and (b) secure deduplication, searchable encryption, and privacy-preserving memory allocators within the DS paradigm.
The Internet enables people around the world to communicate, fostering free speech, a free press, and democracy. For billions of people, however, the freedom to communicate via the Internet is regulated, monitored and restricted by governments or corporations. To combat such censorship, researchers have designed and deployed a variety of censorship circumvention systems. Unfortunately, such systems have been designed based on ad hoc heuristics (rather than on solid, theoretical foundations) and can be defeated by typical state-level censors. This research project is developing theory, methodologies, and tools to formally design, evaluate, and compare censorship resistance systems. <br><br>The researchers are developing a formal model for the Internet censorship problem based on theoretical foundations. In particular, they are deriving a standard set of metrics for modeling the parties involved in each Internet censorship scenario, and leverage game theory, network science, and information theory for the analysis of specific censorship resistance systems. An important part of this project is the design and deployment of effective censorship resistance systems that will provide reliable, sustainable censorship resistance to Internet users. One approach being targeted by the researchers is leveraging emerging communication paradigms such as content caching, mobility, and cloud computing in the design of censorship circumvention tools. The second approach targeted by the researchers is adapting the design of circumvention systems to the architectural evolutions of the Internet. Specifically, the researchers are investigating the impacts of software-defined networking (SDN) and network functions virtualization (NFV) on Internet censorship and adapting the design of circumvention systems to ensure sustainable circumvention performance for the future.
Use of encrypted Web traffic is growing at an unprecedented rate. While enhancing user privacy, the Secure Hypertext Transfer Protocol (HTTPS) makes it difficult for middleboxes that are commonly used by Internet service providers and mobile carriers to operate, because numerous beneficial middlebox functions (e.g., caching, web page optimization) rely on accessing the unencrypted traffic content. To overcome this challenge, this project develops a system aiming for a practical, ready-to-deploy solution that allows middleboxes to selectively inspect and manipulate HTTPS traffic while still respect the privacy requirements of users. This research will lead to new and continuous innovations in network services that are hard or impossible to achieve today. <br><br>The system has two prominent features. First, it is only deployed at client hosts as an operating system (OS) service, as well as on middleboxes. In addition to being transparent to applications, it does not change the encryption protocol or anything on the server side. Therefore, the system can be easily deployed by, for example, regular OS update pushed by mobile carriers. Second, the system allows clients to control what information the middlebox can access. Doing so provides least privileges to middleboxes for performing their functions. In addition, the proposed system is easy to use, secure, and incurs low overhead.<br><br>Developing these technologies will facilitate our understanding of the possible design space to allow coordinated, secure, and efficient manipulation of HTTPS traffic, ultimately leading to improved Internet user experience and privacy. The PIs will incorporate knowledge and results developed in this project into both undergraduate and graduate courses in networking, mobile computing and network security.
Semiconductor chip fabrication is being increasingly outsourced to off-shore foundries. Outsourced fabrication reduces cost by leveraging economies-of-scale and ensures access to the most advanced manufacturing technology, but comes at the expense of trust. How can the chip designer trust that the off-shore (untrusted) foundry does not pirate its intellectual property (IP), or maliciously modify the integrated circuit (IC) by inserting a hardware Trojan in the chip? This project develops transformative new solutions for trustworthy chip fabrication at off-shore foundries. Traditionally, chips have been designed with metrics like performance and power consumption in mind; this project aims to introduce and account for security as a new and equally important metric in each step of the chip design flow. The outcome of the proposed research is a new set of algorithms for designing chips that are not only high performance and low power, but also secure against IP theft or hardware Trojan insertion by an untrusted, off-shore foundry. The project ensures that defense agencies and commercial chip design companies in the United States are able to access top-end foundries anywhere in the world without having to compromise trust, thus contributing to the US economy and enhancing national security. Furthermore, the project trains a new generation of security professionals by introducing students to fundamental security concepts at an early stage, and encourages greater participation of under-represented minorities in this critical area.<br><br>The research builds upon two promising (and related) techniques that have been proposed in literature to enable secure outsourced IC fabrication, logic encryption and split fabrication. Both approaches are premised on the same basic idea, i.e., to provide the untrusted foundry (the attacker) with only partial knowledge of the design so as to limit the attacker?s ability to pirate or modify the design. However, existing approaches for logic encryption and split fabrication largely retrofit these techniques as extra steps into the conventional chip design flow; that is, they treat security as an afterthought. This project aims to fundamentally re-think automated chip design algorithms (referred to as EDA algorithms) so as to provide formal security guarantees and to provide maximum security while optimizing for chip performance and power. Specifically, the research develops new security-aware algorithms for three critical steps in chip design: logic synthesis (the chip 'compiler'); (ii) logic partitioning (breaking up a circuit into smaller components) and (iii) placement (determining the physical location of each component on the chip surface). These are integrated into a new end-to-end secure EDA flow for trustworthy off-shore chip fabrication.
Message passing has long been known as a powerful tool for structuring parallel and distributed computation. Systems dating back more than 30 years have been built around message passing as the fundamental interprocess communications primitive. However, the use of message passing has been restricted to relatively coarse-grained application architectures due to message passing overhead. This project provides hardware to support an initial demonstration of coupling programmable network interfaces (10 Gbps NetFPGAs) into process scheduling in support of fine-grained message passing.<br><br>The project explores novel hardware and software support for message-driven computation based on the concept of futures, a nearly 40 year old concept from programming languages. It also builds on both the NetFPGA platform and the memory models made available by the PCI-E bus and processors such as the latest Intel Xeon E5 series processors. Using the hardware support for locks and transactional memory as well as Data-Direct I/O into the cache in combination with a process execution model based on futures, this new approach to futures and message-driven scheduling revisits powerful historical approaches like dataflow in a realistic framework that stands to have impact in high-performance parallel computing and scalable network service architectures.
One of the most significant challenges in cybersecurity is that humans are involved in software engineering and inevitably make security mistakes in their implementation of specifications, leading to software vulnerabilities. A challenge to eliminating these mistakes is the relative lack of empirical evidence regarding what secure coding practices (e.g., secure defaults, validating client data, etc.), threat modeling, and educational solutions are effective in reducing the number of application-level vulnerabilities that software engineers produce. This research aims to perform experiments analyzing programming assignment submissions to Massively Open Online Courses (MOOCs) before and after secure coding and threat modeling techniques are taught to empirically measure their impact on the rate of security vulnerabilities in assignment implementations. A key component of this research will be the use of MOOC assignment specifications and variations that have the potential to be affected by common cybersecurity vulnerabilities, such as problems with input validation to web applications or privilege escalation on mobile platforms. Because these critical security implementation issues will be known ahead of time, the MOOC assignments will allow automated assessment of how successfully each assignment implementation manages these security issues.<br><br>Key questions investigated by this research include analyzing the impact of varying secure coding and threat modeling techniques on vulnerability production in software, what level of abstraction these techniques need to be taught at to be effective, the relative return on investment of threat modeling vs. automated vulnerability assessment effort, and the comparative effectiveness of making developers aware of security issues versus requiring active application of secure coding and threat modeling techniques. The broader impact of this research is substantial. Very little empirical data is available for organizations to use to properly value the secure coding and threat modeling techniques that have been developed. By creating a large body of rigorous evidence to illustrate how effective (or possibly not effective) different techniques are, the research will allow organizations to evaluate their return on investment and improve the use of these techniques in the software engineering process.
This project addresses how semiconductor designers can verify the correctness of ICs that they source from possibly untrusted fabricators. Existing solutions to this problem are either based on legal and contractual obligations, or use post-fabrication IC testing, both of which are unsatisfactory or unsound. As a sound alternative, this project designs and fabricates verifiable hardware: ICs that provide proofs of their correctness for every input-output computation they perform in the field. These proofs must be efficiently verifiable in less time and energy than it takes to re-execute the computation itself.<br><br>Building upon exciting recent theoretical and practical advances in verifiable outsourced computation for the cloud, this project develops new techniques that exploit the unique constraints and adversary models that relate to the verifiable hardware problem. In addition, the project also develops new practical approaches to the problem of general verifiable computation. As a broader impact, computing systems security is one of the greatest technological problems faced by society today. Verifiable hardware is an essential foundation for building future computing systems that are reliable and free from catastrophic security failures. The ultimate goal of this project is to make verifiable hardware practical and accessible for use in cryptographic and mission-critical hardware applications through open-source tools. The PIs are strongly committed to education and public outreach by producing widely-used course materials and taking active roles in outreach at minority-serving universities, community colleges, student organizations and high schools.
The explosion of digital data carries a wealth of opportunities. The ability to collect and mine data at scale continues to enable new applications and transform our lives. However, privacy concerns are seen as a major hurdle towards data sharing and analytics. This project develops a practical framework for "oblivious computation", which allows general computation over sensitive data, but without disclosing the data. <br><br>The proposed work takes a combined algorithms and programming language lens. On the programming language side, the proposed work designs friendly programming abstractions that facilitate the compilation of programs into efficient, oblivious representations. On the algorithms side, the proposed work designs efficient oblivious algorithms for a wide characterization of realistic tasks. The resulting framework, ObliVM, allows non-expert developers to write programs much as they do today, and ObliVM automatically generates the corresponding oblivious computation implementation. ObliVM supports several different architectures for implementing oblivious computation, including those based on trusted hardware and those based on cryptographic secure computation. ObliVM offers a unified programming framework such that a developer can write a program irrespective of the backend architecture -- through a universal intermediate representation, this program can be compiled to either a trusted hardware-based or a cryptography-based backend architecture. ObliVM can facilitate the deployment of oblivious computation in real-life scenarios, and allow businesses and individuals to monetize sensitive data without the risk of exposure.
The security architecture of consumer operating systems is currently undergoing a fundamental change. In platforms such as Android, iOS, and Windows 8, each application is a separate security principal that can own data. While this distinction is a vast improvement over traditional user-focused security architectures, sharing data between applications results in an unexpected loss of control of that data, potentially exposing security and privacy sensitive information. This research improves the security of these modern consumer operating systems by providing a holistic view of data protection. In particular, this work proposes a new operating system abstraction for transparently tracking and controlling access to all data, allowing policy to determine if a reader is given the true value, a fake or modified value, or no value at all. To efficiently and practically accomplish this goal, this work combines several existing and new techniques to track and control access to data. The new abstraction provided by this work not only solves a significant problem affecting modern consumer operating systems by enabling applications to retain pervasive control over their data, but also more broadly provides a new abstraction on which a variety of new security solutions can be built.
Machine learning on large-scale patient medical records can lead to the discovery of novel population-wide patterns enabling advances in genetics, disease mechanisms, drug discovery, healthcare policy, and public health. However, concerns over patient privacy prevent biomedical researchers from running their algorithms on large volumes of patient data, creating a barrier to important new discoveries through machine-learning. <br><br>The goal of this project is to address this barrier by developing privacy-preserving tools to query, cluster, classify and analyze medical databases. In particular, the project aims to ensure differential privacy --- a formal mathematical notion of privacy designed by cryptographers which has gained considerable attention in the systems, algorithms, machine-learning and data-mining communities in recent years. The primary challenge in applying differentially-private machine learning tools to biomedical informatics is the lack of statistical efficiency, or the large number of samples required.<br><br>The project will overcome this challenge by drawing on insights obtained from the PI's expertise to develop differentially-private and highly statistically-efficient machine learning tools for classification and clustering. The proposed research will advance the state-of-the-art in privacy-preserving data analysis by combining insights from differential privacy, statistics, machine learning, and database algorithms. <br><br>The proposed research is closely tied to the development of the undergraduate and graduate curricula at UCSD, feeding into the PI's new undergraduate machine learning class, a new graduate learning theory class, and updates to an algorithm design and analysis class. The corresponding materials will be publicly disseminated through the PI's website. The PI is strongly committed to increasing the participation of women and minorities, and will engage in outreach activities to attract and retain women in computer science.
Interoperable, reconfigurable systems of medical devices are the future of medical technology. They will improve care outcomes by catching common mistakes, reduce clinician cognitive workload by suppressing false alarms, and streamline and simplify continued care, especially when patients move between different medical facilities. As the penetration of "smart" networked medical technology increases, we will see increased problems with cybersecurity of such systems. This project is building the theoretical foundations and software prototypes to enable safe and secure real-time medical coordination in the presence of not only random faults, but actively malicious actors.<br><br>Medical and cyber-physical systems rely on real-time feedback and control, where microseconds could mean the difference between correct functionality and a fault, and ultimately, in medical systems, life and death. Since it is not possible to count on technology functioning flawlessly, especially with intelligent active attackers who may have access to medical devices or the network through which they communicate, this project seeks to develop requirements and best practices for "optimistic real-time" safety-critical systems, with built-in fallback to safe states if timing or performance guarantees cannot be met. The software and communication protocols will allow for global-scale medical systems, with real-time care independent of the location of the clinician or the patient, minimizing the chance of malfunction as a result of natural faults or tampering. The status of the system will be communicated to users without requiring specialty knowledge of security or communication protocols.
Security and privacy are prominent concerns in modern communications. Although cryptographic approaches have been widely studied to protect a message's content from deciphering by an eavesdropper, there are many times when hiding the very existence of the communication is critical. The hiding of communication, termed covert (private) communication, is important in many domains such as covert military operations, and removing the ability of users to be tracked in their everyday activities. It is also important to study how to limit such covert communications, for example between parties such as terrorists organizing activities to do harm. This project is focused on understanding what the potential is for covert communications, i.e., how much information can be communicated without detection, and the development of practical schemes for providing covert communications as well as techniques for limiting such communication. <br><br>Covert communication has been historically considered from a practical perspective. For example spread spectrum communications was developed as a wireless communication technique to provide covert communications. Systems such as Tor were developed to provide covertness in the Internet. This project focuses on the systematic investigation of the fundamental limits in providing covertness in communications at the physical, the network, and the application layers of modern communication networks. It will explore the use of noise in wireless channels and timing variabilities in networks to implement covert communications. This includes the development of fundamental limits in terms of the amount of information that can be conveyed covertly without being detected, while accounting for uncertainties among all participants. The project will also focus on the development of fundamental limits for application-level covert communications using voice over IP and image posting on social networks. A key consideration will be how these limits can be impacted by changes in the operating environment, including those changes made intentionally by allies of the communicating parties to enhance covert communications or those made by adversaries of the communicating parties to limit such. A second focus will be on the design and evaluation of algorithms that ensure communicating parties achieve these limits and another set of algorithms that ensure these parties are detected when they attempt to exceed the limits.
This project supports hosting the four day 21th edition of the GENI Engineering conference, including organizing and hosting the demo session, to be held October 20 to 23, 2014 at the Indiana University (IU) in Bloomington, Indiana. The Global Environment for Network Innovations (GENI) is a virtual instrument that is rapidly emerging in prototype form across the United States. GENI is an instrument designed to address three issues: <br>1) Science Issues: We cannot currently understand or predict the behavior of complex,large-scale networks. <br>2) Society Issues: We increasingly rely on the Internet but are unsure we can trust its security, privacy or resilience. <br>3) Innovation Issues: Pre-GENI substantial barriers existed to at-scale experimentation with new architectures, services, and technologies. <br>GENI addresses these issues via scale (from federation) and support for two kinds of experiments: 1) controlled and repeatable experiments, which will greatly help improve our scientific understanding of complex, large-scale networks; and 2) in-the- wild trials of experimental services that ride atop or connect to today's Internet and that engage large numbers of human participants. The GEC meeting and Demo sessions provide graduate students with both an opportunity to demonstrate and explain their work to the GENI community prior to formal publication. It is a key part of helping new graduate students understand what is being done with GENI and who amongst their peers at other institutions might be valuable resources. It also supports outreach to new community members, including the emerging US Ignite community. GENI is already being used as an instrument for research. This project supports the development and use of the research instrument.<br><br>The four-day conference will be held at the Indiana Memorial Union (IMU) Biddle Hotel and Conference Center at the heart of the Bloomington campus. The demo night event will be held at the Cyberinfrastructure Building (CIB), located in IU's growing tech park at the edge of campus. Event planning and logistical support for the event will be coordinated by the IT Communications Office's events team, which has extensive experience in conference planning and access to executive and internal technical support. The IT Communications Office is part of University Information Technology Services (UITS), which maintains a modern IT environment throughout the university in support of research, teaching, outreach, and lifelong learning.
This project takes a new approach to problems involving sensitive data, by focusing on rigorous mathematical modeling and characterization of the value of private information. By focusing on quantifying the loss incurred by affected individuals when their information is used -- and quantifying the attendant benefits of such use -- the approaches advanced by this work enable concrete reasoning about the relative risks and rewards of a wide variety of potential computations on sensitive data. <br><br>Specifically, this work has four main technical thrusts. The first is the development of new models and definitions, enabling privacy considerations to be incorporated into agent utility functions. The second is analysis of the feasibility and costs of eliciting sensitive information, in light of these models. The third focus is on enabling more sophisticated computations in settings where individuals value their privacy. Finally, more complex settings incorporate the interests of additional actors.<br><br>One of the goals of this project is not only to develop a science of the value of private information, but to build bridges between computer science and economics that will enable such work. Further, the models and algorithms developed by this project could inform future regulation regarding the use, exchange, and monetization of sensitive data. The project supports and is supported by a wide variety of educational goals, including significant research involvement of students at a range of stages, development of a course series with a substantial research component, and assessment of a pedagogical technique created to facilitate meaningful engagement with research literature.
This project aims to reduce the impact of software vulnerabilities in Internet-connected systems by developing data-driven techniques for vulnerability measurement, assessment, and notification. Recent advances in Internet-wide scanning make it possible to conduct network surveys of the full public IPv4 address space in minutes. These advances, in turn, offer the promise of truly effective community responses: when new vulnerabilities are announced, the Internet security community can comprehensively identify the systems that suffer from these vulnerabilities and automatically take steps to help affected system operators correct the problems. This project seeks to directly impact the availability and reliability of the Internet and provide the security community with tools, platforms, and comprehensive vulnerability measurement data.<br><br>To achieve this vision, this project develops new techniques for vulnerability measurement, including creating improved security measurement techniques that function at global scale, in the presence of heterogeneous network systems, and in a timely, accurate, complete, and ethical manner. The investigators create new vulnerability assessment methods that lower the barriers faced by researchers seeking to access and analyze vulnerability measurement data, in order to maximize security benefits. The project explores new notification mechanisms that achieve targeted and effective notification of affected organizations, and that can be delivered and acted upon quickly in response to the emergence of new threats.
This project addresses how semiconductor designers can verify the correctness of ICs that they source from possibly untrusted fabricators. Existing solutions to this problem are either based on legal and contractual obligations, or use post-fabrication IC testing, both of which are unsatisfactory or unsound. As a sound alternative, this project designs and fabricates verifiable hardware: ICs that provide proofs of their correctness for every input-output computation they perform in the field. These proofs must be efficiently verifiable in less time and energy than it takes to re-execute the computation itself.<br><br>Building upon exciting recent theoretical and practical advances in verifiable outsourced computation for the cloud, this project develops new techniques that exploit the unique constraints and adversary models that relate to the verifiable hardware problem. In addition, the project also develops new practical approaches to the problem of general verifiable computation. As a broader impact, computing systems security is one of the greatest technological problems faced by society today. Verifiable hardware is an essential foundation for building future computing systems that are reliable and free from catastrophic security failures. The ultimate goal of this project is to make verifiable hardware practical and accessible for use in cryptographic and mission-critical hardware applications through open-source tools. The PIs are strongly committed to education and public outreach by producing widely-used course materials and taking active roles in outreach at minority-serving universities, community colleges, student organizations and high schools.
This project focuses on tackling the security and privacy of Cyber-Physical Systems (CPS) by integrating the theory and best practices from the information security community as well as practical approaches from the control theory community. The first part of the project focuses on security and protection of cyber-physical critical infrastructures such as the power grid, water distribution networks, and transportation networks against computer attacks in order to prevent disruptions that may cause loss of service, infrastructure damage or even loss of life. The second part of the project focuses on privacy of CPS and proposes new algorithms to deal with the unprecedented levels of data collection granularity of physical human activity. The work in these two parts focuses on the integration of practical control theory concepts into computer security solutions. In particular, in the last decade, the control theory community has proposed fundamental advances in CPS security; in parallel, the computer security community has also achieved significant advances in practical implementation aspects for CPS security and privacy. While both of these fields have made significant progress independently, there is still a large language and conceptual barrier between the two fields, and as a result, computer security experts have developed a parallel and independent research agenda from control theory researchers. In order to design future CPS security and privacy mechanisms, the two communities need to come closer together and leverage the insights that each has developed. This project attempts to facilitate the integration of these two communities by leveraging the physical properties of the system under control in two research problems: (1) Physics-based CPS security; and (2) Physics-based CPS privacy.<br><br>Physics-based CPS security leverages the time series from sensor and control signals to detect deviations from expected operation. This is a growing area of research in both security and control theory venues, although there are several open problems in this space. This proposal tackles some of these open problems including the definition of new evaluation metrics that capture the unique operational properties of control systems, the consistent evaluation of different proposals for models and anomaly detection tests, and the development of new industrial control protocol parsers. Physics-based CPS privacy focuses on how to guide the implementation of general privacy recommendations like the Fair Information Practice principles into cyber-physical systems, leveraging the fact that these physical systems often have an objective to achieve, and this objective depends on the data-handling policies of the operator. The project focuses on investigating the trade-off between privacy and control performance and developing tools to guide how data minimization, data delays, and data retention should be implemented.
The proliferation and increasing sophistication of censorship warrants continuing efforts to develop tools to evade it. Yet, designing effective mechanisms for censorship resistance ultimately depends on accurate models of the capabilities of censors, as well as how those capabilities will likely evolve. In contrast to more established disciplines within security, censorship resistance is relatively nascent, not yet having solid foundations for understanding censor capabilities or evaluating the effectiveness of evasion technologies. Consequently, the censorship resistance tools that researchers develop may ultimately fail to serve the needs of citizens who need them to communicate. Designers of these tools need a principled foundation for reasoning about design choices and tradeoffs. <br><br>To provide such a foundation, this project develops a science of censorship resistance: principled approaches to understanding the nature of censorship and the best ways to facilitate desired outcomes. The approach draws upon empirical studies of censorship as the foundation for models and abstractions to allow us to reason about the censorship-resistant technologies from first principles. The project aims to characterize and model censorship activities ranging from blocked search results to interference with international network traffic. The research develops theoretical models of censorship; reconciles these with large-scale empirical measurements; and uses these observations to design censorship-resistance tools to deploy in practice, as both components of Tor and standalone systems.
The proliferation and increasing sophistication of censorship warrants continuing efforts to develop tools to evade it. Yet, designing effective mechanisms for censorship resistance ultimately depends on accurate models of the capabilities of censors, as well as how those capabilities will likely evolve. In contrast to more established disciplines within security, censorship resistance is relatively nascent, not yet having solid foundations for understanding censor capabilities or evaluating the effectiveness of evasion technologies. Consequently, the censorship resistance tools that researchers develop may ultimately fail to serve the needs of citizens who need them to communicate. Designers of these tools need a principled foundation for reasoning about design choices and tradeoffs. <br><br>To provide such a foundation, this project develops a science of censorship resistance: principled approaches to understanding the nature of censorship and the best ways to facilitate desired outcomes. The approach draws upon empirical studies of censorship as the foundation for models and abstractions to allow us to reason about the censorship-resistant technologies from first principles. The project aims to characterize and model censorship activities ranging from blocked search results to interference with international network traffic. The research develops theoretical models of censorship; reconciles these with large-scale empirical measurements; and uses these observations to design censorship-resistance tools to deploy in practice, as both components of Tor and standalone systems.
This project addresses how semiconductor designers can verify the correctness of ICs that they source from possibly untrusted fabricators. Existing solutions to this problem are either based on legal and contractual obligations, or use post-fabrication IC testing, both of which are unsatisfactory or unsound. As a sound alternative, this project designs and fabricates verifiable hardware: ICs that provide proofs of their correctness for every input-output computation they perform in the field. These proofs must be efficiently verifiable in less time and energy than it takes to re-execute the computation itself.<br><br>Building upon exciting recent theoretical and practical advances in verifiable outsourced computation for the cloud, this project develops new techniques that exploit the unique constraints and adversary models that relate to the verifiable hardware problem. In addition, the project also develops new practical approaches to the problem of general verifiable computation. As a broader impact, computing systems security is one of the greatest technological problems faced by society today. Verifiable hardware is an essential foundation for building future computing systems that are reliable and free from catastrophic security failures. The ultimate goal of this project is to make verifiable hardware practical and accessible for use in cryptographic and mission-critical hardware applications through open-source tools. The PIs are strongly committed to education and public outreach by producing widely-used course materials and taking active roles in outreach at minority-serving universities, community colleges, student organizations and high schools.
Cryptography is essential to ensure confidentiality and integrity of information. Due to their practicality, symmetric algorithms ­­ where the same secret key is used by the sender and the recipient ­­ underlie most practical deployments of cryptographic techniques. However, also as a result of this, symmetric cryptography suffers from an inherent tension between real ­world efficiency demands and provable security guarantees. This project investigates new technical advances aimed at narrowing the gap between provable security and the practical demands of symmetric cryptography.<br><br>The project develops new cryptographic algorithms and proof techniques, drawing from techniques in theoretical computer science, applied mathematics, and information theory. This involves the study of combinatorial problems whose solutions yield security proofs for existing and new encryption paradigms, and the development of new provably secure methods to encrypt data from arbitrary domains. The project identifies widely deployed cryptographic methods without provable security guarantees, introduces new assumptions on their components and new frameworks to validate their security with proofs, and explores the trade­off between efficiency and security of symmetric cryptographic algorithms. The project will organize an annual cryptography academy targeted at economically disadvantaged high-school students, to increase their interest and representation in computing.
Crypto-currencies and smart contracts are a new wave of disruptive technology that will shape the future of money and financial transactions. Today, crypto-currencies are a billion-dollar market, and hundreds of companies are entering this space, promising exciting new markets and eco-systems. Unfortunately, usage of crypto-currencies outstrips our understanding. Currently most crypto currencies rely on heuristic designs without a solid appreciation of the necessary security properties, or any formal basis upon which strong assurance of such properties might be achieved.<br><br>This work aims to establish a rigorous scientific foundation for crypto-currencies. To achieve this, this work blends cryptography, game theory, programming languages, and systems security techniques. Expected outcomes include new crypto-currency designs with provable security properties, financially enforceable cryptographic protocols whose security properties are backed by enforceable payments in case of a breach, smart contract systems that are easy to program and formally verifiable, as well as high-assurance systems for storing and handling high-value crypto-currencies and transactions. The project will provide solutions to some of the most difficult and important technical questions surrounding the current digital-money revolution. The investigators will organize a crypto-currency speaker series that will bring together technologists, economists, social scientists, and policy-makers to foster collaborations that will shape the future of digital currencies.
Forged digital images or video can threaten reputations or impede criminal justice, due to falsified evidence. Over the past decade, researchers have developed a new class of security techniques known as 'multimedia forensics' to determine the origin and authenticity of multimedia information, such as potentially falsified images or videos. However, the proliferation of smartphones and the rise of social media have led to an overwhelming increase in the volume of multimedia information that must be forensically authenticated. Forger's capabilities have also grown dramatically, as sophisticated editing software allows forgers to perform complex manipulations of digital images and videos. Researchers have recently demonstrated that an adversarial forger can design anti-forensic attacks capable of fooling forensic algorithms. By contrast, little multimedia forensics research has focused on improving the speed at which multimedia forensics techniques operate, particularly on large data sets. This research project is focused on scaling multimedia forensic algorithms to address these new challenges that have arisen due to the evolving technical and social landscape. <br><br>The research project is focusing on three main aims: (1) Scaling forensic algorithms to meet big data challenges, (2) Scaling forensic algorithms to handle complex forgeries, and (3) Scaling forensics to meet increased adversarial capabilities. To accomplish these aims, the research is drawing from a wide variety of fields such as signal processing, estimation theory, statistical hypothesis testing, machine learning, optimization theory, and game theory.
ACM MobiHoc conference is the leading international conference on the theory and practice of mobile multi-hop wireless networks. It invites research contributions addressing the challenges in the area of multi-hop wireless networks, ranging from cognitive radio networks to ad hoc networks. The conference features a high-quality technical program, with an acceptance rate of around 10% out of around 250 submissions. It has a single-track session, which offers significant opportunities for individual and small groups that foster technical and social interactions among a diverse set of participants. MobiHoc is also an international conference that stimulates exchanges between various international research communities. <br><br>This award will help increase the representation and participation of United States-based students at the conference by providing 20 or more travel grants limited to a maximum of $750 each. By creating new opportunities for graduate students, especially those from under-represented groups, to attend a high-quality conference, this award will benefit the students by giving them an opportunity to interact with world-class researchers, inspire them to try new research directions, providing mentoring opportunities, as well as the chance to seek out internships and post-doctoral positions which will help the students advance in their research career.
Content distribution is an important application domain for cryptographic techniques. Existing security solutions for multi recipient communication, like broadcast encryption, focus mostly on the concerns of the content originator. This project tackles the problem from a broader perspective that includes the privacy concerns of the recipients, and develops cryptographic models and protocols for content distribution that provide guarantees beyond the mere secrecy of the data. The outcomes of this research will enable solutions that address the privacy issues associated with cloud storage. The techniques developed in the course of the research will be stimulating for researchers across the cryptography and information-hiding communities, thus potentially fostering collaborations between the fields. <br><br>The project has four specific research objectives: (1) the design of cryptographic constructions for receiver-anonymous broadcast encryption that at once provide transmission secrecy, afford anonymity to the receivers, and enjoy performance comparable to standard broadcast encryption; (2) the exploration of the relationship between receiver anonymity and ciphertext ambiguity, which refers to the possibility that a given ciphertext might appear valid to multiple decryptors; (3) the formulation of the concept of broadcast steganography to enable the use of a broadcast channel as a medium for covert communication; and (4) the investigation of applications like collaborative remote storage, whereby a group of users accesses shared content in the cloud privately and obliviously.
Statistical privacy, or the problem of disclosing aggregate statistics about data collected from individuals while ensuring the privacy of individual level sensitive properties, is an important problem in today's age of big data. The key challenge in statistical privacy is that applications for data collection and analysis operate on varied kinds of data, and have diverse requirements for the information that must be kept secret, and the adversaries that they must tolerate. Thus, application domain experts, who are frequently not experts in privacy, cannot directly use an existing, general-purpose privacy definition. Instead, they must develop a new privacy definition or customize an existing one. Currently there exist no rigorous techniques to customize privacy to applications.<br><br>This project builds PROTEUS, a general-purpose toolkit for developing rigorous privacy definitions and mechanisms that can be customized to applications. The cornerstone of PROTEUS is a novel privacy framework that allows customized privacy protection by explicitly listing the secrets to be protected, enumerating the (potentially infinite set of) possible adversaries, and ensuring rigorous bounds on the information disclosed to each adversary about every secret. Novel theoretical tools in PROTEUS include methods to reason about privacy for correlated data, privacy against realistic adversaries, and techniques to express and enforce personalized privacy preferences. These tools result in practical privacy mechanisms for publishing social science survey data, social network analysis, and analysis of user-activity streams. Broader impacts of this project include developing new courses in privacy and big-data management, as well as technology transfer to the US Census.<br>
The past decade has seen a growing reliance on data driven technologies, including recommendation systems, targeted advertising, and search personalization. This growth in big data has made data privacy into a central concern. The central question raised is: how can we continue to extract useful information from large datasets, while provably protecting some measure of privacy for the individuals contained in these datasets?<br><br>This research centers around advancing the state of the art in privacy preserving data analysis. It specifically has several themes: (1) Exploiting structure in the private data being analyzed, as well as the classes of queries used in the analysis to give computationally efficient algorithms for private data analysis. (2) Deepening the connections between private data analysis and machine learning theory. (3) Relaxing the adversarial collusion model implicit in most work on the foundations of data privacy, and (4) applying the tools of differential privacy to usefully exploit and analyze noise in other algorithmic settings. To ensure the broad impact of this research, this project includes substantial outreach activities, including workshop organization, course development, and the development of a textbook and other educational materials.
perfSONAR (http://www.perfsonar.net) is a set of community-developed protocols and a widely-adopted infrastructure for multi-domain network performance monitoring, facilitating the ability to collect and share measurement data relevant to solve end-to-end network performance problems and to enable network-aware applications. The first perfSONAR workshop was successfully held 8-9 July 2010 in Arlington, VA. This project will organize and hold the Second perfSONAR workshop to be held February 20-21 2014 at at the NSF in Arlington VA, open to members of the perfSONAR community. The goal of the second workshop is to build upon the first workshop outcomes and capitalize on the inherent flexible multi-domain nature of the perfSONAR protocols and infrastructure. The intended focus is to cross-fertilize ideas from a variety of stakeholders that include: researchers, applications developers, network operators, network managers, and others with an interest in network research and performance measurement/monitoring.<br><br>The workshop goals include:<br> 1. Identification of unimplemented techniques and network research focus areas with existing ideas that can help solve problems of R&E networks, as well as open research questions focused on solving real world end-to-end performance problems;<br> 2. Identification of required perfSONAR infrastructure components for network operators, end users, network researchers, and virtual organizations, and any missing components;<br> 3. Operational requirements, federation policies and best practices for ongoing and on-demand measurements end-to-end, cross-domain, and transoceanic links; and<br> 4. Creating a larger perfSONAR community seeded by the workshop participants, including strategies for engaging new network researchers, new domain science researchers, new science communities, and new networks.<br><br>perfSONAR is a tool supporting multiple high-priority programs in multiple U.S. agencies. It is a key tool for network diagnostics for in the High Performance Computing community. As such enhancements to the perfSONAR framework have direct impacts on projects across a wide range of disciplines. The output of the workshop will be a report suitable for archival within the ACM Digital Library. The report will summarize the discussions and recommendations of participants in accordance with the aforementioned workshop goals, and could serve to inform and guide future community actions.
This collaborative research project, conducted jointly by the investigators from the Michigan State University (MSU) and the University of Michigan at Dearborn (UM-D), investigates the issues and techniques for storing and searching/querying large scale k-mer data sets (i.e., overlapping k-length subsequences obtained from genome sequences) for sequence analysis in bioinformatics. Efficient k-mer indexing, storage and retrieval are vital to sequence analysis tasks like error correction as sequencing data set sizes increase vastly. Most existing methods for storing and searching k-mers are optimized for exact or range queries. However, this reliance limits the types of sequence analysis that can be done efficiently. Moreover, most existing methods for storing k-mers do not support efficient storage of k-mers at multiple word lengths. For many sequence analysis problems, including error correction, variant detection, and assembly, searches with multiple word lengths enable better sensitivity and specificity. In this project, various techniques for efficiently supporting so-called (discrete) box queries and other related queries (e.g., hybrid queries) on large scale k-mer data sets for sequence analysis are investigated. The approaches to optimizing box queries in solving sequence analysis problems like the error correction are examined. The storage structure and adoption of box queries for supporting searches with multiple word lengths on k-mer data sets are explored. The results from this research will advance the state of knowledge for storage, indexing and retrieval techniques for genome sequence databases. They are expected to significantly impact current practice in bioinformatics by making available new efficient on-disk solutions for sequence analysis. They will also impact a number of other popular application areas including biometrics, image processing, social network, and E-commerce, where processing non-ordered discrete multidimentional data is crucial. <br><br>This collaborative research project, conducted jointly by the investigators from the Michigan State University (MSU) and the University of Michigan at Dearborn (UM-D), investigates the issues and techniques for storing and searching/querying large scale k-mer data sets for sequence analysis in bioinformatics. Efficient k-mer indexing, storage and retrieval are vital to sequence analysis tasks like error correction as sequencing data set sizes increase vastly. Most existing methods for storing and searching k-mers are optimized for exact or range queries. However, this reliance limits the types of sequence analysis that can be done efficiently. Moreover, most existing methods for storing k-mers do not support efficient storage of k-mers at multiple word lengths. For many sequence analysis problems, searches with multiple word lengths enable better sensitivity and specificity. In this project, various techniques for efficiently supporting so-called (discrete) box queries and other related queries (e.g., hybrid queries) on large scale k-mer data sets for sequence analysis are investigated. In particular, a new index tree, named the BoND-tree, specially designed for a non-ordered discrete data space characterized by k-mer data sets is developed. The unique properties of the space are exploited to develop new node splitting heuristics for the index tree, and theoretical analysis is performed to show the optimality of the proposed heuristics. Besides the BoND-tree, which is based on data partitioning, space-partitioning based index schemes for box quieres in such a space are also developed. To support a more flexible type of query (i.e., hybrid box and range queries), hybrid index schemes integrating strengths of both box query indexes and range query indexes are studied. To facilitate an efficient index construction for large scale k-mer data sets, bulk loading techniques are also developed for the proposed index trees. In addition, the approaches to optimizing box queries in solving sequence analysis problems like the error correction are examined. The storage structure and adoption of box queries for supporting searches with multiple word lengths on k-mer data sets are also explored. The research in the project will result in the discovery of fundamental properties of the data space for sequence data in bioinformatics, the development of a number of novel storage, indexing and retrieval techniques exploiting the properties of such a data space, and the applications of the proposed techniques for solving important problems in sequence analysis. These results will advance the state of knowledge for storage, indexing and retrieval techniques for genome sequence databases. They are expected to significantly impact current practice in bioinformatics by making available new efficient on-disk solutions for sequence analysis. They will also impact a number of other popular application areas including biometrics, image processing, social network, and E-commerce, where processing non-ordered discrete multidimentional data is crucial.
This grant supports student attendance to the IEEE Cyber Security Development (SecDev) conference. Research on software security usually focuses on detecting vulnerabilities in software and attacks on resources. However, there is not much attention to how programmers can develop secure software by construction. This new conference series on Secure Development (SecDev) focuses on this problem area. The support for the conference is important for educating/training the workforce in this area, and to help provide a pathway to research careers. The technical advances presented and nurtured by the conference are important to development of secure software, which is important to society.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
The more people use the Internet, the more they risk sharing information they don't want other people to know. Tor is a technology that every day helps millions of people protect their privacy online. Tor users -- ranging from ordinary citizens to companies with valuable intellectual property -- gain protection for the content of their online messages and activities, as well as whom they interact with and when. For the most part, Tor is very secure. However, it has a known vulnerability to an attack called website fingerprinting. An attacker, such as someone eavesdropping on a wireless connection, can analyze recognizable patterns in data that websites send to visitors, potentially determining which websites a user visits. Studies have shown that, in some situations, this attack can be successful up to 90% of the time. Developers of Tor and a team of researchers will collaborate to build and deploy new defenses against website fingerprinting, which substantially lower attack accuracy without degrading user experience or increasing the costs of running the system. By widely deploying such a defense, Tor's security is greatly improved. This also provides an experimental platform and data that other researchers can use for their own experiments, helping to further strengthen Tor.<br><br>Previous approaches to defending against website fingerprinting increased latency, so that web pages load 2 to 4 times slower than normal. To design an effective defense that doesn't unacceptably slow browsing or increase bandwidth overhead, this project builds on a technique called Adaptive Padding, which has shown promising results in preliminary work. Adaptive Padding works by noticing distinctive gaps in data packets flowing over the network between a website and Tor user and filling these gaps with extra packets to obfuscate the website's fingerprint. The research team first developed a platform for evaluating Adaptive Padding and other defenses in Tor, allowing security experiments in the live Tor network without full deployment or endangering user privacy. Leveraging this platform, the team performs extensive experiments on website fingerprinting defenses and attacks, leading towards deployment. The project focuses on defenses that can be practically deployed and significantly improve user security. Since defenses meeting these requirements have been understudied to date, this project enhances knowledge in this area. Finally, the findings of the project are fully transitioned to Tor to make Internet browsing safer and more secure.
This research seeks to develop novel machine learning algorithms that enable real-time video and sensor data analysis on large data streams given limited computational resources. The work focuses on healthcare as an application domain where real-time video analysis can prevent user-errors in operating medical devices or provide immediate alerts to caregivers about dangerous situations. The research will develop algorithms to automatically adapt data analysis approaches to maximize accuracy of analysis within a short time period despite limited available computing resources. Today's healthcare environment is significantly more technologically sophisticated than ever before. Many medical devices are now frequently used in patient's homes, ranging from simple equipment such as canes and wheelchairs to sophisticated items such as glucose meters, ambulatory infusion pumps and laptop-sized ventilators. The rapidly growing home health industry raises new safety concerns about devices being used inappropriately in the home setting. The proposed research is designed to reduce medical device related use-errors by developing computational algorithms that perform real-time video analysis and alert the patient or caregiver when medical devices are not used appropriately. The real-time video and sensor data analysis is also critical to the healthcare systems that monitor the activities of the elderly or those with disabilities in order to allow a caregiver to react immediately to an incident. <br><br>New machine learning theories and algorithms will automatically adapt to hardware limitations, with the aim to learn from a large number of training examples, a prediction function that (i) is sufficiently accurate in making effective predictions and (ii) can be run efficiently on a specified computer system to deliver time critical results. Three types of prediction models are studied to address the problem of automatic hardware adaptation, including a vector-based model, a matrix-based model, and a prediction model based on a function from a Reproducing Kernel Hilbert Space (RKHS). A general framework and multiple optimization techniques are being developed to learn accurate prediction models that match limited memory and computational capacity. The new learning algorithms will be evaluated in several medical scenarios through real-time prediction of a patient's activities from observations in the large video archives collected by several healthcare related projects. The intellectual merit of the proposed work is in bridging the gap between the high complexity of a prediction model and limited computational resources, a scenario that is encountered in many application domains besides healthcare. The proposed research in machine learning algorithms and theories will make it possible to run complicated prediction algorithms on big data within the limitation of a given computing infrastructure. The developed techniques for automatic hardware adaptation will be applied to a large dataset of continuous video and sensor recordings for medically-critical activity recognition. The project's broader impacts include providing medical experts with algorithms and tools supporting novel approaches to analyzing observational data in their quest to recognize and characterize human behavior. Surveillance systems with continuous observations will be able to categorize salient events with co-located, limited hardware. Researchers with complex data from continuous streams will be able to explore their domains with greater accuracy within constrained time using their available computing resources. Similarly, large archives can be exploited as rapidly as possible with limited hardware.
The production of computer chips has universally moved offshore in recent years, reducing design complexity and fabrication cost. But these benefits come at the expense of security: An attack anywhere along the supply chain can insert malicious components into an integrated circuit, pirate its design or counterfeit it. These attacks, which are exceedingly difficult to detect, jeopardize the computer industry, undermine national security, and put critical infrastructure in danger. More than a decade of research in hardware security has resulted in a plethora of solutions for these problems, but many of these solutions address specific attack models and, hence, are not universally applicable. This project breaks this barrier by developing hardware design approaches that are both provably secure and applicable across the entire hardware industry for differing businesses and threat models. To engage and teach the next generation of cybersecurity experts, the project uses puzzle-, challenge-, and competition-based educational and outreach activities at the high-school, undergraduate, and graduate levels.<br> <br>The project has three components. First, the research develops a secure synthesis approach to prevent piracy and reverse engineering using provably-secure camouflaging and logic encryption, where the attacker is provided with only partial knowledge of the design to obfuscate the design intent. Second, the research analyzes the security implications of untrusted test facilities by demonstrating an attack to compromise secrets through test data. It develops a provably-secure test pattern generation technique for testing chips with secrets. Third, this project designs chips such that any (malicious) alterations and counterfeits are provably-detected by existing techniques.
OpenSSH reveals excerpts from encrypted login sessions. TLS (HTTPS) reveals encrypted PayPal account cookies. DTLS is no better. EAXprime allows instantaneous forgeries. RFID security has been broken again and again. All of these failures of confidentiality and integrity are failures of authenticated ciphers: algorithms that promise to encrypt and authenticate messages using a shared secret key.<br><br>It is easy to blame many of these security problems on a lack of education: much stronger authenticated ciphers have been in the literature for many years. However, in many cases these stronger authenticated ciphers fail to meet the performance requirements of the applications. Performance is exactly the motivation for RC4 in WEP; EAXprime in the "Smart Grid"; HB in RFID; and "IPsec" continuing to support unauthenticated encryption.<br><br>This project is building a new generation of authenticated ciphers that improve efficiency without compromising security and that improve security without compromising efficiency. This work spans seven main topics: more efficient ciphers; more efficient MACs; more efficient forgery rejection; improved protection against side channels; improved protection against misuse and bad luck; improved quantitative security; and improved security proofs. The ultimate objective is to obtain the best possible security subject to a variety of performance constraints specified by cryptographic users.<br><br>The high-security high-performance authenticated ciphers produced in this project will be directly and straightforwardly usable in cryptographic applications, avoiding the disasters in current applications and finally bringing secure secret-key cryptography from theory to practice.
In 2016, the cyberthreat landscape showcased advanced attack techniques, escalated attack frequency, and high levels of adversarial sophistication. Conventional cyberattack management is response-driven, with organizations focusing their efforts on detecting threats, rather than anticipating adversarial actions. This reactive approach has limited efficacy, as it does not capture advanced and sophisticated adversaries, mutating or unknown malware, living-off-the-land techniques or new variants being deployed. There is thus an immediate need for a paradigm shift in the area of cybersecurity. Security experts are calling for anticipatory or proactive defense measures that focus on adversarial behavior and movement. This research aims to develop a criminological theory that captures the dynamics of cybercrime and a corresponding simulator to generate attack scenarios that adapts to ever changing and diverse cyber vulnerabilities, defense, and adversary tactics. <br><br>This research has two connected objectives: (1) Develop (and evaluate) an integrated Dynamic Routine Activities Theory (DRAT), which examines the continually changing interaction between offender, target, and guardian (OTG) along cyberattack trajectories aided by Monte-Carlo simulation; and (2) Understand how variations in OTG impact dynamic adversarial attack trajectories. Specifically, how can these variations and amounts of variations be measured, modeled and simulated, and what might these variations imply for DRAT -- Understanding adversarial attack trajectories, and how these can be disrupted to impact adversaries, will be instrumental in comprehending anticipatory cyber defense and ultimately contribute to the paradigm shift towards proactive cybersecurity. This exploratory, multidisciplinary research marries the two disciplines of criminology and computer engineering to push the research frontier on proactive cybersecurity. This groundbreaking intersection will generate new criminological theoretical knowledge, mixed-method innovations, and theoretically-informed simulation that prepare defenders with preemptive and comprehensive knowledge and tools in facing adaptive and sophisticated adversaries.
Modern networks are often federated in nature---i.e., they are an interoperation between independent networks spanning multiple administrative domains. For example, in many enterprises, different business units control various logical segments of the network, but share common resources, such as routers, firewalls, and load-balancers. In such federated systems, the correct enforcement of network security policies relies on interactions that span multiple administrative domains. This project is developing techniques for enforcing security policies in federated networks using a new form of Proof Carrying Code (PCC), specialized to the networking domain. This enforcement mechanism will ensure that only authorized actors can reconfigure devices in federated networks, and will guarantee that configuration software preserves "behavioral" policies such as access control, slice isolation, etc.<br><br>The technical contributions of this research will include (i) developing PCC techniques for NetKAT, a language for SDN programming that comes equipped with a sound and complete equational reasoning system, and (ii) integrating NetKAT PCC into the Nexus Authorization Language (NAL), a framework that provides methods for specifying and enforcing distributed authorization policies. Key challenges will include how to generate, represent, and transform NetKAT proofs, and how to deal with dynamic behaviors such as network configuration changes and evolving trust models. The broader impacts of this project include (i) developing open-source software that will be tested on a GENI rack hosted by the BTV Ignite program with broader impacts in the local Burlington, VT community, and (ii) presenting education opportunities for underrepresented groups via an outreach program for high school students developed in partnership with the New York State 4-H and Science Leadership Academy.
The Intel Software Guard Extensions (SGX) is a new technology introduced to make secure and trustworthy computing in a hostile environment practical. However, SGX is merely just a set of instructions. Its software support that includes the OS support, toolchain and libraries, is currently developed in a closed manner, limiting its impact only within the boundary of big companies such as Intel and Microsoft. Meanwhile, SGX does not automatically secure everything and it still faces various attacks such as controlled-side channel and enclave memory corruption.<br><br>This research investigates how to enable application developers to securely use the SGX instructions, with an open source software support including a toolchain, programming abstractions (e.g., library), and operating system support (e.g., kernel modules). In addition, this research systematically explores the systems and software defenses necessary to secure the SGX programs from the enclave itself and defeat the malicious use of SGX from the underlying OS.
Prior research notes that many cyberattacks are preventable if end users take precautionary measures, such as keeping systems updated, but they often fail to do so. This proposal builds upon theories of risk communication, emotional intelligence, and self-determination to design new approaches to cybersecurity risk communication and training. The goals are to enable users to assess risks, costs, and benefits consistently and correctly, to promote task-focused coping responses, and to facilitate their internalization of values, promoting spontaneous diffusion of cybersecurity knowledge. By enabling non-expert users to make informed security decisions through raising cybersecurity risk awareness and self-efficacy development, this project directly addresses an increasingly serious threat to economic growth and national security. This project also creates cybersecurity research and training opportunities for graduate and undergraduate students, and members from the underrepresented groups through outreach initiatives.<br><br>This project systematically tests two hypotheses: (i) that addressing gaps in mental models along with development of self-efficacy can promote task-focused coping responses and early conformance behavior, and (ii) that communicating social motives can lead to the development of intrinsic motivation and spontaneous diffusion of information. Towards that end, the researchers design and conduct a series of interview-style user studies including both expert and non-expert users, and they develop effective risk communication modules that address gaps in mental models and enable non-expert users to evaluate risks, costs and benefits of security decisions. This project will also test the efficacy of different interventions to promote task-focused coping responses and promote spontaneous diffusion of information. By systematically testing the aforementioned hypotheses, this project provides in-depth understanding regarding the influence of emotions and social motives in cybersecurity behavior and makes a valuable contribution to the theoretical foundation of risk communication. By investigating mental models of high school students as well as adults, this project advances the theory of risk communication for adolescents in the cybersecurity context and enables cybersecurity professionals to design risk communication modules specifically targeting this vulnerable demographic. Research results are synthesized in modular tutorials and made publicly available.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
OpenSSH reveals excerpts from encrypted login sessions. TLS (HTTPS) reveals encrypted PayPal account cookies. DTLS is no better. EAXprime allows instantaneous forgeries. RFID security has been broken again and again. All of these failures of confidentiality and integrity are failures of authenticated ciphers: algorithms that promise to encrypt and authenticate messages using a shared secret key.<br><br>It is easy to blame many of these security problems on a lack of education: much stronger authenticated ciphers have been in the literature for many years. However, in many cases these stronger authenticated ciphers fail to meet the performance requirements of the applications. Performance is exactly the motivation for RC4 in WEP; EAXprime in the "Smart Grid"; HB in RFID; and "IPsec" continuing to support unauthenticated encryption.<br><br>This project is building a new generation of authenticated ciphers that improve efficiency without compromising security and that improve security without compromising efficiency. This work spans seven main topics: more efficient ciphers; more efficient MACs; more efficient forgery rejection; improved protection against side channels; improved protection against misuse and bad luck; improved quantitative security; and improved security proofs. The ultimate objective is to obtain the best possible security subject to a variety of performance constraints specified by cryptographic users.<br><br>The high-security high-performance authenticated ciphers produced in this project will be directly and straightforwardly usable in cryptographic applications, avoiding the disasters in current applications and finally bringing secure secret-key cryptography from theory to practice.
This project explores a new, integrated approach to securing decentralized applications. The key problem is that decentralized applications are executed by mutually distrusting entities in a decentralized distributed system (such as a blockchain), where the entities must collaborate to execute the desired computation, despite not trusting each other. Building decentralized applications is difficult and error prone because the low-level security mechanisms are too removed from the high-level policies, thus it is difficult for programmers to correctly implement the policies. In these cases, no single entity is trusted to fully specify or enforce security policies. The project will develop Flame, a programming language offering more precise abstractions for expressing security intent in decentralized systems. Using Flame gives developers assurance that their programs are both secure and realizable without requiring them to design and implement complex security protocols. This project will also develop Decent, a decentralized runtime platform for executing decentralized applications built with Flame. The project will open-source Flame and Decent and promote them with publications, tutorials, and course materials. <br><br>To explore a new, integrated approach to enforce end-to-end security for decentralized applications the project will build a prototype based on techniques for decentralized information flow control, blockchain networks, trusted computing, and cryptography to create a high-level programming layer that eases the task of building, verifying, and deploying decentralized applications. The prototype will support policies that cannot be enforced in current information control models and are too difficult to realize with cryptographic and access control mechanisms alone.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
The project performs empirical studies of code bases to characterize vulnerabilities that occur in practice on software projects. The studies will identify the vulnerability-causing commits to understand when security vulnerabilities are introduced and how long they are exposed. The empirical methodology for studying security vulnerabilities sets the stage for more rigorous and efficient empirical studies important for evaluating the efficacy of new software development methods aimed at design more security systems. The initial studies will look at Apache HTTPD service data. An additional objective of the research is to gather more information about how industrial projects collect and analyze the data needed for learning about security vulnerabilities in practice.
The prospect of quantum computers is a threat against the security of currently used public key cryptographic algorithms. It has been widely accepted that, both public key cryptosystems including RSA and ECC will be broken by quantum computers employing certain algorithms. Although large-scale quantum computers do not yet exist, but the goal is to develop quantum-resistant cryptosystems in anticipation of quantum computers as most of the public key cryptography that is used on the Internet today is based on algorithms that are vulnerable to quantum attacks. <br><br>This project will explore isogenies on elliptic curves as a foundation for quantum-resistant cryptography. Isogeny computation is known to be difficult. This project will analyze newer and faster families of isogenies, which yield a faster solution to the problem of finding isogenies. It will exploit state-of-the-art techniques and employ new optimizations to speed up the computation in isogeny-based cryptography, including tower field and curve arithmetic. The performance of field arithmetic computation is strongly influenced by the processor micro-architecture features, the size of the operands, the algorithms, and programming techniques associated to them. This research will provide preliminary results on developing fast algorithms and architectures for post-quantum cryptographic computations suitable for emerging embedded systems. <br><br>For further information see the project website at: http://people.rit.edu/~rxaeec/Research.html
The cyber security of advanced manufacturing systems (AMS) has raised significant interest amongst both the general public and researchers. However, corresponding education programs fall behind in many aspects. Limited curriculum or hands-on learning resources are available for security education in AMS, especially exercises that cover the complete manufacturing cycle. This project will try to bridge the gap by developing an experiment platform dedicated to security education for AMS, and designing a suite of course modules and hands-on projects upon it. The research achievements will provide a new method to train qualified workforce to fill tens of thousands of open positions in this traditional yet fast evolving industry and improve the sustainability and security of future cyber-physical systems. Minority and under-represented students will benefit from the project. Two community colleges have shown a great interest in and support for this project.<br><br>The team will develop an experiment platform for AMS by implementing new modules for equipment reservation, command transmission, and sensing data collection upon the Remote Automation Management Project (RAMP) system. This platform covers both cyber and physical systems underpinning modern manufacturing operations. Three course modules and four hands-on projects on infrastructure and data security in AMS will then be developed for knowledge learning and skill training. Special efforts have been planned for the evaluation and dissemination of the proposed experiment platform and educational materials. Rigorous evaluation plans will be carried out by experienced evaluators to assess the objectives and achievements of each phase of the project. The new instructional materials will be implemented in four courses at UNC Charlotte. Through collaborations with local community colleges, the NSF STARS Alliance, NSF REU site, and NSF SFS Scholarship program, the researchers will reach out to both high school and undergraduate students through summer camps and presentations.
The production of computer chips has universally moved offshore in recent years, reducing design complexity and fabrication cost. But these benefits come at the expense of security: An attack anywhere along the supply chain can insert malicious components into an integrated circuit, pirate its design or counterfeit it. These attacks, which are exceedingly difficult to detect, jeopardize the computer industry, undermine national security, and put critical infrastructure in danger. More than a decade of research in hardware security has resulted in a plethora of solutions for these problems, but many of these solutions address specific attack models and, hence, are not universally applicable. This project breaks this barrier by developing hardware design approaches that are both provably secure and applicable across the entire hardware industry for differing businesses and threat models. To engage and teach the next generation of cybersecurity experts, the project uses puzzle-, challenge-, and competition-based educational and outreach activities at the high-school, undergraduate, and graduate levels.<br> <br>The project has three components. First, the research develops a secure synthesis approach to prevent piracy and reverse engineering using provably-secure camouflaging and logic encryption, where the attacker is provided with only partial knowledge of the design to obfuscate the design intent. Second, the research analyzes the security implications of untrusted test facilities by demonstrating an attack to compromise secrets through test data. It develops a provably-secure test pattern generation technique for testing chips with secrets. Third, this project designs chips such that any (malicious) alterations and counterfeits are provably-detected by existing techniques.
With the advancement of technologies, networked devices become ubiquitous in the society. Such devices are not limited to traditional computers and smart phones, but are increasingly extended to cover a wide variety of embedded systems (ES), such as sensors monitoring bridges, electronics controlling the operation of automobiles and industrial equipment, home medicine devices that are constantly reporting patient health information to doctors. While the wide deployment of networked ES significantly benefits various aspects of human life and society at large, it also poses daunting security challenges that can put national security as well as the privacy of ordinary citizens at risk. Adequately addressing such challenges requires advanced technologies to be developed by industries and ES designers as well as users to be well educated about the security related issues. To facilitate technology development and better educate future designers, this project develops curricula focusing on the unique challenges of the emerging ES security, which has not been systemically covered in existing computer security related curricula that emphasize security in computers and the traditional Internet.<br><br>This project makes intellectual contributions through the completion of the following objectives: 1) developing course modules (lecture notes, labs and evaluation questionnaire) to introduce ES security in the layers of software, networking, operating system, architecture, and hardware; 2) integrating the developed material into several existing undergraduate courses at PIs' Universities; 3) establishing a unified ES security course with two versions (computer engineering and computer science versions) by integrating the developed course modules; 4) getting the developed material evaluated by an External Advisory/Review Committee; 5) teaching the developed material using both project-based learning and flipped classroom learning; 6) assessing the proposed teaching methods using formative and summative approaches; 7) broadly disseminating the developed material and promoting diversity in ES security education. Material to be developed will reach over 100 students per year, including many minorities and women.
With the advancement of technologies, networked devices become ubiquitous in the society. Such devices are not limited to traditional computers and smart phones, but are increasingly extended to cover a wide variety of embedded systems (ES), such as sensors monitoring bridges, electronics controlling the operation of automobiles and industrial equipment, home medicine devices that are constantly reporting patient health information to doctors. While the wide deployment of networked ES significantly benefits various aspects of human life and society at large, it also poses daunting security challenges that can put national security as well as the privacy of ordinary citizens at risk. Adequately addressing such challenges requires advanced technologies to be developed by industries and ES designers as well as users to be well educated about the security related issues. To facilitate technology development and better educate future designers, this project develops curricula focusing on the unique challenges of the emerging ES security, which has not been systemically covered in existing computer security related curricula that emphasize security in computers and the traditional Internet.<br><br>This project makes intellectual contributions through the completion of the following objectives: 1) developing course modules (lecture notes, labs and evaluation questionnaire) to introduce ES security in the layers of software, networking, operating system, architecture, and hardware; 2) integrating the developed material into several existing undergraduate courses at PIs' Universities; 3) establishing a unified ES security course with two versions (computer engineering and computer science versions) by integrating the developed course modules; 4) getting the developed material evaluated by an External Advisory/Review Committee; 5) teaching the developed material using both project-based learning and flipped classroom learning; 6) assessing the proposed teaching methods using formative and summative approaches; 7) broadly disseminating the developed material and promoting diversity in ES security education. Material to be developed will reach over 100 students per year, including many minorities and women.
User behavior is a critical element in the success or failure of computer security protections. The field of Human Security Informatics (HSI) combines security informatics and human-computer interaction design to learn how the design of a human-computer interface can affect the security of a computer system. This research project is contributing to the scientific foundations of HSI by modeling how multitasking users behave when making security-critical decisions. In particular, the researchers are modeling user behavior when the users are engaged in typical PC-based mobile messaging with security concerns such as phishing or spam. The project is evaluating how well the models capture the impact of incentives and interventions on user security behaviors.<br><br>This project extends the cognitive modeling (CogM) architecture to characterize and improve user security decision-making and behaviors. Focusing on cognitive constructs in the ACT-R and Soar architectures, it models the multi-tasking application and security activities with varying cognitive traits and security constraints, through representations of productions and information chunks, as well as their utility and activation calculations. An analytic user model not only describes a problem in making a security decision, but also can explain why and how it happens for incentive and intervention selection. Moreover, CogM models and empirical user testing comparatively study common and advanced users in typical messaging applications, regarding security mistakes and efficiency in task completion. This project is focused on establishing the principles for analytically modeling user cyber behaviors and bridging the gap from understanding security behaviors to effectively improving security performance.
As communication networks play an increasingly vital role in our society, ensuring the confidentiality of information transmission and storage has become an increasing concern. New classes of networks, such as heterogeneous wireless networks and distributed storage networks, are emerging, in which the deployment of off-the-shelf cryptographic solutions faces several limitations. These include, for instance, the overhead of key management to maintain synchronized private and public keys; the challenge of distributing keys within the stringent delay constraints imposed by clients; and the exposure to large-scale attacks that were once deemed infeasible. Consequently, several solutions from network coding to physical-layer security have been developed to improve the confidentiality of data over modern wireless networks. Many key-independent and keyless schemes have been developed to provide additional robustness against attacks and more flexibility in the network operation. These schemes have in common that they exploit coded data as keys and move away from the traditional paradigm in which data is a commodity and in which information packets must be transmitted and protected independently. Instead, these schemes envision that information packets could be mixed in a controlled manner so as to introduce an intrinsic level of security against adversaries.<br><br>Most existing secrecy results hinge on the crucial assumption that data is uniformly distributed and independent from a packet to another. Unfortunately, recent results have shown that even optimal data compression algorithms uniformize the statistics of coded data only in a very weak sense. Consequently, several security guarantees established in the literature may well collapse in the absence of any proven robustness with respect to data uniformity assumptions. The objective of this project is to develop a better understanding of how the statistical properties of passwords and data influence the security of secrecy systems. The project investigates several interrelated research tasks: (i) the analysis of the fundamental limits of data-compression techniques with improved uniformity properties; (ii) the design of low-complexity codes for uniformization; (iii) the application of such algorithms in cloud storage systems. Additional activities include an outreach effort to high-school students.
Network attacks are increasingly complex and fast-evolving. A single attack may use multiple reconnaissance, exploit, and obfuscation techniques. This project investigates how to extract critical attack attributes, synthesize novel attack sequences, and reveal potential threats to critical assets in a timely manner. The project uses machine learning techniques to simultaneously identify new attack types and observed events that could identify those attacks. The Transition-to-Practice component in the project includes a three-phase plan to provide a positively reinforced and measurable cycle to develop, evaluate, and refine a prototype system in real-world environments. This significantly broadens the engagement of security practitioners and student teams, who will be planning and executing attacks to test the prototype system. The outcome of this research will provide timely comprehension and anticipation of critical attack strategies, offering the practitioners a solution to level the playing field against sophisticated attackers.<br><br>Specifically, this work develops an online semi-supervised learning framework to capture both spatial and temporal features of attack strategies. An attack behavior model is a collection of feature probability distributions. The attack features are used to synthesize attack sequences via Monte-Carlo simulation. The attack sequences along with an ensemble prediction are then used to reveal potential threats to critical assets in the network. The project will be evaluated on real-world attack data as well as synthetic network attacks. An extensive outreach plan includes course module development, a mid-project workshop to engage security researchers and practitioners, and a summary panel in an international conference.
This award establishes a new Research Experiences for Teachers (RET) Site focused on cybersecurity research at Texas A&M University. Cohorts of high school teachers and community college faculty in the areas of Science, Technology, Engineering, and Mathematics (STEM) will participate in summer research projects with Texas A&M faculty mentors who are actively involved in leading-edge research on cybersecurity. The participating teachers will translate their research experiences and knowledge into classroom practice by developing instructional modules and course materials that they will introduce in their classrooms and share with others. These activities all contribute to the formation of a community of practice between Texas A&M faculty and local educators that has the potential to significantly enhance and improve STEM education in the school districts around the university.<br><br>RET participants will attend a 6-week summer institute to participate in cutting-edge research projects with mentoring from computer science faculty who lead cybersecurity research programs. The RET Site research topics focus on software, network security, cryptography, and malware. These are all topics that are of current interest and important to our nation. The RET Site project will provide a platform for the participating teachers to develop effect practical problem-based instructional materials and laboratory modules that they will share with teachers in their school districts as well as teachers from across the state of Texas. The excitement of learning about cybersecurity can inspire the K-12 and community college students to pursue further computing education and related careers. The SECURE program will strengthen ongoing partnerships between Texas A&M University and the surrounding schools and lay the foundation for quality computing education in the schools and provide for the future computing workforce needs of the community.
Wi-Fi has emerged as the technology of choice for Internet access. Thus, virtually every smartphone or tablet is now equipped with a Wi-Fi card. Concurrently, and as a means to maximize spectral efficiency, Wi-Fi radios are becoming increasingly complex and sensitive to wireless channel conditions. The prevalence of Wi-Fi networks, along with their adaptive behaviors, makes them an ideal target for denial of service attacks at a large, infrastructure level.<br><br>This project aims to comprehensively investigate the resiliency of Wi-Fi networks to smart attacks, and to design and implement robust solutions capable of resisting or countering them. The project additionally focuses on harnessing new capabilities of Wi-Fi radios, such as multiple-input and multiple-output (MIMO) antennas, to protect against powerful adversaries. The research blends theory with experimentation and prototyping, and spans a range of disciplines including protocol design and analysis, coding and modulation, on-line algorithms, queuing theory, and emergent behaviors.<br><br>The anticipated benefits of the project include: (1) a deep understanding of threats facing Wi-Fi along several dimensions, via experiments and analysis; (2) a set of mitigation techniques and algorithms to strengthen existing Wi-Fi networks and emerging standards; (3) implementation into open-source software that can be deployed on wireless network cards and access points; (4) security training of the next-generation of scientists and engineers involved in radio design and deployment.
Perhaps the greatest single impediment to the broad adoption of public clouds is concerns about security. Reasoning about all the security aspects of complex modern information systems is enormously difficult. Security is especially problematic in the cloud, where a customer must place their trust in opaque complicated services that they do not understand or control and that are shared with many other customers. Yet, in today's public clouds, the assumption is that providers of cloud services can be fully trusted to provide systems secure against any threat. An architecture that exposes the security properties of the underlying services will enable a community of researchers to innovate in the implementation of secure cloud services. It will also provide customers visibility and control of the security in the services they use. Confidence in the security of the cloud will enable transformational societal benefits as the massive public cloud infrastructure becomes more broadly adopted.<br><br>This project defines a modular security architecture for cloud services where providers of different services each expose the security properties of their service, and the consumer can construct a compositional service that matches their application requirements and then reason about the security of the compositional service. The investigators extend existing cloud infrastructures to support this architecture, and explore secure modular networking and operating system technologies in the context of this architecture.
The goal of the project is to provide a secure foundation for a transportation system that increasingly relies on the cooperation, connectedness, and automation of vehicles to achieve increases in safety, efficiency, and capacity. The financial losses attributable to congestion in America's transportation infrastructure are more than $1 trillion annually and the parallel loss of life in vehicle collisions is 40,000 deaths per year. Cooperative, autonomous vehicles are expected to increase the throughput of vehicles; reduce emissions, fuel consumption, and injuries; extend personal transportation to the disabled and elderly; and lessen the number and size of roadways.<br><br>This project leverages a multi-disciplinary group, composed of security, transportation, control, and communication researchers to secure an automated transportation system that is available to all vehicles, trusted or not, that may experience impaired connectivity. The team is (1) developing a secure and resilient control regime for automated vehicles, (2) building a framework based on the physical layer to enable vehicles to establish peer trust, and (3) providing a trusted infrastructure the ability to securely gather and disseminate traffic and environmental data to vehicles for optimal route planning and accident avoidance using Bayesian inference on Markov models.<br><br>The proposed research will advance the knowledge in many fields: secure and resilient control, VANET security, trust establishment and management, physical-layer security, decision theory, and secure protocol design. Results from this research will be disseminated in peer-reviewed journals and conferences. The research will provide opportunities for research training for underrepresented students at undergraduate and graduate levels.
Many application protocols on the Internet, especially those used by malware, are proprietary and have no publicly released specifications. According to the Internet2 NetFlow weekly reports on backbone traffic, more than 40% of Internet traffic belongs to unidentified application protocols. Therefore, it is critical for network security solutions to understand the specifications of these unknown application protocols. For instance, protocol specifications are needed for parsing unknown application protocol in advanced intrusion prevention systems. Protocol specifications are also useful for many other applications such as vulnerability discovery and system integration. Furthermore, even for some application protocols with known specifications, protocol inference is also needed sometimes for identifying implementation details and bugs that are not unambiguously specified. Inferring protocol specification for unknown application protocols is therefore fundamental to network security.<br><br>The objective of this project is to develop schemes for automatically inferring the protocol specification of unknown applications from their network traces. The PI proposes a semantics aware approach that takes network traces as the input and automatically outputs the inferred protocol message format. This project represents the first effort towards developing semantics aware approaches to protocol inference, a fundamental building block of many network security solutions. This project is potentially transformative research with high-impact. It will enable a spectrum of new network security applications and solutions. The proposed project is interdisciplinary in nature as it applies natural language processing techniques to network security problems.
Ubiquitous computing technologies such as "smart" door locks, thermostats, fitness trackers and video monitors can help make users' lives safer and more efficient. These devices automatically collect data about users and their activities within their homes, which are then combined and processed by algorithms on a cloud server owned by the service provider. This enables beneficial system functionality that would not be possible from the devices in isolation. However, aggregating data from different points in time and about many different devices and users can also produce potentially invasive insights and inferences about individuals and households that can be surprising, unsettling or harmful when used for purposes users do not expect. This project develops a coordination mechanism for users to jointly manage derived data as a common pool resource. This shifts privacy problems from the current up-front decisions about what to disclose toward a collective governance model that supports updating disclosure decisions as technology and social norms evolve.<br><br>This project will investigate norms for acceptable uses of derived data, as well as develop and evaluate tools to support collective privacy management decisions. The social norm studies include semi-structured interviews to identify norms, and validation experiments involving simulated norms violation and responses. Building on frameworks for analyzing social-ecological common pool resource systems, the project will perform iterative design and prototyping of a privacy coordination mechanism based on home automation systems. The system will be installed and evaluated in a real-world test to evaluate effectiveness and usability, as well as qualitative analysis of unexpected events.<br><br>More information is available on the project website at: https://bitlab.cas.msu.edu/privacy/
Malicious programs ("malware") are expensive and can put people's lives at risk. Unfortunately, automatic malware detection is difficult and many automated detection systems produce a large number of false alarms. In large enterprises, detectors may create millions of security log entries per day, deluging the human analysts with false alarms. This project is developing algorithmic and statistical techniques to automatically analyze these security logs and reduce the number that human analysts must review from millions to only tens or hundreds per day.<br><br>The researcher's key insight is that attack patterns induce transient correlations across time and nodes (users or devices). The project explores the hypothesis that encoding and algorithmically exploiting such transient correlations can lead to tremendous dimensionality reductions of the multi-scale alert data, and allow statistically significant insights into malware activity. The team is exploring this hypothesis using two ideas. First, they have defined the idea of a "neighborhood" that allows filtering of alerts. A neighborhood is a set of nodes that shares an action attribute such as having visited a common website or received emails from the same source within a specific time window. Thus, neighborhoods are dynamic collections of nodes that are likely to be exposed to a similar attack vector, e.g., a compromised web-server or a malicious phishing email. The second idea is a statistical approach for composing local detectors that uses the feature vectors (FVs) leading to local detector alerts ("alert-FVs") instead of operating only on the original alert flags from nodes. This may allow a global detector to better separate true positive neighborhoods from false positive neighborhoods by comparing the distributional shape of alert-FVs from each neighborhood. The research team will perform experiments to evaluate their techniques using production-scale, real-time alert logs from a large commercial enterprise and the University of Texas' Information Security Office.
OpenSSH reveals excerpts from encrypted login sessions. TLS (HTTPS) reveals encrypted PayPal account cookies. DTLS is no better. EAXprime allows instantaneous forgeries. RFID security has been broken again and again. All of these failures of confidentiality and integrity are failures of authenticated ciphers: algorithms that promise to encrypt and authenticate messages using a shared secret key.<br><br>It is easy to blame many of these security problems on a lack of education: much stronger authenticated ciphers have been in the literature for many years. However, in many cases these stronger authenticated ciphers fail to meet the performance requirements of the applications. Performance is exactly the motivation for RC4 in WEP; EAXprime in the "Smart Grid"; HB in RFID; and "IPsec" continuing to support unauthenticated encryption.<br><br>This project is building a new generation of authenticated ciphers that improve efficiency without compromising security and that improve security without compromising efficiency. This work spans seven main topics: more efficient ciphers; more efficient MACs; more efficient forgery rejection; improved protection against side channels; improved protection against misuse and bad luck; improved quantitative security; and improved security proofs. The ultimate objective is to obtain the best possible security subject to a variety of performance constraints specified by cryptographic users.<br><br>The high-security high-performance authenticated ciphers produced in this project will be directly and straightforwardly usable in cryptographic applications, avoiding the disasters in current applications and finally bringing secure secret-key cryptography from theory to practice.
This project investigates the foundational computational underpinnings of secure systems. Cryptographic constructions such as encryption, signatures, and more rely for their security on the conjectured computational difficulty of certain problems. For example, many public key encryption currently in use would be broken if someone discovered an efficient algorithm to factor large integers. Unfortunately, the current state of art is that we are unable to prove that these problems are truly hard, and so need to rely on unproven conjectures. Moreover, a handful of these conjectures serve as the foundations of many if not most of current cryptographic schemes, and so each such conjecture is a single point of failure whose refutation could have severe consequences for a large fraction of our systems. In particular, progress in quantum computing threatens some of these conjectures, and motivates reevaluation of the right basis for cryptography.<br><br>The goal of this project is better understand and remedy these issues. Concretely, this project investigates cryptographic schemes, and particularly public key encryption, that are based on assumptions that are qualitatively different from current ones, and hence more likely to survive technological or algorithmic advances that would break current schemes. The project obtains new forms of evidence for computational assumptions, thus deriving some assurances that current schemes are secure. The project also explores assumptions for new cryptographic primitives such as software obfuscation that are more well founded by computational complexity considerations
This project develops the foundations for automating verification of secure and trustworthy systems. It extends the range of analyses that are amenable to automated checking and addresses scalability. Symbolic techniques that represent possibly infinite sets of states by symbolic constraints have become important tools, but many systems of interest fall outside the scope of current techniques. There is a real need to extend and combine the power of symbolic analysis techniques to cover a much wider class of systems in order to develop the foundations for security and trustworthy software and systems.<br><br>Maude is a language based on rewriting logic. Maude can be used to model a system of any kind -- for example, an algorithm, a database, a hardware system, a programming language, a network protocol, a sensor network, or the molecular biology dynamics of a cell -- using a set of rewrite rules that describe the systems behavior. The current Maude implementation provides a high performance rewrite engine, as well as built-in search, unification, and model checking tools to support execution and analysis of systems specified in Maude. This project will develop general extensibility techniques for symbolic analysis that can simultaneously combine the power of Satisfiability Modulo Theories (SMT) constraint solving, rewriting- and unification-based analysis, and automata-based model checking to analyze a wide variety of systems beyond the scope of each separate technique. Specifically, the goals of the project are to: (i) develop the semantic foundations of extensible symbolic analysis combining SMT solving, rewriting and narrowing, and automata-based model checking; (ii) endow the Maude formal specification system with combined symbolic analysis capabilities based on such foundations; and (iii) demonstrate through case studies the power of such combined and extensible symbolic techniques in analyzing challenging systems in areas such as: model checking, theorem proving, programming languages, cryptographic protocols, and real-time and cyber-physical systems. <br><br>Maude has a substantial set of users who are doing research on approaches to secure and trustworthy systems. These users are poised to use the new techniques and tools as they develop. For critical systems, where even small security issues can lead to catastrophic failures, this foundational research will support rigorous techniques and tools for automated and scalable checking.
This research project will explore several questions concerning counting in number theory. One of the fundamental goals of number theory is to understand solution sets of polynomial equations. These equations define geometric objects, for example, the algebraic curves on which many modern cryptographic systems are based. Instead of focusing on solutions to a single equation, one can consider a family of equations and attempt to understand the average behavior, the extremal behavior, and in particularly nice settings, to compute the entire distribution of the number of solutions when varying through this family. Within families of curves there are certain properties that one might want to avoid, or select for, so it is an important problem to understand how often these properties arise. In the second half of the twentieth century, mathematicians began to develop the interplay between number theory and the theory of error-correcting codes. This project will explore this connection, using ideas from coding theory to understand families of algebraic curves.<br><br>The questions examined in this research project are a part of the field of arithmetic statistics. The principal investigator will explore distributions of rational point counts for families of elliptic curves over finite fields, especially families that play a key role in cryptography. The project will build on earlier work studying rational point count distributions for elliptic curves over a fixed finite field, applying these ideas to answer statistical questions about Legendre curves and pairing-friendly elliptic curves. The project will also study the distribution of rational point counts for genus-3 curves over finite fields. Computational evidence suggests that there are more curves with many rational points than with few points. The principal investigator aims to use ideas from the theory of error-correcting codes to understand this asymmetry. A major theme of this project is finding boundaries between counting problems that have polynomial answers, ones where formulas are not polynomial but can be expressed in terms of quantities such as Fourier coefficients of modular forms, and problems where we can only hope for asymptotic answers.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
Current cloud based systems enable distributed access to both information and computational resources. In this setting, it is imperative to have secure communication, and powerful and expensive cryptographic techniques have been proposed to address this issue. A severely limiting factor, however, is that these methods for securely accessing or processing data between participating parties can result in communication overheads when processing large amounts of data. This project focuses on the question of minimizing the communication complexity of cryptography and explores new approaches for tackling them. This work could lead to wider deployment of ideas in cryptography which will result in better security and privacy for users, as well as reduced costs and increasing security for cloud service providers.<br><br>The goal of this project is to investigate computationally lightweight solutions whose security can be analyzed without resorting to unproven mathematical conjectures, and diversifying the set of conjectures that suffice for provable security to be achieved. The project develops new techniques for low communication interactive proofs and arguments in order to improve their efficiency, diversify the underlying intractability assumptions, and minimize the necessary set-up assumptions. The investigators explore the possibility of reducing the communication complexity of secure computation protocols while avoiding the use of expensive general-purpose tools such as fully homomorphic encryption. The project investigates new connections between communication complexity and cryptography by using recent results and techniques for interactive compression towards minimizing information leakage in unconditionally secure protocols. The results from this project could enable new technologies for secure manipulation of big data.
The cyber security threat to organizations and governments has continued to grow with increasing dependence on information technology; meanwhile, the entities behind cyber attacks increase in sophistication. Cyber security professionals, the individuals responsible for keeping organizations secure, investigate network activity to find, identify, and respond to threats. These individuals are among the last lines of defense for an organization. Cyber security professionals depend on automated tools to perform their jobs but must make critical decisions that impact security. Therefore, successful defense against cyber attacks depends on human decision making. This research identifies cognitive outcomes that predict successful threat response. The researchers are investigating the content and structure of cyber security professionals' knowledge, creating assessments of cyber security professional cognition, and developing training techniques for cyber security decision making. This project's broader impacts address the large need for cyber security workforce development. The training developed through this research will make cyber security careers more accessible to individuals beyond traditional computer science career paths. Threat response training for network defense provides a strategic advantage against cyber adversaries and increasingly sophisticated threats.<br><br>Effective human decision making is a determinant of effective cyber security. Situation awareness and mental models are cognitive outcomes that predict human performance. Situation awareness, defined as goal-relevant knowledge held during task performance, predicts good decision making. Security professionals also utilize internal representations of the task environment, such as how computers are interconnected, in the form of mental models. Because multiple mental models support situation awareness and vary as a function of task and expertise, understanding decision making in computer network defense requires identifying critical mental models. This research is identifying cognitive outcomes, including mental models and situation awareness, that predict successful threat response in computer network defense and leveraging them to improve training for cyber security professionals. Informed by knowledge of mental models, the research will lead to new training techniques that transfer broadly to cyber security decision making. This training will increase access to cyber security careers, especially to members of underrepresented groups. Threat response training provides a strategic advantage, not only against known threats, but against novel and increasingly sophisticated threats.
As communication networks play an increasingly vital role in our society, ensuring the confidentiality of information transmission and storage has become an increasing concern. New classes of networks, such as heterogeneous wireless networks and distributed storage networks, are emerging, in which the deployment of off-the-shelf cryptographic solutions faces several limitations. These include, for instance, the overhead of key management to maintain synchronized private and public keys; the challenge of distributing keys within the stringent delay constraints imposed by clients; and the exposure to large-scale attacks that were once deemed infeasible. Consequently, several solutions from network coding to physical-layer security have been developed to improve the confidentiality of data over modern wireless networks. Many key-independent and keyless schemes have been developed to provide additional robustness against attacks and more flexibility in the network operation. These schemes have in common that they exploit coded data as keys and move away from the traditional paradigm in which data is a commodity and in which information packets must be transmitted and protected independently. Instead, these schemes envision that information packets could be mixed in a controlled manner so as to introduce an intrinsic level of security against adversaries.<br><br>Most existing secrecy results hinge on the crucial assumption that data is uniformly distributed and independent from a packet to another. Unfortunately, recent results have shown that even optimal data compression algorithms uniformize the statistics of coded data only in a very weak sense. Consequently, several security guarantees established in the literature may well collapse in the absence of any proven robustness with respect to data uniformity assumptions. The objective of this project is to develop a better understanding of how the statistical properties of passwords and data influence the security of secrecy systems. The project investigates several interrelated research tasks: (i) the analysis of the fundamental limits of data-compression techniques with improved uniformity properties; (ii) the design of low-complexity codes for uniformization; (iii) the application of such algorithms in cloud storage systems. Additional activities include an outreach effort to high-school students.
There is a growing need for techniques to detect security vulnerabilities in hardware and at the hardware-software interface. Such vulnerabilities arise from the use of untrusted supply chains for processors and system-on-chip components and from the scope for malicious agents to subvert a system by exploiting hardware defects arising from design errors, incomplete specifications, or maliciously inserted blocks. This project addresses the problem by developing foundational techniques and tools for formal and semi-formal specification and verification of security properties of hardware. <br><br>This project addresses gaps in the current specification and verification processes for hardware designs. Given a design and a (possibly informal) specification, the approach first identifies signals that correspond to high-integrity or confidential parts of the design, such as privileged mode flags or secret keys. The approach uses this information to perform critical signal analysis, specification generation, security-aware specification analysis, and test characterization and augmentation. These steps are iterated until a suitable level of security assurance is attained. The methods build upon formal computational engines for Boolean reasoning, symbolic simulation, and model checking. The project is evaluated using case studies based on processor cores and non-processor blocks, where each case study includes both offensive and defensive components. Tangible results will include theories, threat models, software tools, benchmarks, and case studies. Results from the project are incorporated into courses and textbooks written by the PIs to teach students how to design systems with a security mindset.
As passive tagging technologies like RFID become more economical and ubiquitous, it can be envisioned that in the future, millions of sensors integrated with these tags could become an integral part of the next generation of smart infrastructure and the overall concept of internet-of-things. As a result, securing these passive assets against data theft and counterfeiting would become a priority, reinforcing the importance of the proposed dynamic authentication techniques. This research project investigates dynamic hardware-software authentication techniques on passive RFID sensors and tags based on zero-power timing and synchronization circuits. <br><br>This project explores dynamic anti-counterfeiting and hardware assurance techniques based on zero-power timers. The operation of these timers are based on physics of quantum-mechanical tunneling of electron transport through the oxide layer and through synthetically introduced oxide-traps. The hardware-software authentication strategies being explored include: (1) Born-on-Date timing strategy where the response of the timers will be synchronized across different trusted RFID sensors/tags and any deviation from an expected response will be used to isolate counterfeits, (2) Tamper-sensitive timing strategy where the timer are used to detect any snooping or tampering of the trusted RFID sensors/tags, and (3) Dynamic authentication strategy where the timers are used to generate hashing functions that will be difficult to reverse engineer. The project develops a cross-disciplinary educational forum between the electrical engineers and computer scientists in the area of hardware-software trust verification.
Big data analytics centers promise to address central public policy problems such as health disparities and access, mitigating natural and human disasters, contributing to social stability in urban settings, and managing and planning habitat for wildlife. Embedded in these problems are central ethical questions that take up issues of privacy, inequalities, validity, and meaningful use. National commitments to bringing new analytical skills to the collection and analysis of data make a theoretically and empirically driven analysis of ethics crucial to science and society. Those who develop new analytical tools are not always closely connected to those who use them, yet collaboration develops meaningful ethical practices. This workshop will develop a collaborative strategy for ethical big data practices by including data scientists, local government officials, community stakeholders, and social scientists. Bringing together these various stakeholders will build research teams and projects that combine ethics and big data in productive ways.<br><br>Problems are better defined and gain better answers when people from diverse perspectives are included in the design of research and its use. Research concerning data analytics emphasizes the centrality of local stakeholders' definitions of problems and of where and how analyses are used, yet academic professions do not always build in incentives for collaboration. Building in validity, and a concern for privacy, surveillance and inequality requires working with multiple communities and analytical strategies. By including ethnographers of scientific practices of and users of data analytics who have tracked how analyses have been used, as well as data scientists who design problems and users of analyses, the workshop will develop a framework for the creation of big data with an emphasis on analysis of ethical issues.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
How does the average user cope with the threats they encounter while engaged in the most sensitive of all online activities, online banking? Online Safety for the Ages (OSA) examines generational differences in motivations to use risky online services and self-protective measures in the context of online banking. An influx of older adults attracted to the Internet by social media but at times unfamiliar with dealing with the hazards of online life, as well as younger users who are sometimes oblivious to those dangers, pose distinct challenges to the preservation of online safety.<br><br>A partnership with the Michigan State University Federal Credit Union will provide access to both users and non-users of online banking services of various ages to explore these issues. OSA will work from group interviews and observations of users in their homes to understand the risks that ordinary users perceive when attempting to use online banking, how they cope with risks currently, and the gaps that they see in their own abilities to bank safely online. In-depth analysis of surveys administered to credit union customers will reveal the factors that drive and the barriers that prevent adoption of online banking and online consumer safety measures. Finally, OSA will create and test online tutorials designed to help credit union customers become more confident in their abilities to protect themselves while banking online and to understand how their banking institution can assist them.<br><br>Thus, OSA will contribute new knowledge about how to motivate average users to play their part in making the Internet safer for themselves and for the online community at large. In public discussions of online security, user education is often mentioned as a priority, but too often only in passing, and with self-canceling lamentations about the difficulty of achieving it. The present project will contribute by developing scientifically grounded, evidenced-based knowledge about effective approaches to consumer education. The project focuses on a vulnerable group of older Americans whose lives can be improved through secure access to financial services. Older Americans, however, are also vulnerable to online scammers and are too often uninformed about online dangers and inexperienced with effective protections. OSA provides a model through which bank customers and their financial institutions can work together to improve online security, a model that will be disseminated widely in the banking community with the assistance of a banking industry partner and to the computer security community through professional publications. Finally, the project will support doctoral students who will pursue careers in academia and government and further the goal of online safety through their own students and constituents.
The statistical analysis of behavioral data collected through clinical trials, surveys, and experimentation, has a long history in academic disciplines like medicine, sociology, and behavioral economics. The privacy risks inherent in such studies are often at odds with the tremendous societal benefits resulting from sharing data among researchers and practitioners. Mining behavioral data at scale is also a ubiquitous practice among Internet companies, giving rise to significant privacy concerns. As the potential benefits to society are enormous, harnessing this data for the better good while protecting privacy is one of the grand challenges faced by our society today. This project addresses this challenge by bringing Secure Function Evaluation (SFE) of practical, real-life data mining and machine learning algorithms into the realm of practicality, through the development of a highly parallel, efficient, scalable computation platform for secure computation operating at a massive scale. <br> <br>The project develops a Massively Scalable Secure computation Infrastructure using FPGAs (MaSSIF), accelerating secure computations over a cluster of FPGAs and leveraging benefits of both hardware acceleration and multi-device parallelism. MaSSIF significantly differs from previous implementations of SFE in that it is the first to accelerate secure computation primitives: specifically, Garbled Circuits (GC) with FPGAs on such a massively parallel scale. The algorithms considered are (a) computationally intensive, (b) non-trivial to parallelize under SFE, and (c) of considerable practical importance. MaSSIF advances the state of the art both through novel SFE algorithms, as well as in the design and optimization of accelerated, scalable systems for SFE.
Title: SHF: Small: Refinement Types For Verified Web Frameworks and Applications<br><br>Web applications play a crucial role in every aspect of our lives, including banking, commerce, education and healthcare and travel. Despite their importance and ubiquity, they remain notoriously hard to design, develop and deploy as they span several tiers and languages: an HTML/JavaScript client that runs on users' browsers, a central server that implements the application's logic in the "cloud" and a database that stores persistent user data. The goal of this research is to build upon recent advances in SMT-based software verification to develop reliable and secure web frameworks. The intellectual merits of this research are new techniques for specifying and verifying multi-lingual systems spanning databases, scripting languages and service protocols, which are essential ingredients of large software systems. Thus, the project's broader significance and importance is that it will lower the cost of constructing robust web applications, with strong guarantees about the protection of sensitive data about the users' health, finances and other personal information.<br><br>To mitigate the impedance mismatch across tiers, developers use web frameworks which have simplified the construction of web applications. However, reliability and security concerns still cut across multiple tiers and languages, making them hard to achieve. This research will use refinement types to specify and verify properties for frameworks and end-to-end safety and security properties for applications. In particular, it will build on the refinement type system of LiquidHaskell, developed in preliminary research, to verify existing frameworks like Haskell's popular SNAP framework, and use it to develop a suite of applications with strong guarantees, thereby showing how the idea can be widely adopted in mainstream frameworks and languages.
This project envisions a mixed-security system where some components are trusted while others are not-trusted. This includes both hardware and software. The target hardware platform is a heterogeneous multicore system-on-a-chip where some hardware cores are trusted and other cores are untrusted. The applications executing on this multicore substrate are similarly made out of tasks where some tasks require secure execution and other tasks may be unsecured. The problem is highly relevant to so-called "Internet of Things" systems built from trusted and untrusted components. <br><br>This proposal conceptualizes a mixed security computing framework that implements user-defined security policies executing on a heterogeneous mixed-trust multicore system-on-a-chip. Four hardware trust "zones" are considered, ranging from highly trusted, somewhat trusted, untrusted to unknown; tasks belonging to an application may execute accordingly based on its security requirement. The project will investigate software-defined security policies and develop hardware hooks to support the software defined security goals. Among other broader impacts, the PI is developing new teaching materials and will pilot a hardware-software co-design course on Hardware-Oriented Cyber Security. This project will also help in that educational effort.
The annual ACM CCS conference is a leading international forum for computer and communications security researchers, practitioners, developers, and users to explore cutting-edge ideas and results, and to exchange techniques, tools, and experiences. ACM CCS is the flagship event of the ACM Special Interest Group of Security, Audit and Control (SIGSAC). Its acceptance rate is around 15-20%, which makes it a highly selective conference.<br><br>This grant provides support for 32 students to attend ACM CCS and associated workshops. Preference will be given to undergraduate students participating in the poster session, and students with papers in the conference or associated workshops who do not have other sources of support. Participation by women and underrepresented groups will also be encouraged.
In a crowdsensing system, energy efficient data collection is a primary concern for mobile sensing service providers (i.e., mobile users offering sensing as a service via built-in sensors on their mobile devices) in order to maximize battery life whereas trustworthiness is a primary concern for the end users. The proposed research will simultaneously address energy-efficient data collection and context-aware incentives to both minimize power consumption and maximize data trustworthiness. Furthermore, this research will propose new user-driven crowdsensing business models where smart phone users compete with each other for compensation based on the usefulness and trustworthiness of their sensing data. The ultimate societal impacts of the research are new crowdsensing applications in the areas of public safety, disaster management and community engagement that will be enabled by improved energy-efficient data collection, increased crowdsending trustworthiness through context aware sensing, and new crowdsensing business models that will incentivize more users to offer their mobile device built-in sensors as a service.<br><br>The proposed research will extend the ongoing efforts on trustworthy crowdsensing to address energy efficient data collection and new context-aware user incentive strategies to improve data trustworthiness. In order to address energy efficient data collection, coalitional game theory-based algorithms will be proposed while trustworthiness of the aggregated system will be addressed by defining new trustworthiness functions and context analysis of mobile social networks of the sensing data providers. These methodologies will be validated through comparison to benchmark optimization models. Statistical and collaborative trust scores will be used to introduce new trustworthiness and reputation functions for sensing service providers. The new trustworthiness and reputation functions will mitigate the impact of adversaries including the Sybils who aim at misinformation and manipulation. An emphasis will be placed on compatibility with emerging mobile social network (MSN) models and their associated spatio-temporal context analyses. The research will be completed by building a framework which combines the merits of energy efficient data collection and context-aware user incentives.
The objective of this project is to gather empirical evidence on the tradeoffs between security and usability in programming language and library design. Although it is well known that poorly-designed interfaces can lead to increased defect rates and software vulnerabilities, there is currently little specific guidance to designers on what precise language and library features make programmers more or less likely to write vulnerable code. Furthermore, little of the existing guidance is empirically based. The project will develop empirically-based guidance on two issues. First, the ISO/IEC standardization working group for the C programming language is currently evaluating multiple proposals for adding concurrency to the language, and this project will produce data to inform their decision-making process. Second, by evaluating the impact of the use of mutability, the project will provide data that may influence how future programming languages and libraries are designed. <br><br>The project involves three parts. The first phase is an analysis of flaws in code that uses the draft versions of the C concurrency APIs under consideration as well as comparable Java databases on concurrency-related flaws. In the second and third phases, programmers who have between 2 and 5 years of experience will be asked to complete tasks using competing interface designs. The first set of experiments will evaluate competing C and C++ parallel language extensions to determine which language and library features are more likely to result in secure code. Specifically, the investigators will measure the programmers' ability to produce concurrent code free from security-related defects, such as "data races" and "time-of-check-to-time-of-use" errors using the different libraries. The investigators will then build upon this work to evaluate tradeoffs between security and usability when using immutability to reduce the likelihood of vulnerabilities in concurrent code. Through these two experiments, the project will advance the science of cybersecurity by developing a methodology for empirically evaluating how library and language design affect the frequency with which trained professional programmers inadvertently introduce security vulnerabilities during implementation.
This project provides support for a National Academies Roundtable, the Forum on Cyber Resilience. The Forum will facilitate and enhance the exchange of ideas among scientists, practitioners, and policy makers concerned with the resilience of computing and communications systems, including the Internet, critical infrastructure, and other societally important systems. Resilience encompasses not only security in the face of attacks, resistance to degradation, and the ability to recover from adverse events but also the capacity for innovation and adaptation and the ability to absorb rapid technological disruption in a way that reflects the values, such as privacy, and needs of the infrastructure's many stakeholders. Information technology systems are deployed at ever-increasing scale and have an impact on nearly every area of human activity. Cybersecurity has taken on increasing visibility and priority among policymakers and federal research sponsors, as has the need for information and communications infrastructure that can withstand other forms of damage, disruption, and adverse events and that meet the other evolving needs and demands of those who use them. The Forum would provide a unique venue for stakeholders from academia, industry, and government to consider resilience and these other attributes broadly along with the tensions that may arise among them.<br> <br>The Forum will convene senior representatives from government, universities, and industry to define and explore critical issues that are of shared interest; to frame critical questions and needs; and to incubate activities of on-going value to participants. Discussions will encompass such issues as research directions, emerging technologies, design and engineering approaches, human-system interactions, policy and social implications, education and workforce considerations, and institutional roles. Modalities would include cross-sector and public-private dialogue about goals and challenges; consideration of technical and/or policy means to achieve goals shared by system owners, end users and other stakeholders; and exploration of case studies to extract lessons applicable in other domains. The forum would facilitate cross-sector exchange of ideas among scientists, practitioners, and policy makers, joint exploration of challenges and opportunities, and enable the early identification of promising approaches to improve cyber resilience and the vitality of software-intensive systems and critical infrastructure.
Insider attacks present an extremely serious, pervasive and costly security problem under critical domains such as national defense and financial and banking sector. Accurate insider threat detection has proved to be a very challenging problem. This project explores detecting insider threats in a banking environment by analyzing database searches.<br> <br>This research addresses the challenge by formulating and devising machine learning-based solutions to the insider attack problem on relational database management systems (RDBMS), which are ubiquitous and are highly susceptible to insider attacks. In particular, the research uses a new general model for database provenance, which captures both the data values accessed or modified by a user's activity and summarizes the computational path and the underlying relationship between those data values. The provenance model leads naturally to a way to model user activities by labeled hypergraph distributions and by a Markov network whose factors represent the data relationships. The key tradeoff being studied theoretically is between the expressivity and the complexity of the provenance model. The research results are validated and evaluated by intimately collaborating with a large financial institution to build a prototype insider threat detection engine operating on its existing operational RDBMS. In particular, with the help of the security team from the financial institution, the research team addresses database performance, learning scalability, and software tool development issues arising during the evaluation and deployment of the system. Research results are reported via technical papers and disseminated through conferences and journals, through a new research webpage at the UB's NSA- and DHS-certified center of excellence (CAE) in Information Assurance, and at the center's future workshops.
Mobile devices equipped with touch screens have increasingly rich functionality, enhanced computing power, and greater storage capacity. These devices often contain private information such as personal photos, emails, and even corporate data. Therefore, it is crucial to have secure yet convenient user authentication mechanisms for touch screen devices. However, the widely used password/PIN/pattern based solutions are susceptible to shoulder surfing (as mobile devices are often used in public settings where shoulder surfing often happens either purposely or inadvertently) and smudge attacks (as oily residues left by fingers on touch screens can be recognized by impostors) and are sometimes inconvenient for users to input when they are walking or driving.<br><br>The goal of this project is to develop a behavior based user authentication approach for touch screen devices. Rather than authenticating users solely based on what they input (such as a password/PIN/pattern), Behavioral Authentication is based upon how users provide input input. Specifically, a user is first asked to perform certain actions, such as gestures/signatures, on touch screens and then the behavior feature information (such as velocity magnitude and device acceleration) is extracted from the actions to authenticate the user based on machine learning techniques. The intuition behind the proposed approach is that people have consistent and distinguishing behavior of performing gestures and signatures on touch screens. Compared with current user authentication schemes for touch screen devices, the proposed approach is significantly more difficult to compromise because it is nearly impossible for impostors to reproduce the behavior of others doing gestures/signatures through shoulder surfing or smudge attacks - they can see it, but they cannot do it.<br><br>This project will advance the knowledge and understanding of behavior based user authentication on touch screen devices. This is potentially transformative research with high-impact. If successful, this project will not only yield a theoretical foundation for behavior based user authentication on touch screen devices but also invite future research along this direction.
The use of outsourcing in silicon manufacturing has rendered hardware susceptible to malicious bugs, called Trojans, that can cause an Integrated Circuit (IC) to fail in the field, similar to the way viruses manifest themselves in software. While there has been significant inroads into Trojan detection and diagnosis in the recent past, high-resolution Trojan detection has been hampered by the increased variability in silicon manufacturing processes, allowing Trojans to hide behind the design guardbands necessitated by process variability effects. The key objective of this research is to develop techniques, algorithms and support infrastructure for detecting, diagnosing and mitigating the effects of Trojans in a variety of circuits that can cause system malfunction after deployment in the field, in the presence of process variability effects.<br><br>The underlying Trojan detection techniques for both mixed-signal and digital circuits use test stimulus optimization algorithms that maximize the sensitivities of the tests applied to the presence of malicious hardware Trojans. Such algorithms are supported by hardware for delivering the tests to vulnerable hardware designs in the field. Since the nature of bugs inserted maliciously into chip designs is not known apriori, the investigators use on-the-fly learning algorithms to refine the applied tests to expose the effects of inserted Trojans. In addition, precomputed and side-channel tests are applied to increase overall test effectiveness by up to 30X over existing methods. These techniques will enable significantly increased security of US industrial and government intellectual property and prevent tampering of US chip designs by external third parties.
The recent data revolution is driving many aspects of modern societal and economic progress. Most of this massive data is now stored in the cloud to enable easy access for a myriad of users who wish to share information including, for example, photos, videos, publications, opinions, and scientific data. Unfortunately, this has come at the expense of the user's privacy whose online activity can be used to profile him/her, making large parts of the population an easy target for discrimination and possible persecution. This research aims at addressing the privacy challenge of data in the cloud by focusing on the problem of Private Information Retrieval (PIR) and Search in distributed storage systems (DSSs). PIR schemes enable users to query data without revealing information about the queries and hence their personal preferences, tendencies, health, or other traits.<br><br>Classical information theoretic PIR schemes require data to be replicated, which is not a scalable solution given the exponential growth of data. This research aims at creating a unified framework for studying coding schemes that, in addition to providing data reliability, cater to the need of private queries. The focus of the proposed research is on (i) explicit constructions of codes and PIR schemes that address practical and important aspects of distributed storage, such as storage cost, network communication cost, disk reads, latency and computations; (ii) explicit constructions of codes and schemes for private keyword search; (iii) characterization of the fundamental limits and tradeoffs between reliability, privacy and the different system overheads; (iv) testing software implementations of the schemes on real genomic and social science data. The project also incorporates several educational and outreach efforts, including the development of new publicly accessible online content on information theory, security, and privacy in distributed storage systems as well as pre-college outreach through the Global Leaders Program at the PI's institution.
Increasing cyber security depends on our ability to guarantee that the system will provide the expected functionality under normal circumstances as well as if the system is perturbed by some random events or security threats. Providing such guarantee is often complicated due to several factors such as changes in system requirements caused by user demands, exposure to a new threat model that was not considered (or not relevant) in the original design, or identifying bugs or vulnerabilities during a system life cycle. The purpose of the project is to develop automated techniques --that provide justifiable confidence about correctness-- to transform an existing software model into a new model that satisfies both the existing functionality and the desired security requirements. <br> <br>Developing algorithms that generate models that satisfy existing functionality and new security requirements poses new challenges due to the fact that existing trace-based properties do not suffice for several security properties. A characteristic of trace-based properties is that if a model satisfies a trace-based property and it is restricted by removing some undesired behaviors then the revised model still satisfies that trace-based property. Hence, adding a trace-based property can be achieved by removing behaviors that violate it. Since trace-based properties cannot express several security properties, this project will utilize a new formalism, hyperproperties, that generalizes trace-based properties and can be used for modeling security requirements. In particular, a hyperproperty consists of a set of trace-based properties and to satisfy that hyperproperty it is required that the repaired program exhibit `all? behaviors in one of these properties.<br> <br>To develop algorithms that justifiably provide assurance about models developed by them, this project will first focus on formalizing commonly used security requirements using hyperproperties. It will perform complexity analysis to evaluate the complexity of adding different security properties to an existing model. To mitigate cases where the complexity is high, it will develop heuristics and algorithms that (1) identify whether adding the given hyperproperty can be achieved via adding a related stronger trace-based property, and (2) identify a subset of hyperproperties where adding the given property is more efficient. This work will also result in the development of efficient algorithms and tools that utilize the complexity bottlenecks. Thus, the results of the proposed project will enhance assurance of software systems by repairing security flaws and vulnerabilities in an automated fashion.
User behavior is a critical element in the success or failure of computer security protections. The field of Human Security Informatics (HSI) combines security informatics and human-computer interaction design to learn how the design of a human-computer interface can affect the security of a computer system. This research project is contributing to the scientific foundations of HSI by modeling how multitasking users behave when making security-critical decisions. In particular, the researchers are modeling user behavior when the users are engaged in typical PC-based mobile messaging with security concerns such as phishing or spam. The project is evaluating how well the models capture the impact of incentives and interventions on user security behaviors.<br><br>This project extends the cognitive modeling (CogM) architecture to characterize and improve user security decision-making and behaviors. Focusing on cognitive constructs in the ACT-R and Soar architectures, it models the multi-tasking application and security activities with varying cognitive traits and security constraints, through representations of productions and information chunks, as well as their utility and activation calculations. An analytic user model not only describes a problem in making a security decision, but also can explain why and how it happens for incentive and intervention selection. Moreover, CogM models and empirical user testing comparatively study common and advanced users in typical messaging applications, regarding security mistakes and efficiency in task completion. This project is focused on establishing the principles for analytically modeling user cyber behaviors and bridging the gap from understanding security behaviors to effectively improving security performance.
Power systems are changing with the rapid deployment of remote sensing devices such as Phasor Measurement Units (PMU) and integration of more capable Supervisory Control and Data Acquisition (SCADA) systems. PMU measurements, generated every second, are used by power system operators to make critical decisions. With more utilities adopting PMUs for real-time system monitoring, power systems are exposed to more cyber-threats targeting these devices.<br><br>This research investigates means to determine the impacts of data intrusion on PMU devices, and will propose mitigation strategies. The outcomes will identify cyber-attacks that can result in cascading blackouts as well as the most critical components of power systems that are likely to be targeted by cyber threats. This multidisciplinary research will focus on three fundamental goals: (1) Quantifying the impact and severity of false data injection; (2) Detection of anomalies; and (3) Mitigation of the impacts. The project delineates differences between trivial and critical data manipulations and evinces the need to protect some measurements more than others. The project will systematically identify the most critical power system measurements that are best candidates for additional protection.<br><br>The findings of this research will establish the foundations for protecting the most critical assets in power grids. As part of the broader impacts of this research, a diverse group of graduate and undergraduate students, especially women and underrepresented students can be trained in smart grid protection and planning. Mitigation methods proposed in this research can be extended to other complex networks and the proposed methods for identifying most critical components can be employed in other industries.
The goal of this project is to create the algorithms, frameworks, and systems for defending the open web ecosystem from emerging threats. This project aims to (i) analyze malicious tasks and behaviors of crowdturfers; (ii) detect malicious tasks on crowdsourcing platforms by developing novel malicious task detectors; (iii) design and build a task blacklist; (iv) uncover the ecosystem of crowdturfers and detect crowdturfers; (v) combine crowdturfer detection approaches with other malicious participants detection approaches. Crowdsourcing systems have successfully leveraged the attention of millions of "crowdsourced" workers to tackle vexing problems. From specialized systems for crisis mapping, for protein folding, for translation to general-purpose crowdsourcing platforms. However, these positive opportunities have sinister counterparts: large-scale "crowdturfing", wherein masses of cheaply paid workers can be organized to spread malicious URLs in social media, formation of artificial grassroots campaigns ("astroturf"), and manipulation of search engines. As a result, crowdsourced manipulation threatens the foundations of the open web ecosystem, reducing the quality of online social media, degrading our trust in search engines, manipulating political opinion and ultimately, reducing security and trustworthiness of cyberspace. Products of the research will be available for public use. The education and outreach efforts of the project are tightly linked to the research goals through curriculum development, workshops, direct training of underrepresented women, and involvement of industry. <br><br>The intellectual merit of the project is it will advance the current security systems against crowdsourced manipulation in cyberspace. This project fundamentally alters the landscape of malicious task problems by detecting malicious tasks in crowdsourcing platforms. Early detection of malicious tasks has the potential to transform our solutions for secure and trustworthy information systems. Given our malicious task detection systems, identified malicious tasks can be used as samples for creating new blacklists. The blacklists have the potential to prevent propagation of malicious tasks to popular online target sites. Given our novel techniques, detecting almost all crowdturfers becomes a distinct possibility in the near future. Overall, this project will advance knowledge and understanding the crowdsourced manipulation problem, and the proposed detection framework will complement the current security systems against crowdsourced manipulation. The broader impacts of the proposed work include advances to discovery and understanding while promoting teaching, training and learning. To benefit society, the proposed malicious task and crowdturfer detection framework including task blacklists will enable crowdsourcing service providers and target sites providers to detect crowdsourced manipulation with protecting information quality and trust.
The objective of this project is to understand and strengthen the security of Multipath TCP (MPTCP) - an IETF standardized suite of TCP extensions that allow one MPTCP connection, consisting of multiple sub-connections between two hosts, to use multiple paths simultaneously. Even though MPTCP has been gaining momentum in being widely deployed, its security is yet to be well understood. The project is expected to raise awareness of MPTCP security and ultimately yield a foundation for MPTCP security. The study will further increase the acceptance of MPTCP as an efficient, trustworthy, and next-generation transport layer protocol, especially considering that the deployment of new protocols can always be hindered by security concerns. The results will lead to development of guidelines and specifications for MPTCP through standards organizations such as IETF.<br><br>This project aims to gain an in-depth understanding of the implicit interaction among sub-connections within an MPTCP connection, the information that can be leaked or inferred through side channels by eavesdropping such interaction, and the potential attacks on MPTCP by exploiting such leaked or inferred information. The key insight is that the current MPTCP design inherently allows an attacker eavesdropping on one path to learn information (e.g., throughput) about the sub-connections along other paths. Such seemingly benign information leakage allows an attacker to hijack the entire MPTCP connection. This project considers three general threat models: on-path only attacker, host-assisted off-path attacker, and host-assisted on-path attacker. Based on these threat models, the PIs propose to study traffic offloading/onloading and sequence number inference attacks. The PIs also plan to design and validate countermeasures and defense mechanisms for MPTCP against such threats.
This proposal supports 12 students for their travel to attend the 16th Workshop on the Economics of Information Security (WEIS) held at the University of California San Diego, on June 26-27, 2017. WEIS is an annual event that serves as a leading forum for interdisciplinary scholarship on information security, combining expertise from the fields of computer science and electrical engineering, economics, social science, business, law, and policy. Student participation in WEIS is a critical part of the educational experiences of students with interdisciplinary interests related to security and privacy. WEIS provides them an opportunity to interact with senior researchers and to be exposed to leading work in the field. As such, it fits closely with the goals of NSF's Secure and Trustworthy Cyberspace (SaTC) program, which include socio-economic approaches to information security.
The digital provenance of a digital object gives a history of its life cycle including its creation, update, and access. It thus provides meta-level information about the sequence of events that lead up to the current version of the object, as well as its chain of custody. Such provenance information can be used for a variety of purposes, such as identifying the origins of a document, assessing the quality or reliability of data, and detecting undesirable actions such as forgery or unauthorized alteration of data. However, all of these practical uses of provenance information presuppose that the provenance system is secure, i.e. that provenance data is collected, processed, and stored in a manner that ensures its confidentiality and integrity. Without such guarantees, users can get an incorrect impression of document authenticity, potentially with significant real-world consequences.<br><br>This project investigates the design of secure provenance collection systems where the collected meta-data can be relied upon even in light of realistic insider attack models. Security, however, is not sufficient; a practical system must also be efficient even when large amounts of fine-grained provenance data needs to be stored and processed. The project is aimed at addressing both issues through the following three objectives. (1) Techniques for continuously updatable software tamperproofing to ensure the integrity of the system itself. (2) Techniques for robust, continuous marking, collusion-free, text fingerprinting to mitigate document leakage. (3) Techniques for anonymous storage on untrusted storage servers to allow for efficient storage and access of fine-grained provenance data.
Living in an age when services are often rated, people are increasingly depending on reputation of sellers or products/apps when making purchases online. This puts pressure on people to gain and maintain a high reputation by offering reliable and high-quality services and/or products, which benefits the society at large. Unfortunately, due to extremely high competition in e-commerce or app stores, recently reputation manipulation related services have quickly developed into a sizable business, which is termed Reputation-Escalation-as-a-Service (REaaS). As REaaS attacks grow in scale, effective countermeasures must be designed to detect and defend against them.<br> <br>This research addresses REaaS from two aspects. First, it aims to understand the economics of REaaS by conducting empirical studies of e-markets. Second, it aims to develop defensive measures, which involve both technical approaches and market intervention. The technical approaches focus on detection of REaaS from e-markets, and novel detection techniques will be developed using content analysis, machine learning, social ties, and graph theory. For market invention, after a holistic analysis of REaaS, this research aims to identify its bottleneck (the weakest link) and also measure the efficacy of intervention. The outcome of this data-driven security research will enhance security education with labs based on social-economic data analysis. The success of this research will attract more attention of industry practitioners, government sectors, and academia to jointly tackle the REaaS problem.
This proposal provides funding for the third GREPSEC: Underrepresented Groups in Security Research workshop, which will held in May 2017, in San Jose CA. This day-and-a-half-long workshop intended for women and underrepresented minorities in computer security and privacy, will be co-located with the IEEE Computer Society's Security and Privacy Symposium, the premier conference in security.<br><br>The broad goal of the workshop is to increase the number of women and underrepresented minorities in computer security research. Security is a wide field, encompassing network security, operating system security, language-based security, forensics, privacy, as well as legal and policy issues. The goal of the organizers is to encourage Ph.D. students who are female and from underrepresented groups to choose security as their field of specialization. Their approach is to show the wide range of problems within the field and how women and underrepresented groups are working towards solving those problems.
Cryptographic protocols are a fundamental tool to secure distributed computer applications, but also notoriously hard to design and analyze. With modern computer applications becoming increasingly complex, interconnected, distributed and interactive, there is a pressing need to improve the researchers' ability to design and analyze protocols that go well beyond the traditional problem of secure message transmission. This research investigates frameworks to improve the way cryptographic protocols are designed and analyzed, by investigating new mathematical models of computation specifically targeted to security analysis. These methods will allow security analysis of more complex applications, and also to improve public confidence in the analysis itself. <br><br>This project explores computation models where time is only treated implicitly, through logical dependencies. Avoiding the explicit modeling of time greatly simplifies the analysis of cryptographic protocols, still capturing timing constraints that are relevant to security properties. Different communication and security models are considered, and compared to each other via reductions, with respect to security guarantees, their ability to capture realistic attacks, and expressiveness in describing protocols of cryptographic interest. Models are evaluated by exemplifying their use in the analysis of a set of representative case studies, including Oblivious Transfer protocols, and protocols for secure multiparty computation. These tools and techniques will help developers to more easily reason about the security of a wider range of applications, and lead to more secure and trustworthy software.
The objective of this project is to investigate the security of fingerprint authentication systems, especially those using partial fingerprints. A number of consumer electronic devices, such as smartphones, are beginning to incorporate fingerprint sensors for user authentication. The sensors embedded in these devices are generally very small and the resulting images are, therefore, limited in size. To compensate for the limited size, these devices often acquire multiple partial impressions (templates) of a single finger during enrollment to ensure that at least one of them will successfully match with the image obtained from the user during authentication. In some cases, the user may even be allowed to enroll multiple fingers, and the templates pertaining to these multiple fingers are associated with the same identity (i.e., one user). A user is deemed to be successfully authenticated if the partial fingerprint obtained during authentication matches with any one of the stored templates. <br><br>This project is investigating the possibility of generating a "Master Print," a synthetic or real partial fingerprint that serendipitously matches with a large number of partial impressions pertaining to multiple users. This is akin to having a Master Password that can unlock a diverse set of user accounts. In this regard, the following tasks are being conducted: (a) Analyzing the vulnerability of fingerprint authentication systems that use partial fingerprints by developing methods to generate Master Prints; (b) Models for computing the distinctiveness or uniqueness of partial fingerprints compared to full prints; (c) Methods for mitigating the vulnerability associated with the adversarial use of Master Prints.
Despite rampant criticism of passwords and an abundance of alternative proposals for user authentication (e.g., biometrics), passwords are not likely to be replaced in the near future due to their ease of deployment and familiarity to users. Indeed, while a number of policies for improving password systems have emerged, the most widely adopted of these is to simply increase the size of the space from which passwords are drawn. Even so, for user-chosen secrets, these policies generally make passwords harder to remember and type, leading to user frustration. Worse, users generally fulfill these policies in predictable ways, impairing the security benefits they are intended to provide.<br><br>This project leverages linguistic expertise to develop techniques that provide memorable passwords through both user input and automated processes. Specifically, we explore the formation of pronounceable authentication strings that lead to improved system security and a decreased burden on users (by providing memorable, hint-able, easily type-able passwords that are resistant to attack). Our user-influenced, but system-generated, pronounceable strings combine source words to make lexical blends (aka portmanteaus, e.g., flamingo + mongoose -> flamongoose), or elicit user-generated blends from system-suggested semantic domains. Additionally, we examine techniques for rating pronounceability of word-like strings, allowing us to quantify pronunciation difficulty and proactively apply rigorous security analysis techniques to the space of pronounceable word-like strings. The broader significance of the work is to increase our collective understanding of the driving forces behind string pronounceability and the complex relationships involved in human and automated formation of lexical blends.
The past several years have seen a fundamental change in the way that individuals use technology to communicate. One aspect of this change has been the widespread deployment of new encrypted communications systems that are used by billions of users. With the emergence of new, practical encrypted messaging protocols and storage technologies, encryption is now available to the public in a quantity and quality that could only be imagined in previous decades. With the deployment of secure encryption technology comes new challenges. These span the traditional domains of cryptography, software design, and usable security. Technical flaws in these systems have already exposed hundreds of millions of users to the threat of data compromise. At the same time governments around the world have called for the introduction of new potential points of failure, in the form of exceptional access systems that would allow law enforcement to access communications on demand. <br><br>This project studies problems arising from the often contradictory requirements of providing user security and providing exceptional access to government agencies. The work involves research into many aspects of the problem, ranging from cryptographic protocol design through the careful consideration of legal and administrative procedures. Research outputs will include development of requirements for these systems; analysis of concrete proposals put forward by government agencies; and the design of meaningful auditing systems and revocation mechanisms to maintain security for such systems in the event of a catastrophic breach. The research results have been integrated into graduate and undergraduate courses, and are disseminated through news publications and a public blog.
Recent work has established the possibility of deriving auxiliary information from biometric data. For example, it has been shown that face images can be used to deduce the health, gender, age and race of a subject; further, face images have been used to link a pseudonymous profile in the Web with a true profile, thereby compromising the privacy of an individual. The objective of this work is to design and implement techniques for imparting privacy to biometric data such as face, fingerprint and iris images. <br><br>In this regard, the following tasks are being conducted: (a) methods to modify biometric data such that the modified data can be used for re-identifying an individual but cannot be used to derive auxiliary information about the subject, such as gender and age; (b) methods to generate multiple privacy-enhanced templates from the same biometric data in such a way that these templates cannot be linked using a biometric matcher; and (c) methods to decompose and store the biometric data of a subject across entities such that individual entities cannot determine the identity of the subject, but collaboration across entities is essential for eliciting the identity of the subject. Finally, methods to assess the degree of privacy of a biometric image are being developed in order to quantify the amount of private information that can be derived from it. The proposed methods are being evaluated on publicly available face, fingerprint and iris datasets in order to determine their efficacy in the context of cyberspace applications.
By the end of this decade, it is estimated that Internet of Things (IoT) could connect as many as 50 billion devices. Near Field Communication (NFC) is considered as a key enabler of IoT. Many useful applications are supported by NFC, including contactless payment, identification, authentication, file exchange, and eHealthcare, etc. However, securing NFC between mobile devices faces great challenges mainly because of severe resource constraints on NFC devices, NFC systems deployed without security, and sophisticated adversaries.<br><br>This project investigates three techniques to secure NFC: (1) energy-efficient and fast key agreement mechanisms by exploiting full-duplex capability of NFC devices; (2) RF signal randomization to provide NFC confidentiality without a pre-shared key; and (3) a proximity verification mechanism defending against relay attacks utilizing magnetic sensing. These techniques are expected to significantly improve the key generation rate and reduce energy consumption compared with the conventional Diffie-Hellman key agreement protocol, and achieve high security and usability. These proposed techniques will be evaluated through theoretical analysis, numeric simulation, testbed experiments, and user study, and compared with conventional security mechanisms under different system settings and conditions.<br><br>The proposed project will advance research on lightweight, energy-efficient, and usable security mechanisms in mobile networks for IoT applications. The research is applicable to important applications, such as mobile payment and access control. Graduate, undergraduate, minority, and high school students will be actively involved into the proposed research. The newly established Cyber Security Engineering (CYSE) BS program at George Mason University will be enriched through this project. Materials of this project will be made available online in the forms of tutorials, talks, publications, and software toolkits.
As mobile phones become capable of performing increasingly complex and sensitive tasks, the loss, theft or destruction of such devices represents one of the most significant classes of security problems. This research improves the security of data stored on and generated by these devices by breaking the mandatory binding between mobile phones and hardware. In particular, this work limits the damage associated with this class of vulnerabilities not to the value of the data they transport but to the cost of the device itself. In this system, mobile phone users can seamlessly migrate software images of their phone to any device at their disposal, while data present on previously used devices is automatically encrypted or securely deleted. Phone images themselves are efficiently pushed into and pulled from the cloud, which also supports patching and the upgrade of phone images to occur both over the air and within the cloud itself, increasing the speed with which software vulnerabilities can be mitigated. In so doing, this approach allows network providers and users to adopt highly dynamic responses to security incidents.
Used by hundreds of millions of people every day, online services are central to everyday life. Their popularity and impact make them targets of public opinion skewing attacks, in which those with malicious intent manipulate the image of businesses, mobile applications and products. Website owners often turn to crowdsourcing sites to hire an army of professional fraudsters to paint a fake flattering image for mediocre subjects or trick people into downloading malicious software. This research aims to disrupt fraudulent job markets, identify behavioral differences between fraudsters and honest users, and design fraud detection methods for popular crowdsourcing sites such as Yelp and Google Play. Detecting fraudulent information and malicious behavior serves to improve the quality of life of online service users, help reduce the distribution and impact of malware, and protect the credibility of online services.<br><br>The overarching goal of this project is to significantly increase the complexity and cost of attacks that seek to undetectably influence the ranking and public image of online service subjects. The project consists of two thrusts: modeling and detecting search rank fraud. The modeling thrust dissects fraudulent job markets supported by crowdsourcing sites, documents and models their employer-to-worker interactions and equilibria, and identifies the subjects they target. The researchers will monitor subjects and leverage community expertise and malware detection tools to create large-scale, ground truth datasets in order to assist the effort to identify temporal, spatial and social indicators as well as patterns that differentiate fraudsters from legitimate users. The detection thrust builds upon game theory to develop solutions that disrupt detected, active fraudulent jobs. The researchers will also design scalable search rank fraud detection techniques and algorithms - built on the indicators and patterns identified in the modeling thrust to detect fraudulent, search rank altering behaviors - for online services. The researchers will devise graph-based methods that identify suspicious connections among users and flag multiple colluding accounts. This final aspect uncovers not only targets of large-scale review campaigns but also less popular subjects, whose rank is impacted by even a few fraudulent reviews.
Online opinions now play a pivotal role in decision making and influence a wide spectrum of our lives. Choices of restaurants at which to dine, places to stay, universities to attend, books to read, doctors to consult, and even political candidates to vote for, are largely influenced by crowdsourced opinions. However, it is estimated that up to 30% of reviews on websites are fake. As a larger part of the US economy is becoming driven by social opinions, it poses a serious risk to the general public (e.g., by getting mislead to invest on low quality products, services or doctors). The Federal Trade Commission Opinion may soon consider online fraud as unlawful and a legal offense. Detecting fake online opinions is an urgent research area. Otherwise, online social media might continue to progress undetected. This project aims to develop novel deception detection algorithms in order to identify fraudulent behavior. It synergistically integrates techniques from computational linguistics, behavioral modeling and statistical machine learning in order to advance knowledge in this area. <br><br>The project consists of a four-pronged research effort: 1) novel methods to learn deception classifiers from large-scale noisy crowd data and small-scale domain expert coded data, 2) unsupervised models that treat "spamicity" of reviewers as latent with observed behavioral footprints, 3) a relational architecture for jointly modeling reviews, reviewers, and their linguistic and behavioral patterns leveraging inherent reinforcement relations, and 4) an ensemble scoring mechanism blending cues from of all approaches, and an end-to-end validation framework. The techniques developed in the project can (1) reduce the marketing, consumer, and economic risk in e-commerce; (2) improve user profiling, detecting online harassment, bigotry, trolls, and other social media fraud that are of major relevance to national security; and (3) transition techniques developed to courses/tutorials and attract underrepresented students, including minorities and women. The result is a suite of novel, principled, and scalable techniques to filter opinion spam at large scale.
GameSec is a research conference focused on analytical models based on information, communication, optimization, decision, control and game theories that are applied to diverse security topics. At the same time, the connection between theoretical models and real world security problems are emphasized to establish the important feedback loop between theory and practice. The conference helps to promote a "science of security" with a theoretical foundation that helps us understand security risk in a principled way.<br><br>This grant provides travel support to allow more students to attend GameSec 2013. Preferences for travel support are based on the credentials of the students, with a focus on attracting women and underrepresented minority students to support their participation in this event.
Autonomous systems (AS) are key building blocks of the Internet's routing infrastructure. Surveillance of AS may allow large-scale monitoring of Internet users. Those who aim to protect the privacy of their online communications may turn to anonymity systems like Tor, but Tor is not designed to protect against such AS-level adversaries. AS-level adversaries present unique challenges for the design of robust anonymity systems and present a very different threat model from the ones used to design and study systems like Tor. Thus, new research is needed to understand this threat and to defend against it. <br><br>This project is investigating the design of anonymity systems that are resilient against AS-level adversaries. First, the project aims to quantify the capabilities of AS-level adversaries, who are powerful eavesdroppers and also capable of active attacks, but also have some limitations in practice. Second, the project is designing new route-selection strategies for anonymity systems that can limit how much of the anonymized traffic the AS-level adversary can observe and attack. Finally, the project is investigating how anonymity systems can hinder an AS-level adversaries' ability to analyze encrypted traffic by injecting spurious cover traffic and timing delays. The findings and new anonymity system designs from this research will impact the privacy of a broad class of users in the context of forms of large-scale monitoring of online communications.
The objective of CanSec (formerly Greater Kansas Area Security Workshop or KanSec) is to provide a regular forum for researchers and students across several Midwestern states (Kansas, Missouri, Colorado, Iowa, Arkansas, Oklahoma, Nebraska, Texas, and Indiana) to present research and educational activities, and to promote interactions and collaborations. The workshop was initiated by three NSA/DHS National Centers of Academic Excellence in Information Assurance Education (CAE/IAE) and IA Research (CAE/R) in the State of Kansas: the University of Kansas, the Kansas State University, and the Fort Hays State University. In 2013 and 2014, they met as KanSec; in 2015, they have renamed the conference CanSec, and broadened the scope to other Midwestern states.<br><br>This grant provides support of students to attend CanSec, where they can interact with peers and faculty from across the region.
Quantum computers, which harness the peculiarities of quantum physics to solve hard computational problems, are poised to deliver significant and far-reaching impacts to cryptography and privacy. Significant progress is being made in developing these devices, indicating that quantum computing will likely be viable in the next couple decades. Once viable, quantum computers will open up new attack vectors that will render many current cryptosystems insecure.<br><br>This project is building new protocols to protect against these new quantum attack vectors. Examples include multiparty computation, public key cryptography, block ciphers, and more. Simultaneously, this research is also devising novel systems that actually take advantage of quantum computing to perform exciting new cryptographic tasks that were not previously possible. As part of these goals, the project is developing new theoretical foundations for studying and analyzing cryptosystems in the presence of quantum computers. Finally, this project is developing and studying a new theory of differential privacy in the quantum setting and devising new quantum differentially-private protocols that provide improved privacy guarantees.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
Algorithms are increasingly being used in systems that make decisions that affect people, including filtering news and updates we see, setting prices for items, scoring resumes and credit applications, recommending routes and places, and controlling smart homes and autonomous cars. As algorithms make these decisions, it is natural to ask whether, when, and why we should trust them, and to consider ways to improve their trustworthiness. To this end, researchers, regulators, and industry have increasingly called for methods to audit and account for algorithmic decisions to ensure their transparency and fairness. This project's goal is to integrate these perspectives, bringing together people who design and study these algorithms for a two-day workshop to lay out the problem space and possible ways forward for algorithmic trustworthiness. The workshop organizers will emphasize diversity of perspectives, recruiting participants from a wide variety of disciplines, jobs, and backgrounds with a particular focus on including people from underrepresented groups in computing and PhD students. <br><br>The focus will be on developing interdisciplinary and convergent perspectives on algorithmic decision-making by bringing together researchers, designers, and policy-makers working on different aspects of the problem and different domains, with the goal of integrating their ideas to get a bigger picture of the larger question of trustworthiness of these algorithms in society. The main output will be a report describing the problem space of trustworthy algorithmic decision-making, outlining the major issues that need research to move these algorithms and the decisions they make toward being trustworthy, and identifying promising opportunities and approaches for studying these issues. It will also identify some of the major challenges and constraints that will make progress on these issues difficult, and will further the discussion of moving past these challenges. In addition to the report, the participants will produce a set of whitepapers that will illuminate important aspects of this problem, along with responses and additional reflections by attendees.
INSPIRE<br><br>This INSPIRE project is co-funded by the Science, Technology, and Society (STS) program in the Social and Economic Sciences Division, which is in the Directorate Social, Behavioral, and Economic Sciences, the Office of Integrative Activities (OIA), and four programs in the Division of Computer and Network Systems, which is in the Directorate for Computer and Information Science and Engineering: Secure and Trustworthy Cyberspace (SaTC), Networking Technology and Systems (NeTS), Computer Systems Research (CSR), and Cyber-Physical Systems (CPS).<br><br>General Audience Summary <br><br>This interdisciplinary project brings together social scientists, computer scientists, engineers, and designers to engage in a collaborative research project. The goal of the project is to obtain a better understanding of value handoffs in complex systems that involve interconnected social and technological agents. The social agents may include humans and organizations, the technological agents may include devices and infrastructures. An example of such a system is the internet, a global communication network that allows almost all users of computers worldwide to connect and exchange information. When there are interactions between agents in such systems, there is a hand off of functions. With regards to the Internet, one such function is the preservation of information content; that handoff involves others that represent specific values such as reliability and trustworthiness. This project focuses on the Internet of things, an extension of the Internet to include physical devices (such as vehicles, buildings, and sensing devices) that are monitored and controlled remotely across that network. The research team will develop three case studies in in this broader domain: bio-sensing, smart homes, and visual data processing. The research team has developed a preliminary model for value handoffs. In each of the three case studies, they will collaborate with an identified technical researcher to use the model to shape the technology, and to gain insights from the technology to refine their model; the version of the model that results from numerous feedback processes that are to occur through the sequence of cases is expected to be applicable to a broad range of socio-technical systems. The results of this project will serve to meet an urgent need to foster rigorous thinking about humans and machines in relation to one another, to making things work well across society, in concert with human need, and in service of societal values. Among the values potentially under consideration in this project are security, privacy, trustworthiness, accountability, transparency, autonomy, intellectual property, freedoms of speech and association, justice, and fairness. Failures to protect value handoffs are likely to pose barriers to technical adoption, and to impose burdens on the least privileged in society. This indicates that models to guide decisions about value handoffs are likely to be of critical importance.<br><br>Technical Summary <br><br>The research team will develop three case studies in socio-technical integration research in the domain of the Internet of Things: bio-sensing, smart homes, and visual data processing. The PIs will learn from close study of particular cases about actual and potential handoffs of value-laden functions by characterizing them in terms of their provisional model; in turn, the model will undergo evolution as the project develops. The model that results after a number of feedback iterations through the three cases is expected to be applicable to a broad range of socio-technical systems. The project will also facilitate the development of new methods of work and patterns of interaction that could advance a more integrated and less reactive and oppositional process around value handoffs. In addition to making transformative contributions to process and methodology, the project makes transformative intellectual contributions in identifying how and where values are part of technology systems design, in particular as seen in three socially important technology systems (IoT, sensors, and smart homes). The project will bring to bring to light and address the ethical, political, and societal issues that are enmeshed with the design and development of real world complex socio-cyber-physical systems using insights from mature, highly developed theoretical ideas resulting from prior STS research. In the reverse direction, the project holds potential to contribute to the STS literature and to advance the field of STS field with new insights drawn from their collaborative experiences with technologists developing real world functioning systems, reinforcing and challenging controversial positions.
The more people use the Internet, the more they risk sharing information they don't want other people to know. Tor is a technology that every day helps millions of people protect their privacy online. Tor users -- ranging from ordinary citizens to companies with valuable intellectual property -- gain protection for the content of their online messages and activities, as well as whom they interact with and when. For the most part, Tor is very secure. However, it has a known vulnerability to an attack called website fingerprinting. An attacker, such as someone eavesdropping on a wireless connection, can analyze recognizable patterns in data that websites send to visitors, potentially determining which websites a user visits. Studies have shown that, in some situations, this attack can be successful up to 90% of the time. Developers of Tor and a team of researchers will collaborate to build and deploy new defenses against website fingerprinting, which substantially lower attack accuracy without degrading user experience or increasing the costs of running the system. By widely deploying such a defense, Tor's security is greatly improved. This also provides an experimental platform and data that other researchers can use for their own experiments, helping to further strengthen Tor.<br><br>Previous approaches to defending against website fingerprinting increased latency, so that web pages load 2 to 4 times slower than normal. To design an effective defense that doesn't unacceptably slow browsing or increase bandwidth overhead, this project builds on a technique called Adaptive Padding, which has shown promising results in preliminary work. Adaptive Padding works by noticing distinctive gaps in data packets flowing over the network between a website and Tor user and filling these gaps with extra packets to obfuscate the website's fingerprint. The research team first developed a platform for evaluating Adaptive Padding and other defenses in Tor, allowing security experiments in the live Tor network without full deployment or endangering user privacy. Leveraging this platform, the team performs extensive experiments on website fingerprinting defenses and attacks, leading towards deployment. The project focuses on defenses that can be practically deployed and significantly improve user security. Since defenses meeting these requirements have been understudied to date, this project enhances knowledge in this area. Finally, the findings of the project are fully transitioned to Tor to make Internet browsing safer and more secure.
The growing sophistication of online threats requires that the larger educated workforce understands risks posed by such threats. In recent past, the importance of infusing cyber security concepts in computer science courses has been recognized. This project will explore the viability of an approach that advocates infusion of important cyber security concepts in meaningful context in courses that are part of the general education of undergraduate students across multiple disciplines. Based on a learning sciences informed approach, the project will identify existing courses that provide suitable context for cyber security topics. These courses will range from introductory computing courses to discipline-specific courses in business and public policy colleges at the Georgia Institute of Technology. The relevance of key cyber security concepts in the professional context of various majors will be the primary consideration in identifying courses where these concepts can be infused. <br><br>The interdisciplinary project team, with considerable expertise in the learning sciences, will work together to achieve this goal. After a rigorous evaluation and refinements, content modules and experiences will be shared with the larger community for dissemination. By developing an effective approach to infuse key cyber security concepts in courses that are part of the general education of all undergraduates, the project hopes to have impact on the education of the workforce of the future.
Critical research into cybersecurity vulnerabilities may be affected by legal considerations. For example, cybersecurity researchers fear certain good-faith work could put them in personal legal jeopardy. At the same time, the risks to the public and the economy associated with security research must be addressed. This project convenes a set of leading computer scientists, academics, and lawyers to map out the challenges and propose a set of concrete solutions, including articulating reasonable norms, standards, or best practices for the conduct of cybersecurity research that could be used as a guide for defining good-faith research and for applying current statutes and exemptions.
The 17th Workshop on the Economics of Information Security (WEIS) will be held at the University of Innsbruck, on June 18-19, 2018. WEIS is an annual event which acts as a leading forum for interdisciplinary scholarship on information security, combining expertise from the fields of computer science and electrical engineering, economics, social science, business, law, and policy. The event will feature keynotes from experts in privacy and security research, as well as speakers with research experience in interdisciplinary topics of interest to WEIS (e.g., behavioral economics and cognitive science). This award supports graduate and undergraduate students (who are US citizens or based at US Universities) to travel to the conference.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
Peer-review is a well-known process by which peers evaluate one another's work. In educational settings, peer review involves students evaluating the work of classmates. Peer evaluations can serve many educational purposes: they foster comprehension skills (as students read the work of others), encourage self-assessment and meta-reflection (as students contrast their solutions to others'), demand synthesis of comments from multiple perspectives (as students combine feedback from multiple reviews), and develop professional skills around giving and receiving critique from colleagues.<br><br>The skills that educational peer review attempts to foster are critical in cybersecurity: code review is part of modern industrial software practice (and has identified high-profile security bugs), security problems are multi-faceted and require developers who can synthesize needs of many stakeholders, and developers must prioritize among vulnerabilities identified through different sources and processes. Peer review, with its emphasis on developing students' reflective skills, thus promises to be a valuable mechanism in training security professionals. There are, however, many configurations of peer review, each of which could engage students in different ways. Educational research focused on linking peer review configurations to learning outcomes in cybersecurity is thus critical to using this mechanism effectively.<br><br>This project will experiment with peer-review configurations in a variety of cybersecurity courses. The courses span several areas of cybersecurity (software, system, and policy), as well as both undergraduate and graduate students. The project will explore how various cybersecurity-specific learning objectives manifest through peer review. It will also yield software infrastructure for using and assessing peer review across a variety of courses and configurations. Expected deliverables from the project include observations about students' reviewing practices, refined research questions about how to use peer-review successfully in security education, and software tools that others can use for similar projects (which will be made publicly available).
Mobile Cloud Sensing (MCS) is a promising paradigm for collaborative information collection and sharing in emerging smart cities. MCS is based on the fundamental principle of Sensing-as-a-Service and enables on-demand network access to a shared pool of sensing hardware and software that can jointly sense urban physical/social environments. The major conceptual difference of MCS from existing mobile sensing paradigms lies in the introduction of MCS providers, each having virtually owned an extremely large sensing infrastructure comprising heterogeneous smartphones and tablets (called sensing agents). Upon request from a smart-city application which may demand realtime or historical sensed data, an MCS provider either coordinates its distributed sensing agents to jointly perform the sensing task and then return the sensed data or respond with historical sensed data previously collected from its sensing agents.<br><br>This project is to investigate several fundamental security and privacy challenges associated with MCS. Specifically, there are four main thrusts in this project: (1) developing a suite of secure and privacy-preserving data aggregation primitives; (2) designing differentially-private sensing task assignment mechanisms; (3) developing a unified framework for verifiable query processing via untrusted smart-city service providers; and (4) building a prototype MCS system for validation and evaluation. The project also actively channels the research results into undergraduate and graduate curriculum, provides research experience for undergraduate and under-represented students, and includes outreach activities to K-12, underrepresented, and oversea students.
Everyday web users have little guidance in handling the growing number of privacy issues they face when they go online. Many web sites - some legitimate, some less so - have behaviors many would consider unexpected or undesirable. These include popular and well-known web sites, as well as web sites that aim to dupe customers with "free" trials. These kinds of sites often detail their behaviors in privacy policies and terms of use pages, but these policies are rarely read, hard to understand, and sometimes intentionally obfuscated with legal jargon, small text, and pale fonts. The goal of this research is to develop new techniques to pinpoint and summarize the most surprising and most important parts of policies. The results of this research will be made publicly available on a web site and through web browser extensions.<br><br>The major research activity for this research will be to design, implement, and evaluate CrowdVerify, a system that combines crowdsourcing with machine learning techniques to flag the most important and unexpected behaviors of web sites. The core idea is to slice up a given policy into smaller text segments, have crowd workers compare different segments, and then aggregate the results together. A number of competitor scoring systems will also be evaluated for rating the importance of segments, including ELO, Glicko, and TrueSkill. Using these results, computational models will be built that can predict what people find most surprising as well as most important in web policies.
Database-driven dynamic spectrum sharing (DSS) is a key enabling technical paradigm approved by FCC for increasing wireless spectrum access. In such a system, a geo-location database administrator (DBA) accepts registrations from primary users and determines spectrum availability, and secondary users are all required to inquire the DBA about the availability of any interested spectrum before using it. An effective approach to improve the spectrum-estimation accuracy in database-driven DSS systems is to deploy a small number of dedicated spectrum sensors at strategic locations and outsource most spectrum-sensing tasks to ubiquitous mobile users. This approach is not only highly feasible given the wide penetration of increasingly powerful mobile devices into everyday life and the foreseeable prevalence of DSS in future mobile communication systems, but also expected to be much more cost-effective than deploying a large-scale network of dedicated distributed spectrum sensors. <br><br>This project is to investigate several fundamental security and privacy challenges associated with database-driven DSS systems armed with spectrum-sensing outsourcing. Specifically, there are four main thrusts in this project: (1) secure radio environment map construction in the presence of false spectrum measurements; (2) incentive-compatible and differentially-private mechanisms for crowdsourced spectrum sensing; (3) physical-layer secondary user authentication techniques for spectrum misuse detection; and (4) performance evaluation through a combination of measurement campaign, simulation study, prototyping, and experimentation. The project will actively channel the research results into development of undergraduate and graduate curricula, engage undergraduate and under-represented students into research, and include outreach activities to K-12, underrepresented, and oversea students as well as the local military community.
Most of the world's internet access occurs through mobile devices such as smart phones and tablets. While these devices are convenient, they also enable crimes that intersect the physical world and cyberspace. For example, a thief who steals a smartphone can gain access to a person?s sensitive email, or someone using a banking app on the train may reveal account numbers to someone looking over her shoulder. This research will study how, when, and where people use smartphones and the relationship between these usage patterns and the likelihood of being a victim of cybercrime. This research is the first step to a better scientific understanding how the physical world surrounding smartphone use enables cybercrime. Tired users may be less cautious in browsing to unsafe websites, or distracted users may miss a critical pop-up that a virus has been detected. Once these unsafe patterns of behavior are identified, new techniques, tools, and training can be developed to help prevent smartphone users from becoming victims of cybercrime.<br><br>This research expands existing theories of victimization in the domain of mobile devices, where both the criminal activity and the victimization occur online but may be affected by the offline environment. This research collects sensor data from the smartphones of 160 volunteers, such as GPS location, call frequency, and app usage. The smartphone sensor data is combined with questionnaires, demographic data from the U.S. Census, and neighborhood condition data from Google Street view. This research also provides a baseline of smartphone security threats stemming from behavioral and social factors, and applies new methods for social science research using mobile sensor data to unobtrusively observe the daily activities of subjects. Finally, this research adds to the body of knowledge on the fundamental limitations of sensor-based activity and context inferences, provides a unique corpus of smartphone sensor data that is freely available to the scientific community, and a set of open source tools for collecting and analyzing the data.
Video-based traffic monitoring systems have been widely used for traffic management, incident detection, intersection control, and public safety operations. Current designs pose critical challenges. First, it relies heavily on human operators to monitor and analyze video images. Second, commercially available computer vision technologies cannot satisfactorily handle severe conditions, such as weather and glare, which significantly impair video image quality. Third, the simultaneous transmission of numerous video signals to a central facility creates extreme demands on the communications network, which can lead to jamming. This project presents a novel approach that incorporates wireless sensor networks, hierarchical edge-computing, and advanced computer vision technology. The methods can be expanded to address a wide spectrum of potential applications including wrong-way driving alerts, congestion detection under bad weather conditions, accident scene management support, suspect vehicle tracking, wildfire detection and alert, and emergency evacuation, which could save lives and hundreds of billions of dollars annually. It also aligns with the smart city initiative.<br><br>By using bluetooth/WiFi detection technology, the trajectories and speeds of vehicles equipped with such devices will be collected. This information, along with the captured video data, will be analyzed by the proposed computer vision software, installed at the edge of the network on cloudlets, to perform fast detection and prioritization of the video streams from different cameras. The proposed hierarchical edge-computing paradigm will not only enable real-time big data analysis at the edge but will also be demonstrated and actualized to perform timely efficient video analytics. Depending on the weather conditions, different detection and prioritization algorithms will be activated. Video coding will then be implemented to transmit the selected video streams to the central back-end system for further processing. If an incident is detected by the algorithm either at the edge or at the back-end, a necessary feedback action will be taken, such as calling an emergency group, the highway safety dispatch, or the police. Under a technical partnership with New Jersey Department of Transportation, multiple pilot tests of the proposed system will be implemented on selected highway corridors designated by the department.
New security exploits emerge far faster than manual analysts can analyze them, driving growing interest in automated machine learning tools for computer security. Classifiers based on machine learning algorithms have shown promising results for many security tasks including malware classification and network intrusion detection, but classic machine learning algorithms are not designed to operate in the presence of adversaries. Intelligent and adaptive adversaries may actively manipulate the information they present in attempts to evade a trained classifier, leading to a competition between the designers of learning systems and attackers who wish to evade them. This project is developing automated techniques for predicting how well classifiers will resist the evasions of adversaries, along with general methods to automatically harden machine-learning classifiers against adversarial evasion attacks.<br><br>At the junction between machine learning and computer security, this project involves two main tasks: (1) developing a framework that can automatically assess the robustness of a classifier by using evolutionary techniques to simulate an adversary's efforts to evade that classifier; and (2) improving the robustness of classifiers by developing generic machine learning architectures that employ randomized models and co-evolution to automatically harden machine-learning classifiers against adversaries. Our system aims to allow a classifier designer to understand how the classification performance of a model degrades under evasion attacks, enabling better-informed and more secure design choices. The framework is general and scalable, and takes advantage of the latest advances in machine learning and computer security.
The design of smart electric grids and buildings that automatically optimize their energy generation and consumption is critical to advancing important societal goals, including increasing energy-efficiency, improving the grid's reliability, and gaining energy independence. To enable such optimizations, smart grids and buildings increasingly rely on Internet-connected sensors in smart devices, including digital electric meters, web-enabled appliances and lighting, programmable outlets and switches, and intelligent HVAC systems. However, a key barrier to the broad adoption of energy-related optimizations is that prior work has shown that Internet-connected sensors inadvertently leak sensitive private information about user behavior. For example, a high or variable home energy usage typically correlates with a home being occupied. To address the problem, this research will design low-cost, non-intrusive, privacy-enhancing techniques that reduce the sensitive information leaked through smart sensor-driven devices, while still permitting the sophisticated analytics, control, and verification necessary to enable energy optimizations for smart grids and buildings. <br><br>The research includes developing both consumer- and utility-driven mechanisms to preserve sensor-data privacy. The consumer-driven mechanisms leverage batteries, elastic appliances, noise injection, and renewable energy sources to obfuscate private information in externally visible energy usage data at low cost. The utility-driven mechanisms leverage cryptographic techniques within the devices themselves to enable utilities to implement critical electric grid optimizations, such as demand response, time-of-use billing, and fault localization, without requiring consumers to provide utilities, or other third-parties, with their raw sensor data. The research also develops an approach to controllable privacy, which enables users to control the amount of information smart devices leak to third parties. In this case, consumers voluntarily use smart devices, which are able to verify that consumers engage in some particular energy-efficient behavior without directly revealing sensitive information. The research includes implementing and evaluating the techniques in a prototype programmable building, which includes programmable smart devices, batteries, and renewable energy sources. The research and prototype provide awareness of smart grid privacy and its implications on public policy, and contribute to both graduate courses on smart grids and energy, as well as undergraduate research projects.
This project addresses the need to train students, researchers, and practitioners on diverse hardware security and trust issues as well as emergent solutions. The primary goal is establishing a set of hardware security courseware and enabling adoption of these courseware through the development of an online Hardware Attack and Countermeasure Evaluation (HACE) Lab. The lab will be amenable for remote access and hence will help instructors adopt a curriculum aimed at training students with skills in various aspects of hardware security and trust including Trojan attacks, supply chain issues, side channel attacks, reverse engineering, piracy, and trustable design solutions. <br><br>The HACE laboratory platform is expected to enhance existing cybersecurity curricula for both undergraduate and graduate students by including key hardware security topics. It will facilitate adoption and distribution of practical hardware security training modules with an easy-to-use interface that gives users unified access to experimental platforms, software tools for security analysis, metrics, and benchmarks. Students will be able to remotely access the specialized hardware, which are often expensive to acquire or require special training to install/use, to investigate various hardware-based attacks and countermeasures and to get practical understanding on these topics. The project can significantly impact the cybersecurity education through well-designed hardware security training modules and experiment platforms to universities and community colleges nationwide that will vastly increase the pool of well-trained hardware security professionals. The results of the project assessment and student learning outcomes will be shared with the educational community through the HACE website and the Trust-Hub web portal.
People regularly need to make security and privacy decisions; however, they often don't realize they are making these decisions, and when they do, they often lack the experience and ability to make good choices. Based on studies of how people make decisions "in the wild", this project looks to improve people's security education, training, and awareness (SETA) by (1) using short stories about regular users' security behaviors, rather than expert advice, facts, and warnings, to raise awareness of and suggest responses to security risks, and (2) deliver those stories at exactly the times people might need them, rather than as a separate training program divorced from people's regular use and needs around security. Through a series of interviews the project team will learn more about how experts versus non-experts make security-related decisions in the moment. Using these insights and theories of decision-making, the team will develop and test a set of story-based training materials for common security decisions including selecting passwords, ignoring phishing emails that lure people to download malware or give personal information to fake websites, and avoiding sites that present invalid security credentials. These experiments will increase knowledge of how people make security decisions and how to design materials to support SETA, as well as directly improving security at the lead researcher's institution through live testing with students and staff. The PI will also involve both undergraduate students and people from underrepresented groups in the research and publicly release the materials the team develops.<br> <br>The project seeks to test the hypothesis that telling end users stories about security incidents can better train them to resist semantic attacks than traditional facts-and-advice training. The researchers will first develop a detailed understanding of how people make everyday in-the-moment security decisions, using Critical Decision Method and Experience Sampling Method-based approaches that focus on specific past attacks. The team will interview both experts and non-experts to learn what features they use to recognize attacks and how they identify actions to take; comparing expert to non-expert behavior will help identify vulnerabilities and inform both effective training goals and materials. These insights will be used in developing a set of story-based training materials that emphasize important constructs suggested by the theory of Naturalistic Decision Making including incident typicality, social norms around responses, causality (linking responses to outcomes), and empowerment and efficacy in security decision-making. Through a series of field experiments in collaboration with security mangers at the lead researcher's institution, the team will iteratively improve the training materials while developing theoretical knowledge of how stories about security incidents can support security decision-making in naturalistic settings.
Getting access control policies right is challenging, especially in large organizations. This project is developing techniques and tools to support efficient and trustworthy administration of Attribute-Based Access Control (ABAC) policies. ABAC is a flexible, high-level, and increasingly popular security policy framework.<br><br>ABAC promises long-term cost savings through reduced administrative effort, but manual development of an initial ABAC policy can be expensive. This project is developing policy mining algorithms that promise to drastically reduce the cost of migrating from legacy access control frameworks to ABAC. These algorithms generate candidate ABAC policies from existing lower-level policies, if available, or operation logs, together with data about attributes of users and resources.<br><br>An administrative policy specifies how each user may change the access control policy. Fully understanding the implications of administrative policies in enterprise systems can be difficult, because of the size and complexity of the policies, and because sequences of changes by different users may interact in unexpected ways. This project is developing policy analysis algorithms that support validation of administrative policies, by answering questions such as whether, how, and under what conditions specified administrators can together change the policy in order to grant specified permissions to specified users.<br><br>Powerful development environments for creating and validating access control policies, incorporating algorithms like the ones being developed in this project, have the potential to significantly increase the trustworthiness of IT systems, by helping security administrators efficiently and reliably develop correct policies.
Human beings have evolved to detect and react to threats in their physical environment, and have developed perceptual systems selected to assess these physical stimuli for current, material risks. In cyberspace, the same stimuli are often absent, subdued, or deliberately manipulated by malicious third parties. Hence, security and privacy concerns that would normally be activated in the offline world may remain muted, and defense behaviors may be hampered. While it is not possible to directly test such conjecture, it is possible to test the impact that "visceral" stimuli in the physical world (that is, physical, sensorial cues processed non-consciously rather than with conscious awareness) have on security and privacy behavior in cyberspace. We use a stream of human subjects experiments to investigate the impact of three sets of stimuli over security behavior and privacy behavior in cyberspace: 1) sensorial stimuli (such as auditory, visual, or olfactory cues of the physical proximity of other human beings); 2) surveillance stimuli (such as cues that one is being observed); and 3) environmental stimuli (such as inherent characteristics of the physical environment in which a subject is located). Security behavior is operationalized in terms of individuals? ability to recognize and react to cyber attacks. Privacy behavior is operationalized in terms of individuals? propensity to disclose personal or sensitive information.<br><br>The goals of the experiments are twofold. From a positive perspective, the goal is to understand whether privacy and security decision making online is made harder by the absence of sensorial stimuli that humans have evolved to use to detect and react to threats in the physical world. From a normative perspective, the goal is to examine whether physical stimuli can be used to ameliorate security and privacy behavior in cyberspace. For instance: Can stimuli indicating physical proximity to others trigger changes in security and privacy behavior in cyberspace? If so, can the same stimuli be leveraged and exploited to design privacy and security interventions aimed at helping end users? Findings from this research may inform the work of security and privacy technologists, providing insights that go beyond the technical security of hardware and software infrastructure, and that help revisit the strategies and assumptions underlying those systems. Finally, by exposing conditions under which technology alone may not guarantee cybersecurity, this research can actively inform the work of policy makers.
Research on the human factors of cybersecurity often treats people as isolated individuals rather than as social actors within a web of relationships and social influences. This project leverages known social influence principles such as making public commitments and social proof (i.e., people tend to copy others' behavior, especially when in doubt) to develop techniques that improve cybersecurity behavior and enhance security tool adoption. The team will design, develop, and deploy examples of the use of social influence in three common contexts: standalone security training materials, real-time training ("micro-interventions") given at the moment of a security-related decision, and adoption of security tools and updates. The work will deepen our knowledge of how to incorporate social influences into interface designs that improve people's security sensitivity, that is, the awareness, knowledge, and motivation to be secure. It will also add to the toolbox of cybersecurity researchers and practitioners designing human-facing security tools, and raise public awareness through outreach efforts and widely deploying the security training mini-games. Finally, the project will provide educational opportunities for a number of PhD and undergraduate students, both in doing the research and through integrating the research work and products into courses on human-computer interaction and security.<br><br>The project uses a number of well-known social influence mechanisms to influence security behavior, including reciprocity, social proof, consistency and commitment, liking, authority, and scarcity, through three main research thrusts. The first thrust will develop standalone security training though security related mini-games. The games will allow the researchers to control the observability of others' behaviors and deploy interface features and messages informed by social influence processes. In experiments, the research team will compare how emphasizing different influence processes affect people's security awareness, knowledge and behavior both immediately after the experiment and two weeks later. The second thrust will develop micro-interventions in the context of login pages, based on preliminary work showing this is the most common time people think about security. Working with their institution's information security office, the team will embed security training in system login pages. They will evaluate effectiveness of the training using logged user behavior and a one-month follow-up survey and interview. The third thrust will encourage adoption of new security tools, behaviors, and updates by varying the social influence mechanisms used at different points in the adoption curve of a new tool. Again, the team will run field studies in conjunction with their institution's information security office, measuring relative effectiveness of messages employing different social influence processes based on time-to-update. Experimental materials, monitoring and analysis software, the mini-games themselves, and (when not creating security and privacy risks) the datasets themselves will be released publicly.
Cyber-physical systems (CPSs) operate nearly all of society's critical infrastructures (e.g., energy, transportation and medicine). In performing mission critical functions, CPSs exhibit hybrid (both discrete and continuous) behavior as they use digital technology to control and monitor physical processes. CPS security analysis is particularly challenging because an attacker can make use of a wide variety of vulnerabilities in the digital elements of the system (e.g., the network), the physical elements of the system, or some combination. This project is developing a mathematical and computational framework for modeling and analyzing large, complex CPSs to capture their vulnerabilities and the resulting attack paths (steps an attacker might use to disrupt the system).<br><br>This project is developing hybrid attack graphs (HAGs) as a mathematical formalism for representing security properties and compound exposures in CPSs. HAGs reflect a functional view of exposures, capturing state transitions over CPSs due to the execution of exploits in either the cyber or physical domains. As such, they offer the potential to comprehensively document a CPS attack surface. The researchers are designing HAG generation algorithms that apply intelligent search and parallelization strategies and creating a suite of web-based tools to cope with the computational burdens of large-scale CPS attack surface modeling. The project is developing an array of analytical methods, refined based on Markov Processes, classic reachability, and other techniques. To provide an experimentation platform for evaluating the project's tools and techniques, the researchers are building a CPS test bed comprised of network-controlled robotic vehicles. The testbed will also provide a competitive learning environment in which to teach students about CPS security principles in a fun and engaging manner.
Internet censorship consists of restrictions on what information can be publicized or viewed on the Internet. According to Freedom House's annual Freedom on the Net report, more than half the world's Internet users now live in a place where the Internet is censored or restricted. However, members of the Internet Freedom community lack comprehensive real-time awareness of where and how censorship is being imposed. The challenges to achieving such a solution include but are not limited to coverage, scalability, adoption, and safety. The project explores a linguistically-informed approach for measuring and circumventing Internet censorship.<br><br>The research takes a new perspective on the problem by investigating a hybrid method for censorship detection and evasion from the lens of linguistic analysis. The team develops new models to measure Internet censorship, investigates mechanisms to circumvent censorship using linguistic techniques, conducts communication and social network measurements of censored content. Active Sensing and natural language processing techniques, in conjunction with machine learning and optimization, invigorates new research directions in Internet Freedom and produces new high quality data and tools available for public use. This new allogamy between computer science, information security, network analysis and linguistics provides the foundation for evolution of anti-censorship technologies. The research contributes to a number of fields including Internet censorship, privacy and online information retrieval, as well as computational social science by modeling and analyzing the phenomenon of censorship using the signal available in language. The broader contribution includes wide dissemination of the research results via peer-reviewed publications, special topic courses and workshops. Additional benefits include providing graduate and undergraduate researchers with significant experience of highly practical work on a difficult interdisciplinary problem. Significant gains are obtained in recruitment of minority students through research training in computer science and linguistics.
Industrial control systems differ significantly from standard, general-purpose computing environments, and they face quite different security challenges. With physical "air gaps" now the exception, our critical infrastructure has become vulnerable to a broad range of potential attackers. In this project we develop novel network monitoring approaches that can detect sophisticated semantic attacks: malicious actions that drive a process into an unsafe state without however exhibiting any obvious protocol-level red flags. In one thrust, we conduct a measurement-centric study of ICS network activity, aimed at developing a deep understanding of operational semantics in terms of actors, workloads, dependencies, and state changes over time. In a second thrust, we develop domain-specific behavior models that abstract from low-level protocol activity to their semantic meaning according to the current state of the processes under control. Our goal is to integrate these models into operationally viable, real-time network monitoring that reports unexpected deviations as indicators of attacks or malfunction. A separate "Transition to Practice" phase advances our research results into deployment-ready technology by integrating it into the open-source Bro network monitor. Overall, our work will improve security and safety of today's critical infrastructure by providing effective, unobtrusive security monitoring tailored to their specific semantics. In addition, we tie a number of educational activities to the research and involve students at all levels.
The Transport Layer Security (TLS) protocol constitutes the key building block for today's Internet security and is, for example, used for encrypted web connections using the HTTPS protocol. However, from its first version in 1994 until today, researchers and practitioners keep discovering TLS deficiencies undermining the protocol's security on a regular basis. While the academic community has applied intense scrutiny to the TLS/X.509 ecosystem, much of such work depends on access to difficult to acquire representative data on the protocol's deployment and usage. This project leverages an already operating large-scale passive TLS traffic measurement effort that has been continuously collecting TLS information from live Internet uplinks of 8 large research institutions with about 390,000 users total. The current data set contains more than 100 billion observed TLS connections with more than 100 million unique certificates. This project expands the collection effort and uses both historic and new data to perform studies of current TLS ecosystem trends as well as what-if analyses of future developments.<br><br>The new measurements will address different parts of the TLS ecosystem, including studying the impact of certificate revocation, non-HTTPS deployments of TLS, and applications masquerading as TLS without actually speaking it. Furthermore, leveraging historic data, the project examines trends in TLS usage and deployment like the evolution of TLS software, session resumption, and virtual hosting. Finally, the project combines historic and new measurements to drive a series of what-if analyses predicting the impact of upcoming and proposed ecosystem changes like OCSP stapling for certificate revocation and Google's Certificate transparency. In addition to these measurement efforts, the project offers a community service that makes the data collection accessible to researchers and practitioners by allowing them to run their own analyses on the data set using a mediation process.
Hardware security, specifically the protection of integrated circuit intellectual property (IP), has gained importance as adversaries have the financial and experiential means to reverse engineer and replicate competitors' IP. Significant research effort has been devoted to protecting digital circuits, but the protection of analog circuits from an adversary has largely been ignored. The focus of this work is to explore techniques to enhance the security of analog circuits from attacks such as reverse engineering and cloning, both of which can lead to IP theft. <br><br>Analog parameter obfuscation is proposed as a means to protect analog circuits from adversarial theft. The large design space for analog parameter obfuscation, which includes biasing conditions, gains, bandwidths, noise figure, quality factors, center frequency, phase noise, and many more, provides a means to mask analog circuit functionality beyond the simple binary functional logic locking that has been developed for digital circuits. To enhance the security of analog circuits from reverse engineering, the proposed research includes 1) the development of novel parameter-based obfuscation techniques for analog circuits, 2) the development of algorithms and methodologies to select and prune analog circuit parameters (gain, biasing points, bandwidth, noise figure, quality factor, phase noise, etc.) best suited for obfuscation, 3) the development of initial metrics for the evaluation of parameter obfuscation techniques, and 4) the implementation of the obfuscation technique on a superheterodyne receiver for experimental verification and algorithm refinement.<br> <br>The fundamental outcome is to develop a systematic approach to analyze and obfuscate analog circuit parameters that are multi-dimensional and continuous by nature. The research results will be used to expose high school students to engineering topics through presentations and hands-on workshops. In addition, high school students will be mentored in research through an outreach program, initiated and led by the investigator, which pairs students with faculty mentors. <br><br>The data generated from the project will be maintained online on a server at Drexel University (http://ice.ece.drexel.edu) - with the exception of publications, for which copyright is transferred to a professional organization (such as IEEE or ACM) and which maintain their own repository. At the completion of the project, all data and code will be released in the public domain and maintained in the repository for at least the required period set by agency and university guidelines.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
This project aims to address the growing threat of phishing attacks, messages that try to trick people into revealing sensitive information, by combining human and machine intelligence. Existing detection methods based on machine learning and blacklists are both brittle to new attacks and somewhat lenient, in order to avoid blocking legitimate messages; as a result, widely used email systems are vulnerable to carefully crafted phishing emails. To address this, the project team will develop systems that automatically block obvious scams while forwarding less certain cases to groups of crowd workers trained to detect phishing mails. To support these workers' decision-making, the team will develop novel explanations of the system's decision making that will highlight the aspects of both the message and its algorithm that triggered the need for human judgment. The system will also aggregate these crowd decisions to generate real-time phishing alerts that can be shared to both individual users and to email systems. The project will lead to advances in interpretable machine learning, an important topic given the increasing role that artificial intelligence and machine learning systems play in society, and also increase our ability to characterize the evolution of phishing attacks and the vulnerability of internet platforms and users to those attacks over time. The project team will also use the work as an important component of new courses on usable security and outreach programs to high school teachers and students to both educate them about and increase their participation in cybersecurity research.<br><br>The work is organized around three main objectives: empirical characterization of phishing risks, developing accurate and interpretable machine learning models for phishing detection, and developing reliable crowdsourcing systems for phishing alerts. The team will assess phishing risks through developing analytics tools on the effective adoption and configuration of anti-spoofing protocols in email systems, using adversarial machine learning methods to conduct black box testing on existing phishing detectors, and creating reactive honeypots that entice and respond to phishing attacks in order to collect data on not just the initial phishing emails but on attackers' behaviors throughout the course of a successful phishing attack. The data collected on phishing emails will be used to develop the machine learning models, using Convolutional Neural Network and Long Short-Term Memory based deep learning techniques to generate both suspicious features and confidence estimates of individual decisions. The suspicious features will be used to generate interpretable security cues such as text annotations or icons by first creating simpler and more interpretable machine learning models such as decision trees that mimic the local detection boundary near the target emails in the feature space. Rules in the decision tree will be mapped back to interface elements and email content to provide the warnings, and these will be compared to generic email security warnings in a series of user studies that also model people's ability to detect phishing using a variety of cues, features, and media. Those individual models, along with the confidence estimates from the phishing detection model, will then be used to drive a crowdsourcing-based system where the models of individual users' quality will be aggregated to make reliable judgments around emails the models judge as too suspicious to pass but not suspicious enough to automatically filter.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
The United States is experiencing an increasing frequency of catastrophic weather events that inflict serious social and economic impacts. A critical issue associated with such catastrophes is the availability of electricity for the recovery efforts. Community resilience microgrids can connect critical loads in the community and share the distributed energy resources of multiple providers to enhance the availability of electricity supply during disruptions. However, community resilience microgrids are complex networked systems, and their operation can be often interrupted or halted due to the cascaded growth of failures in interconnected electrical and communications components or the unwillingness or inability of individual microgrid partners to respond. In order to enable the full functionality of community resilience microgrids, this project investigates an integrated reconfigurable control and self-organizing communication framework for enhancing operations in both grid-connected and islanded modes. The effectiveness and benefit of the proposed framework will be demonstrated and evaluated through the hardware-in-the-loop simulation and an actual community microgrid project, which will ultimately provide a model for the successful deployment of community resilience microgrids in the U.S. and beyond. In addition to including doctoral students in research and creating educational materials for the next generation operators and researchers of electrical and communications systems, projects will involve underrepresented students in evaluating social, economic, and resilience benefits of integrated control and communication approaches.<br><br>Coordinated dynamic control strategies for distributed energy resources and loads of multiple owners across different timescales, together with their distinct communication requirements, are the key to the resilient and economic operation of community microgrids in both grid-connected and islanded modes. This research will address these challenges by (1) exploring a hierarchically reconfigurable centralized/distributed control strategy to optimally manage power flows of distribution lines, dispatches of distributed energy resources and flexible loads, and the voltage and frequency of the microgrid across multiple timescales; (2) investigating a self-organizing infrastructure with network topology adjustment and multi-scale data aggregation for flexible, fast, and reliable communication; (3) developing an integrated reconfigurable control and self-organizing communication framework to study the interdependency and interaction between control strategies and communication requirements; and (4) validating, demonstrating, and promoting the developed framework through the hardware-in-the-loop simulation and an ongoing community microgrid project.
Residential computer networks are often insecure because they are unable to apply the best practices employed in corporate networks. The general public, who are often responsible for administering these networks, may lack the financial resources or computing expertise to deploy state-of-the-art network security systems. As a result, residential networks often offer little resistance to fraud and compromise. Further, these networks can enable infiltrations into corporate networks when users bring their mobile devices from the home to the corporate network. The rise of Internet-enabled embedded devices, such as household appliances and electrical power switches, can exacerbate these problems since a compromise can affect the residence's physical environment. To address these risks, this project will explore new mechanisms to send network traffic through security enforcement systems located outside the residence to carefully screen for attacks, both to traditional computers and to Internet-enabled embedded devices. The project's goal is to create new techniques that can improve security for the millions of residential computer networks in the United States.<br><br>The researchers will create a system to answer research questions surrounding the effectiveness, efficiency, performance, scalability, costs and incentives of delegating network security decisions to an external third-party security provider. Using an array of cloud-hosted security middleboxes, the researchers will measure the network latency and impact on bandwidth associated tunneling residential network traffic through these middleboxes before sending the traffic to its destination. The researchers will evaluate how new security mechanisms can be introduced at these middleboxes and how existing security protocols can be fortified in this model. The project will further explore how to detect and create custom security filters for Internet-enabled embedded devices to protect them attempts to exploit vulnerabilities that may be present on the devices. The researchers will explore generalizable models that can apply to embedded devices that have similar network interaction patterns to enable support for a large number of devices. Finally, the researchers will explore the potential for a new subfield of deployable residential network security. The researchers will examine which types of techniques are compatible with external third-party security providers and which techniques require an on-site security solution to be viable.
Mobile authentication is necessary for preventing unauthorized access to mobile devices with increasingly more private information. Despite significant progress in mobile authentication for sighted people, secure and usable mobile authentication for people with visual impairment remains largely under-explored. This project is to develop, prototype and evaluate novel secure and usable mobile authentication techniques for people with visual impairment. <br><br>There are three research thrusts. The first thrust is to develop CurveAuth, which authenticates a user based on his/her finger-drawing curves on the device screen. The second thrust is to develop TapAuth, which authenticates a user based on his/her sequence of rhythmic finger taps or slides on the device screen. The third thrust is to develop ShakeAuth, which authenticates a user based on his/her sequence of rhythmic shakes of the device. This research also includes a plan to prototype and evaluates the proposed techniques through comprehensive user experiments. <br><br>Successful development of the proposed techniques will have profound impact on allowing the visually impaired to fully embrace the power of modern mobile devices for improving their quality of life. Project outcomes will be made publicly available online in the forms of talks, publications, datasets, and Android/iOS apps.
This project designs and deploys a multi-disciplinary framework to model spatial, temporal and social dynamics of cyber criminals. The framework fuses theories in both computer science and criminology. Specifically, project objectives are a) Apply and validate existing theories in the realm of general criminology (in particular Akers? social learning theory and Gottfredson and Hirschi?s general theory of crime) to study cyber crimes; b) Derive novel Internet usage features as fingerprints for cyber crimes; c) Design classification algorithms (based on multi-fractal analysis and petri-net designs) to subsequently model multiple dynamics of cyber criminals by integrating theoretical and practical outcomes from the above two objectives; and d) Extensively test and validate project outcomes. The core novelty of this project is in using real Internet data from subjects (initially a cyber savvy college sample) that is collected continuously, unobtrusively, while still preserving a high degree of privacy.<br><br><br>Outcomes of this project will have far reaching impacts. It lays a foundation for fusing expertise in social sciences (specifically criminology) and cyber security, as a result of which existing theories in general criminology can be empirically tested for practical validity in studying cyber crimes. The identification of unique Internet fingerprints associating with cyber crimes will provide new insights into human centered aspects of cyber crimes, which is lacking today. The classification algorithms designed will provide cyber defenders with new tools to combat cyber crimes from multiple perspectives including prevention, detection, forensic investigations and prosecution.
This project aims to provide people with disabilities, particularly those with visual impairments, better privacy tools when working with computers. Although information privacy is a concern for everyone, common tools such as spam-detecting captchas, password strength meters, security alert messages, and browser icons that indicate secure connections are often designed without considering people with visual impairments and thus are hard for this group to use. Meanwhile, common workarounds such as audio screen readers and requests for help from other people come with their own privacy risks. To better understand the privacy challenges people with visual impairments face, the researchers will first study their use of and known privacy concerns around technologies. They will then work with people with visual impairments to generate, test, and improve a number of design ideas that might address those challenges and concerns. Finally, they will work to generalize the studies and designs to other populations, including older adults who might have different privacy expectations than younger people as well as people with cognitive impairments. The research will lead to a better understanding of privacy needs across the population, as well as "inclusive" designs for privacy management tools that can be better not just for underserved populations but for all people. To spread the knowledge and increase the impact of the work, the team will hold workshops at relevant research communities and with local disability groups, as well as develop course materials on inclusive and accessible privacy for the Security Education (SEED) labs program that is widely used in education. <br><br>The research is organized around three main phases. The first phase aims to learn more about the privacy needs of people with visual impairments through a combination of longitudinal diary studies, in which people record and answer questions about incidents where they felt their privacy was at risk, and observational studies of people with visual impairments and their help givers using technology in context. The second phase looks to develop better privacy support tools; the team will focus first on privacy threat reminders and tools for privacy-respecting collaborative use as these are key issues that arose in preliminary work, but will also develop tools in response to the concerns identified in the first phase. In each design activity, the researchers will use a participatory design approach that includes people with visual impairments (and when appropriate their help givers) on the design team, working together at both local disability support centers and at the research lab. Designs will follow a standard iterative process, starting with initial requirements generation and review, moving through brainstorming and low-fidelity prototypes, and finally developing and testing high-fidelity prototypes. The third phase involves using the results from the first two phases to generate guidelines for inclusive privacy design -- that is, general privacy guidelines that may apply to a wide range of user populations with varying abilities. To do this, the team will conduct research similar to phase one, but with groups of older adults, people with cognitive impairments, and a group of younger people without disabilities; they will also test the privacy tools generated in phase two with these groups to both identify new issues that arise in these populations and modify the tools to be more broadly inclusive.
Systems like Amazon's Alexa, Google Home and Apple's Siri allow users to issue voice commands and pose questions to personal digital assistants. Since these systems often have access to sensitive data and can perform tasks with serious impact (e.g., spend money to make a purchase), attacks against them could have significant consequences. Unfortunately, recent research has shown that attacks against such voice-based interfaces are feasible. This project is exploring methods of securing the voice interfaces to smartphones and other devices to ensure that commands are only accepted from the devices' owners.<br> <br>The researchers recently introduced the notion of hidden voice commands: audio that is constructed to be interpreted as voice commands by a computer speech recognition system, but is incomprehensible to human listeners. In theory, attackers may use hidden voice commands to surreptitiously control victims' smartphones and other electronic devices. Is this a realistic threat in practice? This project is studying both the practicality of this threat and approaches to protection. First, the researchers are investigating whether an attacker could construct hidden voice commands efficiently and covertly and make the commands operate under realistic conditions to circumvent previously proposed defenses. Second, they are developing scalable detection techniques and defenses that reliably and efficiently prevent such attacks.
We are evaluating a new model of password security in which users place pieces on a game board (e.g., chess pieces on a chessboard). The fact that existing systems are either memorable or secure, but not both, motivated our approach. We are testing 14-15 year old high school students, college students 18-30, and older adults 60-80, and we are conducting two types of experiments. First, we are measuring all groups' memories for passwords of two and four game pieces (after a 20-minute filled delay). Second, we are testing college students' memories for five different passwords over a 12-week period in which the game changes after week 10. The results are expected to reveal a dramatically better authentication method compared to existing systems. More specifically, participants are expected to create unique passwords that they can remember. Furthermore, performance is expected to decline during the first 10 weeks, as their passwords begin to interfere with one another, and increase dramatically during the final two weeks, once the game changes and they are able to use a new type of memory. We will present the results at social science and computer security conferences, and submit for publication to sociology, psychology, and security journals. Our approach offers a radical breakthrough that is mathematically secure and easy to remember. The model is applicable to a wide range of electronic platforms, including smartphones, computers, ATMs, and other high-risk electronic gateways. Consequently, the potential to benefit society with more secure systems should have an enormous impact.
The critical role of spectrum as a catalyst for economic growth was highlighted in the 2010 National Broadband Plan (NBP). A challenge for the NBP is realizing optimal spectrum sharing in the presence of interference caused by rogue transmissions from any source, but particularly secondary users who share the spectrum. This complex problem straddles wireless technology, industrial economics, international standards, and regulatory policy.<br><br>This interdisciplinary, multi-university collaborative project studies the many dimensions of the problem from algorithms to law enforcement. The investigators study (1) ex-ante spectrum rule enforcement mechanisms (i.e., preventive) such as spectrum access control via policy reasoners, (2) ex-post spectrum rule enforcement schemes (i.e., punitive) with policy conformance monitoring that employ cryptographic commitments, (3) ex-post enforcement schemes that can uniquely identify rogue transmitters, and (4) the economic viability of spectrum sharing with different enforcement schemes.<br><br>The project provides a broad range of education and industry outreach activities in order to rapidly insert research advances into curriculum and university-industry partnerships. Specifically, the investigators will present short courses and tutorials at the annual Virginia Tech Wireless Symposium and Summer School, and widely disseminate findings through NSF Industry & University Collaborative Research Centers (I/UCRC) at the Virginia Polytechnic Institute and State University.
This project will focus on the topic of Cybersecurity for Middle School Students at Museums in a joint effort between the University at Buffalo (UB) and the Tech Museum of Innovation (The Tech), San Jose. The project will span multiple disciplines ranging from computer science and information systems to forensics and law. The participants shall pay particular attention to concepts and conceptual understanding of cybersecurity. The project will involve the design, development, assessment and refinement of interactive and hands-on experiences in a museum setting, with follow-up workshops targeting middle school students. Given the wide-spread use of the Internet, cybercrime is on the rise and cybersecurity is a much needed component in any STEM curriculum. Exposing students to learning situations through exhibits is a form of informal learning, and the follow-up workshops complement this type of learning with a less informal and more in-depth coverage of the material. The Tech's Smart Museum infrastructure will also support data analysis in order to evaluate the educational efficacy and engagement of the hands-on museum experiences and workshops.<br><br>The partnership between UB and The Tech will: (a) develop and assess interactive museum exhibits on cybersecurity, and (b) develop and deliver targeted workshops to middle school students. The main objective for the exhibits will be to increase awareness of cybersecurity among a school audience. The main objective for the workshop series will be to build conceptual understanding and subject interest among young students who may otherwise not be exposed to the content. In an effort to help break down the perceived barriers to entry often associated with STEM fields and careers, various object lessons, demonstrations, puzzles, and examples will be extensively utilized. A detailed assessment of student learning and engagement throughout the workshop sessions will be conducted. Also, students in the Information Assurance Scholarship Program and the CyberCorps Program at UB will be involved in various aspects of the proposed project.
The National Climate Assessment of the U.S. Global Change Research Program shows that the health, prosperity and welfare of members of U.S. federally-recognized Tribes are already or will be affected by climate change impacts that range from sea-level rise to shifting precipitation patterns to increased frequencies of extreme weather events. STEM fields in the area of climate science provide a number of tools that Tribal decision-makers can use to understand historic climate change trends, model future scenarios for strategic planning, and determine what indicators in the environment should be monitored now for keeping on top of changes. The U.S. President's State, Local and Tribal Leaders Task Force on Climate Preparedness and Resilience recommended that the U.S. federal government "Provide actionable data and information on climate change impacts and related tools and assistance to support decision-making at all levels." Over 75 organizations in the U.S. - mostly federally-funded - aim to improve the climate change preparedness of decision-makers, and include organizations such as the Climate Science Centers of the U.S. Geological Survey and the Regional Integrated Sciences + Assessments (RISA) Centers of the National Oceanic and Atmospheric Administration. Yet, typically relationships between scientific organizations and Tribes can be strained by crucial ethical issues. If not worked out between the parties, the presence of these ethical issues can derail potential collaboration in ways that ultimately prevent Tribes from having fair opportunities to benefit from scientific resources. <br><br>This project seeks to understand the range of practices that climate science organizations employ to prepare their staff for ethical issues that will occur when engaging with Tribes and to evaluate the perceptions of the effectiveness of these practices from organizational and Tribal perspectives. The project will support better collaboration between governmental and nongovernmental organizations in the U.S. and Tribes. The project will improve the government-to-government relationship and the U.S. federal trust responsibility for Tribes, increase the ability of Tribes to work with non-federal nonprofit groups, and create knowledge that will build awareness of how Tribal self-determination and sovereignty can be advanced through collaboration with decision-support organizations. The research will be carried out as a collaboration between Michigan State University and the College of Menominee Nation Sustainable Development Institute. Specifically, the research is using a survey instrument to identify the range of activities that scientific organizations have undertaken that would fall under cultivating cultures of ethical STEM, find out what has been learned by these organizations and the Tribes they partner with, and rank the organizational and Tribal perceptions of the effectiveness of the various activities. On the basis of these findings, and in collaboration with these organizations and Tribes, the project will create a set of recommendations and case studies for moving forward and design evaluation criteria for assessing the long-term impact of old and new practices. This project will be evaluating whether particular non-conventional forms of ethical culture in decision-support organizations have actually led to better STEM support in collaborations with Tribes. The research is expected to generate knowledge about what the range of non-conventional activities are that support cultures of ethical STEM; the research will also make headway in comparing the desired outcomes with the outcomes perceived by the Tribes to have improved or detracted from collaboration. These findings will help to fill a major gap in literatures pertaining to cultures of ethical STEM because there is little information comparing non-conventional activities geared at improving interactions between STEM-based decision-support organizations and Tribes.
Oregon Security Day is an annual one-day event at the University of Oregon, focusing on trends and challenges in computer security as faced by industry, academia, and government and targeted to participants throughout the Pacific Northwest and particularly within the state of Oregon. Building on the 2011 and 2012 events, the funding from this grant will support student travel from more remote areas within Oregon to be able to come to Eugene for the event.<br><br>The Security Day event is an opportunity for students and members of the community to be exposed to trends and new topics in computer security and to discuss ongoing research initiatives. It is also an opportunity to form new collaborations.<br><br>Exposure to nationally-recognized speakers in security for students and others throughout the state of Oregon, particularly from underserved areas who would not be able to receive this access otherwise, aids in the pedagogical and outreach mission of the university and can be an encouraging factor for more students to consider graduate-level study in the area of computer security.
Online social networks (OSNs) face various forms of fraud and attacks, such as spam, denial of service, Sybil attacks, and viral marketing. In order to build trustworthy and secure OSNs, it has become critical to develop techniques to analyze and detect OSN fraud and attacks. Existing OSN security approaches usually target a specific type of OSN fraud or attack and often fall short of detecting more complex attacks such as collusive attacks that involve many fraudulent OSN accounts, or dynamic attacks that encompass multiple attack phases over time. This research, dubbed oSAFARI (Online SociAl network Fraud and Attack Research and Identification), models, analyzes and characterizes OSN frauds and attacks; designs, develops, and evaluates a new approach to detecting static OSN frauds and attacks; and further enhances the approach to handle dynamic attacks with multiple phases. The research team plans to develop a new course focused on OSN attacks and defenses, which has the potential to be offered across many institutions. To increase public security awareness, the team also plans to develop tutorial courses on typical OSN attacks and their defense and offer them at popular public events and in freshman classes. The research team will broadly disseminate their results, tools, software, and documents to the research community, IT industries, and to OSN companies.<br> <br>This project embraces a systematic, comprehensive study of OSN frauds and attacks. It models OSN threats by viewing an OSN as a graph embedded with attacker nodes and edges, identifies and analyzes specific forms of frauds and attacks, and evaluates state-of-the-art attack analysis and defense approaches. It develops a spectral-analysis-based framework for OSN fraud and attack detection. The framework transforms topological information of an OSN graph into patterns formed by spectral coordinates in the spectral space, and introduces the use of the spectral graph perturbation theory to more easily model and capture changes of spectral coordinates for attacker, victim, and regular nodes. Further, this research develops spectral-analysis-based detection approaches for complex networks where nodes can carry attributes and edges can be negative, weighted, or asymmetric. Through a novel combination of the network dynamics and the vector autoregressive model, it develops an automatic spectral-analysis-based approach to detecting dynamic attacks while avoiding the high cost and low accuracy of traditional approaches. It also transforms attack characteristics from high-dimensional spectral spaces into distinctive visual patterns, and develops interactive mechanisms for analysts to incorporate domain knowledge and flexibly handle attacks. The research team will build a simulation framework to evaluate the detection approaches against different types of OSN attacks, where one can plug in different OSN datasets to evaluate and compare different detection approaches. Moreover, the research team will build a prototype oSAFARI on top of an OSN, and evaluate how oSAFARI can withstand various attacks in a real setting.
This award is to support student participation in the annual ACM Symposium on Computer and Communication Security conference (CCS), to be held November 4-8, 2013.<br><br>The ACM Conference on Computer and Communications Security (CCS) is the flagship annual conference of the Special Interest Group on Security, Audit and Control (SIGSAC) of the Association for Computing Machinery (ACM). The conference brings together information security researchers, practitioners, developers, and users from all over the world to explore cutting-edge ideas and results. It provides an environment to conduct intellectual discussions. From its inception, CCS has established itself as a high standard research conference in its area.
The proposed project intends to expand and mature the extramural STEM program Cyber Adventurers through collaboration between the California Polytechnic State University, California State University Monterey Bay, Hartnell Community College and the Lyceum of Monterey. The project seeks to include Cybersecurity topics appropriate for its target audiences: middle school, high school, and undergraduates early in their career. The project seeks novel ways to bring Cybersecurity topics into existing curricula at the K-12 and undergraduate levels to address the widening gap between the supply and demand for qualified Cybersecurity professionals. The developed Cybersecurity lessons will be accessible to a broad audience and synergize with existing programs in formal and informal education contexts. This intervention will inform students early in their education about careers in Cybersecurity; help to understand the value of digital assets and related Cybersecurity issues; create activities to engage students in Cybersecurity lessons typically reserved for advanced computer science majors; and present Cybersecurity as an interdisciplinary concern relevant to a variety of STEM fields. The Secure and Trustworthy Cyberspace (SaTC) program funds proposals that address Cybersecurity from a Trustworthy Computing Systems perspective; a Social, Behavioral and Economic Sciences perspective; and proposals focusing entirely on Cybersecurity Education.<br><br>The project will design activities that synergize with existing K-12 STEM programs. It will increase interest in those existing programs, diversify those programs, engage new audiences, and educate that Cybersecurity is relevant across a variety of STEM fields. The collaboration network of two K-12 schools and three post-secondary schools will unite interested practitioners and researchers, and will facilitate community building among STEM stakeholders in the Central Coast region of California. The dissemination strategy has the potential to impact and inform other projects at the national level.
Field-programmable gate arrays (FPGAs) represent an important computing infrastructure which must be protected from attackers. They are used in a wide variety of applications, including networking routers, satellites, military equipment, and automobiles, among others. The storage of FPGA programming information in memory external to the device creates a natural security weakness which, to date, has primarily been addressed via bitstream encryption. Recent work has shown that bitstream encryption is not impervious to attack and, with sufficient effort, the logical function of some or all of an FPGA design can be determined from a bitstream. This work systematically investigates advanced attacks on FPGA designs and, more importantly, develops sound countermeasures against FPGA design manipulations by determined attackers. To eliminate weaknesses, FPGA security is addressed from a new angle: the use of hardware obfuscation to make the true functionality of an FPGA design nearly indecipherable even if the entire logic-level design can be determined by bitstream reverse engineering. These questions are addressed by first developing a series of search-based computer-aided design tools which can identify security primitives (e.g. crypto primitives) in FPGA design logic-level netlists. As a result of this work, a series of automated tools which allow FPGA circuit designers to obscure the functionality of their subcircuits will be developed. These tools will make malicious design modification significantly more difficult or impossible.
The modern web experience is dynamic, providing users with a highly responsive interface through which to interact with the world. Today's mechanisms allow servers---even those which are controlled by an attacker---to download arbitrary programs into a user's browser. It is extraordinarily difficult to secure the web browser (and its user) against attack in this scenario. While tools and techniques are useful to analyze and restrict downloaded code, they are by their very nature incomplete. As a result, the security of web services relies on a series of ad hoc, service-provided techniques. Thus even large organizations routinely outsource too-difficult-to-secure web services.<br><br>This project will explore an alternative: A modern, dynamic web experience with a focus on safety. Rather than attempting to make arbitrary code safe, it aims to design a safe interface which is far less complex than today's browser environment. This interface will be analyzed for its security properties. It will result in a more tractable environment in which to secure web applications than exists today. Many security properties will be built in; such properties are not dependent on the server side-efforts to secure them. Thus, when using this interface, visiting web sites will pose a smaller threat to users, even from sites which are under the control of an attacker. The project will develop a new semantic foundation for web security and make available open source tools and educational materials for the next generation of web developers.
Data provenance involves determining the conditions under which information was originally generated, as well as all subsequent modifications to that information and the conditions under which those modifications were performed. As systems become increasingly distributed and organizations become reliant on cloud computing for processing their data, the need to securely manage and validate the provenance of that data becomes critical.<br><br>This project develops new frameworks for evaluating secure fine-grained provenance collection and management in hosts. The research activities examine the architectures and algorithms required to make the collection and management of trustworthy provenance feasible at scale. We provide a general architecture for collecting provenance at the kernel level and consider methods of reducing the amount of provenance generated and managed while maintaining high-fidelity provenance records. <br><br>The project introduces a number of optimizations to enable scalable and performant provenance collection, including policy-based log reduction and provenance deduplication. The project's main scientific contributions include (1) the development of Linux Provenance Modules that provide complete provenance mediation within the Linux kernel; (2) the design of policy-reduced provenance through the use of mandatory access control policies to reduce the number of subjects and actions that are provenance-generating events to those of interest in a system; and (3) techniques for deduplication of provenance such that minimal records for commonly occurring events can be stored and later fully reconstructed. We will demonstrate that our approach makes provenance collection practical at scale, enabling more secure and trustworthy computing environments.
The cybercriminal community is inarguably more organized, better resourced and more motivated than ever to perpetrate massive-scale computer infections across the Internet. The malware distribution systems that they control and operate are characterized by their use of highly specialized suppliers and commoditized malware services. As a consequence of this development, criminals with little technical expertise can deploy and administer sophisticated exploit kits, and instantiate malicious-content advertising (malvertising) campaigns that surreptitiously infect hundreds of thousands of innocent victims. The MALDIVES project is developing a new generation of technologies to provide deeper insights into how these malware distribution systems are deployed, operated, and interlinked with open web sources.<br><br>The MALDIVES project is organized as a sequence of five attack observation lablets (ATOLLs) which are collectively designed to acquire an in-depth understanding of the key stages in contemporary malware dissemination infrastructures. The Platform Acquisition Observatory (PLATO) is focused on studying the deployment phase of the server-side infection infrastructures. This observatory extends web-application-vulnerability mimicry systems with a dynamic exploit-kit interrogation system, and adds automated intelligence tools to understand subsequent victim infection strategies. The Victim Enticement Scheme Evaluation Lablet (VESSEL) is focused on studying the targeting phase of the malware infection lifecycle. It develops tools and conducts measurements on various enticement schemes, such as Search Engine Optimization (SEO) poisoning and malvertising. The Traffic Redirection Observation Lablet (TROLL) is focused on the delivery phase and builds active and passive techniques to measure malware-related traffic redirection chains. The Exploit Kit Interrogation Environment (EXPLORE) builds automated probes to facilitate the detection and measurement of professionally designed automated infection services. The Defensive Strategies Investigation Lablet (DISTILL) investigates novel malware-defense capabilities based on the insights acquired from prior lablets.
Access to publicly available information can be disrupted by various techniques, and alternative disruptive techniques continue to be developed. Understanding these alternative disruption techniques and how they affect network anonymity, privacy, and performance is paramount not only to the successful design of future technologies, but also to the security of existing networks and systems. Accordingly, this project explores, designs, and transitions to practice techniques that will improve the resilience of privacy-enhancing technologies against these realistic but understudied threats to network anonymity, privacy, and availability. The project consider adversaries that look beyond weaknesses in software implementations or protocols and instead seek to destabilize anonymity services by affecting the shared resources upon which these services depend. <br><br>This project studies how Internet infrastructure attacks apply to anonymity networks. The research designs defenses that improve the resilience against such threats, and transitions such defenses to the deployed Tor network. Our research activities (i) examine performance-based resource attacks and design privacy-preserving detection techniques to understand not only how denial-of-service attacks can drain network resources, but more importantly, how to automatically detect and prevent such attacks; (ii) study how control-plane routing attacks can be used to harm anonymity, and develop attack mitigation techniques to understand how to improve the resilience of anonymity networks against threats from the underlying untrusted Internet infrastructure; and (iii) analyze the impact of human mobility on anonymity to understand how to provide robust and secure anonymity services to the now ubiquitous mobile operating environment. The activities help expand understudied research areas and not only help improve the design of future technologies, but also enhance the security of existing networks and systems.
The goal of the proposed project is to use case studies to introduce design thinking to first-generation and underrepresented students to help them transition from classroom and lab-based learning to engineering capstone design and ultimately to their careers in engineering fields. The case studies will be implemented as part of a new discussion section for a Mechanical Engineering class at UC Merced, a Hispanic Serving Institution where over 60% of undergraduates are the first in their families to attend college, more than half come from bilingual or non-English-speaking homes, and more than 75% of students receive financial aid. This project also represents the first collaboration between an associate professor in Mechanical Engineering at UC Merced who teaches design and is familiar with the challenges students face but has no formal training in education, and an associate professor in Educational Psychology at Michigan State University with expertise in case studies and engineering education. The project will have direct impact on the students at UC Merced who participate in the pilot program, longer-term and wider-reaching impact through dissemination of the case studies and evaluation of their success, as well as on the PIs who will learn from each other's expertise and use this as the first step towards future collaborative education innovation. <br><br>The engineering profession is a complex and ill-structured domain, and it is recognized that the skill sets which will be required for engineers to successfully fulfill the mission of their profession are much broader than those honed in traditional engineering curricula. This is the premise for promoting and cultivating design thinking in engineering students, and is the focus of the proposed research, which leverages the experiential contexts to develop desired attributes of future engineers. Specifically, this project is based the hypothesis that engaging students in a case-based class before the capstone design course will enable them to both perform better in the design class and will prepare them for real world engineering. This hypothesis will be explored by integrating the component-specific instruction of lectures from an existing Mechanical Component Design course into case studies, with the goal of introducing the students to design thinking. More specifically, design thinking will be taught using case studies that involve the five phases of the Stanford design process: Empathize, Define, Ideate, Prototype, and Test. Given the complex cognitive nature of design thinking, this structured approach will allow students to generate and evolve their solutions/ideas while helping them navigate the challenges of design thinking. The main objectives of this project are to: (1) Develop the PI's expertise in embedding case studies to teach design thinking, (2) establish a library of case studies that use design thinking to expand engineering students' view of problem formulation and solution development, and (3) evaluate the effectiveness of case-based instruction for instilling design thinking behavior in a diverse student population.
The project from the University of North Carolina at Charlotte will prepare students to demonstrate digital citizenship and cyber safety. The goal of this project is to increase cyber safety knowledge and skills among middle school students, teachers, and technology facilitators, while creating cyber safety awareness among parents of middle school students. This project will assist in designing a suite of instructional materials and application activities (e.g., e-learning modules, online course and videos) dedicated to bridge the gap in cyber safety education in schools. The project will also provide interdisciplinary research experiences in cyber safety, technology education, and pedagogical practices to both graduate and undergraduate students. <br><br>The proposed project will address the following objectives: 1) develop five e-learning modules on cyber safety topics (e.g., cyber bullying, digital footprints, digital identity, digital privacy and digital Netiquette) to communicate the importance of digital citizenship to the students; (2) design and deliver an online course on digital citizenship to 20 technology facilitators and 30 middle school teachers; (3) apply the train-the-trainer model by which the technology facilitators will train the teachers in their schools and classroom teachers train the students after the summer course on digital citizenship; (4) pilot the cyber safety e-learning modules with 200 middle school students in three different school districts and a charter school; and (5) help students create videos on cyber safety and disseminate the videos to their parents and a larger audience through social media. The instructional modules and online course content created will be shared with institutions outside the current scope of the project. Further, the project will establish a teacher education and training pipeline to attract more K-12 educators to the program, equip them with much needed cyber security knowledge and skills, and prepare them for the challenges of educating the next generation.
This proposal provides support for the 2013 Workshop on the Economics of Information Security (WEIS) and a one-day follow-on workshop. WEIS fosters cross-disciplinary, cross-sector (i.e., academia, industry, nonprofit, and government), and cross-national discussion on information security. The focus on the economics of information security was chosen not only because of its intrinsic importance, but also because of its basis for bringing together social, computer, and information scientists and engineers to share knowledge, information and methods from their respective domains. WEIS covers issues that are core to the NSF's Secure and Trustworthy Cyberspace (SaTC) program, and spans both the Computer and Information Science and Engineering (CISE) and Social, Behavioral and Economic Sciences (SBE) Directorates within the Foundation. The one-day follow-on workshop focuses on incentive-related issues to cybersecurity.<br><br>Funds for this grant are from NSF for student travel support, and via inter-agency transfer from DHS Science & Technology for sponsorship of the follow-on workshop.
As the Internet grows in importance, it is vital to develop methods and techniques for educating end-users to improve their awareness of online privacy. However, the development of Web-based education tools for online privacy is still in the early stage. Traditional solutions involving professionals can make the tool development costly. It is also not clear how motivating, inspiring, and/or effective these education tools are to general users, especially novice users who have rarely dealt with privacy issues. <br><br>Through interdisciplinary research between a computer scientist and two social scientists, this project aims to exploit both group-sourcing and crowdsourcing approaches to develop effective education tools for online privacy. Research activities include: (1) designing novel methods to generate collective wisdom from non-expert user groups for the development of innovative ideas of privacy education tools; (2) investigating the main characteristics of a wise group that is capable of developing creative and high-quality ideas for privacy training; (3) developing methods to enhance the originality and practicality of the ideas generated by the non-expert groups; and (4) integrating group-sourcing, crowdsourcing, and experts' opinions to evaluate the effectiveness of the developed privacy training tools.<br><br>This interdisciplinary, high-risk, high-payoff project will dramatically advance research in security/privacy and social science. The research results will be disseminated broadly through curricular materials appropriate for computer science, College of Arts and Letters, and MBA students.
Publicly available and searchable genomic data banks could revolutionize clinical and research settings, but privacy concerns about releasing such information are currently preventing its usage. This project aims to address these concerns by providing new mechanisms by which individuals can donate their genomic information to a data bank in such a way that third parties, such as doctors or researchers, querying the data bank are guaranteed to learn only aggregate functions of the population's data that the individuals authorize. <br><br>The guarantee comes from the use of cutting-edge cryptographic techniques, specifically functional encryption. The project develops new functional encryption schemes that are highly tailored to genomic applications and support the above-mentioned system model. Additionally, these schemes support a core functionality of query types that the PIs identify for genomic applications. The PIs target reasonably efficient schemes as a proof of concept, and develop a prototype system to evaluate the practicality in real-world settings. This project addresses the immediate need for methods and technologies that provide safe and secure storage and retrieval of genomic information.
We believe it is a national imperative to cultivate American cybersecurity experts from a young age. However, middle school students from underrepresented groups are typically unaware of career opportunities in cybersecurity, and what they entail. Children who are members of underrepresented groups often lack a sense of identification with STEM fields and endeavors and should be introduced to career paths that are culturally relevant and developmentally appropriate. Cybersecurity professionals employ certain habits of mind toward ensuring continuous security which can be cultivated from an early age, and involve a high degree of creative problem solving, emergent negotiated action in groups, making sense of chaotic complexity and other "21st century skills." <br><br>This project endeavors to create a collectible card game (CCG) similar to other popular battle card games (such as Magic: The Gathering and Pokemon) to be used for teaching underrepresented groups of middle school children (grades 6-8) the habits that have become second nature to cybersecurity professionals and introducing them to growing opportunities in the field. Two K-8 schools in urban Chicago participate in the project. The project involves exploring the potential of CCGs in conjunction with current cybersecurity learning progression to develop a CCG that utilizes common game affordances such as backstory and character identification in ways that are culturally relevant and developmentally appropriate. Garnering an appreciation for the interrelations between multiple sign systems is central to learning. CCGs offer an appropriate path for capturing this complexity by mapping real world cybersecurity concepts and actions onto a CCG for middle school students.
Tor is used daily by millions of users, including journalists, militaries and law enforcement, activists, companies, whistleblowers, and ordinary people, to protect their web browsing against surveillance. However, the internal architecture of Tor is very complicated. This complexity creates performance problems, and it makes security analysis difficult. Furthermore, Tor's encryption will be broken by future quantum computers. Spies are recording larger and larger fractions of Internet traffic; once the spies build a large enough quantum computer, they will be able to retroactively see who was saying what to whom. This FASOR ("Faster and Stronger Onion Routing") project is interdisciplinary, combining theory and practice, with research covering protocol design, software engineering, post-quantum cryptography, and privacy analysis.<br><br>FASOR brings together three complementary research directions. The first component is Tor itself, with a deployed user base in the millions, broad deployment experience, and a history of analyzing privacy protocols to discover vulnerabilities. The second component is "MinimaLT", a clean-slate low-latency encrypted network protocol that reduces complexity and increases security and privacy. The third component is post-quantum cryptography, which introduces cryptographic algorithms that resist quantum computers, but which also poses efficiency and network protocol integration issues. The FASOR project unifies these three components, increasing performance, providing high-security post-quantum cryptography, reducing duplication among different system layers, making it easier to introduce new functionality, and reducing surface area exposed to attackers. The FASOR project will also analyze these protocols for new types of vulnerabilities and threats, and expose and clarify new research problems for the world.
This project develops a low-cost and non-invasive method that can help in assessing cardiovascular health and disease by deriving personalized cardiovascular risk predictors. Cardiovascular disease remains a major source of morbidity and mortality in the United States and around the world. The developed methods can be widely used to improve cardiovascular risk stratification and thereby reduce the incidence of stroke and heart disease. This project provides new opportunities for technological advances in pervasive and personalized medicine, which can ultimately improve the quality of life of human beings. This project also impacts education by developing new multi-disciplinary course modules and encouraging minority students to participate in this project.<br><br>This research derives a methodological framework to infer cardiovascular risk predictors from the analysis of blood volume waveform signals measured by low-cost and non-invasive modalities such as oscillometric cuff oscillations. In this framework, model-based adaptive signal processing methods analyze blood volume waveform signals measured at peripheral locations on the body to derive personalized blood pressure waveform signals. Then, cardiovascular risk predictors are derived from a model-based analysis of these blood pressure and volume waveform signals. The research work includes: (1) deriving mathematical models that dictate the relation between blood pressure versus volume waveform signals; (2) deriving adaptive signal processing methods that transform blood volume waveform signals to blood pressure waveform signals; and 3) deriving methods that compute cardiovascular risk predictors from blood pressure and volume waveform signals. This project makes contributions to the derivation of a unified framework for mathematical modeling of the relation between blood pressure and volume waves. It also contributes to the advancement of adaptive signal processing methodologies relevant to physiological system modeling and health monitoring.
Truly ubiquitous computing with very small, self-powered and wirelessly networked integrated circuits will become possible within a decade. Applications of these devices include biosensors, environmental monitors, and defense, all of which bring a need for security and privacy. Enabling the use of strong cryptographic algorithms on extremely constrained devices requires rethinking, from an energy-first perspective, the design and implementation of basic cryptographic building blocks. The Secure Dust project seeks to reduce the energy of cryptographic functions in advanced technologies by an order of magnitude, and to validate the designs using test chips. The findings of this project will help to secure future ubiquitous devices and the Internet of Things.<br><br>The specific research objective of this project is to explore the scaling down of security functions into advanced CMOS technologies and in particular the important role of manufacturing variations and noise that can be both advantageous (Physical Unclonable Functions and Random Number Generation) and detrimental (side-channel resistant ciphers and hash functions) depending on the cryptography block. We target an energy budget of picojoules per secure transaction, built upon basic cryptography functions. The project combines design expertise in lightweight cryptography using block ciphers, hash functions, PUFs and RNGs, along with low-energy techniques and realistic semiconductor design flows and economic realities. FPGA-prototyping and CMOS FinFET test chips will be used to demonstrate complete cryptosystem functionality, including side-channel susceptibility.
The ability to generate random numbers -- to flip coins -- is crucial for many computing tasks, from Monte Carlo simulation to secure communications. The theory of building such subsystems to generate random numbers is well understood, but the gap between theory and practice is surprisingly wide. As built today, these subsystems are opaque and fragile. Flaws in these subsystems can compromise the security of millions of Internet hosts.<br><br>This project will develop black-box techniques for finding entropy failures at Internet scale related to randomness. These techniques, which build on programming languages, operating systems, networking, security, and cryptography, will then be applied to perform a systematic, ongoing census of the state of random number generation vulnerabilities. Through this census, the project can analyze the "longtail" of deployed networked systems rather than a handful chosen a priori.<br><br>The project will develop and disseminate defensive analysis tools that will help programmers debug and correct entropy problems in their code before they ship it. It will produce cryptographic countermeasures and entropy-gathering subsystems that provide better security guarantees than existing systems, reducing the impact of those entropy failures that do slip through.<br><br>The result will be a better understanding of entropy and more trustworthy systems, today and in the future.
This research focuses on understanding the digital security and privacy needs of journalists and their sources to evaluate and design communication technologies that better support the fundamental operations of a globally free and unfettered press. Journalists -- along with their organizations and sources -- are known to be high-risk targets for cyberattack. This community can serve as a privacy and security bellwether, motivated to use new technologies, but requiring flexibility and ease-of-use. Many existing secure tools are too cumbersome for journalists to use on a regular basis. Moreover, these tools may lack important security and privacy-protecting features that are needed not only by the large and diverse community that is part of journalistic activity, but by other individuals and groups that may have a harder time recognizing and articulating their needs. By learning about the needs and constraints of the journalism community, this project will identify both technical and training interventions that can improve the daily security and privacy of journalists, the many communities with which they interact.<br> <br>The researchers will perform in-depth interviews and usability tests with journalists and their sources. The insights gained will illuminate both the conceptual and technical issues they encounter with respect to cybersecurity. Using the specific risk- and resource-models relevant to these populations, the researchers will propose, prototype, and begin evaluating novel technical solutions to issues like communications metadata, as well as data management, syncing, search and permission controls, and the possibilities of trusted distributed key servers and "disappearing data." The results of this work will lay the groundwork for future technical advances, not only for journalists but also for use by researchers and organizations interested in implementing and testing these tools and processes for other communities.
This project is to design, develop, and evaluate an innovative family routine sensing and feedback system called FRESH (Family Routine, Education, and Sensing Health), which empowers families to actively engage in preventing child obesity and improving family wellness. We develop unobtrusive sensing system using audio, motion, and light sensors from off-the-shelf mobile devices (e.g., Tablet personal computer (PC), smartphone). Integrated with an off-the-shelf wearable physical activity detection device, our system will detect screen viewing duration, family dinner dynamic, sleep quality and duration, and physical activity level of the child. The tablet PC will display collected sensor data through virtual pet and visual metaphors such as a blossoming flower or a growing plant. The family's progress toward improved routine will be reflected through the virtual pet and visual metaphors, which will be available in the periphery of the family's activities throughout the day (e.g., displayed in the living room, parents' smartphone home screen). Families will receive automated feedback and suggestions for improving their routine. Family members will also see how other families are doing compared to them for encouragement and insights. We plan to engage K-12 students during summer to play with the demonstration of our project, increase motivation for scientific research, and increase awareness of family wellness to the surrounding communities. Our technology will be shared as an open-source after the completion of the project for broader dissemination and development of the science we have developed from our project. Overall, our project develops new methods and paradigms of clinical support that engage all family members and a community of families in improving child and family health.<br><br>The goal of this project is to design and evaluate the FRESH system, which automatically senses family routine and gives motivational feedback to help families improve daily routines for child obesity prevention. Family routines, such as sleep, screen viewing, family dinner, and physical activity, are critical predictors of child obesity. While many mobile health devices focused on motivating individuals to pursue healthy behaviors, systems that take a family- and sensor-based approach have been under explored. No existing technologies sense family routines critical to child obesity. With visual and textual feedback driven by sensor data on routines, FRESH offers an engaging way for the children, the family, and the community to involve in family wellness. The technical merits of the project includes: (1) Develop and evaluate unobtrusive sensing technology for monitoring family routines; (2) Formatively assess designing visual and textual feedback in the FRESH system; (3) Evaluate the feasibility and acceptability of the system deployment. To fulfill the objective, we will use participatory design, interviews, diaries, field studies, experiments, and user log analysis.
Cybersecurity is one of the most strategically important areas in computer science, and also one of the most difficult disciplines to teach effectively. Historically, hands-on cyber security exercises helped students reinforce basic concepts, but most of them focused on user level attacks and defenses. Since OS kernels provide the foundations to the applications, any compromise to OS kernels will lead to an entirely untrusted computing. Therefore, it is imperative to teach students the practice of kernel level attacks and defenses.<br><br>Over the past decade, there has been great interest in using virtualization to profile, characterize, and observe kernel events including the security incidents. Inspired by the great success from virtual machine introspection (VMI), this project aims to provide an advancement by directly building practical VMI tools and libraries (or toolkit) on top of virtualization, and applying them for deep cybersecurity education. The deepness comes from the study of the lower level system internals such as OS kernels. The project will further provide a number of seed contents to teach both instructors and students on utilizing the toolkit to be used for studying not only traditional user level attacks such as buffer overflow, but also defenses inside the OS kernels. The outcome of this project (i.e., the toolkit and the cybersecurity exercises) will contribute to the health, safety, and economic well-being of our society by helping to improve the state-of-the-art in cybersecurity education, especially for effectively performing hands-on cybersecurity exercises.
Embedded processing systems are widely used in many devices and systems that are essential for daily life. These embedded systems are increasingly connected to networks for control and data access, which also exposes them to remotely launched malicious attacks. It is of paramount importance to develop embedded processing systems that are hardened to withstand these remote attacks while continuing to operate effectively. Since embedded systems are often used in real-time environments with lightweight operating systems and limited processing and power resources, conventional software solutions for malware detection are not suitable in this domain. Instead, architectural solutions that are specialized to embedded processing systems are necessary. <br><br>This project develops a comprehensive attack detection and mitigation system that is based on hardware monitors that are co-located with the embedded processor. The hardware monitor tracks the operation of the processor and compares each executed instruction with a model of the application that was created by analyzing the original binary. Changes in operation caused by an attack can be detected within one cycle, and recovery steps can be taken. The proposed system does not require any changes to the software running on the processor and does not cause any reduction in processing speed. This project aims to realize a transformational shift in embedded system security from software-based defenses to hardware-based defenses. The results from this research address current security shortcomings and provide solutions that make embedded processors more resilient.
Exploiting advances in underwater robotics, sensor networks, signal processing, and biophysical modeling, the goal of this award is to create a novel paradigm for monitoring and understanding aquatic ecosystems and thus enable sustainable management of water resources. In this paradigm, schools of autonomous gliding robotic fish adaptively sample the water environment. The collected measurements are used to reconstruct high-resolution data fields with advanced multidimensional signal processing algorithms. The reconstructed data fields, along with the data samples, facilitate the monitoring of aquatic ecosystems and enable high-fidelity, mechanistic modeling of the underlying biophysical processes for accurate forecast. The objectives of this award include addressing fundamental problems at the interfaces between the building blocks of the paradigm, and demonstrating a proof of concept for the latter. Specifically, five highly integrated research thrusts are pursued: (1) developing path-planning and control algorithms for the robots to realize information-driven, energy-efficient sampling, (2) developing robust communication protocols and effective in-network parameter-estimation algorithms, (3) establishing tensor sparsification-based frameworks for data-field reconstruction using limited data samples, (4) exploiting reconstructed data fields and network-estimated sub-models to create accurate mechanistic models, and (5) evaluating and demonstrating the integrative paradigm in the monitoring and prediction of Harmful Algal Blooms. <br><br>This award is expected to result in a new, holistic framework for monitoring, understanding, and managing freshwater and marine environments, with a myriad of applications in oil spill response, ecosystem monitoring, and drinking water safety, to name a few. The project provides interdisciplinary training opportunities for students, including those from underrepresented groups. Robotic fish demos, museum exhibits, and teacher-training activities are offered to engage K-12 students, teachers, and the public, and to pique their interest in science and engineering. Besides the dissemination of research findings through conference presentations, publications, and workshops, commercialization of the developed technologies is pursued to facilitate their practical adoption.
Support for research on distributed data sets is challenged by stakeholder requirements limiting sharing. Researchers need early stage access to determine whether data sets are likely to contain the data they need. The Broker Leads project is developing privacy-enhancing technologies adapted to this discovery phase of data-driven research. Its approach is inspired by health information exchanges that are based on a broker system where data are held by healthcare providers and collected in distributed queries managed by the broker. Such systems have potential to support public health and biomedical research. The project targets "similar patient queries" where the query is a patient medical record and the response is information about similar patients. Such queries have value for many applications, including developing cohorts for finding institutions for further discussions about joint research.<br><br>Broker Leads uses the concept of a "lead" in which data holders provide representative collections of non-identifiable real or synthetic data meeting strong privacy guarantees, e.g., differential privacy. Even though such data may be unsuitable for clinical decision making and scientific discovery due to the transformations done for privacy protection, they guide a user of a broker lead system to the data sets very likely to be useful to addressing a given similar patient query. These data sets can then be used with other privacy-protecting strategies, such as secure multiparty computation or restrictive data use agreements ensuring adequate data protection. In addition to providing practical and well-analyzed strategies for early stages of research on healthcare data, this project will provide new insights into practical issues with privacy technology in end-to-end applications.
A fundamental problem in psychology and neuroscience is to understand how the transient memory of an experience becomes stabilized and available as long-term memory. A general theory of memory is that sleep is important to make the memory of an experience stable and resistant to interference. One specific theory has proposed that there are two systems at work during learning, a fast acting system that encodes temporary memories into a brain area called the hippocampus and a slower system that transfer these memories during sleep into a more permanent form in higher-level cortical regions. This process depends on a communicative interaction between the hippocampus and cortex. The present research is the first to directly test the hypothesis of the interleaved interaction between brain regions in the formation of stable more permanent memories from experience. Evidence of this interaction between fast-acting and long-term representations has implications for understanding a number of neurological problems involving memory, for explaining changes in memory with aging, and for the development of new robust computer memory systems. The project provides training opportunities for postdoctoral fellows and data and tools dissemination. <br> <br>Simultaneous electrical and optical recordings from the hippocampus and neocortex will be made as rodents acquire new memories and consolidate these memories into a stable more permanent form of long-term memory. The project examines patterns of activity in these different brain regions to test the hypothesis that interleaved activity patterns during resting state reflects an interplay of recent and long-term memories. Further, a comparison of brain activity in resting states and task-dependent states will examine the question of whether stable long-term memories are regularized by consolidation to be less detailed and more general. The research will measure patterns in collections of spiking neurons along with global patterns of brain electrical activity to test these hypotheses about the process of memory consolidation.
This project develops the theory and algorithms for autonomous navigation of mobile sensing platforms, such as unmanned ground, aerial, and underwater vehicles, so that the collected information is maximized while constraints on movement capabilities and energy expenditure are accommodated. This work facilitates the use of autonomous robots in environmental monitoring, search and rescue, surveillance and security, among other applications of societal importance. The algorithms are evaluated in field trials using unique gliding robotic fish. The project provides training for both graduate and undergraduate students, including those from underrepresented groups. Through showcasing at the Museum of Science and Industry in Chicago and offering of an open-source robotic fish education kit, the project promotes the interest of K-12 students and the general public in science and engineering. The project further facilitates transfer of software and hardware for robotic sensing to the market.<br><br>The goal of this project is to bridge the gap between the theory and practice in information-driven mobile sensing and to develop a principled theoretic and algorithmic framework for autonomous exploration in uncertain, specifically underwater, environments. The approach exploits the concept of ergodic exploration, where the underlying optimization problem is solved using methods from nonlinear optimal control. The research consists of: 1) Establishing a rigorous theoretical framework for ergodic exploration for guaranteeing solution well-posedness and stability, and developing synthesis methods for real-time control; 2) exploring active probing of flow conditions via auxiliary measurement of tracer agents to mitigate environmental uncertainty; 3) investigating collaborative exploration schemes that strike balance among performance, complexity, and robustness; and 4) conducting field experiments to validate the framework using a group of gliding robotic fish to monitor harmful algal blooms and localize sources of chemical spills.<br>
Plausibly deniable encryption is the ability to hide that given data is on a device, whether the ability exists to decrypt it, or even that the data exists. Plausible deniability is a powerful property to protect data on devices the user has lost physical control over, such as protecting consumers from accidental mass disclosures of private data through misplaced devices. This issue is of particular concern for anyone who travels internationally with sensitive data, including human rights workers, diplomats, military personnel, or even business travelers. This project leverages low-level characteristics of flash and other emergent persistent memories to hide data with plausible deniability, improving performance and capacity over the state of the art. <br><br>This project investigates a unique opportunity to implement plausibly deniable encryption using the underlying electrical properties of flash memory. The promising property of flash is that the same hardware cell can encode data in multiple ways, and adjust the encoding dynamically. This project integrates this encoding mechanism with data hiding: as long as the encoding follows an expected voltage distribution, an adversary cannot discern the precise encoding technique or how much data is encoded. This project also investigates firmware-level techniques to manage hidden data; extends these techniques to emerging persistent memories, such as phase change memory; and augments widely-used flash simulators. This project develops novel teaching materials for low-level flash programming.
Modern networks are often federated in nature---i.e., they are an interoperation between independent networks spanning multiple administrative domains. For example, in many enterprises, different business units control various logical segments of the network, but share common resources, such as routers, firewalls, and load-balancers. In such federated systems, the correct enforcement of network security policies relies on interactions that span multiple administrative domains. This project is developing techniques for enforcing security policies in federated networks using a new form of Proof Carrying Code (PCC), specialized to the networking domain. This enforcement mechanism will ensure that only authorized actors can reconfigure devices in federated networks, and will guarantee that configuration software preserves "behavioral" policies such as access control, slice isolation, etc.<br><br>The technical contributions of this research will include (i) developing PCC techniques for NetKAT, a language for SDN programming that comes equipped with a sound and complete equational reasoning system, and (ii) integrating NetKAT PCC into the Nexus Authorization Language (NAL), a framework that provides methods for specifying and enforcing distributed authorization policies. Key challenges will include how to generate, represent, and transform NetKAT proofs, and how to deal with dynamic behaviors such as network configuration changes and evolving trust models. The broader impacts of this project include (i) developing open-source software that will be tested on a GENI rack hosted by the BTV Ignite program with broader impacts in the local Burlington, VT community, and (ii) presenting education opportunities for underrepresented groups via an outreach program for high school students developed in partnership with the New York State 4-H and Science Leadership Academy.
The main research focus of this proposal is to create a platform that allows to automatically find attacks in unmodified binaries of distributed systems. The attacks are conducted through message manipulation by insider attackers and impact primarily performance and availability. The platform combines existent open-source virtualization environments such as KVM, and network simulation and emulation tools such as NS3, to create a realistic environment in which target systems will run. The platform is general, scalable, and can be used for testing a large variety of distributed systems such as intrusion-tolerant and peer-to-peer systems.<br><br>The platform will improve the trust that distributed systems work according to their intended specifications in spite of faults, misconfigurations, or attacks.<br>The platform can serve as a tool for system developers from industry, government labs, and academia to test their systems. In addition, it can be used for programing exercises for distributed systems and computer security courses at both undergraduate and graduate level.
The computer security community has long advocated the concept of building multiple layers of defense to protect a system. Unfortunately, it has been difficult to realize this vision in the practice of software development, and software often ships with inadequate defenses, typically developed in an ad hoc fashion.<br><br>Developers face a number of challenges when protecting a software system with multiple layers of defense. They lack holistic frameworks in which to express policies and mechanisms for different software layers, automated tools to add these defenses, and tools to prove that software enhanced with defenses has an advertised level of assurance.<br><br>This project develops new techniques to retrofit software for defense in depth. It takes a comprehensive view of the problem, with an emphasis on automated, interactive tools that developers can use to identify site-level security goals, explore the design space of adding security mechanisms, and retrofit legacy code to enforce security policies in a manner that can be machine-verified for assurance. The project develops theory and tools for formal policy language design and validation, static and dynamic code analyses, interactive tools for developers to explore the design space of security, functionality and performance tradeoffs, and methods to formally verify the correctness of program transformations to introduce defenses such as authorization, attacker containment, and auditing mechanisms.<br><br>The broader impact stems from the improved security of systems and the reduced cost of achieving better security, also education activities in the form of summer schools for graduate, undergraduate and high-school students. The tools developed will be released to the public domain, benefiting software developers in the field.
As social media permeates our daily life, there has been a sharp rise in the use of social media to humiliate, bully, and threaten others, which has come with harmful consequences such as emotional distress, depression, and suicide. The October 2014 Pew Research survey shows that 73% of adult Internet users have observed online harassment and 40% have experienced it. The prevalence and serious consequences of online harassment present both social and technological challenges. This project identifies harassing messages in social media, through a combination of text analysis and the use of other clues in the social media (e.g., indications of power relationships between sender and receiver of a potentially harassing message.) The project will develop prototypes to detect harassing messages in Twitter; the proposed techniques can be adapted to other platforms, such as Facebook, online forums, and blogs. An interdisciplinary team of computer scientists, social scientists, urban and public affairs professionals, educators, and the participation of college and high schools students in the research will ensure wide impact of scientific research on the support for safe social interactions.<br><br>This project combines social science theory and human judgment of potential harassment examples from social media, in both school and workplace contexts, to operationalize the detection of harassing messages and offenders. It develops comprehensive and reliable context-aware techniques (using machine learning, text mining, natural language processing, and social network analysis) to glean information about the people involved and their interconnected network of relationships, and to determine and evaluate potential harassment and harassers. The key innovations of this work include: (1) identification of the generic language of insult, characterized by profanities and other general patterns of verbal abuse, and recognition of target-dependent offensive language involving sensitive topics that are personal to a specific individual or social circle; (2) prediction of harassment-specific emotion evoked in a recipient after reading messages by leveraging conversation history as well as sender's emotions; (3) recognition of a sender's malicious intent behind messages based on the aspects of power, truth (approximated by trust), and familiarity; (4) a harmfulness assessment of harassing messages by fusing aforementioned language, emotion, and intent factors; and (5) detection of harassers from their aggregated behaviors, such as harassment frequency, duration, and coverage measures, for effective prevention and intervention.
Protecting the confidentiality of information manipulated by a computing system is one of the most important challenges facing today's cybersecurity community. Many complex systems, such as operating systems, hypervisors, web browsers, and distributed systems, require a user to trust that private information is properly isolated from other users. Real-world systems are full of bugs, however, so this assumption of trust is not reasonable. The goal of this proposed research is to apply formal methods to complex security-sensitive systems, in such a way that we can guarantee to users that these systems really are trustworthy. Unfortunately, there are numerous prohibitive challenges standing in the way of achieving this goal. One challenge is how to specify the desired security policy of a complex system. In the real world, pure noninterference is too strong to be useful. It is crucial to support more lenient security policies that allow for certain well-specified information flows between users, such as explicit declassifications. A second challenge is that real-world systems are usually written in low-level languages like C and assembly, but these languages are traditionally difficult to reason about. A third challenge is how to actually go about conducting a security proof over low-level code and then link everything together into a system-wide guarantee.<br><br>In this effort, the PI proposes to design and implement a new set of formal techniques and tools for overcoming all of these challenges. First, the PI will develop a new methodology for formally specifying, proving, and propagating information-flow security policies using a single unifying mechanism, called the "observation function." A policy is specified in terms of an expressive generalization of classical noninterference, proved using a general method that subsumes both security-label proofs and information-hiding proofs, and propagated across layers of abstraction using a special kind of simulation that is guaranteed to preserve security. Second, to demonstrate the effectiveness of the new methodology, the PI will build an actual end-to-end security proof, fully formalized and machine-checked in the Coq proof assistant, of a nontrivial concurrent operating system kernel. Third, the PI will also demonstrate the generality and extensibility of the methodology by extending the kernel with a virtualized time feature allowing user processes to time their own executions. The goal is to prove that user processes cannot exploit virtualized time as an information channel. The technology for building certified secure system software will dramatically improve the reliability and security of many key components in the world's critical infrastructure. It will advance human knowledge in the specification and understanding of software and catalyze a cultural change in U.S. universities by pushing new courses on formal methods into the existing cybersecurity curriculum.
Advances in computing and manufacturing have led to rapid developments in autonomous robots. For sophisticated tasks such as search and rescue, it is often critical to integrate human knowledge and perception skills with the capabilities offered by robots. Taking underwater search and rescue as a motivating context, this project focuses on developing a principled design framework for optimizing the performance of a mixed human-robot team comprised of multiple human operators and heterogeneous robots. By enabling efficient and reliable human-robot interactions, this work will facilitate the use of robots in hazard response, environmental monitoring, mobility of goods and humans, healthcare, manufacturing, and many other applications of societal impact. The project will provide training opportunities for graduate and undergrad students, including those from underrepresented groups. It will also provide research training to high school students and K-12 teachers. An open-source robotic fish educational kit and demos of EEG-mediated human-robot interactions will be developed to pique the interest of K-12 students in science and engineering. The project will further produce an underwater robotics testbed available for use by the broader robotics and control community.<br><br>This research will develop a generalizable framework for rigorous and systematic design of autonomy supervised by a team of interacting human operators, which will enable the leveraging of human operators' adaptivity in complex scenarios while mitigating performance deterioration due to loss of situational awareness. The framework will consist of two tightly coupled modules. The first module will involve optimal task allocation and scheduling for event-triggered human team supervision, which will be formulated as a semi-Markov decision process (SMDP) for a complex queueing network capturing task processing by a team of human operators with different skill sets. Human cognitive dynamics will be incorporated via practical models, and efficient algorithms for solving the SMDP are examined while uncertainties introduced by stochasticity in cognitive processes and variability among human operators are accommodated. The second module of the framework will deal with informative path planning for autonomous robots that optimally balances the explore-exploit trade-off in their search for targets of interest, by solving a multi-armed bandit problem that incorporates mobility constraints of the robots. The framework will be experimentally evaluated in field trials emulating underwater search and rescue, which will involve a group of gliding robotic fish and remotely operated vehicles (ROVs), supervised by a team of two human operators.
Support for research on distributed data sets is challenged by stakeholder requirements limiting sharing. Researchers need early stage access to determine whether data sets are likely to contain the data they need. The Broker Leads project is developing privacy-enhancing technologies adapted to this discovery phase of data-driven research. Its approach is inspired by health information exchanges that are based on a broker system where data are held by healthcare providers and collected in distributed queries managed by the broker. Such systems have potential to support public health and biomedical research. The project targets "similar patient queries" where the query is a patient medical record and the response is information about similar patients. Such queries have value for many applications, including developing cohorts for finding institutions for further discussions about joint research.<br><br>Broker Leads uses the concept of a "lead" in which data holders provide representative collections of non-identifiable real or synthetic data meeting strong privacy guarantees, e.g., differential privacy. Even though such data may be unsuitable for clinical decision making and scientific discovery due to the transformations done for privacy protection, they guide a user of a broker lead system to the data sets very likely to be useful to addressing a given similar patient query. These data sets can then be used with other privacy-protecting strategies, such as secure multiparty computation or restrictive data use agreements ensuring adequate data protection. In addition to providing practical and well-analyzed strategies for early stages of research on healthcare data, this project will provide new insights into practical issues with privacy technology in end-to-end applications.
This research project develops ideas and designs that can be used to fingerprint or authenticate computer hardware, to generate cryptographic keys, or form basis of new security protocols, all leveraging the physical properties of the computer hardware. Especially, the focus of this research is on commodity memories found in today's computers, and the work advances fundamental understanding of how the physical properties of memories can be used in computer security. By focusing on hardware already present in commodity computing devices, the ideas developed in this research can be readily deployed. Through development of professional and educational activities, and interaction with international colleagues, this project also supports dissemination of research ideas to a broad audience.<br><br>To advance the hardware security research field, this research project explores the cell decay effects in Dynamic Random Access Memories (DRAMs) and applies them to the design of DRAM-based Physically Unclonable Functions (PUFs), as well as to development of new virtual proofs of reality and Physical Cryptography primitives, all based on commodity DRAMs. Through design of a manual refresh approach, this research shows how the DRAM's properties can be measured even if DRAM is part of a commodity computer system and actively used by software. Environmental impacts on DRAM are also evaluated and understanding is developed of how the environment affects DRAM-based security primitives. In addition, this research tackles challenges such as theoretical and mathematical issues of developing error correction schemes for use with DRAM PUFs, or practical issues of accelerating DRAM PUF readout time.
Two methods used for vulnerability discovery in network protocols are testing and a semi-automated technique called model checking. Testing and model checking implementations of network protocols is a tedious and time-consuming task, where significant manual effort goes into designing test cases and protocol property specifications. Both approaches require detailed and structured information about the tested protocols, in the form of messages, state machine, invariants, etc. Most of the time this information is derived manually by people with different levels of expertise. The process can be made more effective and less expensive by leveraging documentation and specification about these protocols and available in text format. Automatically analyzing the information available in documentations in the form of textual specification will open new avenues not only for improving vulnerability finding for network protocols, but for software design in general. <br><br>This project combines expertise from natural language processing and network security to create and build a framework for vulnerability discovery in network protocols, by leveraging semantic interpretation of textual specification, automated attack generation and injection, and property model checking for software implementations. The framework consists of two phases, a knowledge building phase and a vulnerability finding phase. In the knowledge building phase, semantic interpretation natural language processing techniques is applied to structured text (protocol specifications and documentation) and unstructured text (blogs, forums, and bug reports) to learn structured information about protocols such as: message formats, protocol state machine, constraints, etc. In the second phase, the information learned in the knowledge phase is applied to two mechanisms for vulnerability finding, the first uses the structured protocol information to create and inject attacks, and the second uses the same information to derive protocol requirements and use them to model check finite state machines extracted from protocol implementations.
Many networking protocols have been designed without security in mind, and many cryptographic schemes have been designed without practical deployments in mind. Moreover, most of security-enhanced communication protocols still lack the provable-security treatment and hence the security guarantees. This project aims at bridging the gap between protocol design, implementation, deployment, and security guarantees by developing a novel general security framework that facilitates the provable-security analyses of practical networking protocols. <br><br>The project has an interdisciplinary approach as it combines concepts from applied cryptography and algorithms with implementation and empirical analyses to provide a unifying framework for studying and developing secure communication protocols. This joint design effort yields both new cryptographic foundations and fundamentally secure networking protocols.
Cybersecurity has become a significant issue that presents new challenges to individuals, industry, and government. To help deal with complex cybersecurity challenges, the international Intelligence and Security Informatics (ISI) community has published high-impact, Big Data driven cybersecurity research since 2003. Despite the many novel advances in data-driven cybersecurity research, there is no sharing platform that aggregates and provides data and tools used and developed in cybersecurity research for the larger cybersecurity community. The proposed project aims to fill this gap by developing the Cybersecurity Big Data and Analytics Sharing Platform to encourage cybersecurity researchers to share their data, tools, and analytical approaches. In addition, the project will support two Security Big Data and Analytics Sharing Workshops to engage the community in the platform development. Upon project completion, the platform will be open for access by the broad cybersecurity research and education community.<br><br>The proposed data sharing platform would enable the publication of high-impact, reproducible, and cutting edge research to advance scientific discoveries. Such a platform would also enhance the educational experience for cybersecurity students, specifically CyberCorps SFS students as they prepare to enter the cybersecurity workforce. The proposed project will provide value to both cybersecurity researchers and students by providing data for cutting-edge research and enhanced educational experiences. In addition, this project will also have significant value to government agencies and other organizations interested in developing cyber threat intelligence knowledge. The project team will consist of leading scholars in Big Data Security.
As society becomes more dependent on cyber infrastructure, the security of networks and information technologies has become a growing concern. Individuals, businesses, and governmental organizations are now common victims of cyber-attacks that seek to steal private data, gain remote control over remote systems, and cause harm to networks and systems through other malicious means. Additionally, critical infrastructures such as smart power grids and communication networks are facing an increasing number of cyber-based threats. As a result, many researchers and security practitioners have begun to investigate cyber attacker communities in order to learn more about cyber attacker behaviors, emerging threats, and the cybercriminal supply chain. Unfortunately, there is a lack of established science for cyber security research. The lack of literature is problematic for researchers wanting to learn more so that they may contribute to and advance the current state of cyber security research. For example, many cyber attacker communities take careful measures to hide themselves by employing anti-crawling measures. This would be a challenge for many researchers and security practitioners. Furthermore, some may find cyber attacker community discussion difficult to interpret due to cyber attacker jargon, advanced security concepts, or foreign contents belonging to cyber attacker groups spanning across different countries or regions.<br><br>For these reasons, research studying hacker communities is greatly needed, as well as research that advances others? capacity to understand and investigate contents from such communities. Specifically, the development of automated tools and analyses increases the potential for more cyber security research. Web mining and machine learning technologies can be used in tandem with social science methodologies to help answer many questions related to hacker behaviors and culture, illegal markets and covert networks, cybercriminal supply chain, malware analysis, emerging security threats, and other matters. There are many opportunities for extending current cyber security research by combining hacker community data with social science methodologies, computational techniques, and security analysis. <br> <br>In this research, important questions about hacker behaviors, markets, community structure, community contents, artifacts, and cultural differences are explored. Automated techniques to collect and analyze data from forums, Internet Relay Chat, and honeypots will be developed. The development of such tools will help further proactive approaches for preventing cyber-based threats, rather than taking the traditional approach of reacting when something "bad" happens. Better understanding of hacker communities across multiple geopolitical regions will support a better understanding of cybercriminal behavior, and improved and safer practices for security researchers and practitioners.<br><br>The proposed integrated computational framework and the resulting algorithms and software will also allow social science researchers and security practitioners to closely examine how cyber attacker groups form, develop, and spread their ideas; identify important and influential cyber criminals in the online world; and develop the means to recognize online hacker identities through their communication and interaction styles. Knowing more about cyber criminals, hackers, and their illegal black markets can help policy makers and security professionals make better decisions about how to prevent or respond to attacks. <br><br>The proposed work also contributes to the educational and professional development of the student research associates who contribute to it. They will learn sound research methods, and how to write about and present their work for scientific and other professional audiences.
This research seeks to develop the science of blockchains. A blockchain is a distributed append-only database containing cryptographically linked records. The technology is the basis of cryptocurrencies (e.g., bitcoin). Principled methods for analyzing blockchain data will be developed in order to answer key questions about the economics, security, privacy, and anonymity of cryptocurrencies. The project envisions blockchains as the pillar of a new breed of decentralized applications and Internet security mechanisms. The project will develop a new open-source blockchain analysis tool, BlockSci, and use it to answer research questions including: How should we model cryptocurrency participants? How well do decentralized markets work, and how do they fail? How private are cryptocurrencies in practice? Can blockchains serve as the foundation for a secure, decentralized Internet? The research outputs of the project will be integrated into Princeton's Massive Online Open Course on cryptocurrencies, student projects, and a new course on the economics of security. The project will inform the cryptocurrency industry and developer community through conferences and release of open-source software.<br><br>This project will combine computer science research on cryptocurrencies with cutting-edge techniques from game theory and mechanism design. The project could validate the applicability of powerful machine learning methods, including spectral graph analysis, to the rich data in blockchains. The system design and deployment component will contribute to important ongoing debates on the different approaches to scaling of big data analytics techniques. The PI will continue his engagement with policy makers and regulators to ensure that government agencies are informed by the results of this project.
Cyber-Physical Systems (CPS) encompass a large variety of systems including for example future energy systems (e.g. smart grid), homeland security and emergency response, smart medical technologies, smart cars and air transportation. One of the most important challenges in the design and deployment of Cyber-Physical Systems is how to formally guarantee that they are amenable to effective human control. This is a challenging problem not only because of the operational changes and increasing complexity of future CPS but also because of the nonlinear nature of the human-CPS system under realistic assumptions. Current state of the art has in general produced simplified models and has not fully considered realistic assumptions about system and environmental constraints or human cognitive abilities and limitations. To overcome current state of the art limitations, our overall research goal is to develop a theoretical framework for complex human-CPS that enables formal analysis and verification to ensure stability of the overall system operation as well as avoidance of unsafe operating states. To analyze a human-CPS involving a human operator(s) with bounded rationality three key questions are identified: (a) Are the inputs available to the operator sufficient to generate desirable behaviors for the CPS? (b) If so, how easy is it for the operator with her cognitive limitations to drive the system towards a desired behavior? (c) How can areas of poor system performance and determine appropriate mitigations be formally identified? The overall technical approach will be to (a) develop and appropriately leverage general cognitive models that incorporate human limitations and capabilities, (b) develop methods to abstract cognitive models to yield tractable analytical human models (c) develop innovative techniques to design the abstract interface between the human and underlying system to reflect mutual constraints, and (d) extend current state-of-the-art reachability and verification algorithms for analysis of abstract interfaces, iin which one of the systems in the feedback loop (i.e., the user) is mostly unknown, uncertain, highly variable or poorly modeled.<br><br>The research will provide contributions with broad significance in the following areas: (1) fundamental principles and algorithms that would serve as a foundation for provably safe robust hybrid control systems for mixed human-CPS (2) methods for the development of analytical human models that incorporate cognitive abilities and limitations and their consequences in human control of CPS, (3) validated techniques for interface design that enables effective human situation awareness through an interface that ensures minimum information necessary for the human to safely control the CPS, (4) new reachability analysis techniques that are scalable and allow rapid determination of different levels of system safety. The research will help to identify problems (such as automation surprises, inadequate or excessive information contained in the user interface) in safety critical, high-risk, or expensive CPS before they are built, tested and deployed. The research will provide the formal foundations for understanding and developing human-CPS and will have a broad range of applications in the domains of healthcare, energy, air traffic control, transportation systems, homeland security and large-scale emergency response. The research will contribute to the advancement of under-represented students in STEM fields through educational innovation and outreach. The code, benchmarks and data will be released via the project website.<br><br>Formal descriptions of models of human cognition are in general incompatible with formal models of the Cyber Physical System (CPS) the human operator(s) control. Therefore, it is difficult to determine in a rigorous way whether a CPS controlled by a human operator will be safe or stable and under which circumstances. The objective of this research is to develop an analytic framework of human-CPS systems that encompasses engineering compatible formal models of the human operator that preserve the basic architectural features of human cognition. In this project the team will develop methodologies for building such models as well as techniques for formal verification of the human-CPS system so that performance guarantees can be provided. They will validate models in a variety of domains ranging from air traffic control to large scale emergency response to the administration of anesthesia.
Monitoring and understanding aquatic environments is critical to water sustainability. The goal of this award is to establish a theoretical framework and provide an enabling technology for robust underwater collaborative sensing with small, inexpensive robots. Inspired by the source-seeking behavior of live fish, computationally efficient algorithms are developed for cooperative tracing of the gradients of environmental fields, and their robustness is analyzed in the presence of localization error and changing communication topology. The algorithms are experimentally validated in thermal source seeking and tracing with a group of energy-efficient and highly maneuverable gliding robotic fish, which are enhanced in this project with optical communication and localization capabilities. Advanced controllers are developed for these robots to realize three-dimensional maneuvering and to track reference paths planned through collaborative sensing algorithms. This award offers fundamental understanding of limits and robustness properties of collaborative sensing by resource-limited robots, and contributes to the knowledge base in underwater communication and ranging for small robots. It enables technological advances for persistent sampling of versatile aquatic environments including coastal waters, lakes, and rivers, with a myriad of applications such as oil spill response, ecological monitoring, and port and drinking water security. The findings from this project are disseminated through publications, software sharing, and technology commercialization. The project provides interdisciplinary training opportunities for students, including those from underrepresented groups. Outreach activities, including museum/aquarium exhibits and teacher training, are developed to pique the interest of K-12 students, teachers, and the public in science and engineering.
This project investigates how to apply big-data analysis techniques to analyze mobile apps for the Android platform, for the purpose of accurately identifying security problems therein. A major challenge is the scale of the problem, with thousands of new apps entering the online app markets on a daily basis. Current technologies cannot keep up with the pace of the threats, and malware are regularly found in both large-scale marketplaces such as the official Google Play market and in third-party markets. The project adopts a number of advanced machine learning and data mining techniques to tackle those challenges. The large number of apps in the markets allows an automated machine learning algorithm to better capture security-related patterns and trends in the data, so that it can predict with good accuracy which apps may have security problems. Those apps are worth the more in-depth and expensive analysis that usually requires significant human effort. This creates an effective triage to deal with the scale challenge, and can be used by industry to scale the security vetting process of mobile apps. Artifacts produced from the research are released in open source and benefit practitioners. New courses on mobile apps and their security are developed. Undergraduate students are involved in this research. Underrepresented groups, including female students, also participate in the research. The materials developed from the research are used to further enrich cybersecurity education opportunities in the PIs' multiple outreach platforms in their institutions, to enable a large student body to benefit from the project.<br><br><br>The project designs solutions to tackle the unique challenges in applying machine learning for mobile app security analysis, most of which are due to the big data nature of the problem. A key scientific challenge faced in mobile app security analysis is the difficulty in obtaining high-quality ground truth. Many times one has to rely upon imperfect data in training and evaluation. The research experiments with a number of approaches to deal with the noise due to the imperfect labels, including semi-supervised learning algorithms, which can learn from small amounts of labeled data, or even from positive data only, together with unlabeled data. The project also explores a novel approach that uses social media information to acquire additional information to improve the ground truth and/or the prediction accuracy.
Security protocols enable useful tasks over untrusted networks. For example, confidential communication over the Internet between users and Web services like Google, Facebook, Amazon and Bank of America rely on protocols like SSL/TLS and the supporting Public Key Infrastructure (PKI). These protocols are designed to provide global security properties like authentication and confidentiality when various parties (e.g., the user, the Web service, and participants in the PKI such as certificate authorities) execute their prescribed programs. However, when individual parties deviate from their prescribed programs and the global security property is violated, it is important to hold agents accountable by detecting deviant behavior and determining which deviations actually caused the violation. Such determinations are useful in a wide range of distributed security settings, including in protocols for authentication and key exchange, electronic voting, and online auctions. <br><br>This project develops logic and language-based methods for deviance and causal determination in distributed systems. The project addresses the following scientifically challenging tasks: (1) Developing a language for distributed computing in which prescribed behavior of agents are represented with contracts. The contracts are specified via types and a type-directed distributed monitoring infrastructure is designed to detect deviance from contracts. The technical approach is based on novel dependent and stateful session types to express and verify security-relevant properties of systems. (2) Developing a formal blame semantics for distributed systems that is extensional (protocol- or system-independent). Recognizing that some deviations may not affect the security property, the blame semantics combines deviance from contracts with a novel definition of programs as actual causes of global security properties. The formalization of actual causation in this setting, while inspired by counterfactual theories of actual causation in philosophy and in computer science, goes beyond those theories by dealing with interacting distributed programs with nondeterministic operational semantics. (3) Applications of these methods to conduct a comprehensive study of proposed protocols for augmenting accountability in the public key infrastructure. <br><br>The project has potential for significant broader impact on society. Recent results have exposed the fragility of the Public Key Infrastructure on which hundreds of millions of people around the world rely to protect their communication over the Internet. A systematic basis for design, analysis, and comparison of protocols that improve accountability of the PKI can help protect Internet users from malicious adversaries who seek to snoop on their communications. The project also provides extensive training and educational opportunities for undergraduate and graduate students at Carnegie Mellon University.
The objective of this project is to strengthen the Transmission Control Protocol (TCP), a ubiquitous core Internet protocol, under emerging threat models to make it robust and secure enough to serve the needs of 'smart' technologies in communications, automobiles, medical devices, and other devices that touch our lives every day. It is terrifying to imagine that a smart car could fail to report an accident automatically due to a denial of service attack on its TCP connections, or a smart medical device could fail to report a patient's change in condition. This is not to mention the ever growing cyber attacks that leverage the global and powerful Internet. This project will systematically analyze the root causes of recent security vulnerabilities and generalize them. The results will offer valuable insights on how to avoid the problems. Further, the research is expected to lead to changes to the TCP implementations in major operating systems.<br><br>Specifically, the research is motivated by the following observations. First, more subtle problems such as side channels have been overlooked in TCP stacks. Second, new threat models have merged, e.g., co-located entities that do not trust each other. Third, the end-to-end assumption of TCP is broken due to the prevalence of network middleboxes, host-based firewalls, and censorship firewalls. The research will leverage model checking to systematically search for vulnerabilities under a variety of threat models and network settings. The models will be constructed from popular operating systems (with recent and representative versions) as well as network middleboxes. They can serve as the basis for testing and verifying future TCP stack implementations.
Fundamental research in quantum information performed since the 1980s shows that the principles of quantum mechanics can lead to dramatic computational and cryptographic consequences, from exponentially faster algorithms to unbreakable cryptosystems. The first practical quantum devices, from single-photon receptors used in quantum cryptography to large-scale quantum optimizers, are now being actively developed. These stunning experimental advances raise a very practical challenge: how can classical users establish and maintain a trusted interaction with a priori unknown and untrusted quantum devices?<br><br>This project aims to address the many aspects of this question, from the development of novel secure cryptographic protocols to the study of the fundamental consequences of quantum mechanical devices for the theory of computation. Research in this direction is essential for the establishment of a secure quantum network of trusted interactions. Making progress will require a combination of insights from computer science, physics, and mathematics. By nature the project is highly interdisciplinary, and the PI will put substantial effort into disseminating the ideas that support, and arise from, the research. This includes making best use of the possibilities for communication through the internet (including online seminars and courses) and encouraging, via outreach and teaching, the emergence of a generation of researchers equipped to address the upcoming challenges posed by the interaction of physics and information technologies.<br><br>Research by the PI on this project will build upon recent striking developments in cryptography and complexity theory, including the framework of device-independence and the theory of quantum multi-prover interactive proof systems. Recent works in these areas have identified a key property of quantum entanglement, the monogamy of entanglement, which places very strong constraints on quantum mechanical systems. The PI will develop techniques that leverage entanglement and its monogamy in order to enable testing and secure interactions between classical users and quantum devices. The insights gained in the process will find applications beyond the framework of the project to the many areas of physics in which entanglement plays a role, from the theory of superconductors to that of black holes.
Online advertising plays a critical role in allowing a vast majority of web content to be offered free of charge to users, with the implicit quid pro quo agreement that users agree to watch targeted ads to support these "free" services. Unfortunately, the economic magnetism of online advertising has made it an attractive target for various types of abuses. For instance, online advertising incentivizes the widespread tracking of users across websites raising privacy and surveillance concerns. Malvertising is another serious security threat to users. As a result, ad-blockers are gaining popularity because they not only provide a clean browsing experience but also protect user security and privacy.<br> <br>The research is motivated by the observation that websites are now starting an arms race to fight against ad-blockers that cause significant revenue loss to the publishers. Publishers use anti ad-blockers to detect the presence of ad-blockers and react in certain ways (e.g., reminding users to turn off ad-blockers). Specifically, the research will be primarily focused on two fronts: (1) Measuring the arms race between ad-blockers and anti ad-blockers, e.g., developing techniques to detect anti ad-blockers. (2) Understanding the technological means of anti ad-blockers and possible countermeasures that may follow on the ad-blocker side. The proposed research will inform industry stakeholders and policymakers.
The objective of this project is to improve the security of a wide range of network protocols that the Internet relies on. Unfortunately, the Internet has been evolving at a rapid rate but its initial design did not take security into consideration. In practice, this leads to a never-ending stream of network attacks that are continuously being discovered. The defenders are forced into a reactive position to these new and creative attacks, without having the necessary tools to understand and anticipate them. The proposed project aims to identify and analyze protocol flaws proactively and stay ahead of attackers. In particular, the project will develop a set of innovative and timely techniques, tools, and insights that will empower developers and researchers to analyze network protocols, identify their weaknesses, and correct them early on. The results will benefit all Internet users by providing a more secure network environment overall. <br><br>Specifically, the research is motivated by the following observations. First, emerging threats such as side channels have been largely overlooked in network protocols. Second, network attacks are getting more sophisticated, with new threat models such as cooperating local and remote attackers. Third, the network protocols and their interactions with the environment are getting more complex, especially when considering the prevalence of network middleboxes, host-based firewalls, and censorship firewalls, etc. The research will develop a combination of program analysis and network measurement techniques to systematically uncover vulnerabilities in a variety of network protocols. The insights gained from the project will enable better and more secure design and implementation of protocols.
Touch screens on smart mobile devices such as cell phones or tablets allow both user input (touch events) and display output. For a touch screen to function, the mobile device stores input and display data in a graphics buffer internal to the device. The researchers have discovered that a malicious application running on the mobile device could silently monitor characteristics of the graphics buffer to identify the alphanumeric characters that the user types into the touch keyboard or information displayed on the screen. The malicious application could then send that information to a third party, violating the confidentiality of the user's input or output. This project is assessing the feasibility of attacks on the graphics buffer and studying characteristics of graphics buffer vulnerabilities. The researchers are developing software- and hardware-based defenses to mitigate such vulnerabilities.<br><br>The researchers are studying attacks that use a CPU cache-based side channel, a technique for deriving the access pattern of a process from another process, to identify which locations on the screen are being modified, allowing the attacker to gain information about user I/O activity such as data being typed on a keyboard. Prior work on cache-based side channel attacks and defenses has focused on cryptographic algorithms where the critical data has a small memory footprint, and is read-only. In contrast, graphics buffers are extremely large (on the order of MBytes), and are both read and written to, requiring new approaches for attacks and defenses. The project is studying how such attacks might be generalized, as well as the extent of feasible resolution and precision. Finally, the researchers are designing countermeasures, considering security, performance overhead, complexity, and impact on the core process pipeline and caches.
The objective of this project is to understand and strengthen the security of Multipath TCP (MPTCP) - an IETF standardized suite of TCP extensions that allow one MPTCP connection, consisting of multiple sub-connections between two hosts, to use multiple paths simultaneously. Even though MPTCP has been gaining momentum in being widely deployed, its security is yet to be well understood. The project is expected to raise awareness of MPTCP security and ultimately yield a foundation for MPTCP security. The study will further increase the acceptance of MPTCP as an efficient, trustworthy, and next-generation transport layer protocol, especially considering that the deployment of new protocols can always be hindered by security concerns. The results will lead to development of guidelines and specifications for MPTCP through standards organizations such as IETF.<br><br>This project aims to gain an in-depth understanding of the implicit interaction among sub-connections within an MPTCP connection, the information that can be leaked or inferred through side channels by eavesdropping such interaction, and the potential attacks on MPTCP by exploiting such leaked or inferred information. The key insight is that the current MPTCP design inherently allows an attacker eavesdropping on one path to learn information (e.g., throughput) about the sub-connections along other paths. Such seemingly benign information leakage allows an attacker to hijack the entire MPTCP connection. This project considers three general threat models: on-path only attacker, host-assisted off-path attacker, and host-assisted on-path attacker. Based on these threat models, the PIs propose to study traffic offloading/onloading and sequence number inference attacks. The PIs also plan to design and validate countermeasures and defense mechanisms for MPTCP against such threats.
This project is funded as part of the United States-Israel Collaboration in Computer Science (USICCS) program. Through this program, NSF and the United States - Israel Binational Science Foundation (BSF) jointly support collaborations among US-based researchers and Israel-based researchers. The availability of fast and cheap computers coupled with massive storage devices has enabled the collection and mining of data on a scale previously unimaginable. This opens the door to potential abuse regarding individuals' information. This work explores the fundamental tradeoffs between privacy for individuals' data and the usefulness of the information one can obtain from these large datasets.<br><br>Differential privacy is a well-established paradigm aimed at mitigating the drawbacks of traditional anonymization techniques, as it provides a rigorous guarantee for the added risk to an individual in participating in a database. This research addresses fundamental questions clarifying the boundaries of what is possible under differential privacy and its relaxations, by exploring the fundamental conflicts between privacy and utility and the additional tensions introduced by computational efficiency. This work expands the potential impact of differentially private algorithms on real-world applications, and also ensures broad impact via curriculum development, pedagogical development, and outreach activities.
Attributed-based obligatory access control is a new access control paradigm for achieving fine-grained authorization and assured system accountability. However, access control and obligation policies can be implemented incorrectly for various reasons, such as programming errors and misunderstanding about the policies. It is important to reveal discrepancy between the policy specification and the actual system implementation. The objective of this ?Transition To Practice? project is to develop an open source tool for model-based testing of attribute-based access control and obligation policies. It can build test models by integrating attribute-based access control and obligation rules with functional test models, generate test cases from the test models to meet given coverage criteria, and transform model-level test cases into executable code in a target language and test execution environment. The test code can then be executed with the system under test to exercise the access control and obligation policies. The tool is applicable to a great variety of systems due to the support for various programming languages and test execution environments. It is independent of how access control and obligation policies are implemented in the system under test. The broader impacts of this project include deployment of the tool to various academic and industry projects and involvement of students, particularly undergraduate students, in cutting-edge research.
Mobile devices, including smartphones and tablets, are becoming extremely prevalent nowadays. Equipped with diverse sensors, from GPS to camera, and paired with the inherent mobility of their owners, mobile devices are capable of acquiring rich information of surrounding environment. However, the wide adoption of mobile crowd sensing is largely hindered by its privacy concerns. To facilitate the functionality of each stage of mobile crowd sensing, including sensing task allocation, sensing data collection, and result aggregation, sensing devices report their location information, sensing capabilities, task preferences, and sensing results to servers that will potentially disclose their daily routings, behavior patterns and even identities. With these concerns, the overall goal of this project is to address privacy leakage issues from different stages of mobile crowd sensing. Privacy-enhanced mobile crowd sensing will attract more participants and thus accelerate the maturity of smart health care, environment monitoring, traffic surveillance, social event observation, etc. In addition, this project will also serve as a training ground for educating future decision-makers and workforce on theory and tools. <br><br>The PIs plan to develop effective and efficient privacy preservation schemes for different stages of mobile crowd sensing. It corresponds to three closely intertwined research thrusts. Thrust I explores protecting user's sensitive information, such as locations, sensing capabilities and task preferences, from the server, while still allowing it to optimally or approximately solve task allocation problems. Rather than highly computationally-intensive crypto-based techniques, privacy preservation schemes will be designed based on decomposition methods and distributed computing algorithms. Thrust II aims to provide user's location privacy in the stage of data collection. Since locations of users, who perform sensing over the same event within a certain geographic area, are highly correlated, it deteriorates user's privacy achieved individually. To address this issue, privacy preservation schemes will be developed by exploring collaborations among users. Game theories will be adopted to further analyze users' strategies and interactions. The objective of Thrust III is to protect users' sensing data privacy during the stage of data analysis. The research is featured by jointly considering the data imperfection that is caused by the limited sensing capabilities at mobile devices and even the misbehavior of lazy/malicious users. To achieve data privacy and service accuracy simultaneously, novel schemes will be developed combining efficient matrix completion methods and advanced crypto techniques.
This project will develop a software assurance education artifact repository, designed for use across numerous computer science programs and institutions. The repository will help students to obtain a firm understanding of the software assurance process and necessary skills to develop highly assured software. The team will also create instructional materials for effective software artifact use.<br><br>The project transitions recent software assurance research to education domain including highly effective techniques for finding security defects. Artifacts will represent typical interdependent software assurance activity results in areas such as security requirements analysis, access control policy analysis, threat modeling and verification, and security testing and assessment. Specifically, the proposed repository will include seven types of software artifacts for several carefully selected and widely used open source security-critical software applications: security requirement specifications, security policies, threat models, security test models, security test cases, vulnerability models, and security mutants. <br><br>The proposed efforts will help with a critical shortage of software assurance workforce and will also raise software security awareness among a broad audience by introducing the topic to high school computer teachers. This will be done in collaboration with an NSF CS10K project preparing 30-40 high school teachers to teach Computer Science Principles courses at regional high schools. The project will collaborate with Florida A&M, Monmouth University and Gannon University. The project will develop a web application enabling public access to artifacts and instructional materials.
The Secure and Trustworthy Cyberspace (SaTC) program is NSF's flagship cybersecurity research program. With the increasing importance of cybersecurity to the nation as a whole, and to the Foundation as a research area, improving communication between program officers and researchers supported by NSF and other government funding agencies, coordination among PIs from the different perspectives sponsored by SaTC, and outreach to the broader community is increasingly important.<br><br>The SaTC program provides national visibility with the participation of the NSF Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), Mathematics and Physical Sciences (MPS), and Social, Behavioral, and Economics Sciences (SBE). There are currently over 800 active awards in the program. The PI meeting will be a large, major event for the Foundation and the community, bringing together PIs with government and industry representatives. For this event there is a pressing need to meticulously plan and organize the technical program, the venue and conference logistics. This grant provides funding for the venue and conference logistics, including conference registration, audio visual, and meeting space.
Access control policies specify which users may perform which actions on which resources within which environments. Defective policies may have serious impacts, allowing unintended access (e.g., bank account withdrawals by a stranger) or preventing critical legitimate access (e.g., a doctor cannot view her patient's x-ray). As computer systems become more complex, policy defects have become more common. However, existing testing methods for detecting faults in access control policies have not been very successful and there is no explanation for why they are unable to detect a majority of faults. This project is investigating the inherent strengths, limitations, and cost-effectiveness of existing testing methods for access control policies. The results of this project will provide essential guidelines for planning testing efforts and selecting appropriate testing methods.<br><br>The project focuses on access control policies expressed in the XACML language. The project is formalizing fault detection conditions that test cases must satisfy in order to detect specific types of access control faults. These conditions consist of reachability constraints, necessity constraints, and propagation constraints of various faults in XACML policies. They are used to determine the fault detection ability of a given testing method by evaluating whether or not its test cases satisfy the fault detection conditions. Based on the collective fault detection conditions of fault groups, the project is developing a method for generating optimal test suites using an efficient constraint solver. The optimal test suites are used to quantitatively measure cost-effectiveness levels of other testing methods in terms of the ratio between the number of faults detected (i.e., effectiveness) and the size of test suite generated (i.e., cost). Thus, the project is a study of benchmarking testing methods for access control policies.
To tackle the ever-increasing spectrum scarcity issue, dynamic spectrum access is envisioned as a set of promising new spectrum management paradigms. Although it has enabled the opportunistic access of underutilized licensed bands, various practical factors, such as environmental dynamics, intentional interference, and unauthorized transmission, hinder it from wide deployment. The recently released FCC rules suggest participatory real-time spectrum sensing can greatly improve the spectrum utilization efficiency for database-driven spectrum sharing, which forms a new paradigm, hybrid dynamic spectrum sharing. However, the frequent information exchanged between secondary users and spectrum database can be easily intercepted and manipulated by malicious users, which not only downgrades the spectrum efficiency but also incurs severe security breaches to the hybrid dynamic spectrum access system. This project will explore new paradigms of safeguarding the future cognitive radio system with focus on non-compliance behavior detection. The success of this project will serve as a key enabler to provide reliable wireless communication in the near future.<br><br>This project will investigate several fundamental security challenges in the newly defined hybrid dynamic spectrum access. This first research task will identify new attack models that compromise the spectrum efficiency and then provide countermeasures adapted to future wireless systems. Due to the inherent nature of database-driven spectrum access, primary user emulation (PUE) attackers can retrieve the spectrum availability information to either perform as the incumbent user (IU) when it is not present, or try to increase secondary users' transmission power to interfere with present IUs. Featuring the sensing results stored in the database, novel detection schemes will be designed to mitigate the influence brought by the attack. The second research task leverages physical-layer approaches to detect unauthorized access under different channel models. To address this issue, channel availability information will be used to detect malicious secondary users. Meanwhile, the detection mechanisms will be developed with joint consideration on practicality and efficiency. Additionally, the project includes strong validation component that combines simulation study, prototyping, and experimentation. It will thus provide an effective training ground for interdisciplinary subjects including wireless networks, wireless communication, and cybersecurity, all of which are critical to diversified professionals for future national work force.
This workshop is to foster discussions among the leading researchers toward a roadmap for foundational research in cybersecurity and cyberspace over the next ten years with a broad perspective, taking into consideration relevant science, technology, and policy issues, and with an emphasis on the social sciences and education. The previous ten years has seen cyberspace become ubiquitous and essential for modern life. It has also seen the emergence of a criminal cyber-underground and exfiltration of corporate and personal information on a massive scale. The next ten years will likely see equally dramatic change too. <br><br>This proposal is for support of this workshop, for travel, and for post-workshop report preparation and publication.
The primary goal of this project is to connect the ecosystem of disparate community practitioners and researchers within the growing, cross-disciplinary field of Secure and Trustworthy CyberSpace (SaTC) by conceptualizing, designing, building, hosting, and maintaining an open source website. This website will advance community building, education, and collaboration in the SaTC and related research and development (R&D) program areas. These services will be enabled via the provisioning of wide-ranging information repository and collaboration services made possible via a robust content management system. The rich assortment of SaTC historic, current, and future multi-disciplinary, multi-institutional, user-provided and administrator-collected content will be provisioned into a customizable, easy to use, searchable, and interactive online format. <br><br>The SaTC Community Forum will connect different science and engineering disciplines, R&D, and researchers and will provide robust data repositories, open collaboration services, and a rich set of virtual communication tools that currently do not exist under one roof. The SaTC Community Forum repositories could advance the state of SaTC knowledge and learning by advancing the collection and dissemination of educational materials to better prepare early career researchers; stimulate collaboration via the development of professional networks around shared resources of mutual interest; and advance the rapid publication of research findings, tools, and techniques for use by the broader SaTC research community, including industry, as a whole. These resources will be made available to users and visitors globally.
Attributed-based obligatory access control is a new access control paradigm for achieving fine-grained authorization and assured system accountability. However, access control and obligation policies can be implemented incorrectly for various reasons, such as programming errors and misunderstanding about the policies. It is important to reveal discrepancy between the policy specification and the actual system implementation. The objective of this ?Transition To Practice? project is to develop an open source tool for model-based testing of attribute-based access control and obligation policies. It can build test models by integrating attribute-based access control and obligation rules with functional test models, generate test cases from the test models to meet given coverage criteria, and transform model-level test cases into executable code in a target language and test execution environment. The test code can then be executed with the system under test to exercise the access control and obligation policies. The tool is applicable to a great variety of systems due to the support for various programming languages and test execution environments. It is independent of how access control and obligation policies are implemented in the system under test. The broader impacts of this project include deployment of the tool to various academic and industry projects and involvement of students, particularly undergraduate students, in cutting-edge research.
Cloud computing provides many clear benefits for users, including scalability and reduced system acquisition cost. However, data security, integrity and privacy are becoming major concerns for scientific researchers when they access data from the cloud to conduct experiments or analytics. In addition, data owners may not want to reveal their data to cloud service providers either because of the sensitivity of the data (e.g., medical records) or because of its value. Therefore, it is important to create cloud data integrity assurance and privacy protection solutions that help users fully embrace cloud services as well as protect cyberinfrastructure resources. With a cloud database, data owners can store large&#8208;scale datasets collected from various sources. Users can then launch queries retrieving the data records for conducting research and experiments. However, there are several possible threats to query result accuracy. For example, a cloud database could be compromised and the stored data could be tampered with. There could be a malfunction in the cloud server, so that the cloud database inadvertently returns incomplete query results. It is unlikely that the client would be aware of such incorrect or incomplete query results. Consequently, erroneous data could be employed in subsequent scientific experiments or analyses, which could lead to false results. Cloud database query integrity assurance is critical issue that underpins a secure and trustworthy end&#8208;to&#8208;end scientific workflow. <br><br>This work approaches these problems in a privacy&#8208;friendly manner, building on top of encrypted queries over encrypted data. This is key for achieving both data privacy and data integrity. Data provenance - the history of the data and how its been handled - is also an important aspect of scientific workflows. However, securing the provenance to provide integrity, privacy, and confidentiality guarantees is also challenging, making it hard for many scientific workflows to provide a verifiable provenance history of scientific data and query results. With clouds, providing such guarantees is difficult for both data and provenance. This project enables infrastructural support for secure collection, storage, transmission, and verification of provenance information for all data and results stored and computed in the cloud. The availability of such verifiable provenance offers benefits to scientific workflows, making the process more trustworthy via verifiable history and results. The research team creates a query integrity assurance, data privacy protection, and verifiable provenance framework which provides an array of solutions for supporting secure cloud services. This project contributes to the cybersecurity research community by piloting novel cloud data security approaches that accomplish the following goals: (1) developing Voronoi diagram&#8208;based integrity assurance techniques, (2) designing cloud database data privacy protection methods, (3) modeling the trade off between query integrity assurance and query evaluation costs, (4) realizing secure cloud data provenance mechanisms, and (5) implementing a prototype system, where all the components are integrated for security and performance evaluation.
Cryptography provides the basic tools to guarantee confidentiality and integrity of data. It hence plays a pivotal role in securing our digital infrastructure, and in enforcing the right for privacy of individuals. The development of secure cryptographic techniques is however difficult and error-prone, as unknown attack strategies need to be taken into account. To overcome this, modern cryptography advocates the paradigm of provable security, where threat models are precisely formalized using the language of mathematics, and the security of cryptosystems is proved within these models. This project aims to develop a better quantitative approach to provable security. The research of this project yields a better understanding of in-use cryptography, therefore contributing to the safer deployment of existing cryptographic solutions, as well as the support of future standardization processes. The educational component of this project includes the development of a comprehensive program to educate undergraduate students in the proper use of cryptography, and to use cryptography as a vehicle for outreach.<br> <br>This project develops better theory to prove rigorous lower bounds on the combination of time and memory needed by the attacker. This allows us to better compare cryptographic solutions, and to favor those which, for equal time resources, require the largest amount of memory in order to be compromised. Concretely, this project contributes along two different fronts. The first direction extends the theory of memory-hard functions, which are functions that are moderately hard to compute with respect to some combination of time and memory resources. This project introduces better hardness metrics as well as new security targets for memory-hard functions, and analyze new constructions. The second direction revisits the security of various schemes in symmetric cryptography, and provides lower bounds on the complexity of adversaries breaking them both in terms of time and memory storage, in the setting where some underlying component of scheme is modeled as ideal.
This project designs, develops, and applies a modular infrastructure for building web-based applications that allow individuals and organizations to benefit from privacy-preserving data aggregation and analysis in contexts where data sharing is encumbered by confidentiality concerns, legal restrictions, or corporate policies. Today, individuals and organizations face a tension between the explosion of valuable data that can be collected and processed and the threat of the exposure of data (which may be sensitive) due to malicious actors, criminal enterprises, and software errors. In response, entities often isolate their data, and in the process forego opportunities to benefit from collaborative data analysis. The infrastructure addresses these circumstances by allowing software developers, entrepreneurs, social scientists, and organizations to build web-based applications that leverage Secure Multi-Party Computation (MPC), a collection of cryptographic techniques that have been known for 35 years. In the last decade, MPC techniques have been implemented in several software frameworks, and specialized individual deployments of MPC include work on tax fraud detection, disease surveillance, and pay equity assessment. However, MPC's social benefits are only broadly realized when it is possible to design and assemble lightweight, user-friendly, web-based MPC applications that decision-makers and stakeholders without a cybersecurity background can understand and that the public and underserved populations can access and utilize. Software libraries, packages, and applications developed and evaluated over the course of this project will have tangible impacts on the ways in which sensitive data corpora can be used by multiple individuals, organizations, and policymakers to identify trends, diagnose problems, test hypotheses, and inform policy decisions.<br><br>This project lowers the barrier for the design, development, and deployment of MPC applications by delivering two types of open-source software: (1) libraries for building back-end frameworks and Application Programming Interfaces (APIs) that can support web-based MPC-enabling services and (2) front-end frameworks for developing client-side functionalities that can operate in a standard browser or on a standard mobile device. Collectively, this software infrastructure enables a diverse collection of MPC functionalities suitable for a variety of deployment scenarios and user roles. The effort selects, adapts, translates, refactors, optimizes, and encapsulates existing MPC algorithms and frameworks with a focus on two operational metrics: (1) enhancing accessibility and driving adoption of MPC, and (2) operating with minimal overhead in low-performance production environments. Three real-world use cases identified by early adopters of MPC technology will inform and ground the work: a pay equity analysis by the City of Boston and the Boston Women's Workforce Council, a mobile health intervention app for addiction recovery, and an effort to design a livelihood assessment of underserved populations based on data sets maintained by a variety of distinct organizations. All three test cases provide essential feedback that can direct efforts leading to successful delivery and utilization of MPC in practice by elucidating the suitability of existing MPC functionalities for such applications, the necessity for optimization or customization of such functionalities for individual scenarios, and the organization and decomposition of such functionalities around real-world participant roles and workflows.
The objective of this project is to revitalize cyber security education and research by introducing competitive aspects into their current lifecycles. The project will create and deploy light-weight, online and diverse Class Capture-The-Flag (CCTF) exercises on the DeterLab testbed. The competitions will require only modest preparation and students will engage in competitions remotely, at any time convenient for both teams. The competitions will cover a broad range of security topics, such as infrastructure threats and defenses, denial-of-service, botnet detection and infiltration, etc. Competitions will occur multiple times during a semester and will involve students from different institutions, alternating between an attacker and a defender role. To address ethical concerns about teaching students offensive technologies, the project will develop online materials on ethical offense, and will require each participant to view the materials and pass the related quiz before engaging in competitions. The project will also create a Security Challenge portal, where researchers can challenge others to break their research prototypes experimentally or by design analysis. The project team will further develop the Grand Challenge portal, hosting grand challenges in several security sub-fields. The initial grand challenges will be created by experts in selected sub-fields during virtual workshops. The Secure and Trustworthy Cyberspace (SaTC) program funds proposals that address Cybersecurity from a Trustworthy Computing Systems perspective; a Social, Behavioral and Economic Sciences perspective; and proposals focusing entirely on Cybersecurity Education.<br><br>The education modules developed to accompany the CCTFs will reach student audiences that would not otherwise receive security education. Researchers that engage in security challenges will benefit from having more sound solutions and stronger publications than they would otherwise. Grand challenges will engage multiple teams competing towards the common goal, galvanizing research on that specific class of problems. Further, security challenges and grand challenges will promote better security metrics, experiment methodologies and code and data sharing. This will improve the quality of security research, and the science of security experimentation. The educational modules that cover topics related to each CCTF exercise will enable participation by underprivileged and minority institutions that may not regularly teach a security class.
This award supports travel of graduate students to a multi-disciplinary workshop in 2017 with emphasis on topics related to cyber-security. The travel grant will enable career development and learning opportunities. Attending conferences is an important component of graduate school education for future computer security researchers. Students will have the opportunity to discuss leading edge research with world-class computer security researchers, and establish networks, connections, and mentoring relationships that will serve them well during their research careers. <br><br>The workshop the graduate students will attend is called the Secure Knowledge Management (SKM) workshop. This workshop deals with topics in machine learning, privacy, trust, risk, and social and economic aspects, and technology domains such as IoT, cloud computing and big data. The requested funds will be used to support student travel awards, and members of underrepresented groups will be especially encouraged to apply. Students will be exposed to the state of the art in cyber-security as presented by experts from both academia and industry. In addition, students will hear about internships and job openings, and have ample opportunity to discuss employment and collaboration with more senior members of the field. The results of the conference, and the awards made possible by sponsors will be made available to the research community.
With the emergence of a new generation of cognitive robots, the capability to communicate with these robots using natural language has become increasingly important. Verbal communication often involves the use of verbs, for example, to ask a robot to perform some tasks or to monitor some physical activities. Concrete action verbs often denote some change of state as a result of an action; for example, "slice a pizza" implies the state of the object pizza will be changed from one piece to several smaller pieces. The change of state can be perceived from the physical world through different sensors. Given a human utterance, if the robot can anticipate the potential change of the state signaled by the verbs, it can then actively sense the environment and better connect language with the perceived physical world such as who performs the action and what objects and locations are involved. This improved connection will benefit many applications relying on human-robot communication. Through a cognitive robot, this project will bring new educational experiences to K-12 students and encourage broader participation in engineering. <br> <br>This research project develops novel causality models for concrete action verbs to capture intended change of state of the physical world. It augments meanings of concrete verbs based on how they might change the environment (i.e., causality) and meanings of concrete nouns based on how they might be changed by actions (i.e., affordance). It incorporates causality models into learning and inference algorithms for grounding language to the physical world. This work will provide a new dimension to connect verb semantics to perception and action. Verb causality models will allow the robot to predict potential change of state from human linguistic utterances. This prediction will provide top-down information to guide visual processing and action modeling.
This project addresses how semiconductor designers can verify the correctness of ICs that they source from possibly untrusted fabricators. Existing solutions to this problem are either based on legal and contractual obligations, or use post-fabrication IC testing, both of which are unsatisfactory or unsound. As a sound alternative, this project designs and fabricates verifiable hardware: ICs that provide proofs of their correctness for every input-output computation they perform in the field. These proofs must be efficiently verifiable in less time and energy than it takes to re-execute the computation itself.<br><br>Building upon exciting recent theoretical and practical advances in verifiable outsourced computation for the cloud, this project develops new techniques that exploit the unique constraints and adversary models that relate to the verifiable hardware problem. In addition, the project also develops new practical approaches to the problem of general verifiable computation. As a broader impact, computing systems security is one of the greatest technological problems faced by society today. Verifiable hardware is an essential foundation for building future computing systems that are reliable and free from catastrophic security failures. The ultimate goal of this project is to make verifiable hardware practical and accessible for use in cryptographic and mission-critical hardware applications through open-source tools. The PIs are strongly committed to education and public outreach by producing widely-used course materials and taking active roles in outreach at minority-serving universities, community colleges, student organizations and high schools.
This award will support student travel to the 2016 IEEE Cyber Security Development Conference to be held in Boston in November 2016. The Cyber Security Development Conference (SecDev) provides a venue for presenting ideas, research and experience about the development of secure systems. SecDev is distinguished by its focus on how to "build security in". Its goal is to encourage and disseminate new ideas for secure system development among both academia and industry. <br><br>SecDev encourages students to consider "big" ideas that will lead to a stimulating, thoughtful, and perhaps (gently) provocative discussion. The support from NSF will be used to sponsor travel expenses for students to attend the conference. The training and development of students in this way will help to widen the talent pool of professionals and researchers focused on addressing challenges of developing critical secure systems and services. The proposed effort particularly encourages students from under-represented populations and institutions.
Outsourcing storage to the cloud has become more widespread in recent years; however, cloud storage services are constantly exposed to a number of non-trivial adversarial threats. This work addresses security risks arising from the leakage of access patterns, which is the ability of an adversary to detect when the same item is accessed repeatedly on a storage server, which has been shown to substantially impact data privacy. This project develops CloudORAM, the first provably-secure fully concurrent and asynchronous oblivious storage system that relies on simple tree-based Oblivious RAM (ORAM) techniques, the state-of-the-art cryptographic solution for hiding access patterns. <br><br>CloudORAM's system architecture uses a trusted proxy node processing concurrent accesses, from potentially multiple clients, to an untrusted server to hide access patterns. CloudORAM also outperforms existing systems in terms of performance, storage requirements, and scalability, while being substantially simpler to describe and deploy due to the tree-based ORAM structure. This project develops better combinatorial techniques to reduce bandwidth consumption in ORAM-based storage solutions as well as proofs of concept for new oblivious storage systems without the need of a trusted proxy node, and presents the first comprehensive formal framework to formalize and prove security of oblivious storage systems.
On-line sharing of images has become a key enabler of users' connectivity. Various types of images are shared through social media to represent users' interests and experiences. While extremely convenient and socially valuable, this level of pervasiveness introduces acute privacy concerns. First, once shared images may go anywhere, as copying / resharing images is straightforward. Second, the information disclosed through an image reveals aspects of users' private lives, affecting both the owner and other subjects in the image. Malicious attackers can take advantage of these unnecessary leaks to launch context-aware attacks (e.g., spearfishing) or even impersonation attacks. This project is developing methods to help users appropriately control access to their shared images.<br><br>The investigators are developing new techniques to tackle image privacy based on the image content as well as images and users' meta-data, by (a) inferring the sensitivity of a given image based on the visual properties of the images and the users' image sharing patterns, and then automatically applying the appropriate privacy settings for that image, and (b) by using discovered users' sharing patters to define access policies according to the locally enforceable controls on the domain of interest. Beyond the technical results, this project is developing a framework for understanding the common classes and categories of images with respect to the users' understanding of privacy. This framework will enable an understanding of the images that need protection and help improve user awareness of classes of images that are often unintentionally or accidentally under-protected.
Present-day cryptography crucially relies on secret-key cryptography, the setting where communicating parties use a shared secret key, hidden to the attacker, to securely encrypt and/or authenticate data. Secret-key cryptography is based on standardized efficient algorithms known as cryptographic primitives, such as block ciphers and hash functions. These act as building blocks for so-called modes of operations, cryptographic algorithms achieving strong security goals for encryption and authentication, and which are orders of magnitude faster than public-key ones. <br><br>This project addresses the two shortcomings of current symmetric key cryptography, namely the lack of provable security for existing block ciphers and the lack of flexibility due to fixed parameters in existing implementations of primitives. The project develops new provably secure ciphers with strong security guarantees under the assumption that an attacker only has black box access to a simple underlying component. The investigator explores a new formal model that captures tradeoffs between local computation and key-dependent access in cryptographic attacks, and develops new modes of operation with improved security under this new viewpoint. The project will have broad impact on society by laying the foundations for the development of secret key cryptography which is used to secure modern communications and commerce.
Society's dependence on mobile technologies rapidly increases as we entrust mobile applications with more and more private information and capabilities. Existing security research follows a common threat model that treats apps as monolithic entities and only captures attack surface between apps. However, recent research reveals that app internal attacks are emerging quickly as complex entities with conflicting interests are commonly included inside a single app to allow for rich features and fast development. <br><br>This project, known as STRUCT, systematically investigates app compartmentalization as a novel and general approach to mitigating the critical yet unaddressed internal threats of apps. It applies this approach to major mobile platforms via solving four challenging and interesting research problems: (1) Deriving principles and models for designing intra-app security mechanisms; (2) Building compiler toolchains for automatically and securely compartmentalizing apps; (3) Building system-level enforcement mechanisms for open platforms; (4) Building app-level system-agnostic enforcement mechanisms for closed platforms. Solutions to these challenges together form a foundation to the design and implementation of intra-app security isolation and policy enforcement, which is currently nonexistent but in high demand. <br><br>STRUCT has its broader impact in fostering a new direction in mobile security research and education as well as increasing society's adoption of mobile technology in security-sensitive scenarios.
This proposal is to fund student travel to the Security and Human Behavior (SHB) workshop to be held in May 2018 at Carnegie Mellon University. The goals of SHB are to discuss, in an informal and interdisciplinary setting, issues where security, psychology, and behavior interact. The scope is broad: topics that have been covered in the past include the misperception of risk, security usability, deception, security and privacy decision making, and so forth. As the Secure and Trustworthy Cyberspace (SaTC) research program has expanded to include social sciences in addition to its core in computer science, gatherings such as SHB provide a key venue for interaction between the different communities.<br><br>Students from U.S. universities, or U.S. students from other universities, will greatly benefit from participating in the workshop, where they will interact with research leaders from a variety of disciplines and will be exposed to the most recent developments in information security and privacy research. In particular, the first rule of the SHB Workshop is that everyone who attends actually participates in the discussion. This will ensure that students get more value from attending SHB than many conferences and workshops where they can simply listen. Further, the organizers will ask invited senior scholars for suggestions of student participants who are from underrepresented groups to invite, increasing the chance that the workshop will broaden participation in the SaTC community.<br><br>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.
Moving Target Defense (MTD) is a new security concept to increase uncertainty and complexity for attackers, reduce their window of opportunity and increase the costs of their attack efforts. MTD solutions involve a wide-range of advanced technical expertise, which current education models lack. The project from Arizona State University proposes to develop an MTD courseware for both senior undergraduate level and graduate level in computer science focusing on network-based MTD technologies. Additionally, a cloud-based hands-on laboratory will be established to support MTD labs, which will increase access to students and educators in lab environments with limited computer networking and system security capabilities. The proposed MTD curricula will be published as a textbook associating with a MTD lab repository allowing instructors to build a new MTD course or pick part of the teaching materials to incorporate them into their current curricula. The project team will also work with industry partners to develop the course content and provide a Teacher Training workshop to disseminate the course materials. All the created course content and labs will be freely downloadable by instructors and students.<br><br>MTD solutions involve technologies in machine learning, artificial intelligence, and big data analysis models, and current education resources in this realm should address these fields. The proposed project will address the research challenge on how to build-out a much-needed hands-on learning module that can be easily deployed on existing cloud service platforms to learn and experiment with new computer networking and security technologies such as Software Defined Networking (SDN), Network Function Virtualization (NFV), and MTD. This project will focus on four interdependent tasks: (a) building the MTD education capability by creating software components to support SDN, NFV, and MTD, and establishing MTD lab repository and APIs to enhance MTD learning outcomes; (b) developing both long-term semester-based course curriculum, and short-term training oriented MTD teaching contents; (c) conducting a comprehensive evaluation plan by involving both internal and external independent evaluators to use the developed course content and labs; and (d) working with industry partners and hosting a Teacher Training workshop to maximally disseminate developed MTD learning contents and hands-on exercises.
Almost every organization depends on cloud-based services. The backend of cloud-based services are designed for multiple tenants and reside in data centers spread across multiple physical locations. Network security and security management are major hurdles in such a complex, shared environment. This research investigates mitigating the security challenges by taking a moving target defense (MTD) approach. Continually adjusting the system resources such as the topology of the data center, bandwidth allocation and traffic flow policies makes it difficult for attackers to compromise the system. New evaluations methods will be developed to ensure that these MTD mechanisms work properly in practice. The outcome of this research is to have cloud services that are more secure and resilient to attacks. This research is a collaborative effort conducted by researchers from three different universities, Arizona State University, Duke University, and the University of Missouri-Kansas City. Graduate students will be trained to serve the growing need for educating professionals in cyber security. The results of the proposed research will be incorporated into several courses taught at the respective institutions. <br><br>The MTD approach in a multi-location, multi-tenant data center environment requires a complex level of coordination. This research investigates defense mechanisms in the data center's virtual networking environment based on programmable networking solutions so that proactive attack countermeasures can be deployed with considerations of the system resource consumption, software bugs/vulnerabilities, effectiveness of countermeasures, and impact on consumers running applications. The research outcomes can be employed for applications that require security situation-awareness variables accurately predicted at a very fine grain resolution, from a few milliseconds to a few seconds. This introduces additional challenges, namely, developing new performance models for networking, data collection, big data-enabled security processing, and control. To address these challenges, this project has two interdependent fundamental research thrusts: (a) investigate a dynamic and adaptive defensive framework at both networking and software levels; and (b) deploy an adaptive security-enabled traffic engineering approach to select optimal countermeasures by considering the effectiveness of countermeasures and network bandwidth allocations while minimizing the intrusiveness to the applications and the cost of deploying the countermeasures. The outcomes of this project will include a set of software APIs and tools to integrate the measurement system and analytical models in a transition to practice effort.
Modern software systems inherit their architecture, software development methodology, and security model from time-sharing operating systems developed four decades ago. Desktop, server, cloud, and even industrial control systems rely on a large stack of commercial off-the-shelf software that runs on top of a monolithic operating system kernel. Each application runs with the full set of privileges of some user, has access to the entire file space of that user, and can access the complete interface of a complex operating system kernel, and a number of privileged systems components. The security model exposed by existing software systems is fundamentally too weak; it fails to provide adequate isolation between computations.<br><br>XCap is a secure environment for least-authority execution of applications and system services. Unmodified, untrusted, off-the-shelf applications, running on untrusted operating systems, are isolated by a virtual machine monitor. XCap builds on two principles: strong isolation and secure collaboration. XCap's default -- a share nothing environment -- is augmented by a capability access control model: a clean and general abstraction, enabling fine-grained delegation of rights in a flexible and manageable way. In XCap, capabilities serve as a general foundation for constructing least privilege services out of existing components of the traditional operating system stack. XCap maximizes the principle of least authority: it redesigns common operating system services in such a way that the authority of individual applications and services is minimized. Each component possesses the smallest subset of rights required to accomplish its task.
